{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import backend as K\n",
    "import keras.layers as layers\n",
    "from keras.models import Model\n",
    "from keras import Sequential\n",
    "from keras.layers import Lambda, Dense, Flatten\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from keras.losses import binary_crossentropy\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import patches\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.1\n",
    "N = 100000\n",
    "\n",
    "myoneD_signal = np.random.normal(epsilon,1,N)\n",
    "myoneD_background = np.random.normal(-epsilon,1,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "gs = gridspec.GridSpec(1, 1) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ax0.minorticks_on()\n",
    "\n",
    "plt.hist(myoneD_signal,bins=np.linspace(-3,3,20),alpha=0.5,label=\"Signal\",hatch='\\\\')\n",
    "plt.hist(myoneD_background,bins=np.linspace(-3,3,20),alpha=0.5,label=\"Background\",hatch='//')\n",
    "plt.ylim([0,16000])\n",
    "plt.xlabel(\"$x$\",fontsize=20)\n",
    "plt.ylabel(\"events\",fontsize=20)\n",
    "plt.legend(frameon=False,fontsize=20)\n",
    "plt.title(r\"$Gaussian$ $Example$\",loc=\"right\",fontsize=20)\n",
    "plt.savefig(\"ensembleLearnPlots/Gaussian_Xhist.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1D = np.concatenate([myoneD_signal,myoneD_background])\n",
    "Y_1D = np.concatenate([np.ones(len(myoneD_signal)),np.zeros(len(myoneD_background))])\n",
    "\n",
    "n = 10\n",
    "if (N % n != 0):\n",
    "    print(\"That is not a valid choice!\")\n",
    "    \n",
    "X_nD = np.reshape(X_1D,[int(len(X_1D)/n),n])\n",
    "Y_nD = np.concatenate([np.ones(int(len(myoneD_signal)/n)),np.zeros(int(len(myoneD_background)/n))])\n",
    "\n",
    "X_1D_train, X_1D_val, Y_1D_train, Y_1D_val = train_test_split(X_1D, Y_1D, test_size=0.5)\n",
    "X_nD_train, X_nD_val, Y_nD_train, Y_nD_val = train_test_split(X_nD, Y_nD, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 1s 10us/step - loss: 0.6930 - acc: 0.5131 - val_loss: 0.6893 - val_acc: 0.5390\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6893 - acc: 0.5388 - val_loss: 0.6885 - val_acc: 0.5388\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6884 - acc: 0.5386 - val_loss: 0.6886 - val_acc: 0.5389\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5386 - val_loss: 0.6885 - val_acc: 0.5390\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5387 - val_loss: 0.6884 - val_acc: 0.5387\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5389 - val_loss: 0.6885 - val_acc: 0.5388\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5383\n"
     ]
    }
   ],
   "source": [
    "model1D = Sequential()\n",
    "model1D.add(Dense(128, activation='relu',input_shape =(1,))) \n",
    "model1D.add(Dense(128, activation='relu'))\n",
    "model1D.add(Dense(1, activation='sigmoid'))\n",
    "model1D.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist_model1D= model1D.fit(X_1D_train, Y_1D_train, epochs=10, batch_size=int(0.1*len(X_1D_train)),validation_data=(X_1D_val, Y_1D_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "10000/10000 [==============================] - 1s 79us/step - loss: 0.6573 - acc: 0.5991 - val_loss: 0.6472 - val_acc: 0.6160\n",
      "Epoch 2/2\n",
      "10000/10000 [==============================] - 0s 49us/step - loss: 0.6481 - acc: 0.6126 - val_loss: 0.6463 - val_acc: 0.6217\n"
     ]
    }
   ],
   "source": [
    "modelnD = Sequential()\n",
    "modelnD.add(Dense(128, activation='relu',input_shape =(n,))) \n",
    "modelnD.add(Dense(128, activation='relu'))\n",
    "modelnD.add(Dense(1, activation='sigmoid'))\n",
    "modelnD.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist_modelnD= modelnD.fit(X_nD_train, Y_nD_train, epochs=2, batch_size=128,validation_data=(X_nD_val, Y_nD_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_1D = model1D.predict(X_1D_val)\n",
    "scores_nD = modelnD.predict(X_nD_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_1D_fromnD = model1D.predict(np.reshape(X_nD_val,[n*len(X_nD_val)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_1D_fromnD = np.reshape(scores_1D_fromnD,[int(len(scores_1D_fromnD)/n),n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_up = np.array([np.prod(scores_1D_fromnD[i,:] / (1.-scores_1D_fromnD[i,:])) for i in range(len(scores_1D_fromnD))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_1D, tpr_1D, _ = roc_curve(Y_1D_val, scores_1D)\n",
    "fpr_nD, tpr_nD, _ = roc_curve(Y_nD_val, scores_nD)\n",
    "fpr_nD_from1D, tpr_nD_from1D, _ = roc_curve(Y_nD_val, scaled_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save everything\n",
    "np.save(\"ensemblelearning/Y_1D_val\",Y_1D_val)\n",
    "np.save(\"ensemblelearning/X_1D_val\",Y_1D_val)\n",
    "np.save(\"ensemblelearning/Y_1D_train\",Y_1D_train)\n",
    "np.save(\"ensemblelearning/X_1D_train\",X_1D_train)\n",
    "\n",
    "np.save(\"ensemblelearning/Y_nD_val\",Y_nD_val)\n",
    "np.save(\"ensemblelearning/X_nD_val\",Y_nD_val)\n",
    "np.save(\"ensemblelearning/Y_nD_train\",Y_nD_train)\n",
    "np.save(\"ensemblelearning/X_nD_train\",X_nD_train)\n",
    "\n",
    "model_json = model1D.to_json()\n",
    "with open(\"ensemblelearning/model1D.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model1D.save_weights(\"ensemblelearning/model1D.h5\")\n",
    "\n",
    "model_json = modelnD.to_json()\n",
    "with open(\"ensemblelearning/modelnD.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "modelnD.save_weights(\"ensemblelearning/modelnD.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load everything\n",
    "Y_1D_val = np.load(\"ensemblelearning/Y_1D_val.npy\")\n",
    "Y_1D_val = np.load(\"ensemblelearning/X_1D_val.npy\")\n",
    "Y_1D_train = np.load(\"ensemblelearning/Y_1D_train.npy\")\n",
    "X_1D_train = np.load(\"ensemblelearning/X_1D_train.npy\")\n",
    "\n",
    "Y_nD_val = np.load(\"ensemblelearning/Y_nD_val.npy\")\n",
    "Y_nD_val = np.load(\"ensemblelearning/X_nD_val.npy\")\n",
    "Y_nD_train = np.load(\"ensemblelearning/Y_nD_train.npy\")\n",
    "X_nD_train = np.load(\"ensemblelearning/X_nD_train.npy\")\n",
    "\n",
    "json_file = open('ensemblelearning/model1D.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model1D = model_from_json(loaded_model_json)\n",
    "model1D.load_weights(\"ensemblelearning/model1D.h5\")\n",
    "\n",
    "json_file = open('ensemblelearning/modelnD.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "modelnD = model_from_json(loaded_model_json)\n",
    "modelnD.load_weights(\"ensemblelearning/modelnD.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "gs = gridspec.GridSpec(1, 1) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ax0.minorticks_on()\n",
    "\n",
    "plt.plot(tpr_1D,1-fpr_1D,label=\"$f_{1}$\")\n",
    "plt.plot(tpr_nD,1-fpr_nD,label=\"$f_{10}$\",ls=\":\")\n",
    "plt.plot(tpr_nD_from1D,1-fpr_nD_from1D,label=r\"$f_{1\\rightarrow 10}$\",ls=\"--\")\n",
    "plt.plot([1,0],[0,1],ls=\":\",color=\"grey\")\n",
    "plt.xlabel(\"True Positive Rate\",fontsize=20)\n",
    "plt.ylabel(\"1 - False Positive Rate\",fontsize=20)\n",
    "plt.legend(frameon=False)\n",
    "plt.title(r\"$Gaussian$ $Example$\",loc=\"right\",fontsize=20)\n",
    "\n",
    "plt.legend(frameon=False,fontsize=20)\n",
    "plt.savefig(\"ensembleLearnPlots/Gaussian_ROC.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32774, 3, 4)"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_nD_train_phys_pfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nD_train_pfn = np.reshape(X_nD_train,[len(X_nD_train),n,1])\n",
    "X_nD_val_pfn = np.reshape(X_nD_val,[len(X_nD_val),n,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10, 1)"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_nD_train_pfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    200         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_3 (TimeDistributed)       (None, None, 1)      129         activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, 1)      0           tdist_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 1)            0           mask[0][0]                       \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            2           sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 1)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,359\n",
      "Trainable params: 23,359\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fe7fc3c7eb8>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe8141c6860>\n",
      "<keras.layers.core.Activation object at 0x7fe8141c6c50>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe8141f74a8>\n",
      "<keras.layers.core.Activation object at 0x7fe8141f7518>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe89e4f09e8>\n",
      "<keras.layers.core.Activation object at 0x7fe89e4f04e0>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe8ae302a90>\n",
      "<keras.layers.core.Lambda object at 0x7fe7fc3c7ef0>\n",
      "<keras.layers.core.Activation object at 0x7fe8ae3029e8>\n",
      "<keras.layers.merge.Dot object at 0x7fe8141c61d0>\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 1s 115us/step - loss: 3.1376 - acc: 0.0362 - val_loss: 1.6188 - val_acc: 0.0520\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 0s 5us/step - loss: 1.8951 - acc: 0.0323 - val_loss: 1.1701 - val_acc: 0.0972\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 0s 5us/step - loss: 1.0537 - acc: 0.1262 - val_loss: 1.2858 - val_acc: 0.1141\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 0s 5us/step - loss: 1.2609 - acc: 0.1200 - val_loss: 0.8025 - val_acc: 0.1918\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 0s 5us/step - loss: 0.8315 - acc: 0.1753 - val_loss: 0.9314 - val_acc: 0.0835\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 0s 5us/step - loss: 0.8155 - acc: 0.1510 - val_loss: 0.7356 - val_acc: 0.3867\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 0s 5us/step - loss: 0.7907 - acc: 0.3663 - val_loss: 0.6531 - val_acc: 0.5396\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 0s 5us/step - loss: 0.6947 - acc: 0.2687 - val_loss: 0.7244 - val_acc: 0.0775\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 0s 5us/step - loss: 0.6864 - acc: 0.3191 - val_loss: 0.7104 - val_acc: 0.5545\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 0s 5us/step - loss: 0.6909 - acc: 0.5566 - val_loss: 0.6608 - val_acc: 0.2741\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 0s 4us/step - loss: 0.6741 - acc: 0.2415 - val_loss: 0.6440 - val_acc: 0.4082\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 0s 5us/step - loss: 0.6635 - acc: 0.4321 - val_loss: 0.6584 - val_acc: 0.4304\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 0s 5us/step - loss: 0.6596 - acc: 0.3835 - val_loss: 0.6586 - val_acc: 0.2898\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 0s 5us/step - loss: 0.6575 - acc: 0.3359 - val_loss: 0.6534 - val_acc: 0.4443\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 0s 5us/step - loss: 0.6583 - acc: 0.4577 - val_loss: 0.6453 - val_acc: 0.3758\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 0s 5us/step - loss: 0.6552 - acc: 0.3394 - val_loss: 0.6439 - val_acc: 0.4251\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 0s 5us/step - loss: 0.6522 - acc: 0.4653 - val_loss: 0.6445 - val_acc: 0.4531\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 0s 5us/step - loss: 0.6518 - acc: 0.3948 - val_loss: 0.6482 - val_acc: 0.3566\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 0s 5us/step - loss: 0.6501 - acc: 0.3913 - val_loss: 0.6496 - val_acc: 0.4870\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 0s 5us/step - loss: 0.6533 - acc: 0.4730 - val_loss: 0.6493 - val_acc: 0.3401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n"
     ]
    }
   ],
   "source": [
    "#Train 1 from N\n",
    "\n",
    "def myloss_many(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true,K.exp(y_pred)/(1.+K.exp(y_pred)))\n",
    "\n",
    "Phi_sizes_Gaussian, F_sizes_Gaussian = (100, 100, 128, 1), []\n",
    "pfn_Gaussian = PFN(input_dim=X_nD_val_pfn.shape[-1], Phi_sizes=Phi_sizes_Gaussian, F_sizes=F_sizes_Gaussian, F_acts='linear', output_dim=1, output_act='linear', Phi_acts=['relu','relu','relu','linear'])\n",
    "\n",
    "pfn_Gaussian.model.layers.pop()\n",
    "pfn_Gaussian.model.layers.pop()\n",
    "for layer in pfn_Gaussian.model.layers:\n",
    "    print(layer)\n",
    "pfn_Gaussian.model.compile(loss=lambda y_true, y_pred: myloss_many(y_true, y_pred), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "historyf_Gaussian = pfn_Gaussian.fit(X_nD_train_pfn, Y_nD_train,\n",
    "          epochs=20,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_nD_val_pfn, Y_nD_val),\n",
    "          verbose=1)\n",
    "\n",
    "from keras.models import Model\n",
    "myPhi_Gaussian = Model(input = pfn_Gaussian.model.input,output = pfn_Gaussian.model.layers[-2].output)\n",
    "myPhi_preds_Gaussian = myPhi_Gaussian.predict(X_nD_val_pfn,batch_size=int(0.1*len(X_nD_train_pfn)))\n",
    "preds_Phi_Gaussian = np.reshape(myPhi_preds_Gaussian,[n*len(myPhi_preds_Gaussian)])\n",
    "Y_Phi_Gaussian = [Y_nD_val[i]*np.ones(n) for i in range(len(Y_nD_val))]\n",
    "Y_Phi_Gaussian = np.reshape(Y_Phi_Gaussian,[n*len(Y_Phi_Gaussian)])\n",
    "fpr_Phi_Gaussian, tpr_Phi_Gaussian, _ = roc_curve(Y_Phi_Gaussian, preds_Phi_Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "gs = gridspec.GridSpec(1, 1) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ax0.minorticks_on()\n",
    "\n",
    "plt.plot(tpr_1D,1-fpr_1D,label=\"$f_{1}$\")\n",
    "plt.plot(tpr_nD,1-fpr_nD,label=\"$f_{10}$\",ls=\":\")\n",
    "plt.plot(tpr_nD_from1D,1-fpr_nD_from1D,label=r\"$f_{1\\rightarrow 10}$\",ls=\"--\")\n",
    "plt.plot(tpr_Phi_Gaussian,1-fpr_Phi_Gaussian,label=r\"$f_{10\\rightarrow 1}$\",ls=\":\",lw=3)\n",
    "plt.plot([1,0],[0,1],ls=\":\",color=\"grey\")\n",
    "plt.xlabel(\"True Positive Rate\",fontsize=20)\n",
    "plt.ylabel(\"1 - False Positive Rate\",fontsize=20)\n",
    "plt.legend(frameon=False)\n",
    "plt.title(r\"$Gaussian$ $Example$\",loc=\"right\",fontsize=20)\n",
    "\n",
    "plt.legend(frameon=False,fontsize=20)\n",
    "plt.savefig(\"ensembleLearnPlots/Gaussian_ROC_both.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "myx = np.linspace(-5,5,1000)\n",
    "xx_vals = np.reshape(myx,[100,10,1])\n",
    "myPhi_Gaussian = Model(input = pfn_Gaussian.model.input,output = pfn_Gaussian.model.layers[-2].output)\n",
    "myPhi_preds_Gaussian = myPhi_Gaussian.predict(xx_vals,batch_size=int(0.1*len(xx_vals)))\n",
    "preds_Phi_Gaussian = np.reshape(myPhi_preds_Gaussian,[n*len(myPhi_preds_Gaussian)])\n",
    "\n",
    "preds_1D_Phi_Gaussian = model1D.predict(np.linspace(-5,5,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'likelihood ratio')"
      ]
     },
     "execution_count": 758,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEJCAYAAAByupuRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3zN1x/H8dfJlsiQRIhEEhFBEgQxitqqqJZSWqtGbfWjQ0t1qS4dWi1dZnVQ1G5/qL1H7D0TMSKJkCnznt8fCT9VIiU3N8n9PB8PD/mO3O/7GveT7znfc47SWiOEEMI8WZg6gBBCCNORIiCEEGZMioAQQpgxKQJCCGHGpAgIIYQZkyIghBBmzMoYL6qUsgCWAzsBG6Ay0F9rfeO2c+yAT4GLQBXgI631SWPkEUIIcXfGvBPYrrWeoLUeD9gDT99xfBRwXmv9ITAZmGHELEIIIe7CKEVAa23QWk8EUEpZAd7AiTtO6wBszz3/EFBLKeVkjDxCCCHuzijNQTcppdoCo4EVWus9dxz2AJJu207M3Zd4x2sMAgYBODg41K1WrZrxAgshRAkUHh4ep7Uue7djqjCmjVBK/Qjs0FpPu23fZmCc1npz7nYi4K21TrzHyxAWFqb37LmzlgghhMiLUipcax12t2NGaQ5SSgUppTrctusc4K+Ucr2tyWcl8Eju+TWAA3kVACGEEAXPWM1B6cAApVRtwBqoDowEXgfigY+AL4FPlVLjgQBggJGyCCGEuAejFAGt9Rn++TQQwJjbzrkBDDfG9YUQQuSPDBYTQggzJkVACCHMmBQBIYQwY1IEhBDCjEkREEKIom7Dx3Bpn1FeWopAAfjll1948cUXGTx4MOvXrzfadc6fP0/fvn1xd3cnMjLy1v6JEycSGhrKsmXLjHZtIYSJHP8DNnzA5Z0LjfLyRp02wlzMmjWL7777Dj8/P4w5AtvHx4e+ffty5swZunTpwpYtW7Czs2P8+PGcPn2aJ5980mjXFkKYQGo86Ute5IzBl3WlezLCCJcoUUXg3eVHOHqpYAcdB1Vw4u2Owfc8vmzZMk6dOsWUKVN47LHH2LhxI7/++isDBw5k586dBAQEMGbMGN566y0CAwM5deoUffv2pXHjxnTv3p2IiAjatGnDtm3b6NSpE7Gxsezbt486deowYcKEu15zwIABbN26lWHDhjFz5swCfb9CiKIjc/loLNKu85XTW3zZwjjzphXK3EEF5X5zB5miCAA0b96c2bNn4+fnB4CdnR2XL1/GycmJQ4cO8fHHH9OlSxe6du3KlStXqFu3LlFRUURGRtKsWTPOnTtHYmIiFSpUICYmBnt7e/z8/Dh//vw/rrVhwwYiIiLo0aMHzZs35/nnn2fw4MH07duX2bNnF+h7F0KY0OFFsLA/n2Z1o9WgSdT2KfPAL5XX3EEl6k7gfh/WhaVcuXKUKZPzFxYaGsrBgwd59dVXbx1LSEggLi4OgEqVKmFhYYGLiwseHh6ULl0aAAuLvLtrbGxsWLRoEY0aNSI0NNSI70YIUeiSrpC1/CUOG/y5Uf/FhyoA9yMdw0aglPrbdq1atThz5gwA0dHRuLi44O7u/tDX8fT05Ndff6Vnz54P/VpCiCJCa7KX/Yfs9FQ+thvNS22DjHo5KQIPaeXKlURGRvL1119z9uxZpk+fTkJCAp9//vmtcz799FP++OMPPvjgA8aNG8e8efNQSjF9+nQiIyNZv349s2fPJiEhgcWLF7N48WISEhKYPn36364VFRXF3LlzWb58OUePHgWgYcOGjB079h+FRwhRTB34FctTfzIp8xmGdG2Hg61xG2xKVJ+AEEIUawkXyJ7akPA0L+YHTeOzZ+sWyMuaTZ+AEEIUW1pjWDqCjIxM3rcewayONQrlstIcJIQQRcHu6VicXc/7mc8xtHMbXB1sCuWycicghBCmFnsCw6o32GKoSUJwHx4PKV9ol5Y7ASGEMKWsdPTCASQZbHnf+kXefSrkH6fMOTKHswlnjXJ5KQJCCGFK6yairhzi5fSBjO7c9B/NQBuiNvDpnk9ZfGqxUS4vzUFCCGEq5zaht33F/OxW2Nfo+I9moOiUaMZvHU8112q8WPtFo0SQO4ECUFiziAKkp6fzySefUKpUKZKTk416LSGEEd24hl48mIsWFfjaph/vPPn3GQ+yDFmM2TSGzOxMPm32KTaWxukoljuBAlBYs4gC7Nixgy5dujBmzBijXkcIYURaw/JRGJKuMCTtXcb3rPePZqBp+6exL2YfHz/6Mb5OvkaLUrKKwJ+vQ/Shgn3N8jWg3Uf3PFzYs4g2a9asYN+fEKLwHfgVji5hcnZ3/Gs2+Ucz0LaL25h+aDpdqnShvX97o0YpWSOGTVAEoHBnEb1JKUVSUtKtCeeEEMVE/Dn0t004lO3LQPU2f45u8be7gNjUWLou74qrnSu/dPiFUlalHvqS5jNi+D4f1oWlMGYRFUIUQ9mZ8PtA0rNhSMpgPupX+28FINuQzdjNY0nNTGVm25kFUgDuRz5pjKCwZhEVQhQz6ybChd28ktaflg3r0KKqx98O/3DoB3ZG72Rcg3FUdqlcKJGkCDykwpxFFCAiIoKJEycCMGnSJI4fP15o71UI8RBO/wVbv2CJRRuOlGnFuPbV/3Z4d/RuvjnwDR38O9ApoFOhxSpZfQJCCFEUJV6Gb5twKduR1knv8MvQ5oRWdLl1+OqNq3Rb3o1S1qWY/8R8HKwdCvTy5tMnIIQQRY0hG34fSHZ6Mn1SxzCoVdDfCsDN8QAJGQlMaz2twAvA/UhzkBBCGNPmzyBiM+9m98fBO4ThLQL+dnjq/qnsit7Fmw3fpKpr1UKPJ3cCQghhLBFb0Bs+ZJt9SxYkNWVlt1pYW/7/Z+/159cz/dB0ugZ25amAp0wSUe4EhBDCGFKuwqIXSCzlzaD4nrzRIQj/sv8f1xOVGMUbW94gyC2I1+u/brKYRrkTUEpVBiYCewFv4KrWesId5/QFhgBpubtmaK3nGiOPEEIUKoMBlgzFkHKVPunv0rCaLz0b+Nw6nJaVxugNo1FK8Xnzz7G1tDVZVGM1B7kC87TWSwGUUkeVUiu11uF3nPes1jrCSBmEEMI0tn0Jp1Yx1XYgly0DmfVMrVvjh7TWTNwxkRPXTjC11VS8SnuZNKpRmoO01rtvFoDbrpNyl1NHKKVeUUq9pZRyNUaW4iIqKoouXbrwzjvv5HnekiVLiIiIuLXdr18/9u3bZ9xwQoj8O7cJ1k7ggFMLPk9szhfdQ/82Kvj3U7+z9MxSBtccTFPvpiYMmsPoHcNKqc7AKq31naOaNgIrtdaxSqn2wAKg1V2+fxAwCMDHx+fOwyVGxYoV6dix498+4O9myZIluLi43JqnaObMmf8YoSyEMJHES7CwP0kOfvSI6cWwFgE0Cvj/7ABHrh7hg50f8IjnIwytNdSEQf/PqEVAKdUCaAGMuvOY1vrcbZvrgGVKKUutdfYd530PfA85g8Xyut7Huz7meHzBjqCt5lqN1+q/luc5ycnJdO/enaZNm3LixAl69OhBVFQUY8eOZfTo0Zw9e5Zjx46xYsUKnJyc+Oabbzhy5AjlypUjMjKSb7/9Fiur//9V7Nmzhx49etC4cWNmzZrFnDlz+O677/jiiy/Yv38/s2fPZseOHbRv356RI0fSt29f+vbty7Fjx/jkk0+oXr06hw4dolu3bjzxxBMF+uchhLiH7ExY0A9DRgq9MsYS6OPJqNaBtw5fvXGVUetH4VbKjY+bfoylhaUJw/6f0YqAUqoD8CjwH8BTKeULnACytNaJSqkPgTe11llAFeDcnQWguLCwsGD06NG0bt2a+Ph42rZty+7du5kzZw6hoaG89tprDB8+nDVr1tClSxe8vb0ZPHgwFhYWjBw5klWrVtGhQ4dbrxcWFsbrr7/OzdHRlpaWTJo0ifr16xMaGkrfvn1p3rw5wK3fAfr378+XX35J/fr1iY6OJjz8zi4YIYTRrHkbonYw2XEMZzO8+ePZ2rceB83MzuSlDS9xPe06P7b7kTJ2ZUwc9v+M9XRQXWA+sAdYDzgAU4HOQDzwERANfKOUOgfUAHo/7HXv9xO7sWit2bBhA9u3b8fa2prY2NhbxwIDc34SKFu2LElJSQDY29szZswY3N3dOXr0KHXq1PnHa/bo0YP33nuPhIQEtmzZQq9eve6b4+DBgwQE5AxEKV++/N8KixDCiI4shh1TCS/fja8iQvnquRpUdLW/dfjj3R+zN2YvHz/6MdXdqufxQoXPKEUg9ymgPCe611p/aYxrm8L06dO5dOkSM2fOJDMzk2+//fbWsbu113ft2pUDBw7g4+NDYmLiXV/Tzs6Onj178sILL9CxY8db+y0tLdFac/r0acqX//tCFDdnK3V1deXixYvs3bv3b98rhDCCuFOwdASJ7rV5LvIJuodVpGOtCrcOLzy5kPkn5tMvuJ/RF4h5EDJiuAC0bduWhQsX8uqrr+Lq6kpCQgLz588nMjKSmTNn0rdvXzZt2sShQ4fo0KEDQ4YMYfjw4TRp0oTt27dz4sQJWrVqxfLly7l27RpHjx4lKCiIYcOG0aBBA3766adb12rdujXTp0/HYDAwduzYW6/bpk0bZsyYwaRJk6hatSoXLlxg7NixJvxTEcIMZKTA/N4YLG159toQKro78/aTQbcO74vZx/s736dRhUb8p85/TBj03mQW0SIqIyOD2NhYZs2axfjx400dRwhxJ61h0QD04d+Z6Po+v8RWZumIxgSWcwTgSsoVuq/ojr21Pb92+BVnW2eTRZVZRIuZ1NRUOnbsSLVq1Xj33XdNHUcIcTdbv4TDi9hYcRgzTvnxebeQWwUgPTudUetHcSPrBtMfm27SAnA/UgSKIHt7e9auXWvqGEKIezn1F/z1DlcqtqPvqcY8W68iT9fxBnIeFJmwfQKHrx7mi+ZfEFAm4D4vZloygZwQQvwbV8/Aov5kuAfxVFQPgjydeefJ4FuHZx+ZzbIzyxhSawitfP8x/rXIkTsBIYTIr/QkmNcDrSwZbniFFG3LvJ51sLPOGfi19vxaJodP5jHfx4rMiOD7kTsBIYTID4MBFg+BuFP86PUOay7Z8skzNfFzz1kJ7NjVY4zdPJZgt2AmNpmIhSoeH6/FI6UQQpjapklwfAVHaozh7cPu9G9cicdDPAGISY1hxLoRONk4MaXlFEpZlTJx2PyT5iAhhLifYytgw4ckVu1K9wOh1PZx5PV21QC4kXWDF9e9SFJGEj+2+5Gy9mVNHPbfkSIghBB5uXIEFg8mu3wo3S52w87agmk962BjZYFBG3hjyxscu3qMKS2nUM21mqnT/mtSBIQQ4l6SY+CX7mhbR163fp3T8dn8/EIYns45zT1f7/uaNZFreCXsFZpXbG7arA9I+gSEEOJuMtNgXg9IiWNe5UksOGVgfIfqNPB3A2DZmWX8cOgHulTpQp+gPiYO++CkCAghxJ20hqXD4cJuDtafxLidljxdx4vnG/kBsOPyDt7e9jYNyjfgjYZvFOuFnaQ5SAgh7rRxEhxeSHzD1+m5tRzBFez5oHMNlFKcvHaS0etH4+fkx+ctPsfawtrUaR+K3AkIIcTtDi+CDR+QGdKd7kcewcpS8W2vuthZWxKdEs3Qv4Zib2XPN62/wcnGydRpH5rcCQghxE0XwmHJMHTFhrx0ox9n4uL5aUADvMvYk5SRxNC/hpKSmcKcx+dQ3qH8/V+vGJA7ASGEALgeBb8+C6XLMb3Ceyw/Es/YdtVpFOBOZnYmo9aPIiIhgi9afEFV16qmTltgpAgIIcSN6/DzM5CVxuZ6U3l/Yyyda3vxwqOV0Frz5rY32RW9iwmNJ9DQs6Gp0xYoKQJCCPOWlQ7ze8HV05xr9R0D/5tMbR8XPnw6pyN4yr4prDy7kpG1R9KxcslbrlX6BIQQ5stggCXDIGIzCe2m8txftrjaw/e9w7CztmTe8XlMPzSdZwKf4YUaL5g6rVHInYAQwnytfRcOLySz+Zv02VOJxLRMpj9fj7KOtvx57k8+2PkBzb2bM67BuGI9FiAvUgSEEOZp1w+w9Qt03f68fKklB6KuM7l7KEEVnNhycQvjNo+jTrk6fNLsE6wsSm6jiRQBIYT5Of4H/DkGAh9nmv0glh28zKttq9I2uDz7Y/bz0oaXCCgTwFctv8LOys7UaY1KioAQwrxc2AML+4NnKKuqf8Ana87SubYXw5pX5tS1UwxfO5yypcryTetvcLRxNHVao5MiIIQwH3Gn4Zfu4FiOA02/Y+Sik9TJfRLoYvJFBq8ZjK2lLd+1+Q73Uu6mTlsoSm5DlxBC3C7hIsztBMCF9nPpNy8ST2c7pj9fj+SsawxeM5i07DTmPD4Hb0dvE4ctPFIEhBAlX2o8/PQ03LhOQvfF9Pr9KlprZverj5V1GgNWDSX2Rizft/meKmWqmDptoZIiIIQo2dKTc0YDx58j47kF9F+dyaWENH4d2ICyzjBozVBOXz/NlBZTCPUINXXaQpevPgGlVFWlVBelVKCxAwkhRIG5ORr40l4MXWYweqcj4ZHX+KJ7KEFepRixdgRH4o7wSdNPeNT7UVOnNYn7FgGl1EBgIfA8sFApVTKHzQkhShZDNiweDGfXw5Nf8XFEACsPXWZc+2q0DnJj1PpRhF8J5/0m79Pat7Wp05pMfpqDqmqta9zcUEpNNmIeIYR4eFrDypfhyGJo8x5z0x/lu02H6d3Ql76NK/LyxpfZdmkbExpNoIN/B1OnNan8FIH4O7av3e8blFKVgYnAXsAbuKq1nnDHOXbAp8BFoArwkdb6ZH5CCyFEntZNhPBZ0HgUfzo9w9u/7KVVNQ/e6BDI2M1j2RC1gXENxtG5SmdTJzW5/BQBd6XUFOAsUBnIzMf3uALztNZLAZRSR5VSK7XW4bedMwo4r7WepJSqAcwAzLNRTghRcDZ/Bps/hTp92FZpBP+ZtYfaPmWY8lwoE3a8zerI1bwS9grPVXvO1EmLhPx0DL8CHAYCgIO523nSWu++WQBuu07KHad1ALbnnn8IqKWUKv5rtQkhTGf7NFg7AWp043Dtdxk0dy9+7vb80KcOn+79gOVnlzMidATPBz9v6qRFxn3vBLTWBuD7m9tKqbbAqvxeQCnVGViltT5+xyEPIOm27cTcfYl3fP8gYBCAj49Pfi8rhDA3u2fAqrFQ/Ukim35K3+9241zKmln9wvjq4McsPLmQgTUGMqjmIFMnLVLuWQSUUpO01mOUUusBfXM34ENOs9B9KaVaAC3Iafq5Uwxw+8QcTrn7/kZr/T25RSgsLEzfeVwIIdj3M6x8CQIfJ6btVHp/H062wcCsfvX54egnLDq1iIE1BvJi7RdL7JTQDyqvO4H/5v6+F5hy2/5h+XlhpVQHctr4/wN4KqV8gRNAltY6EVgJPAJszu0TOJC7Xwgh8u/QQlg2AvxbkPjkdPrO2E9ccjo/vVCfn05/yuLTixlUcxAjQkdIAbiLexYBrfW63C+/11pHAuQOFlt3r++5SSlVF5gP7AHWAw7AVKAzOU8bfQR8CXyqlBpPTn/DgAd/G0IIs3RsBfw+CHweIa3rXAb9dJhTMUn80KcOv5//nKVnljKk1hCG1RomBeAe8vN0UHfg5uOd58n5yT7PPoHcp4BK3+ecG8DwfFxfCCH+6eRqWNAXvOqQ0e1Xhv12nJ3n4vm8Ww3WxH7FsjPLGFZrGENDh5o6aZGWV5/AU0Ancp7a8cvdbQF4GT+WEELk4cR/4bfeUC6I7B4LGL34DOuOxzCxUxC7k79l+dnlDAsdxtBaUgDuJ687gf3AdaAvMCd3XzZwxMiZhBDi3k78CfN7Q/kQDD0X89rK87nTQQRyOPM7Vp5dyYjQEQyuNdjUSYuFvPoEIoFIpdQ2rfWtAWJKKX/yMWpYCCEK3PGV8NvzUL4GuvfvvLP6IgvDL/Cf1pU4mj2VtefXMrL2SAbWHGjqpMVGfvoEbHMnjSubu90UMN/ZloQQpnFseU4fgGcoutciPtpwmR+3RzLgUS+OG75k28VtvFbvNXoF9TJ10mIlPyOGvwHsgBDgMjlNREIIUXiOLs0pABVqQ+/f+WpbLN9tPEv3Bu6csvic7Ze3M6HRBCkADyA/dwKHtNaTlVI2WusflFJuRk8lhBA3HVkMCweAdxj0XMgPu+L4fM1JnqjtRITV55yMPcmkppN4vNLjpk5aLOXnTqCqUsoRKKuUakLOCGAhhDC+g7/lFoB60GsR03fH8f4fx2gdUooLtp9x+vppvmz5pRSAh5CfO4FlQCjwCzA995cQQhjXnpmw4iXwawLP/cr0XbFMXHmMViHWXCz1KVdT4vim9TfU96xv6qTFWn6KQDNgttb6IFDHyHmEEAK2fglr3oIqbaHbHKbvuMzElcdoHpJNpO1kUjNS+eGxH6hVtpapkxZ7+SkCVYBDxg4ihBBoDes/gE2TILgzdP6e6dsvMHHlMZqEJHPKcgo22oZZbWdR1bWqqdOWCPnpE9jBbbN9KqXuNiOoEEI8HK3hv2NzCkDtXtBlxq0C0DA4muN8Qhm7MsxtN1cKQAHKTxEYBEQrpc4ppc4Bbxo5kxDC3BiyYdmLsPMbaDAUOn7F9K2RTFx5jLrBpziuvyLAJYAf2/2It6O3qdOWKPlpDvpVa/36zQ2llMz2KYQoOFkZsHgwHPkdmo6BFuP4dtNZPvrzGDWCwzlpWEijCo2Y3Hwy9tb2pk5b4uRnZbHX79ieYbw4Qgizkp6UMw/Q2fXQZgK60UgmrznJlHUnqRa8ngjDGjr4d+C9Ru9hbWlt6rQlUn7uBIQQouAlx8LPXSH6EDw1DR3ag4krjzFj60kCQ1ZwMXsnfYL68HLYy1io/LRciwchRUAIUfjiz8LcpyEpGp77FUPAY7yx+DDzwo/hF/wbl7NP8HLdl+kb0tfUSUu8f10ElFJBWuujxggjhDADl/bn3AEYsuD55WRVqMurCw6w5PABPKv/RJKO59Nmn9LWr62pk5qFvBaVeeseh2QWUSHEgzmzHub3glJloNfvpJepzMhf9vLX2Z24B/6MlZUV01rOINQj1NRJzUZeDW01gUhyVhKzBqJyf79SCLmEECXNoYXw8zPg4gsD1pDq7M+gH8NZG7UaR7/plC/txs/tf5YCUMjyag4apbW+oJQqq7X+9OZOpZSMExBC5J/WsG1KzjQQvo3h2V+4ZrCn3/QdHEtdQimvVdTyqMOUllNwtnU2dVqzk9fKYhdyv6yvlLLSWmcppWyA2oUTTQhR7GVnwh+vQPjsnGkgOn3LpRRN75lbuGz1EzZld9PBvwMTGk3AxtLG1GnNUn46hlcA55VSMUA54PX7nC+EEJCWCAuehzProMlL0PJNTsWm0Hv2OlKcZ2JZ6iyDaw5meOhwlFKmTmu28jNY7Eel1AqgMnBGax1v/FhCiGLtehT80h3iTsCTX0GdPoRHXqP/L8vQHjOxtklmQuMPecL/CVMnNXv3LQJKKQfgJaAWsF8p9ZHWOsXoyYQQxdOlfTkFIPMG9FwIlVuw/ngMw5b8iFX5ebiWcmRq6zmEuIeYOqkgfxPIfQ4kArOAZGCyURMJIYqv43/ArPZgaQsDVkPlFizcE8WQFZOw8pxDVbfKLHhyvhSAIiQ/fQJntNaTbm4opd4wYh4hRHF06wmgt3MWg39uHrq0B5+tPsT04x9jU/YAj/m04/1HJ2BnZWfqtOI2+SkCFZVSllrrbKWUFTnjBoQQIkdmGiwfCQfnQ1An6PQNGRZ2jPptPRuuTcLa+RIvhv6HgTUHSAdwEZSfIrAGiFBKXQVcgeHGjSSEKDYSL8P8nnAxHFqMh6avkJCWRa85czlr8S129ll81vxLWvi0MHVScQ/5eTpomVJqExAAnNZaXzd+LCFEkXchHOb1yJkOuvvPUP0Jzl9Nofv8j0iyX4aHnRczHv8afxd/UycVecjv00GvIE8HCSFuOjA/ZyUwx3LQew2UC2ZnxCUG/TkGg8MB6ro1ZVrbSThYO5g6qbgPozwdpJQqr5SarpTafY/jzZVS+5VSG3J/vfqvUgshTMOQDavfhMWDwLseDNwA5YL5KXw3A9b0xlDqIH2qDmd2h6+lABQTxno6qAmwFMhrJqhRWusN+XgtIURRkBoPiwbkjACu9wI8/hHawopXV/7Ef698gaW1NZMenUbbyk1MnVT8C0Z5OkhrvVAp1fw+p/VWSoUBTsAPWuuofGQRQpjCxb3w2/OQHA1PfAFh/UhOT6f7b2M5b1iJs5U/Pz85DT8XeXiwuDHV00FHgfe01hFKqWBgTe5iNYYCeG0hREEKn5MzCVzpctD/v+BVl0PRkfRb+R/Src4QVPoxfnzqA2ytbE2dVDwAkzwdpLWOue3rI0opF6AiOesX/I1SahAwCMDHx+dhLy2EyK/MtJwP/31zwb8FdJkBDm7M3vcHn+2bgLbIoo//OMY8+pypk4qHkN/VmxUQAzgppd55kAsppRyUUmVzv35dKeWa+7UrYMM9FqvRWn+vtQ7TWoeVLVv2QS4thPi3rkXCzLY5BeDRV6DXIjJLOTHkj3f57OBrWBpc+LrZHCkAJUB+HhGdAdQHYskpBj7AO/f5nmZAb8BTKTUe+AzoC9QAhgARwJdKqaNAENBba532oG9CCFGATv0Fv78ABgM8Nw+qtiMq8SJ9lo8kLuskZbKbMb/bh3g6OZo6qSgA+ekTcNBa17i5kY8OX7TWG4GNd+yeetvxecC8fGYUQhSG7CxYPxG2TAaPYOg+F9wqs+zkGt7aNp4sQzb1So/k+y4DsLbMbyOCKOryUwR2K6XstdapudtljBlICGECCRdg4QCI2gF1nod2H5NuYcG4te+y+sJCDOkVGBkygcGNG5g6qShg9ywCSqlzgAYsgfeUUjfb7J2AxYWQTQhRGE78CUuG5iwF2WUG1OjKifgTDF31CrEZEdikNOWHJ96mjo+HqZMKI8jrTmCS1vqbO3cqpQYYMY8QorBkZcBf78COqVC+JjwzG+3qz5zDc5kcPpmsLFuqqFHM7tsbF3tZ/7ekymuh+X8UgFxHjJRFCFFY4s/Bwn45q4DVHwyPvUdcZhKv/DmY8NjtZCVVo1flV3m9bT0sLWT655Isr+ag4W7EaKMAABqlSURBVFrrqUqpmbfvJucJnzCjJxNCGMfBBbDyJVAKuv8E1TuyIWoDr28aT0pGKsQ/zVfthtI6qLypk4pCkFdz0M2OYAXMvm1/b6OlEUIYz43rsPJlOLwQKjaAp38gtXRZPtk2gYWnFpCd5knFrP/wfd/2+LrJ5G/mIq/moFm5X47UWifd3K+UOmv0VEKIghWxBX4fDEmXcxZ/aTKa8LgDvL5kMNEpl8iIb0r3gIG80b4GtlaWpk4rClFezUF9bvv69kMdgWeMmEkIUVCyMmD9+7D1S3D1hwFrSCsfzJS9n/PT0Z/Qma4QO5QpT3ambbA0/5ijvJqDngc23WW/q5GyCCEKUuwJWPQCRB/Mefa/7QccSDzDuGVdOZ8USUZ8Q6rZPsvUIY/gXcbe1GmFieRVBEZqrf/xJFDurJ9CiKLKYIDd02HNm2BtD8/+QkaVNkzdP5XZh2ejDC6kRr3AgLDHeLVtVRn9a+by6hM4ArcmeHsDyAY2AGcKJZkQ4t+7eiZn2cfIrRDQGp6aypGMq7yxohtnrp8hO6E+tomd+KFbfVpWK2fqtKIIyM+0ER8BW4HqwA7gQ2CwMUMJIf4lQzbs/A7WTgBLG3jya27U6MI3B79lzpEfsTQ4khrVj0e9mzCpX008HO1MnVgUEfkpAie01nOUUq9preOVUrICmBBFSdwpWDoconZClbbQ8Qt2pkTx7vKuRCVFYZHcgJQr7Xi7XV16N/S980EPYebyUwSClVKegFZKOZOz+IsQwtQM2bB9as7TP1a20OlbEqq157Pwz1h8ejH2qhypkS8Q6FyHKcNDqVJOpn4W/5SfIjAT2E3OU0HDgGeNmkgIcX+xJ2DJMLi4B6p2QHf4jNXxB/lw6VNcS79OqdTWxEQ1Y2CTqrz8WKA8+y/uKT9F4LjW2lsp5a61jlNK1Td6KiHE3WVnwbYpsOEjsHGALjO44t+E93d+wPqo9bhaVSLlbA/sbSvzc/9aNApwN3ViUcTlpwi8DIzNLQDO5HQMtzJuLCHEP1w5CkuH5Uz6Vv1JstpN4tcLfzF1aScys7NwTO1EZGQ9uoX5Mv6JIJzsrE2dWBQD+SkCHZRSS8l5RHQ2EG/UREKIv8vOzFnta+MksHOCZ2azv2wl3tswgpPXTuJlE8rp04/hZuvJrH41aVFV5v0X+ZefItAGGEjOVBHPAOlGTSSE+L8rR2Hx4JxRv8FPc63VeCYfm8PiPW/hautBmaSBHL/gT9e6FXnziSCcS8lP/+LfydfcQcAFIAGoBzyBzB0khHEZsmHbVzlP/tg6YXhmDr9bZ/HF6udJzkghxOEpdu2ri5u9IzOer0Gr6jLwSzyYfzN30FrAD5k7SAjjunomZ7nHqJ1QvSPHGg9n4oGvORh3kEDnWlhGd2D7USc61/bi7Y5BsuqXeCgPMndQTSPmEcJ8GQywZwaseQssrbna8Qu+So/k97WDcbEtQ6jdUDbv8MHLxZ5Z/UKk7V8UiLyKwBUApVTTO/b3JqePQAhRUBIu5oz6PbueTP+W/BLcgm9PfE9aVhqNPTqze18YW5MseKFJJV56LBB7m/x05wlxf3n9S5oLtAO+BPaRs8IY5CwvKYQoKIcXwYrR6OxMNjd7kU+u7yfi8A/UL9eYtCsd+HOjBcEVnJjVpyY1vJ1NnVaUMHnNItou98uRWuvNN/crpRobPZUQ5uDGNfjjVTi0gLNeoUzy8mPr+aX4OfnRyfMtft/iSLbWjGsfSP/GlbCSKZ+FEdz3nvL2ApArmJxZRYUQD+rsRlgylOspMXxX8zHmJZ+m1PVTPFt5BJv2BDI3OpWmga5MfCoEHzdZ8EUYT16PiMYD1+/cDTgB3xszlBAlVmYarJ1A2s5p/Fzejxnl/ElJPkkHv04kXm7FDyuSqOBs4NtedWgbXF5m/BRGl9edwAit9S937lRK9TBiHiFKrssHyf59ICtuRPGVfxWuGNJoWq4efhbd+HFtGmlZyQxrXpkRLQOk41cUmrz6BP5RAPLaL4S4B4MBvX0qW7d+xGQ3F06WdiOkTAB9vQfy0wYrVkYn8WgVd955MpjKZUubOq0wM/LjhhDGlJ3J0QXP8fn1A+ws54q3QwXGVR/O9oPejJ93GU9nO77pWYfHQ6TpR5iGFAEhjCTi2hmmrezHn9nXcHFwZlTNF7lyqQ5v/3oBuCJNP6JIMMq/PqVUeWAiUEtrXe8uxy2AD4BkwBeYobXeYYwsQhS2i8kX+Xb/Nyw7sxRbg4H+bnVwchvLtGUXuZpynk6hFXj18Wp4uZQydVQhjHYn0ARYCoTe43g3wElr/bpSyhXYoZSqrrXONlIeIYzuSsoVfjj0A4tOLcLCkE3PhEQal+vBuBOPEXn1HPX9XJnZtzq1KrqYOqoQtxilCGitFyqlmudxSgdgde658UqpNHLGHxw0Rh4hjGnvhfP0WzwJC+ftgIHOVm4MitjLH1bP0XNfE6p7WjHj+TBaVvOQdn9R5JiqMdIDSLptOzF33z8opQYBgwB8fHyMn0yIvKQnwZUjcOM613Qmc69sY3bEagyOmQSmVmBCZgLVr+7m08xn+MP1Gb7uEUj7EE8sLOTDXxRNpioCMYDjbdtOufv+QWv9PbmD08LCwrTxowlxFxmpsOs72DKZuIwkfnR2Yp5TaW5YWPB4cgrDridQKTOSc4ZyvGP7EsFP9Gd1bS+Z6kEUeYVWBJRSDoC91joWWAk0Bebm9gnYAf+YtloIk8u8AXtmwdYvuHIjjlm+ISwkiQydjWuKP5VjqxDq44tLi2CWxTrgWM6PNwPLYik/+YtiwlhPBzUjZ8ppT6XUeOAzoC85M5AOAX4Daiul3gZ8gD7SKSyKlMwbED4btkzmUlocM7yrstjCgWydgG1aPZIuNqGaV1XGDwwiuELOzJ5PmjaxEA/EWB3DG4GNd+yeettxA/CaMa4txEPJTIO9c2Dz55xPi2O6dxWWW5RCk0bpjEZcjGxIJeeKvPtMVRngJUoEGaUiBEBWOuz9ETZ/zuH0OGZ5VuIvC1usLDJxN7Tk9Kl6WJfy4P0nAnkmzBtraesXJYQUAWHestJh31z05s/ZknmVWeW82a3K42BliZ96gsNHa5JhWYZXWlWmX2M/Gd0rShz5Fy3MU2Ya7P+JzM2T+dNwjVnu5TitPHC3cyGEx9hzKJB4bcfzDX0Z0TIAVwdZzF2UTFIEhHnJSIHw2aRsm8JClcJcVzeuKDf8nHwJy2rL1v3eXMCSZ8IqMrxFgEztIEo8KQLCPKQlwu4fuLBzGr/aZLHYzZkkZUMt99pUSWvDuvAyHDXAM3W9Gd4igIquspqXMA9SBETJlhqP3vENu/dP5yc7CzaUtcdSWfKoV0uskprzxw5rMrM1T9f24sWWVWQpR2F2pAiIkik5hrRtX/LH0V/42d6Gk26lcbEuTTe/riReqcfS9SlkZhvoFOrJi62qUMndwdSJhTAJKQKiZLl6hugtn/Db+dUscLDjepnSBDr6MNy3FyfOBDB7RSyQzNN1vBjSrDL+spKXMHNSBESJYDi/g51bPmDB9SOssy+FdnKgebkGNPbqyfoDjny88Aq2VnH0aujLwKb+0uErRC4pAqL4Mhi4fngBS/d8yQJDPJHW1rg4utCr8lNUdX6aBTtTGbMhFkfbDIY1r0z/xpVwK21r6tRCFClSBESxozNSObBjMvNP/MZqq2wyLBV1SvswsOZAMlPDmL31Al9fjMTNwYYxj1elV0NfnOysTR1biCJJioAoNpLjTrByy0Tmx4VzytoSB2t42qM+7UJHs/uUPR8tjuBywlH8yzrwQecaPF3HCztrS1PHFqJIkyIgijRtMLDn4ByWHJrF6qyrpFlYUN3GgbcDnqZm5Rf4dVcMvb+NIiUjm0f83Xi/cwjNAz1kERch8kmKgCiSoq9HsHTHxyy9vI0oCwOlDZqOpf3pVPdFblCXH7dHMmb5LiyUomOtCgxoUokQL2dTxxai2JEiIIqMjOwM1h2bz5LDs9mWdgWtFPW1JUO929M47GX+ezyNMcsiOB69Ayc7KwY1rUzfRn6Ud7YzdXQhii0pAsKktNYcjT3I0vCv+SNmFwkYKJ+VxSBbL56qM5yssm2Yu+M84ybvIykti+qeTnz0dA2eCvWilI209wvxsKQICJOISopi5ZGfWHlmGRFZydgYNK0yoVPFVoQ1fInN0Xa8sT2STSc3YmWhaF/Dkz6P+FLXt4ws5CJEAZIiIArNtbRrrDr7ByuP/sL+lPMAhKWl87xDJdrUG8INz8dYuO8SY74/w4VrNyjnZMtLbQJ5tn5FPBylyUcIY5AiIIwqLSuNDRc2sPLoPLbE7iULTUBGBv/JtKJD1a6UrfMC6y/b8NKu86w/sQGDhkaV3RjXvjptgsrJCl5CGJkUAVHgMrIz2H5pO6tOL2PdhfWkGDLxyMqiV0oaT7jXJrDhYKJcG/HT3ossmHaCmKR0yjraMqRZZbrXq4ivm0zmJkRhkSIgCkRmdibbL29n1bk/WR/5F0nZaThlG3gsNZUONuUIq9GHzOpdWB2ZzYTN59l6ehMWClpU9aB7vYq0rOaBlfzUL0ShkyIgHtjND/7VEatZF7mGpKxUHA2alikptM2yomHVLliF9mBPujfj915gxar9JKVl4eVSipfbBNI1zBtPZ5nITQhTkiIg/pWM7Ax2XN7Bmsg1rI1cQ1JmCo4aWiQn0zY1g0d8mmHdqDcRLo/w1cEYFs+9QFR8FPY2ljweUp6na3vTqLKbjOgVooiQIiDuKykjic0XNrMuah2bL2wiNesGpbXK+eBPSeERjzrYNOhKYqUO/HYmnd/XXSQ8citKQePK7oxuHUjb4PI42Mo/NyGKGvlfKe7qSsoVNkRtYF3UOnZF7yLLkIWrtqBdUiItU1Np4BKIbe0XSKv6FKsvWbPiwGXWLdlHRraBKh6lee3xanSqXUGae4Qo4qQIiFvOJpxl3fl1rDu/jkNxhwDwwZreCddpmZJMjdIVsQwZRHr1zmy46sKKg5dZu+oYqRnZlHW0pUcDH7rU8SbEy0kGdAlRTEgRMGPp2emER4ez6eImNl/YzPmknAFcIdgw8loCLVNS8HeogArqSWZQFzYlV2D5wcus2RBJUvoZXB1s6FTbi441K1C/kiuW0s4vRLEjRcDMRKdEs+nCJjZf3MzOyzu5kXUDW2VJfYM1va5eo0VqKuVdKkGNF8gM7MimVC/+eySaP2dGcz31Ek52VjweUp6OtSrwSGU3GcwlRDEnRaCEyzJkcTD24K0P/pPXTgJQwao0T6ZD09gY6qWlU6psENQdwY2ADvwZ78Z/j15h3eYYktIu4WBjSZugcnSsVYFHq5TFxko++IUoKaQIlEAXky+y/dJ2tl/azo7LO0jMSMRKWVDbyoWXU+HR+Ev4Z2ahPEOh0RgS/Nqz4kppVh25wua/LpCedR5XBxvahZSnbXB5Gge4ywpdQpRQUgRKgKSMJHZF77r1wX+zbd/D2pGWBhsejU/hkcR4HC2joVIzqDeay+Wbs/q8BauORLPzz3NkGzQVnO14rr4PbYPLU8+vjIzgFcIMGK0IKKVaA08DMYDWWr97x/G+wBAgLXfXDK31XGPlKUkyDZkcjjvM9kvb2XZpG4fjDpOtsyllaUs9Ww96GFx45PIJKmWcRzl4QGB7sqs8Trh1KGtOJ7N+cwwnrhwDIMCjNEOa+fN4sKc81SOEGTJKEVBK2QPfAsFa63Sl1CKlVCut9do7Tn1Wax1hjAwliUEbOHntJLujd7Mrehe7o3eTkpmChbIg2L4C/W28aBRzjlrxp7DmFJQLgQYvkuTbmnVJ3qw9HsfGBbEk3DiAlYWinp8rb7SvTsvqHlQuW9rUb08IYULGuhN4BIjUWqfnbm8FOgB3FoERSqlowB74Wmsdb6Q8xcrtH/q7o3cTfiWcxIxEALxLlaWdbQUeSYulwcWjOGdHgK0z+DdDN36NU04NWHPRinXHYtj7VzwGHY97aRvaBJWjZTUPmlRxx8nO2rRvUAhRZBirCHgASbdtJ+buu91GYKXWOlYp1R5YALS684WUUoOAQQA+Pj7GSWtieX3oV3TwpHXpSoSlJFPvwiHKJ4cDCirUhsajuebZlA0pPmw6c53Nf8YRl3wGgBAvJ0a0rELLah7U9HKWuXqEEHdlrCIQAzjetu2Uu+8WrfW52zbXAcuUUpZa6+w7zvse+B4gLCxMGydu4crIzuDo1aPsi9nHvph9d3zoV6C1YwBhaWnUu3yC8ud25nyTgwcEtCHDryW7LWux/nw2Ww7GcXx1EnAENwcbmlRxp0mAO00Dy1LOSVbiEkLcn7GKwHbAVyllm9sk1BiYppRyBbK01olKqQ+BN7XWWUAV4NydBaCkuJ52nf2x+9kXs4/9Mfs5HHeYDEMGAL6lvWntXJWw9AzqRZ+m/LkdOd9k6wR+TTCEDeK0Q13Wxbuy+fRVdodfIyPrNDaWFtSrVIbX21WjSYA7QZ5O8tO+EOJfM0oR0FqnKqWGAlOUUrHAQa31WqXUJCAe+AiIBr5RSp0DagC9jZGlsGmtOZ90/tYH/t6YvZxLyLnpsbKwIqhMVZ4r9wi109KodeU07od3gDaAlR34NMTQshtnS9dlQ6In2yMS2PXfeJLS44A4qpZzpE9DXx4NLEt9P1dK2ciz+0KIh6O0Lj4tLGFhYXrPnj2mjvE3iRmJHI47zKHYQxyKy/kVn5bTv+1o40ht1yBqW5QmNCWJkMvHsbtyBNBgYQVeYRj8HiXCuR4bUnzZFpHEznPxJKVlAeDv7kADfzca+rvyiL8bHtLEI4R4AEqpcK112N2OyWCxfyEzO5OT105yMO7grQ/9iMSIW8crOVeiiXstQrU1tRPi8L+wH4sTC3IOWjtAxXpkNX2dsw412Jrqx9bzN9i1+SqJaVnAGSq5O/BETU8a+rvRoJIb5Z3lQ18IYVxSBO7BoA1cSLpw66f7Q3GHOH71+K22fDc7N2q4BfGkWygh6RmEXD2P4+lwSN6Y8wKlXMG3ETdC+3PIMoiNiZ7sPp/EgXXXSc8yABH4utnTvkbOh35Df/nQF0IUPikCQLYhm4jECI5ePcqx+GMcu3qM4/HHSc5MBqCUVSmqu1anh197QgwW1EyIo/zlQ6gT88GQ03RDmUpo/2ZcdQ1jj67Khqtl2HP+Oqf3JwMZWFmcJ9jLmV4NfQnzLUNd3zLSvCOEMDmzKwKZ2ZmcSTjDsavHbn3on7x2khtZNwCws7Qj0DWQDr5tqI4tIanJVL5yGquDm+BG7lg2G0fwqkNag5GctqnG9rRK7IxR7D96nbjkDCAFJ7t06vqWoXNtL+r6lqGWt4t05AohihyzKAJHrx7ltxO/cSz+GKeunSLTkAmAg7UD1Vyr0cW/I0HKjuqpKfhdjcTq9H6IX5H73QrKViMrsD0XS4ew1xDApvgy7L+YzLljKbnnxFK5rANNA8tS17cMYb6uVPEoLY9sCiGKPLMoAnE34lgTuYbqbtXpFfgMQdhRPTWZinFnsTi5H+IX//9kZx8MnrW4GtCVoyqATak+7LqUzbHdiWQZNJCBh+N1Qiu60LWuN6EVXajh7SxTMQghiiWzKAKNtR1brAJRx8MhfsH/Dzj7kF2+JlcqdeEY/my7UZHdMYrjh5PIyDIAUNo2kZrezgxs6k8tbxdCK7pIB64QosQwiyJgmZ4IF/aQWa4ml3w6cxR/tqZ4sytGcfpgMobcoRJOdqkEV3CmT0NfQrycCfFywt9dmnWEECWXWRSBdZkhvJ35JVEHb9zaV84pi+AKzjweXJ6gCs4EV3DCu0wpmU9fCGFWzKIIlHUsRU0vF56r70Nw7ge+e2lbU8cSQgiTM4siUMPbmak965g6hhBCFDmyiKwQQpgxKQJCCGHGpAgIIYQZkyIghBBmTIqAEEKYMSkCQghhxqQICCGEGZMiIIQQZqxYrTGcu2h9pKlzPAB3IM7UIQqZvOeSz9zeLxTf9+yrtS57twPFqggUV0qpPfda5Lmkkvdc8pnb+4WS+Z6lOUgIIcyYFAEhhDBjUgQKx/emDmAC8p5LPnN7v1AC37P0CQghhBmTOwEhhDBjZrGeQFGilBoPjNJau5s6izEppSYDqUAyUIuc9xxt2lTGoZRqDTwNxABaa/2uiSMZlVKqMjAR2At4A1e11hNMm8r4lFKlgJ3Aaq31K6bOU1CkCBQipVRzoIypcxSSFK31eACl1GvAG8CLpo1U8JRS9sC3QLDWOl0ptUgp1UprvdbU2YzIFZintV4KoJQ6qpRaqbUON3EuY5sI7DN1iIImzUGFRClVDngW+MrUWQrDzQKQy4KcO4KS6BEgUmudnru9FehgwjxGp7XefbMA5LIAUkyVpzAopXqT83d7ztRZCprcCRQgpdQqoNxdDr0FPAW8AjgXaigjyuv9aq2X5Z7jAjwGdCnMbIXIA0i6bTsxd59ZUEp1BlZprY+bOouxKKWCgOpa63FKqZqmzlPQpAgUIK1127vtV0qFAZnAYHKag0oppV4HFmmtTxVixAJ1r/d7k1LKGZgG9NdaxxdOqkIXAzjetu2Uu6/EU0q1AFoAo0ydxcg6A2m5/2ebADZKqVFa6y9MnKtAyCOihUwp5QfsMYOOYXfgC+A1rfVFpVQXrfUiU+cqaLl9Age5rU8AmFbC+wRQSnUAHgXGAp7kzE2z3bSpjE8p9Q5QuiR1DEsRKERKqQBgCDAU+BCYrLUukW2pSqm95Nxp3rwDSNJadzRhJKNRSrUBugKxQKYZPB1UF9gI7Mnd5QBM1VrPNlmoQqCU6gIMB2zIeb+/mjhSgZAiIIQQZkyeDhJCCDMmRUAIIcyYFAEhhDBjUgSEEMKMSREQQggzJkVACCHMmBQBIYQwY1IEhHgISqn1uYPFUEpNVEpNMXUmIf4NmTtIiIfzNjBBKeUB1AaeNHEeIf4VGTEsxENSSm0ESgPNtdZJ9ztfiKJEmoOEeAhKqRrkTKCWLgVAFEdSBIR4QEopT+BnctaKSFFK5Tm1thBFkRQBIR5A7hTSvwMva62PAe8B75g0lBAPQPoEhBDCjMmdgBBCmDEpAkIIYcakCAghhBmTIiCEEGZMioAQQpgxKQJCCGHGpAgIIYQZkyIghBBm7H8olCu0EJdJ/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(myx,np.exp(preds_Phi_Gaussian),label=\"from N\")\n",
    "plt.plot(myx,preds_1D_Phi_Gaussian/(1.-preds_1D_Phi_Gaussian),label=\"from 1\")\n",
    "plt.plot(myx,np.exp(-(myx-epsilon)**2/2+(myx+epsilon)**2/2),label=\"analytic\")\n",
    "plt.legend(frameon=False)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"likelihood ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on i= 0\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/50\n",
      "100000/100000 [==============================] - 13s 131us/step - loss: 0.6895 - acc: 0.5388 - val_loss: 0.6888 - val_acc: 0.5390\n",
      "Epoch 2/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6884 - acc: 0.5388 - val_loss: 0.6886 - val_acc: 0.5393\n",
      "Epoch 3/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5386 - val_loss: 0.6884 - val_acc: 0.5388\n",
      "Epoch 4/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5388 - val_loss: 0.6885 - val_acc: 0.5394\n",
      "Epoch 5/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5387 - val_loss: 0.6884 - val_acc: 0.5388\n",
      "Epoch 6/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6886 - val_acc: 0.5390\n",
      "Epoch 7/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6883 - acc: 0.5392 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 8/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5394 - val_loss: 0.6885 - val_acc: 0.5385\n",
      "Epoch 9/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 10/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 11/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 12/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 13/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 14/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 15/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 16/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 17/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 18/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 19/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 20/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 21/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 22/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 23/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 24/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 25/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5381\n",
      "Epoch 26/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 27/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 28/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 29/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 30/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 31/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 32/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 33/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 34/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 35/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6886 - val_acc: 0.5381\n",
      "Epoch 36/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 37/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5384\n",
      "Epoch 38/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6886 - val_acc: 0.5383\n",
      "Epoch 39/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 40/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 41/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 42/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6886 - val_acc: 0.5383\n",
      "Epoch 43/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 44/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6881 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 45/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 46/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6890 - val_acc: 0.5383\n",
      "Epoch 47/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 48/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5400 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 49/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 50/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5394 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    200         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_301[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_302[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_3 (TimeDistributed)       (None, None, 1)      129         activation_303[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, None, 1)      0           tdist_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 1)            0           mask[0][0]                       \n",
      "                                                                 activation_304[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            2           sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 1)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,359\n",
      "Trainable params: 23,359\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fe7ffe799b0>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7ffdc8748>\n",
      "<keras.layers.core.Activation object at 0x7fe7ffdc8f98>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7ffd8e860>\n",
      "<keras.layers.core.Activation object at 0x7fe7ffd8e7b8>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7ffd5b320>\n",
      "<keras.layers.core.Activation object at 0x7fe7ffd5b390>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7ffd7dd30>\n",
      "<keras.layers.core.Lambda object at 0x7fe7ffe79ef0>\n",
      "<keras.layers.core.Activation object at 0x7fe7ffd7dc18>\n",
      "<keras.layers.merge.Dot object at 0x7fe7ffe79dd8>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 3.1084 - acc: 0.0343 - val_loss: 1.3510 - val_acc: 0.1220\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 1.3203 - acc: 0.0995 - val_loss: 1.3144 - val_acc: 0.1198\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.9114 - acc: 0.1946 - val_loss: 0.6762 - val_acc: 0.5854\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.7276 - acc: 0.3004 - val_loss: 0.6989 - val_acc: 0.2032\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6771 - acc: 0.3259 - val_loss: 0.6737 - val_acc: 0.5437\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6668 - acc: 0.4273 - val_loss: 0.6472 - val_acc: 0.3540\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6557 - acc: 0.4081 - val_loss: 0.6466 - val_acc: 0.4770\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6552 - acc: 0.4044 - val_loss: 0.6484 - val_acc: 0.4535\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6547 - acc: 0.4181 - val_loss: 0.6640 - val_acc: 0.2577\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6588 - acc: 0.4174 - val_loss: 0.6472 - val_acc: 0.3538\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6510 - acc: 0.4078 - val_loss: 0.6455 - val_acc: 0.4737\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6511 - acc: 0.4112 - val_loss: 0.6437 - val_acc: 0.3970\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6532 - acc: 0.4181 - val_loss: 0.6437 - val_acc: 0.4377\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6530 - acc: 0.4153 - val_loss: 0.6466 - val_acc: 0.3696\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6513 - acc: 0.4159 - val_loss: 0.6438 - val_acc: 0.4468\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6546 - acc: 0.4237 - val_loss: 0.6437 - val_acc: 0.4273\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6504 - acc: 0.4369 - val_loss: 0.6499 - val_acc: 0.3395\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6511 - acc: 0.4194 - val_loss: 0.6464 - val_acc: 0.3734\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6530 - acc: 0.4205 - val_loss: 0.6484 - val_acc: 0.3551\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6532 - acc: 0.4173 - val_loss: 0.6512 - val_acc: 0.3294\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6596 - acc: 0.4001 - val_loss: 0.6504 - val_acc: 0.4905\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6535 - acc: 0.4205 - val_loss: 0.6477 - val_acc: 0.5043\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6517 - acc: 0.4360 - val_loss: 0.6557 - val_acc: 0.4416\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6574 - acc: 0.4139 - val_loss: 0.6534 - val_acc: 0.5002\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6599 - acc: 0.4185 - val_loss: 0.6588 - val_acc: 0.2910\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6591 - acc: 0.3878 - val_loss: 0.6446 - val_acc: 0.4020\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6533 - acc: 0.4275 - val_loss: 0.6446 - val_acc: 0.4426\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6520 - acc: 0.4140 - val_loss: 0.6456 - val_acc: 0.4814\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6538 - acc: 0.4283 - val_loss: 0.6506 - val_acc: 0.3331\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6548 - acc: 0.4094 - val_loss: 0.6783 - val_acc: 0.4492\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6626 - acc: 0.4085 - val_loss: 0.6473 - val_acc: 0.4971\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6556 - acc: 0.4094 - val_loss: 0.6469 - val_acc: 0.3750\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6537 - acc: 0.4138 - val_loss: 0.6454 - val_acc: 0.4581\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6540 - acc: 0.4331 - val_loss: 0.6524 - val_acc: 0.3335\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6537 - acc: 0.4186 - val_loss: 0.6546 - val_acc: 0.3182\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6551 - acc: 0.3960 - val_loss: 0.6696 - val_acc: 0.5530\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6648 - acc: 0.4137 - val_loss: 0.6468 - val_acc: 0.3650\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6535 - acc: 0.4174 - val_loss: 0.6457 - val_acc: 0.4171\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6524 - acc: 0.4226 - val_loss: 0.6480 - val_acc: 0.4966\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6605 - acc: 0.3965 - val_loss: 0.6447 - val_acc: 0.4494\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6595 - acc: 0.4158 - val_loss: 0.6500 - val_acc: 0.4793\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6664 - acc: 0.3856 - val_loss: 0.6433 - val_acc: 0.4152\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6539 - acc: 0.4159 - val_loss: 0.6451 - val_acc: 0.4457\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6513 - acc: 0.4323 - val_loss: 0.6449 - val_acc: 0.4424\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6515 - acc: 0.4188 - val_loss: 0.6450 - val_acc: 0.4687\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6597 - acc: 0.4131 - val_loss: 0.6727 - val_acc: 0.2351\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6563 - acc: 0.4120 - val_loss: 0.6460 - val_acc: 0.3853\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6562 - acc: 0.4288 - val_loss: 0.6691 - val_acc: 0.2497\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6577 - acc: 0.3985 - val_loss: 0.6445 - val_acc: 0.4644\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6517 - acc: 0.4235 - val_loss: 0.6509 - val_acc: 0.3453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on i= 1\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/50\n",
      "100000/100000 [==============================] - 13s 134us/step - loss: 0.6892 - acc: 0.5386 - val_loss: 0.6891 - val_acc: 0.5390\n",
      "Epoch 2/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6884 - acc: 0.5386 - val_loss: 0.6884 - val_acc: 0.5393\n",
      "Epoch 3/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6883 - acc: 0.5386 - val_loss: 0.6885 - val_acc: 0.5390\n",
      "Epoch 4/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5386 - val_loss: 0.6884 - val_acc: 0.5389\n",
      "Epoch 5/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5389 - val_loss: 0.6884 - val_acc: 0.5386\n",
      "Epoch 6/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5394 - val_loss: 0.6886 - val_acc: 0.5387\n",
      "Epoch 7/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5386\n",
      "Epoch 8/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6884 - val_acc: 0.5386\n",
      "Epoch 9/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 10/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5385\n",
      "Epoch 11/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5400 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 12/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 13/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 14/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6886 - val_acc: 0.5385\n",
      "Epoch 15/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 16/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5396 - val_loss: 0.6887 - val_acc: 0.5384\n",
      "Epoch 17/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 18/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 19/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 20/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 21/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 22/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 23/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 24/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 25/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6881 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5384\n",
      "Epoch 26/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 27/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5381\n",
      "Epoch 28/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 29/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 30/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 31/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 32/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 33/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 34/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 35/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 36/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 37/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 38/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6881 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 39/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 40/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6885 - val_acc: 0.5384\n",
      "Epoch 41/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 42/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5381\n",
      "Epoch 43/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 44/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 45/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 46/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 47/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6886 - val_acc: 0.5383\n",
      "Epoch 48/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 49/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 50/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    200         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_306[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_3 (TimeDistributed)       (None, None, 1)      129         activation_308[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, None, 1)      0           tdist_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 1)            0           mask[0][0]                       \n",
      "                                                                 activation_309[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            2           sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 1)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,359\n",
      "Trainable params: 23,359\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fe7ff23b978>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7ff191860>\n",
      "<keras.layers.core.Activation object at 0x7fe7ff191ba8>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7ff1b9be0>\n",
      "<keras.layers.core.Activation object at 0x7fe7ff1b9e48>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7ff104c18>\n",
      "<keras.layers.core.Activation object at 0x7fe7ff104b00>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7ff0c9898>\n",
      "<keras.layers.core.Lambda object at 0x7fe7ff23beb8>\n",
      "<keras.layers.core.Activation object at 0x7fe7ff0c97f0>\n",
      "<keras.layers.merge.Dot object at 0x7fe7ff23b588>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.6847 - acc: 0.3727 - val_loss: 0.6500 - val_acc: 0.3362\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6583 - acc: 0.4060 - val_loss: 0.6516 - val_acc: 0.3265\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6569 - acc: 0.4034 - val_loss: 0.6478 - val_acc: 0.3575\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6511 - acc: 0.4177 - val_loss: 0.6455 - val_acc: 0.3794\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6500 - acc: 0.4188 - val_loss: 0.6450 - val_acc: 0.3879\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6492 - acc: 0.4254 - val_loss: 0.6446 - val_acc: 0.3951\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6492 - acc: 0.4238 - val_loss: 0.6432 - val_acc: 0.4244\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6493 - acc: 0.4251 - val_loss: 0.6438 - val_acc: 0.4487\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6493 - acc: 0.4317 - val_loss: 0.6439 - val_acc: 0.4499\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6491 - acc: 0.4243 - val_loss: 0.6434 - val_acc: 0.4275\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6488 - acc: 0.4307 - val_loss: 0.6438 - val_acc: 0.4489\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6497 - acc: 0.4328 - val_loss: 0.6434 - val_acc: 0.4351\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6501 - acc: 0.4150 - val_loss: 0.6437 - val_acc: 0.4148\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6502 - acc: 0.4364 - val_loss: 0.6447 - val_acc: 0.4663\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6531 - acc: 0.4085 - val_loss: 0.6496 - val_acc: 0.3421\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6497 - acc: 0.4385 - val_loss: 0.6435 - val_acc: 0.4183\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6490 - acc: 0.4260 - val_loss: 0.6435 - val_acc: 0.4398\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6494 - acc: 0.4278 - val_loss: 0.6441 - val_acc: 0.4084\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6510 - acc: 0.4174 - val_loss: 0.6476 - val_acc: 0.3596\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6522 - acc: 0.4160 - val_loss: 0.6566 - val_acc: 0.5158\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6544 - acc: 0.4358 - val_loss: 0.6543 - val_acc: 0.3110\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6534 - acc: 0.3987 - val_loss: 0.6436 - val_acc: 0.4069\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6507 - acc: 0.4308 - val_loss: 0.6457 - val_acc: 0.4705\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6488 - acc: 0.4302 - val_loss: 0.6437 - val_acc: 0.4453\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6498 - acc: 0.4313 - val_loss: 0.6436 - val_acc: 0.4089\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6499 - acc: 0.4107 - val_loss: 0.6440 - val_acc: 0.4483\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6520 - acc: 0.4443 - val_loss: 0.6436 - val_acc: 0.4455\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6497 - acc: 0.4304 - val_loss: 0.6452 - val_acc: 0.3883\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6503 - acc: 0.4182 - val_loss: 0.6461 - val_acc: 0.3737\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6516 - acc: 0.4118 - val_loss: 0.6493 - val_acc: 0.4980\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6518 - acc: 0.4395 - val_loss: 0.6437 - val_acc: 0.4056\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6491 - acc: 0.4274 - val_loss: 0.6441 - val_acc: 0.4191\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6492 - acc: 0.4293 - val_loss: 0.6464 - val_acc: 0.3655\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6494 - acc: 0.4157 - val_loss: 0.6435 - val_acc: 0.4201\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6495 - acc: 0.4284 - val_loss: 0.6439 - val_acc: 0.4509\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6491 - acc: 0.4334 - val_loss: 0.6440 - val_acc: 0.4512\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6493 - acc: 0.4232 - val_loss: 0.6458 - val_acc: 0.3734\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6500 - acc: 0.4234 - val_loss: 0.6433 - val_acc: 0.4262\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6495 - acc: 0.4304 - val_loss: 0.6457 - val_acc: 0.4687\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6500 - acc: 0.4225 - val_loss: 0.6436 - val_acc: 0.4437\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6488 - acc: 0.4386 - val_loss: 0.6434 - val_acc: 0.4289\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6499 - acc: 0.4163 - val_loss: 0.6436 - val_acc: 0.4423\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6503 - acc: 0.4417 - val_loss: 0.6437 - val_acc: 0.4147\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6492 - acc: 0.4106 - val_loss: 0.6446 - val_acc: 0.4530\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6512 - acc: 0.4472 - val_loss: 0.6441 - val_acc: 0.4230\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6506 - acc: 0.4037 - val_loss: 0.6437 - val_acc: 0.4294\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6497 - acc: 0.4375 - val_loss: 0.6441 - val_acc: 0.4433\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6486 - acc: 0.4283 - val_loss: 0.6433 - val_acc: 0.4163\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6490 - acc: 0.4238 - val_loss: 0.6441 - val_acc: 0.4552\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6491 - acc: 0.4306 - val_loss: 0.6436 - val_acc: 0.4394\n",
      "on i= 2\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/50\n",
      "100000/100000 [==============================] - 14s 137us/step - loss: 0.6893 - acc: 0.5386 - val_loss: 0.6893 - val_acc: 0.5390\n",
      "Epoch 2/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6886 - acc: 0.5385 - val_loss: 0.6884 - val_acc: 0.5389\n",
      "Epoch 3/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5382 - val_loss: 0.6885 - val_acc: 0.5390\n",
      "Epoch 4/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5386 - val_loss: 0.6884 - val_acc: 0.5387\n",
      "Epoch 5/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5394 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 6/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5392 - val_loss: 0.6884 - val_acc: 0.5386\n",
      "Epoch 7/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 8/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5385\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5384\n",
      "Epoch 10/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5385\n",
      "Epoch 11/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 12/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 13/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 14/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6886 - val_acc: 0.5383\n",
      "Epoch 15/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 16/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5394 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 17/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 18/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 19/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 20/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 21/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 22/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 23/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 24/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 25/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 26/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6883 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 27/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6887 - val_acc: 0.5383\n",
      "Epoch 28/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 29/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 30/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5400 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 31/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 32/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 33/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 34/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6887 - val_acc: 0.5383\n",
      "Epoch 35/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6881 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5381\n",
      "Epoch 36/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6886 - val_acc: 0.5382\n",
      "Epoch 37/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6883 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 38/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6886 - val_acc: 0.5383\n",
      "Epoch 39/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 40/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 41/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5381\n",
      "Epoch 42/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 43/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5381\n",
      "Epoch 44/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5384\n",
      "Epoch 45/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 46/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5394 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 47/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 48/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 49/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 50/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    200         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_311[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_312[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_3 (TimeDistributed)       (None, None, 1)      129         activation_313[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, None, 1)      0           tdist_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 1)            0           mask[0][0]                       \n",
      "                                                                 activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            2           sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 1)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,359\n",
      "Trainable params: 23,359\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fe7fe58da58>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7fe5447f0>\n",
      "<keras.layers.core.Activation object at 0x7fe7fe55a3c8>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7fe520b00>\n",
      "<keras.layers.core.Activation object at 0x7fe7fe5209e8>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7fe4d3780>\n",
      "<keras.layers.core.Activation object at 0x7fe7fe4d36d8>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7fe4fce80>\n",
      "<keras.layers.core.Lambda object at 0x7fe7fe58d208>\n",
      "<keras.layers.core.Activation object at 0x7fe7fe4a0240>\n",
      "<keras.layers.merge.Dot object at 0x7fe7fe58d710>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.7703 - acc: 0.2938 - val_loss: 0.7195 - val_acc: 0.3299\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 0s 12us/step - loss: 0.6772 - acc: 0.3552 - val_loss: 0.6480 - val_acc: 0.5106\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6602 - acc: 0.4293 - val_loss: 0.6546 - val_acc: 0.3102\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6552 - acc: 0.3909 - val_loss: 0.6452 - val_acc: 0.4613\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6525 - acc: 0.4454 - val_loss: 0.6434 - val_acc: 0.4182\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6503 - acc: 0.4194 - val_loss: 0.6463 - val_acc: 0.3717\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6508 - acc: 0.4128 - val_loss: 0.6448 - val_acc: 0.4628\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6507 - acc: 0.4390 - val_loss: 0.6501 - val_acc: 0.3386\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6540 - acc: 0.4049 - val_loss: 0.6505 - val_acc: 0.4933\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6521 - acc: 0.4248 - val_loss: 0.6478 - val_acc: 0.3582\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6495 - acc: 0.4331 - val_loss: 0.6435 - val_acc: 0.4370\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6490 - acc: 0.4213 - val_loss: 0.6442 - val_acc: 0.4556\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6501 - acc: 0.4284 - val_loss: 0.6434 - val_acc: 0.4224\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6509 - acc: 0.4200 - val_loss: 0.6434 - val_acc: 0.4139\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6517 - acc: 0.4354 - val_loss: 0.6595 - val_acc: 0.2880\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6586 - acc: 0.4145 - val_loss: 0.6454 - val_acc: 0.3805\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6515 - acc: 0.3988 - val_loss: 0.6550 - val_acc: 0.5057\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6546 - acc: 0.4205 - val_loss: 0.6433 - val_acc: 0.4287\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6493 - acc: 0.4416 - val_loss: 0.6433 - val_acc: 0.4257\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6494 - acc: 0.4322 - val_loss: 0.6499 - val_acc: 0.3397\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6510 - acc: 0.4175 - val_loss: 0.6447 - val_acc: 0.4651\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6517 - acc: 0.4187 - val_loss: 0.6470 - val_acc: 0.4804\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6526 - acc: 0.4125 - val_loss: 0.6438 - val_acc: 0.4453\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6515 - acc: 0.4379 - val_loss: 0.6529 - val_acc: 0.3195\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6526 - acc: 0.4262 - val_loss: 0.6471 - val_acc: 0.3630\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6503 - acc: 0.4114 - val_loss: 0.6439 - val_acc: 0.4493\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6536 - acc: 0.4205 - val_loss: 0.6585 - val_acc: 0.4676\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6546 - acc: 0.4192 - val_loss: 0.6439 - val_acc: 0.4245\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6507 - acc: 0.4246 - val_loss: 0.6434 - val_acc: 0.4144\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6495 - acc: 0.4314 - val_loss: 0.6436 - val_acc: 0.4143\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6504 - acc: 0.4230 - val_loss: 0.6436 - val_acc: 0.4214\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6546 - acc: 0.4215 - val_loss: 0.6434 - val_acc: 0.4095\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6490 - acc: 0.4293 - val_loss: 0.6448 - val_acc: 0.4697\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6503 - acc: 0.4182 - val_loss: 0.6434 - val_acc: 0.4344\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6510 - acc: 0.4329 - val_loss: 0.6474 - val_acc: 0.3616\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6534 - acc: 0.4186 - val_loss: 0.6520 - val_acc: 0.3284\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6580 - acc: 0.4125 - val_loss: 0.6437 - val_acc: 0.4189\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6513 - acc: 0.4121 - val_loss: 0.6520 - val_acc: 0.5239\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6499 - acc: 0.4270 - val_loss: 0.6434 - val_acc: 0.4079\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6504 - acc: 0.4281 - val_loss: 0.6474 - val_acc: 0.3652\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6551 - acc: 0.4251 - val_loss: 0.6439 - val_acc: 0.4258\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6523 - acc: 0.4140 - val_loss: 0.6451 - val_acc: 0.4740\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6496 - acc: 0.4179 - val_loss: 0.6447 - val_acc: 0.4639\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6495 - acc: 0.4365 - val_loss: 0.6437 - val_acc: 0.4408\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6494 - acc: 0.4255 - val_loss: 0.6442 - val_acc: 0.4084\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6514 - acc: 0.4279 - val_loss: 0.6477 - val_acc: 0.3589\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6512 - acc: 0.4260 - val_loss: 0.6454 - val_acc: 0.3770\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6505 - acc: 0.4266 - val_loss: 0.6458 - val_acc: 0.4823\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6525 - acc: 0.4128 - val_loss: 0.6645 - val_acc: 0.5058\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6592 - acc: 0.3981 - val_loss: 0.6442 - val_acc: 0.4487\n",
      "on i= 3\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/50\n",
      "100000/100000 [==============================] - 14s 142us/step - loss: 0.6898 - acc: 0.5353 - val_loss: 0.6891 - val_acc: 0.5391\n",
      "Epoch 2/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6884 - acc: 0.5388 - val_loss: 0.6885 - val_acc: 0.5390\n",
      "Epoch 3/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6883 - acc: 0.5390 - val_loss: 0.6884 - val_acc: 0.5394\n",
      "Epoch 4/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5379 - val_loss: 0.6885 - val_acc: 0.5390\n",
      "Epoch 5/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6884 - val_acc: 0.5386\n",
      "Epoch 6/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5392 - val_loss: 0.6885 - val_acc: 0.5386\n",
      "Epoch 7/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 8/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5384\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 10/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 11/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 12/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 13/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 14/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 15/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 16/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 17/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 18/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5381\n",
      "Epoch 19/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 20/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5396 - val_loss: 0.6886 - val_acc: 0.5383\n",
      "Epoch 21/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 22/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5400 - val_loss: 0.6884 - val_acc: 0.5381\n",
      "Epoch 23/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6886 - val_acc: 0.5382\n",
      "Epoch 24/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 25/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 26/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 27/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 28/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 29/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 30/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5397 - val_loss: 0.6886 - val_acc: 0.5382\n",
      "Epoch 31/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 32/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 33/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 34/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5400 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 35/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 36/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 37/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 38/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 39/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 40/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 41/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6886 - val_acc: 0.5383\n",
      "Epoch 42/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 43/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 44/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 45/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 46/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 47/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6881 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 48/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 49/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5400 - val_loss: 0.6887 - val_acc: 0.5383\n",
      "Epoch 50/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6883 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    200         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_316[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_3 (TimeDistributed)       (None, None, 1)      129         activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, None, 1)      0           tdist_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 1)            0           mask[0][0]                       \n",
      "                                                                 activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            2           sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 1)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,359\n",
      "Trainable params: 23,359\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fe7fd9b5828>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7fd90d5f8>\n",
      "<keras.layers.core.Activation object at 0x7fe7fd90dda0>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7fd8c65f8>\n",
      "<keras.layers.core.Activation object at 0x7fe7fd8c6668>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7fd881b00>\n",
      "<keras.layers.core.Activation object at 0x7fe7fd881e48>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7fd847b38>\n",
      "<keras.layers.core.Lambda object at 0x7fe7fd9b5b00>\n",
      "<keras.layers.core.Activation object at 0x7fe7fd847a20>\n",
      "<keras.layers.merge.Dot object at 0x7fe7fd960748>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 1.8342 - acc: 0.0809 - val_loss: 1.2699 - val_acc: 0.0771\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 1.0662 - acc: 0.1345 - val_loss: 0.9826 - val_acc: 0.0121\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.7487 - acc: 0.2747 - val_loss: 0.7337 - val_acc: 0.4618\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6908 - acc: 0.3614 - val_loss: 0.6842 - val_acc: 0.2068\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6706 - acc: 0.3690 - val_loss: 0.6691 - val_acc: 0.5201\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6652 - acc: 0.3782 - val_loss: 0.6487 - val_acc: 0.3464\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6532 - acc: 0.4311 - val_loss: 0.6449 - val_acc: 0.4621\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6498 - acc: 0.4177 - val_loss: 0.6443 - val_acc: 0.3961\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6495 - acc: 0.4365 - val_loss: 0.6457 - val_acc: 0.3775\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6492 - acc: 0.4185 - val_loss: 0.6446 - val_acc: 0.4200\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6527 - acc: 0.4201 - val_loss: 0.6501 - val_acc: 0.4720\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6539 - acc: 0.4096 - val_loss: 0.6522 - val_acc: 0.5049\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6549 - acc: 0.4249 - val_loss: 0.6463 - val_acc: 0.4450\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6519 - acc: 0.4188 - val_loss: 0.6434 - val_acc: 0.4378\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6511 - acc: 0.4171 - val_loss: 0.6516 - val_acc: 0.4746\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6523 - acc: 0.4353 - val_loss: 0.6439 - val_acc: 0.3992\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6509 - acc: 0.4029 - val_loss: 0.6489 - val_acc: 0.4220\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6550 - acc: 0.4179 - val_loss: 0.6463 - val_acc: 0.4211\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6532 - acc: 0.4263 - val_loss: 0.6499 - val_acc: 0.4704\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6519 - acc: 0.4226 - val_loss: 0.6437 - val_acc: 0.4346\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6579 - acc: 0.4000 - val_loss: 0.6468 - val_acc: 0.4342\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6508 - acc: 0.4240 - val_loss: 0.6436 - val_acc: 0.4408\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6527 - acc: 0.4283 - val_loss: 0.6461 - val_acc: 0.4593\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6519 - acc: 0.4263 - val_loss: 0.6497 - val_acc: 0.3433\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6578 - acc: 0.3952 - val_loss: 0.6599 - val_acc: 0.5149\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6622 - acc: 0.4058 - val_loss: 0.6639 - val_acc: 0.2660\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6669 - acc: 0.3857 - val_loss: 0.6628 - val_acc: 0.5266\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6693 - acc: 0.4023 - val_loss: 0.6624 - val_acc: 0.2726\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6626 - acc: 0.3843 - val_loss: 0.6767 - val_acc: 0.4815\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6542 - acc: 0.4211 - val_loss: 0.6436 - val_acc: 0.4041\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6508 - acc: 0.4203 - val_loss: 0.6463 - val_acc: 0.3867\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6549 - acc: 0.4078 - val_loss: 0.6458 - val_acc: 0.4831\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6610 - acc: 0.3992 - val_loss: 0.6482 - val_acc: 0.3484\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6687 - acc: 0.3906 - val_loss: 0.6575 - val_acc: 0.4199\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6628 - acc: 0.3963 - val_loss: 0.6454 - val_acc: 0.4579\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6525 - acc: 0.4221 - val_loss: 0.6628 - val_acc: 0.2781\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6625 - acc: 0.3934 - val_loss: 0.6730 - val_acc: 0.4556\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6661 - acc: 0.3950 - val_loss: 0.6717 - val_acc: 0.2411\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6627 - acc: 0.3836 - val_loss: 0.6507 - val_acc: 0.5211\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6538 - acc: 0.4186 - val_loss: 0.6467 - val_acc: 0.3939\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6532 - acc: 0.4221 - val_loss: 0.6495 - val_acc: 0.4446\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6538 - acc: 0.4328 - val_loss: 0.6608 - val_acc: 0.2816\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6741 - acc: 0.4032 - val_loss: 0.6553 - val_acc: 0.3065\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6655 - acc: 0.3636 - val_loss: 0.6673 - val_acc: 0.5249\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6581 - acc: 0.4186 - val_loss: 0.6661 - val_acc: 0.2553\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 0s 12us/step - loss: 0.6593 - acc: 0.4042 - val_loss: 0.6517 - val_acc: 0.3501\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6541 - acc: 0.3995 - val_loss: 0.6433 - val_acc: 0.4160\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6577 - acc: 0.4203 - val_loss: 0.6436 - val_acc: 0.4138\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6508 - acc: 0.4338 - val_loss: 0.6508 - val_acc: 0.3328\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6513 - acc: 0.4186 - val_loss: 0.6625 - val_acc: 0.5069\n",
      "on i= 4\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/50\n",
      "100000/100000 [==============================] - 15s 148us/step - loss: 0.6893 - acc: 0.5350 - val_loss: 0.6892 - val_acc: 0.5390\n",
      "Epoch 2/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6884 - acc: 0.5385 - val_loss: 0.6884 - val_acc: 0.5392\n",
      "Epoch 3/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5389 - val_loss: 0.6886 - val_acc: 0.5392\n",
      "Epoch 4/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5388 - val_loss: 0.6883 - val_acc: 0.5385\n",
      "Epoch 5/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5392 - val_loss: 0.6886 - val_acc: 0.5390\n",
      "Epoch 6/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5392 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 7/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5387\n",
      "Epoch 8/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5385\n",
      "Epoch 10/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 11/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 12/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 13/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 14/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 15/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 16/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 17/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5384\n",
      "Epoch 18/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 19/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6886 - val_acc: 0.5382\n",
      "Epoch 20/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5395 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 21/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5396 - val_loss: 0.6886 - val_acc: 0.5382\n",
      "Epoch 22/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 23/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 24/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 25/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6886 - val_acc: 0.5382\n",
      "Epoch 26/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 27/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 28/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 29/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6886 - val_acc: 0.5382\n",
      "Epoch 30/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 31/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 32/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 33/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 34/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 35/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 36/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6886 - val_acc: 0.5383\n",
      "Epoch 37/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 38/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6887 - val_acc: 0.5382\n",
      "Epoch 39/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 40/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6881 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 41/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 42/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 43/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 44/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 45/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 46/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 47/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 48/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 49/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 50/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    200         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_3 (TimeDistributed)       (None, None, 1)      129         activation_323[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, None, 1)      0           tdist_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 1)            0           mask[0][0]                       \n",
      "                                                                 activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            2           sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 1)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,359\n",
      "Trainable params: 23,359\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fe7fcd08be0>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7fccd8630>\n",
      "<keras.layers.core.Activation object at 0x7fe7fccd8940>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7fcc85a20>\n",
      "<keras.layers.core.Activation object at 0x7fe7fcc854e0>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7fcc4aa20>\n",
      "<keras.layers.core.Activation object at 0x7fe7fcc4a908>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7fcc11630>\n",
      "<keras.layers.core.Lambda object at 0x7fe7fcd08c50>\n",
      "<keras.layers.core.Activation object at 0x7fe7fcc116a0>\n",
      "<keras.layers.merge.Dot object at 0x7fe7fcd08128>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 3.0649 - acc: 0.0573 - val_loss: 1.2777 - val_acc: 0.0619\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 1.1000 - acc: 0.1321 - val_loss: 0.7197 - val_acc: 0.2231\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.7578 - acc: 0.3145 - val_loss: 0.6950 - val_acc: 0.1952\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6933 - acc: 0.3635 - val_loss: 0.6734 - val_acc: 0.2599\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6615 - acc: 0.3762 - val_loss: 0.6462 - val_acc: 0.3833\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6549 - acc: 0.4485 - val_loss: 0.6462 - val_acc: 0.4922\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6510 - acc: 0.4286 - val_loss: 0.6438 - val_acc: 0.4114\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6502 - acc: 0.4326 - val_loss: 0.6457 - val_acc: 0.4794\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6506 - acc: 0.4279 - val_loss: 0.6435 - val_acc: 0.4500\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6506 - acc: 0.4492 - val_loss: 0.6445 - val_acc: 0.3976\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6519 - acc: 0.4134 - val_loss: 0.6438 - val_acc: 0.4507\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6509 - acc: 0.4290 - val_loss: 0.6454 - val_acc: 0.4682\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6496 - acc: 0.4409 - val_loss: 0.6477 - val_acc: 0.3609\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6526 - acc: 0.3987 - val_loss: 0.6517 - val_acc: 0.5116\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6532 - acc: 0.4407 - val_loss: 0.6464 - val_acc: 0.3657\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6611 - acc: 0.4146 - val_loss: 0.6519 - val_acc: 0.3279\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6533 - acc: 0.4131 - val_loss: 0.6445 - val_acc: 0.4604\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6523 - acc: 0.4232 - val_loss: 0.6470 - val_acc: 0.4654\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6543 - acc: 0.4056 - val_loss: 0.6490 - val_acc: 0.5011\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6607 - acc: 0.4044 - val_loss: 0.6441 - val_acc: 0.3929\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6691 - acc: 0.3989 - val_loss: 0.6865 - val_acc: 0.1872\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6735 - acc: 0.3772 - val_loss: 0.6440 - val_acc: 0.3954\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6546 - acc: 0.3940 - val_loss: 0.6520 - val_acc: 0.5275\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6558 - acc: 0.4308 - val_loss: 0.6468 - val_acc: 0.4247\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6510 - acc: 0.4117 - val_loss: 0.6479 - val_acc: 0.5094\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6515 - acc: 0.4377 - val_loss: 0.6663 - val_acc: 0.2604\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6591 - acc: 0.4124 - val_loss: 0.6540 - val_acc: 0.3166\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6613 - acc: 0.4063 - val_loss: 0.6495 - val_acc: 0.3404\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6558 - acc: 0.4002 - val_loss: 0.6489 - val_acc: 0.4838\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6509 - acc: 0.4240 - val_loss: 0.6466 - val_acc: 0.4868\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6582 - acc: 0.3962 - val_loss: 0.6741 - val_acc: 0.4848\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6623 - acc: 0.4015 - val_loss: 0.6480 - val_acc: 0.5034\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6531 - acc: 0.4263 - val_loss: 0.6663 - val_acc: 0.4658\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6598 - acc: 0.4095 - val_loss: 0.6561 - val_acc: 0.5103\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6529 - acc: 0.4186 - val_loss: 0.6544 - val_acc: 0.4896\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6586 - acc: 0.4117 - val_loss: 0.6486 - val_acc: 0.5011\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6502 - acc: 0.4270 - val_loss: 0.6439 - val_acc: 0.4184\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6491 - acc: 0.4246 - val_loss: 0.6451 - val_acc: 0.4624\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6495 - acc: 0.4268 - val_loss: 0.6475 - val_acc: 0.3611\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6518 - acc: 0.4275 - val_loss: 0.6463 - val_acc: 0.3680\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6504 - acc: 0.4195 - val_loss: 0.6497 - val_acc: 0.3561\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6505 - acc: 0.4292 - val_loss: 0.6464 - val_acc: 0.4432\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6495 - acc: 0.4228 - val_loss: 0.6442 - val_acc: 0.4291\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6513 - acc: 0.4229 - val_loss: 0.6443 - val_acc: 0.4574\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6513 - acc: 0.4314 - val_loss: 0.6499 - val_acc: 0.3374\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6630 - acc: 0.3983 - val_loss: 0.6890 - val_acc: 0.1780\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6709 - acc: 0.3692 - val_loss: 0.6933 - val_acc: 0.1747\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6648 - acc: 0.3927 - val_loss: 0.6534 - val_acc: 0.3162\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6537 - acc: 0.4197 - val_loss: 0.6456 - val_acc: 0.3778\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6632 - acc: 0.3890 - val_loss: 0.6475 - val_acc: 0.3626\n",
      "on i= 5\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/50\n",
      "100000/100000 [==============================] - 15s 147us/step - loss: 0.6891 - acc: 0.5342 - val_loss: 0.6889 - val_acc: 0.5391\n",
      "Epoch 2/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6884 - acc: 0.5384 - val_loss: 0.6887 - val_acc: 0.5392\n",
      "Epoch 3/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5387 - val_loss: 0.6884 - val_acc: 0.5390\n",
      "Epoch 4/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5384 - val_loss: 0.6885 - val_acc: 0.5390\n",
      "Epoch 5/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5389 - val_loss: 0.6885 - val_acc: 0.5385\n",
      "Epoch 6/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5390 - val_loss: 0.6884 - val_acc: 0.5387\n",
      "Epoch 7/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5394 - val_loss: 0.6884 - val_acc: 0.5387\n",
      "Epoch 8/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5384\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5384\n",
      "Epoch 10/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 11/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 12/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6885 - val_acc: 0.5385\n",
      "Epoch 13/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5394 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 14/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5401 - val_loss: 0.6886 - val_acc: 0.5383\n",
      "Epoch 15/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5381\n",
      "Epoch 16/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6886 - val_acc: 0.5383\n",
      "Epoch 17/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6883 - acc: 0.5397 - val_loss: 0.6886 - val_acc: 0.5384\n",
      "Epoch 18/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6883 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 19/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 20/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 21/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 22/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6886 - val_acc: 0.5383\n",
      "Epoch 23/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 24/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 25/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 26/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 27/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 28/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 29/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 30/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 31/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5381\n",
      "Epoch 32/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5400 - val_loss: 0.6886 - val_acc: 0.5382\n",
      "Epoch 33/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5381\n",
      "Epoch 34/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 35/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5381\n",
      "Epoch 36/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 37/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 38/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 39/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 40/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 41/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5384\n",
      "Epoch 42/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 43/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 44/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5381\n",
      "Epoch 45/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 46/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 47/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 48/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 49/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 50/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    200         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_326[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_3 (TimeDistributed)       (None, None, 1)      129         activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, None, 1)      0           tdist_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 1)            0           mask[0][0]                       \n",
      "                                                                 activation_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            2           sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 1)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,359\n",
      "Trainable params: 23,359\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fe7e3bea400>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e3b48470>\n",
      "<keras.layers.core.Activation object at 0x7fe7e3b48240>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e3b119b0>\n",
      "<keras.layers.core.Activation object at 0x7fe7e3b11908>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e3ad8518>\n",
      "<keras.layers.core.Activation object at 0x7fe7e3ad8588>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e3afd550>\n",
      "<keras.layers.core.Lambda object at 0x7fe7e3b94c50>\n",
      "<keras.layers.core.Activation object at 0x7fe7e3afda20>\n",
      "<keras.layers.merge.Dot object at 0x7fe7e3b94860>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.8072 - acc: 0.3354 - val_loss: 0.7013 - val_acc: 0.1590\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6747 - acc: 0.3495 - val_loss: 0.6530 - val_acc: 0.3437\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6589 - acc: 0.3635 - val_loss: 0.6485 - val_acc: 0.4735\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6511 - acc: 0.4335 - val_loss: 0.6461 - val_acc: 0.4652\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6495 - acc: 0.4460 - val_loss: 0.6436 - val_acc: 0.4442\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6490 - acc: 0.4146 - val_loss: 0.6434 - val_acc: 0.4351\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6493 - acc: 0.4307 - val_loss: 0.6442 - val_acc: 0.4008\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6499 - acc: 0.4307 - val_loss: 0.6436 - val_acc: 0.4268\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6488 - acc: 0.4313 - val_loss: 0.6434 - val_acc: 0.4392\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6488 - acc: 0.4205 - val_loss: 0.6468 - val_acc: 0.4830\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6495 - acc: 0.4381 - val_loss: 0.6435 - val_acc: 0.4271\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6492 - acc: 0.4277 - val_loss: 0.6441 - val_acc: 0.4521\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6488 - acc: 0.4355 - val_loss: 0.6440 - val_acc: 0.4069\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6507 - acc: 0.4237 - val_loss: 0.6499 - val_acc: 0.3406\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6503 - acc: 0.4170 - val_loss: 0.6433 - val_acc: 0.4285\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6487 - acc: 0.4317 - val_loss: 0.6458 - val_acc: 0.4796\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6489 - acc: 0.4277 - val_loss: 0.6435 - val_acc: 0.4411\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6504 - acc: 0.4274 - val_loss: 0.6481 - val_acc: 0.4963\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6508 - acc: 0.4369 - val_loss: 0.6435 - val_acc: 0.4355\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6492 - acc: 0.4311 - val_loss: 0.6435 - val_acc: 0.4324\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6489 - acc: 0.4259 - val_loss: 0.6435 - val_acc: 0.4093\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6490 - acc: 0.4296 - val_loss: 0.6437 - val_acc: 0.4117\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6492 - acc: 0.4223 - val_loss: 0.6434 - val_acc: 0.4121\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6494 - acc: 0.4378 - val_loss: 0.6445 - val_acc: 0.4637\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6487 - acc: 0.4214 - val_loss: 0.6439 - val_acc: 0.4442\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6490 - acc: 0.4324 - val_loss: 0.6438 - val_acc: 0.4399\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6496 - acc: 0.4358 - val_loss: 0.6462 - val_acc: 0.4701\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6520 - acc: 0.4167 - val_loss: 0.6436 - val_acc: 0.4120\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6501 - acc: 0.4349 - val_loss: 0.6454 - val_acc: 0.3825\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6493 - acc: 0.4211 - val_loss: 0.6467 - val_acc: 0.3648\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6502 - acc: 0.4221 - val_loss: 0.6442 - val_acc: 0.4016\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6499 - acc: 0.4291 - val_loss: 0.6440 - val_acc: 0.4520\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6491 - acc: 0.4248 - val_loss: 0.6443 - val_acc: 0.3998\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6503 - acc: 0.4355 - val_loss: 0.6435 - val_acc: 0.4181\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6514 - acc: 0.4161 - val_loss: 0.6454 - val_acc: 0.3827\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6528 - acc: 0.4080 - val_loss: 0.6437 - val_acc: 0.4468\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6512 - acc: 0.4337 - val_loss: 0.6437 - val_acc: 0.4461\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6493 - acc: 0.4287 - val_loss: 0.6449 - val_acc: 0.4634\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6498 - acc: 0.4345 - val_loss: 0.6433 - val_acc: 0.4333\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6491 - acc: 0.4332 - val_loss: 0.6439 - val_acc: 0.4189\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6495 - acc: 0.4169 - val_loss: 0.6436 - val_acc: 0.4404\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6504 - acc: 0.4293 - val_loss: 0.6482 - val_acc: 0.4943\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6501 - acc: 0.4374 - val_loss: 0.6434 - val_acc: 0.4102\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6489 - acc: 0.4230 - val_loss: 0.6437 - val_acc: 0.4386\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6491 - acc: 0.4273 - val_loss: 0.6450 - val_acc: 0.4615\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6520 - acc: 0.4357 - val_loss: 0.6449 - val_acc: 0.4673\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6506 - acc: 0.4276 - val_loss: 0.6462 - val_acc: 0.3697\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6494 - acc: 0.4206 - val_loss: 0.6435 - val_acc: 0.4369\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6508 - acc: 0.4343 - val_loss: 0.6479 - val_acc: 0.3548\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6528 - acc: 0.4068 - val_loss: 0.6439 - val_acc: 0.4110\n",
      "on i= 6\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/50\n",
      "100000/100000 [==============================] - 15s 151us/step - loss: 0.6898 - acc: 0.5351 - val_loss: 0.6891 - val_acc: 0.5390\n",
      "Epoch 2/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6884 - acc: 0.5386 - val_loss: 0.6885 - val_acc: 0.5389\n",
      "Epoch 3/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5385 - val_loss: 0.6884 - val_acc: 0.5391\n",
      "Epoch 4/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5388 - val_loss: 0.6884 - val_acc: 0.5389\n",
      "Epoch 5/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5389 - val_loss: 0.6884 - val_acc: 0.5388\n",
      "Epoch 6/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5394 - val_loss: 0.6885 - val_acc: 0.5387\n",
      "Epoch 7/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 8/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5385\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 10/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5394 - val_loss: 0.6885 - val_acc: 0.5384\n",
      "Epoch 11/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5385\n",
      "Epoch 12/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6885 - val_acc: 0.5384\n",
      "Epoch 13/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5381\n",
      "Epoch 14/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 15/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 16/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5384\n",
      "Epoch 17/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 18/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 19/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 20/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6886 - val_acc: 0.5382\n",
      "Epoch 21/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 22/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6886 - val_acc: 0.5384\n",
      "Epoch 23/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 24/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 25/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5400 - val_loss: 0.6886 - val_acc: 0.5381\n",
      "Epoch 26/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 27/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 28/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 29/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6881 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 30/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6886 - val_acc: 0.5382\n",
      "Epoch 31/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 32/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 33/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 34/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6886 - val_acc: 0.5382\n",
      "Epoch 35/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 36/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 37/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 38/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 39/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 40/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 41/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 42/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 43/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5400 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 44/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 45/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 46/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 47/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 48/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5400 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 49/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 50/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    200         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_331[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_332[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_3 (TimeDistributed)       (None, None, 1)      129         activation_333[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, None, 1)      0           tdist_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 1)            0           mask[0][0]                       \n",
      "                                                                 activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            2           sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, 1)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,359\n",
      "Trainable params: 23,359\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fe7e2fbe630>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e2f14710>\n",
      "<keras.layers.core.Activation object at 0x7fe7e2f14be0>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e2ee3400>\n",
      "<keras.layers.core.Activation object at 0x7fe7e2ee3470>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e2e8acf8>\n",
      "<keras.layers.core.Activation object at 0x7fe7e2e8a940>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e2e4f9e8>\n",
      "<keras.layers.core.Lambda object at 0x7fe7e2fbe518>\n",
      "<keras.layers.core.Activation object at 0x7fe7e2e4f940>\n",
      "<keras.layers.merge.Dot object at 0x7fe7e2f69588>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.6676 - acc: 0.3954 - val_loss: 0.6450 - val_acc: 0.3987\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6555 - acc: 0.4027 - val_loss: 0.6512 - val_acc: 0.5078\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6527 - acc: 0.4476 - val_loss: 0.6461 - val_acc: 0.4863\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6494 - acc: 0.4246 - val_loss: 0.6436 - val_acc: 0.4361\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6494 - acc: 0.4257 - val_loss: 0.6435 - val_acc: 0.4392\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6493 - acc: 0.4329 - val_loss: 0.6467 - val_acc: 0.3656\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6526 - acc: 0.4085 - val_loss: 0.6439 - val_acc: 0.4500\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6504 - acc: 0.4364 - val_loss: 0.6459 - val_acc: 0.4774\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6508 - acc: 0.4315 - val_loss: 0.6446 - val_acc: 0.3932\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6496 - acc: 0.4322 - val_loss: 0.6434 - val_acc: 0.4181\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6493 - acc: 0.4262 - val_loss: 0.6435 - val_acc: 0.4192\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6490 - acc: 0.4213 - val_loss: 0.6432 - val_acc: 0.4187\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6503 - acc: 0.4311 - val_loss: 0.6459 - val_acc: 0.4837\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6517 - acc: 0.4310 - val_loss: 0.6578 - val_acc: 0.2953\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6513 - acc: 0.4053 - val_loss: 0.6443 - val_acc: 0.4565\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6512 - acc: 0.4373 - val_loss: 0.6455 - val_acc: 0.4787\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6546 - acc: 0.4105 - val_loss: 0.6442 - val_acc: 0.3924\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6525 - acc: 0.4212 - val_loss: 0.6584 - val_acc: 0.5265\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6522 - acc: 0.4325 - val_loss: 0.6450 - val_acc: 0.4684\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6499 - acc: 0.4333 - val_loss: 0.6446 - val_acc: 0.3972\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6505 - acc: 0.4113 - val_loss: 0.6432 - val_acc: 0.4174\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6500 - acc: 0.4301 - val_loss: 0.6446 - val_acc: 0.4636\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6505 - acc: 0.4293 - val_loss: 0.6494 - val_acc: 0.3430\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6543 - acc: 0.4026 - val_loss: 0.6435 - val_acc: 0.4184\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6510 - acc: 0.4367 - val_loss: 0.6464 - val_acc: 0.4756\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6496 - acc: 0.4271 - val_loss: 0.6445 - val_acc: 0.4631\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6489 - acc: 0.4396 - val_loss: 0.6436 - val_acc: 0.4129\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6499 - acc: 0.4325 - val_loss: 0.6434 - val_acc: 0.4167\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6499 - acc: 0.4235 - val_loss: 0.6449 - val_acc: 0.3884\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6491 - acc: 0.4176 - val_loss: 0.6433 - val_acc: 0.4289\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6492 - acc: 0.4375 - val_loss: 0.6437 - val_acc: 0.4203\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6500 - acc: 0.4266 - val_loss: 0.6504 - val_acc: 0.3362\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6510 - acc: 0.4213 - val_loss: 0.6448 - val_acc: 0.4632\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6507 - acc: 0.4411 - val_loss: 0.6438 - val_acc: 0.4082\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6523 - acc: 0.4114 - val_loss: 0.6456 - val_acc: 0.3788\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6503 - acc: 0.4336 - val_loss: 0.6444 - val_acc: 0.4619\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6493 - acc: 0.4300 - val_loss: 0.6461 - val_acc: 0.4732\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6517 - acc: 0.4241 - val_loss: 0.6436 - val_acc: 0.4173\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6491 - acc: 0.4270 - val_loss: 0.6439 - val_acc: 0.4031\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6492 - acc: 0.4305 - val_loss: 0.6441 - val_acc: 0.3981\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6499 - acc: 0.4205 - val_loss: 0.6439 - val_acc: 0.4100\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6492 - acc: 0.4157 - val_loss: 0.6482 - val_acc: 0.4711\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6514 - acc: 0.4436 - val_loss: 0.6440 - val_acc: 0.4525\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6517 - acc: 0.4226 - val_loss: 0.6450 - val_acc: 0.3803\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6508 - acc: 0.4098 - val_loss: 0.6437 - val_acc: 0.4363\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6508 - acc: 0.4315 - val_loss: 0.6439 - val_acc: 0.4477\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6492 - acc: 0.4341 - val_loss: 0.6439 - val_acc: 0.4521\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6491 - acc: 0.4334 - val_loss: 0.6434 - val_acc: 0.4355\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6488 - acc: 0.4244 - val_loss: 0.6434 - val_acc: 0.4230\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6499 - acc: 0.4405 - val_loss: 0.6435 - val_acc: 0.4242\n",
      "on i= 7\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/50\n",
      "100000/100000 [==============================] - 15s 154us/step - loss: 0.6897 - acc: 0.5301 - val_loss: 0.6892 - val_acc: 0.5393\n",
      "Epoch 2/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6885 - acc: 0.5383 - val_loss: 0.6884 - val_acc: 0.5393\n",
      "Epoch 3/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5388 - val_loss: 0.6884 - val_acc: 0.5388\n",
      "Epoch 4/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5389 - val_loss: 0.6886 - val_acc: 0.5390\n",
      "Epoch 5/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5392 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 6/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 7/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5385\n",
      "Epoch 8/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5400 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 10/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 11/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 12/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 13/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 14/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 15/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 16/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5380\n",
      "Epoch 17/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 18/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 19/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 20/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 21/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6887 - val_acc: 0.5383\n",
      "Epoch 22/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 23/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6886 - val_acc: 0.5383\n",
      "Epoch 24/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 25/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 26/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 27/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 28/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5381\n",
      "Epoch 29/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 30/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 31/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5400 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 32/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5381\n",
      "Epoch 33/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6886 - val_acc: 0.5382\n",
      "Epoch 34/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 35/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5398 - val_loss: 0.6886 - val_acc: 0.5381\n",
      "Epoch 36/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5381\n",
      "Epoch 37/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 38/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 39/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 40/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 41/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 42/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6886 - val_acc: 0.5381\n",
      "Epoch 43/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 44/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6886 - val_acc: 0.5383\n",
      "Epoch 45/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 46/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 47/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 48/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 49/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 50/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    200         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_336 (Activation)     (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_336[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_337 (Activation)     (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_337[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_338 (Activation)     (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_3 (TimeDistributed)       (None, None, 1)      129         activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_339 (Activation)     (None, None, 1)      0           tdist_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 1)            0           mask[0][0]                       \n",
      "                                                                 activation_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            2           sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, 1)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,359\n",
      "Trainable params: 23,359\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fe7e2313c18>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e22e1630>\n",
      "<keras.layers.core.Activation object at 0x7fe7e22e1b38>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e2293cf8>\n",
      "<keras.layers.core.Activation object at 0x7fe7e2293be0>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e22518d0>\n",
      "<keras.layers.core.Activation object at 0x7fe7e2251828>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e221c438>\n",
      "<keras.layers.core.Lambda object at 0x7fe7e2313ac8>\n",
      "<keras.layers.core.Activation object at 0x7fe7e221c4a8>\n",
      "<keras.layers.merge.Dot object at 0x7fe7e23139b0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.6656 - acc: 0.3940 - val_loss: 0.6511 - val_acc: 0.5284\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6532 - acc: 0.4405 - val_loss: 0.6460 - val_acc: 0.3823\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6536 - acc: 0.4174 - val_loss: 0.6496 - val_acc: 0.5186\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6535 - acc: 0.4142 - val_loss: 0.6436 - val_acc: 0.4200\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6519 - acc: 0.4342 - val_loss: 0.6555 - val_acc: 0.3071\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6550 - acc: 0.3930 - val_loss: 0.6465 - val_acc: 0.4654\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6511 - acc: 0.4273 - val_loss: 0.6514 - val_acc: 0.3319\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6548 - acc: 0.4091 - val_loss: 0.6455 - val_acc: 0.4621\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6512 - acc: 0.4224 - val_loss: 0.6433 - val_acc: 0.4228\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6538 - acc: 0.4252 - val_loss: 0.6501 - val_acc: 0.3394\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6501 - acc: 0.4151 - val_loss: 0.6440 - val_acc: 0.4527\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6500 - acc: 0.4239 - val_loss: 0.6433 - val_acc: 0.4273\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6512 - acc: 0.4208 - val_loss: 0.6462 - val_acc: 0.3795\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6502 - acc: 0.4380 - val_loss: 0.6435 - val_acc: 0.4342\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6499 - acc: 0.4159 - val_loss: 0.6450 - val_acc: 0.3987\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6514 - acc: 0.4388 - val_loss: 0.6466 - val_acc: 0.3690\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6513 - acc: 0.4074 - val_loss: 0.6467 - val_acc: 0.4813\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6499 - acc: 0.4295 - val_loss: 0.6456 - val_acc: 0.4603\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6498 - acc: 0.4276 - val_loss: 0.6445 - val_acc: 0.4023\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6491 - acc: 0.4327 - val_loss: 0.6439 - val_acc: 0.4134\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6514 - acc: 0.4210 - val_loss: 0.6438 - val_acc: 0.4484\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6520 - acc: 0.4192 - val_loss: 0.6453 - val_acc: 0.4523\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6509 - acc: 0.4292 - val_loss: 0.6436 - val_acc: 0.4202\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6498 - acc: 0.4161 - val_loss: 0.6434 - val_acc: 0.4316\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6512 - acc: 0.4353 - val_loss: 0.6444 - val_acc: 0.4024\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6524 - acc: 0.4025 - val_loss: 0.6472 - val_acc: 0.4705\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6533 - acc: 0.4241 - val_loss: 0.6470 - val_acc: 0.3653\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6506 - acc: 0.4228 - val_loss: 0.6463 - val_acc: 0.4669\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6493 - acc: 0.4257 - val_loss: 0.6440 - val_acc: 0.4112\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6498 - acc: 0.4292 - val_loss: 0.6492 - val_acc: 0.4685\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6509 - acc: 0.4215 - val_loss: 0.6457 - val_acc: 0.3858\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6537 - acc: 0.4193 - val_loss: 0.6497 - val_acc: 0.4802\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6515 - acc: 0.4151 - val_loss: 0.6454 - val_acc: 0.3920\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6520 - acc: 0.4250 - val_loss: 0.6472 - val_acc: 0.4589\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 0s 16us/step - loss: 0.6533 - acc: 0.4190 - val_loss: 0.6492 - val_acc: 0.3488\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6507 - acc: 0.4193 - val_loss: 0.6468 - val_acc: 0.4696\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6521 - acc: 0.4239 - val_loss: 0.6434 - val_acc: 0.4154\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6504 - acc: 0.4148 - val_loss: 0.6500 - val_acc: 0.4925\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6506 - acc: 0.4434 - val_loss: 0.6442 - val_acc: 0.4041\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6513 - acc: 0.4121 - val_loss: 0.6436 - val_acc: 0.4443\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6502 - acc: 0.4279 - val_loss: 0.6434 - val_acc: 0.4181\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6510 - acc: 0.4129 - val_loss: 0.6437 - val_acc: 0.4315\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6490 - acc: 0.4314 - val_loss: 0.6546 - val_acc: 0.4891\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6536 - acc: 0.4254 - val_loss: 0.6454 - val_acc: 0.3817\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6507 - acc: 0.4289 - val_loss: 0.6435 - val_acc: 0.4402\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6492 - acc: 0.4259 - val_loss: 0.6433 - val_acc: 0.4291\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6493 - acc: 0.4285 - val_loss: 0.6491 - val_acc: 0.3481\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6503 - acc: 0.4123 - val_loss: 0.6436 - val_acc: 0.4446\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6513 - acc: 0.4366 - val_loss: 0.6446 - val_acc: 0.4633\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6514 - acc: 0.4166 - val_loss: 0.6435 - val_acc: 0.4088\n",
      "on i= 8\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/50\n",
      "100000/100000 [==============================] - 16s 157us/step - loss: 0.6917 - acc: 0.5191 - val_loss: 0.6886 - val_acc: 0.5391\n",
      "Epoch 2/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6886 - acc: 0.5382 - val_loss: 0.6886 - val_acc: 0.5394\n",
      "Epoch 3/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5385 - val_loss: 0.6884 - val_acc: 0.5393\n",
      "Epoch 4/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5388 - val_loss: 0.6884 - val_acc: 0.5390\n",
      "Epoch 5/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5384 - val_loss: 0.6885 - val_acc: 0.5391\n",
      "Epoch 6/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5393 - val_loss: 0.6884 - val_acc: 0.5385\n",
      "Epoch 7/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5393 - val_loss: 0.6885 - val_acc: 0.5388\n",
      "Epoch 8/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5385\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 10/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 11/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 12/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 13/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5385\n",
      "Epoch 14/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 15/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 16/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 17/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 18/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5384\n",
      "Epoch 19/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 20/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 21/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 22/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 23/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 24/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 25/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 26/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 27/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 28/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 29/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6886 - val_acc: 0.5382\n",
      "Epoch 30/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 31/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6886 - val_acc: 0.5383\n",
      "Epoch 32/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 33/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 34/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 35/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 36/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 37/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 38/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 39/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 40/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 41/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6886 - val_acc: 0.5383\n",
      "Epoch 42/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 43/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 44/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5381\n",
      "Epoch 45/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 46/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 47/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 48/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 49/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 50/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    200         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_341[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_342[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_3 (TimeDistributed)       (None, None, 1)      129         activation_343[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, None, 1)      0           tdist_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 1)            0           mask[0][0]                       \n",
      "                                                                 activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            2           sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 1)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,359\n",
      "Trainable params: 23,359\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fe7e1739f60>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e16936a0>\n",
      "<keras.layers.core.Activation object at 0x7fe7e1693f98>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e165d860>\n",
      "<keras.layers.core.Activation object at 0x7fe7e165d7b8>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e162b320>\n",
      "<keras.layers.core.Activation object at 0x7fe7e162b390>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e15cdd30>\n",
      "<keras.layers.core.Lambda object at 0x7fe7e16df7f0>\n",
      "<keras.layers.core.Activation object at 0x7fe7e15cdc18>\n",
      "<keras.layers.merge.Dot object at 0x7fe7e16df5c0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 1.0718 - acc: 0.2439 - val_loss: 0.8602 - val_acc: 0.1612\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.7843 - acc: 0.2374 - val_loss: 0.6634 - val_acc: 0.5912\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6784 - acc: 0.5095 - val_loss: 0.6496 - val_acc: 0.3390\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6620 - acc: 0.3456 - val_loss: 0.6438 - val_acc: 0.3947\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6524 - acc: 0.4489 - val_loss: 0.6479 - val_acc: 0.3623\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6534 - acc: 0.4011 - val_loss: 0.6438 - val_acc: 0.4252\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6499 - acc: 0.4389 - val_loss: 0.6445 - val_acc: 0.3948\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6492 - acc: 0.4161 - val_loss: 0.6455 - val_acc: 0.4779\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6510 - acc: 0.4262 - val_loss: 0.6458 - val_acc: 0.3805\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6511 - acc: 0.4243 - val_loss: 0.6433 - val_acc: 0.4214\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6492 - acc: 0.4257 - val_loss: 0.6437 - val_acc: 0.4450\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6501 - acc: 0.4282 - val_loss: 0.6439 - val_acc: 0.4279\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6499 - acc: 0.4374 - val_loss: 0.6534 - val_acc: 0.3181\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6569 - acc: 0.4124 - val_loss: 0.6514 - val_acc: 0.3309\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6548 - acc: 0.4070 - val_loss: 0.6451 - val_acc: 0.3847\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6505 - acc: 0.4304 - val_loss: 0.6458 - val_acc: 0.3849\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6528 - acc: 0.4210 - val_loss: 0.6498 - val_acc: 0.4762\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6579 - acc: 0.4185 - val_loss: 0.6436 - val_acc: 0.4036\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6511 - acc: 0.4001 - val_loss: 0.6582 - val_acc: 0.5419\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6546 - acc: 0.4313 - val_loss: 0.6435 - val_acc: 0.4041\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6493 - acc: 0.4231 - val_loss: 0.6454 - val_acc: 0.4692\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6512 - acc: 0.4240 - val_loss: 0.6459 - val_acc: 0.4660\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6531 - acc: 0.4294 - val_loss: 0.6463 - val_acc: 0.3725\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6544 - acc: 0.4204 - val_loss: 0.6692 - val_acc: 0.2479\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6581 - acc: 0.4042 - val_loss: 0.6435 - val_acc: 0.4343\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6516 - acc: 0.4263 - val_loss: 0.6441 - val_acc: 0.3960\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6542 - acc: 0.4096 - val_loss: 0.6442 - val_acc: 0.4548\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6708 - acc: 0.3910 - val_loss: 0.6545 - val_acc: 0.4498\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6610 - acc: 0.4004 - val_loss: 0.6516 - val_acc: 0.5391\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6564 - acc: 0.4322 - val_loss: 0.6565 - val_acc: 0.3092\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6571 - acc: 0.4160 - val_loss: 0.6511 - val_acc: 0.3314\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6521 - acc: 0.4145 - val_loss: 0.6498 - val_acc: 0.3428\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6513 - acc: 0.4244 - val_loss: 0.6494 - val_acc: 0.3422\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6509 - acc: 0.4236 - val_loss: 0.6437 - val_acc: 0.4207\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6494 - acc: 0.4332 - val_loss: 0.6465 - val_acc: 0.3713\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6516 - acc: 0.4321 - val_loss: 0.6468 - val_acc: 0.3612\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6501 - acc: 0.4117 - val_loss: 0.6465 - val_acc: 0.3917\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6532 - acc: 0.4161 - val_loss: 0.6477 - val_acc: 0.3566\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6574 - acc: 0.4258 - val_loss: 0.6442 - val_acc: 0.4544\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6552 - acc: 0.4155 - val_loss: 0.6594 - val_acc: 0.2881\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6543 - acc: 0.4161 - val_loss: 0.6436 - val_acc: 0.4169\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6554 - acc: 0.4283 - val_loss: 0.6442 - val_acc: 0.4173\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6539 - acc: 0.4050 - val_loss: 0.6502 - val_acc: 0.3437\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6620 - acc: 0.4220 - val_loss: 0.7201 - val_acc: 0.1418\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6707 - acc: 0.3869 - val_loss: 0.6793 - val_acc: 0.2040\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6715 - acc: 0.3813 - val_loss: 0.6683 - val_acc: 0.2501\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6579 - acc: 0.4111 - val_loss: 0.6479 - val_acc: 0.3596\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6512 - acc: 0.4209 - val_loss: 0.6456 - val_acc: 0.3775\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6494 - acc: 0.4269 - val_loss: 0.6437 - val_acc: 0.4153\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6492 - acc: 0.4250 - val_loss: 0.6435 - val_acc: 0.4182\n",
      "on i= 9\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/50\n",
      "100000/100000 [==============================] - 16s 161us/step - loss: 0.6889 - acc: 0.5387 - val_loss: 0.6889 - val_acc: 0.5391\n",
      "Epoch 2/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6884 - acc: 0.5387 - val_loss: 0.6885 - val_acc: 0.5390\n",
      "Epoch 3/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5385 - val_loss: 0.6885 - val_acc: 0.5393\n",
      "Epoch 4/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5385 - val_loss: 0.6885 - val_acc: 0.5394\n",
      "Epoch 5/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5380 - val_loss: 0.6884 - val_acc: 0.5387\n",
      "Epoch 6/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5388 - val_loss: 0.6885 - val_acc: 0.5384\n",
      "Epoch 7/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5385\n",
      "Epoch 8/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5392 - val_loss: 0.6884 - val_acc: 0.5385\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5384\n",
      "Epoch 10/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 11/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 12/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 13/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 14/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 15/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 16/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 17/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5384\n",
      "Epoch 18/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 19/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6886 - val_acc: 0.5384\n",
      "Epoch 20/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 21/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 22/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5395 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 23/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 24/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 25/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5399 - val_loss: 0.6886 - val_acc: 0.5383\n",
      "Epoch 26/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 27/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 28/50\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 29/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 30/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5381\n",
      "Epoch 31/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5400 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 32/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 33/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "Epoch 34/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 35/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5384\n",
      "Epoch 36/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5394 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 37/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6886 - val_acc: 0.5383\n",
      "Epoch 38/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5384\n",
      "Epoch 39/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6883 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 40/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 41/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 42/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5398 - val_loss: 0.6885 - val_acc: 0.5381\n",
      "Epoch 43/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 44/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 45/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 46/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5383\n",
      "Epoch 47/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 48/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5397 - val_loss: 0.6886 - val_acc: 0.5383\n",
      "Epoch 49/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5396 - val_loss: 0.6884 - val_acc: 0.5383\n",
      "Epoch 50/50\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.6882 - acc: 0.5399 - val_loss: 0.6885 - val_acc: 0.5382\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    200         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_3 (TimeDistributed)       (None, None, 1)      129         activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, None, 1)      0           tdist_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 1)            0           mask[0][0]                       \n",
      "                                                                 activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            2           sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 1)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,359\n",
      "Trainable params: 23,359\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fe7e0945dd8>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e0919860>\n",
      "<keras.layers.core.Activation object at 0x7fe7e0919ba8>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e08cbbe0>\n",
      "<keras.layers.core.Activation object at 0x7fe7e08cbe48>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e088dc18>\n",
      "<keras.layers.core.Activation object at 0x7fe7e088db00>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe7e0852898>\n",
      "<keras.layers.core.Lambda object at 0x7fe7e0945978>\n",
      "<keras.layers.core.Activation object at 0x7fe7e08527f0>\n",
      "<keras.layers.merge.Dot object at 0x7fe7e0945cf8>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.7881 - acc: 0.2273 - val_loss: 0.7040 - val_acc: 0.1394\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6689 - acc: 0.4189 - val_loss: 0.6664 - val_acc: 0.5233\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6582 - acc: 0.4140 - val_loss: 0.6512 - val_acc: 0.3289\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 0s 13us/step - loss: 0.6508 - acc: 0.4216 - val_loss: 0.6467 - val_acc: 0.4737\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6502 - acc: 0.4295 - val_loss: 0.6443 - val_acc: 0.3942\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6492 - acc: 0.4272 - val_loss: 0.6437 - val_acc: 0.4447\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6487 - acc: 0.4223 - val_loss: 0.6435 - val_acc: 0.4205\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6485 - acc: 0.4279 - val_loss: 0.6435 - val_acc: 0.4400\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6487 - acc: 0.4301 - val_loss: 0.6433 - val_acc: 0.4230\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6487 - acc: 0.4219 - val_loss: 0.6436 - val_acc: 0.4444\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6487 - acc: 0.4308 - val_loss: 0.6434 - val_acc: 0.4166\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6487 - acc: 0.4275 - val_loss: 0.6434 - val_acc: 0.4308\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6488 - acc: 0.4374 - val_loss: 0.6439 - val_acc: 0.4018\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6492 - acc: 0.4115 - val_loss: 0.6447 - val_acc: 0.4602\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6496 - acc: 0.4223 - val_loss: 0.6437 - val_acc: 0.4135\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6496 - acc: 0.4359 - val_loss: 0.6436 - val_acc: 0.4145\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6489 - acc: 0.4356 - val_loss: 0.6434 - val_acc: 0.4245\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 0s 16us/step - loss: 0.6489 - acc: 0.4219 - val_loss: 0.6437 - val_acc: 0.4462\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6489 - acc: 0.4207 - val_loss: 0.6433 - val_acc: 0.4213\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6487 - acc: 0.4379 - val_loss: 0.6435 - val_acc: 0.4407\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6489 - acc: 0.4244 - val_loss: 0.6435 - val_acc: 0.4396\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6486 - acc: 0.4296 - val_loss: 0.6435 - val_acc: 0.4174\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6490 - acc: 0.4304 - val_loss: 0.6435 - val_acc: 0.4380\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6491 - acc: 0.4187 - val_loss: 0.6440 - val_acc: 0.4522\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6495 - acc: 0.4314 - val_loss: 0.6440 - val_acc: 0.4055\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6489 - acc: 0.4358 - val_loss: 0.6434 - val_acc: 0.4187\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6489 - acc: 0.4314 - val_loss: 0.6437 - val_acc: 0.4087\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6493 - acc: 0.4303 - val_loss: 0.6441 - val_acc: 0.4016\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6494 - acc: 0.4252 - val_loss: 0.6433 - val_acc: 0.4228\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6496 - acc: 0.4312 - val_loss: 0.6435 - val_acc: 0.4295\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6494 - acc: 0.4212 - val_loss: 0.6439 - val_acc: 0.4508\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6489 - acc: 0.4207 - val_loss: 0.6434 - val_acc: 0.4362\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6488 - acc: 0.4343 - val_loss: 0.6437 - val_acc: 0.4068\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6492 - acc: 0.4282 - val_loss: 0.6441 - val_acc: 0.4534\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6498 - acc: 0.4234 - val_loss: 0.6445 - val_acc: 0.4625\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 0s 15us/step - loss: 0.6491 - acc: 0.4244 - val_loss: 0.6434 - val_acc: 0.4334\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6486 - acc: 0.4345 - val_loss: 0.6433 - val_acc: 0.4329\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6490 - acc: 0.4227 - val_loss: 0.6434 - val_acc: 0.4366\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6486 - acc: 0.4298 - val_loss: 0.6436 - val_acc: 0.4279\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6488 - acc: 0.4372 - val_loss: 0.6436 - val_acc: 0.4210\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6491 - acc: 0.4200 - val_loss: 0.6432 - val_acc: 0.4227\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6488 - acc: 0.4166 - val_loss: 0.6436 - val_acc: 0.4444\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6490 - acc: 0.4314 - val_loss: 0.6435 - val_acc: 0.4345\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6496 - acc: 0.4365 - val_loss: 0.6456 - val_acc: 0.3807\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6493 - acc: 0.4338 - val_loss: 0.6432 - val_acc: 0.4201\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6495 - acc: 0.4207 - val_loss: 0.6438 - val_acc: 0.4483\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6485 - acc: 0.4304 - val_loss: 0.6434 - val_acc: 0.4175\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6489 - acc: 0.4272 - val_loss: 0.6436 - val_acc: 0.4082\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6498 - acc: 0.4320 - val_loss: 0.6440 - val_acc: 0.4057\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.6494 - acc: 0.4186 - val_loss: 0.6437 - val_acc: 0.4459\n"
     ]
    }
   ],
   "source": [
    "#Let's do this many times !\n",
    "\n",
    "yvals_1d = []\n",
    "yvals_nd = []\n",
    "for i in range(10):\n",
    "    \n",
    "    print(\"on i=\",i)\n",
    "\n",
    "    model1D_repeat = Sequential()\n",
    "    model1D_repeat.add(Dense(128, activation='relu',input_shape =(1,))) \n",
    "    model1D_repeat.add(Dense(128, activation='relu'))\n",
    "    model1D_repeat.add(Dense(1, activation='sigmoid'))\n",
    "    model1D_repeat.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    hist_model1D_repeat = model1D_repeat.fit(X_1D_train, Y_1D_train, epochs=50, batch_size=int(0.1*len(X_1D_train)),validation_data=(X_1D_val, Y_1D_val))\n",
    "\n",
    "    #Train 1 from N\n",
    "\n",
    "    pfn_Gaussian_repeat = PFN(input_dim=X_nD_val_pfn.shape[-1], Phi_sizes=Phi_sizes_Gaussian, F_sizes=F_sizes_Gaussian, F_acts='linear', output_dim=1, output_act='linear', Phi_acts=['relu','relu','relu','linear'])\n",
    "\n",
    "    pfn_Gaussian_repeat.model.layers.pop()\n",
    "    pfn_Gaussian_repeat.model.layers.pop()\n",
    "    for layer in pfn_Gaussian_repeat.model.layers:\n",
    "        print(layer)\n",
    "    pfn_Gaussian_repeat.model.compile(loss=lambda y_true, y_pred: myloss_many(y_true, y_pred), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    historyf_Gaussian = pfn_Gaussian_repeat.fit(X_nD_train_pfn, Y_nD_train,\n",
    "              epochs=50,\n",
    "              batch_size=int(0.1*len(X_nD_train_pfn)),\n",
    "              validation_data=(X_nD_val_pfn, Y_nD_val),\n",
    "              verbose=1)\n",
    "\n",
    "    ## Evaluate\n",
    "\n",
    "    myx = np.linspace(-5,5,1000)\n",
    "    xx_vals = np.reshape(myx,[100,10,1])\n",
    "    myPhi_Gaussian_repeat = Model(input = pfn_Gaussian_repeat.model.input,output = pfn_Gaussian_repeat.model.layers[-2].output)\n",
    "    myPhi_preds_Gaussian = myPhi_Gaussian_repeat.predict(xx_vals,batch_size=int(0.1*len(xx_vals)))\n",
    "    preds_Phi_Gaussian = np.reshape(myPhi_preds_Gaussian,[n*len(myPhi_preds_Gaussian)])\n",
    "    preds_1D_Phi_Gaussian = model1D_repeat.predict(np.linspace(-5,5,1000))\n",
    "    \n",
    "    yvals_1d+=[preds_1D_Phi_Gaussian]\n",
    "    yvals_nd+=[preds_Phi_Gaussian]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    200         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_3 (TimeDistributed)       (None, None, 1)      129         activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, None, 1)      0           tdist_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 1)            0           mask[0][0]                       \n",
      "                                                                 activation_349[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 23,357\n",
      "Trainable params: 23,357\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pfn_Gaussian_repeat.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvals_nd = np.array(yvals_nd)\n",
    "yvals_1d = np.array(yvals_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_1d = np.array([np.mean(yvals_1d[:,i]/(1.-yvals_1d[:,i])) for i in range(len(myx))])\n",
    "spread_1d = np.array([np.std(yvals_1d[:,i]/(1.-yvals_1d[:,i])) for i in range(len(myx))])\n",
    "central_nd = np.array([np.mean(np.exp(yvals_nd[:,i])) for i in range(len(myx))])\n",
    "spread_nd = np.array([np.std(np.exp(yvals_nd[:,i])) for i in range(len(myx))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe7ba9bacf8>]"
      ]
     },
     "execution_count": 920,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD3CAYAAAANMK+RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3iUVdrH8e9J7z0hQBoJvSOhhI4ouGIFFZEF0UVEXUXdXVff9d21veoWC7irLmJvoIiKstKlSE/oPZQ0ICEQUiipc94/niGySAlkZp4p9+e6coWZeZLnHr38eThzzn2U1hohhBCuz8vsAoQQQtiGBLoQQrgJCXQhhHATEuhCCOEmJNCFEMJN+Jh145iYGJ2SkmLW7YUQwiVlZWUd1VrHnu810wI9JSWFzMxMs24vhBAuSSmVe6HXZMpFCCHchAS6EEK4CQl0IYRwExLoQgjhJiTQhRDCTUigCyGEm5BAF0IINyGBLoQQjrT0r3Boo11+tWkbi4QQwuPsmQ9LXwRLDTTrZvNfLyN0IYRwhFMlMOdhiOsAA56wyy1khC6EEI4w93dGqI+ZBT5+drmFjNCFEMLetn0F22fDoD9C0852u40EuhBC2FNFoTE6b94d+j5m11tJoAshhL1oDXMegZrTcMvb4G3fWW6ZQxdCCHvZ+DFkz4frXobY1na/nYzQhRDCHo7nwrynIKU/9LzfIbeUQBdCCFuzWODbhwAFN/8LvBwTtTLlIoQQtrbu35CzAm56AyKTHXZbGaELIYQtHdkFi56BVsOg21iH3loCXQghbKW2Cr6aAH4hxuhcKYfeXqZchBDCVhY/B0VbYfRMCG3i8NvLCF0IIWxh3xJY/U/oMQHaXGdKCRLoQgjRWCePwdcPQEwbuPZ508qQKRchhGgMrY0uiqdLYMyX4BdkWimXDHSlVBrwArABSACOaa2fO+ea8cAkoNL61Lta649tW6oQQjihrA9g91wY+n92bbzVEA0ZoUcBM7TW3wIopXYopeZqrbPOue5OrXWOrQsUQginVbzH2A2aOgh6P2h2NZcOdK31+nOe8gJOnufS3yqlCoEg4J9a6xIb1CeEEM6pthpmTwDfAKPxloN2g17MZc2hK6VuBeZrrXed89IyYK7WulgpdT3wJTDkPD8/EZgIkJSUdGUVCyGEM1j8LBzeDKM+gbCmZlcDXMYqF6XUYGAw8IuGvlrrA1rrYuvDJcBApZT3ea6bprVO11qnx8bGXmnNQghhrt3zfl6i2O5Gs6up16BAV0oNB4YBk4F4pVSGUipKKRVmff0lpdSZ0X4r4IDWus4uFQshhJnKDsI3k6BJJ+ODUCfSkFUu3YGZQCbwIxAM/Au4FSgBXgYKgbeUUgeAToBjGxgIIYQj1NXCV78x5s9v/8CYP3ciDflQNAsIucQ1U2xWkRBCOKulL0HeahjxDsS0NLuaXzD/Y1khhHAF+5bAileMDoqd7zC7mvOSQBdCiEupKILZEyG2Dfzqb2ZXc0Gy9V8IIS7GUmesN686AXd/Z+rW/kuRQBdCiItZ8QocWA43/RPi2pldzUXJlIsQQlzIviXw44vQ6Q7o9muzq7kkCXQhhDifsgLj9KHYtnDj6w4/fehKSKALIcS5aqvhi7uN76M+Br9gsytqEJlDF0KIc83/HziYCXd8BDGtzK6mwWSELoQQZ9vyBax/BzJ+C+1vNruayyKBLoQQZxTtgO8mQ1IfuOYZs6u5bBLoQggBUFkOX4wF/1C4/X3w9jW7ossmc+hCCKE1fPsQlBwwNg+Fxptd0RWRQBdCiJWvw845cO3zkNLX7GqumEy5CCE8W/ZCWPQsdBwJfR42u5pGkUAXQniuo3th1m8gvqOxtd8FNg9djAS6EMIzVZbDjLvA2wfu/Mypm241lMyhCyE8j8VitMM9thfGfQsR7nFovQS6EMLzLH0J9vxg9DZv0d/samxGplyEEJ5lxxxY/jfo+mvoOdHsamxKAl0I4TmKdsDXk6B5Otzwqst/CHouCXQhhGc4eQxmjDZ2go76BHz8za7I5mQOXQjh/mqrYOYYqCiE8XMhrKnZFdmFBLoQwr1pbTTcylsNt70PCelmV2Q3MuUihHBvK16BzZ/D4D9BxxFmV2NXEuhCCPe1/RtY8jx0uh0G/MHsauxOAl0I4Z4OZhkrWhJ7ucW2/oaQQBdCuJ+yAvh8NITEwqhPwTfA7IocQj4UFUK4l6oT8NmdUH3K2NYfEmt2RQ4jgS6EcB91tTDrXjiyHe76EuLamV2RQ0mgCyHcg9Yw93HIng/DX4VW15hdkcPJHLoQwj2s+Ads+BD6PQ49fmN2NaaQQBdCuL5Nn8GSF6DzKBjyZ7OrMY0EuhDCte1bAnMehhYDPWZ54oW4XKBX1dYxK6sArbXZpQghzHZ4C8wcBzFtYNTH4ONndkWmuuSHokqpNOAFYAOQABzTWj93zjUBwD+Ag0Ar4GWt9R7blwtfbzjIk7O3smhHEX+7vTNhAb72uI0QwtmV5sOnt0NAGIz5EgLCza7IdA0ZoUcBM7TWf9daTwbuVEp1P+eaR4E8rfVLwGvAuzaus96oHok8PbwdC3cWcdMbP7HzcLm9biWEcFanj8Ont0HNaRgzC8Kbm12RU7hkoGut12utvz3nZ06ec9lwYLX1+q1AF6VUmM2qPItSign9U/n8vt6cqq7j1jdXMiurwB63EkI4o+qT8NkoKNkPd34CTdqbXZHTuKw5dKXUrcB8rfWuc16KAyrOelxufe7cn5+olMpUSmUWFxdfdrFn69kiiu8f6UfXxAh+/+Vmnpq9hcqaukb9TiGEk6uthi/GQcF6GDkdWgwwuyKn0uBAV0oNBgYDj53n5SNA6FmPw6zP/Ret9TStdbrWOj02tvHbceNCA/jkN714YFAan6/L57a3V5FfcqrRv1cI4YQsFvjmAdi7CG54DdrfbHZFTqdBga6UGg4MAyYD8UqpDKVU1FnTKnOBDOu1nYDNWmuHTG77eHvxx+va8s64dHKPnWL41BUs2lHkiFsLIRxFa/jhCdg2C4b8BbqPN7sip3TJQLd+ADoT6A38CHwLtAGeBB60XjYFSFZKPQ38DnD4Nq1r2zdh7sP9SYwKYsJHmfx13i5q6yyOLkMIYQ9LX4b170DGb6Hf+SYJBIAyaz13enq6zszMtPnvrayp45k525mxPp/05Eimju5Gs4hAm99HCOEga/9tjM67joGb/+XRG4cAlFJZWuvznqPnchuLLiXA15uXR3bm9VFd2Xm4nOunrmChTMEI4Zq2fGmEeZvhcONUjw/zS3G7QD/jlm7N+f6R/jSPCOS+jzJ59rvtVNXKKhghXMauufD1/ZDcD257D7ylOeyluG2gA7SICWb2g30Y3yeF91fmMPKtVeQcPXcJvRDC6WQvgi/HQ7OuMPpzjzlxqLHcOtAB/H28eeamDvx7bHfyS05zwxs/8e2mg2aXJYS4kP3LYOYYiG0Dv/7K2NovGsTtA/2MYR3i+c/k/rSJD2XyjE08+dUWTlfLFIwQTiVvjXEWaGQKjP0GAiPNrsileEygAzSPCGTGxN48NDiNmZn53PRP6QUjhNM4uMFothUaD+PmQHCM2RW5HI8KdABfby/+MKwtH93bk9LTNdz8z5VMX7Efi0Xa8QphmsKt8PGtEBgBd8+B0CZmV+SSPC7Qz+jfKpZ5k/szoHUsL8zdybj31lFUXml2WUJ4nuLd8NEt4BsEd38H4QlmV+SyPDbQAaJD/HlnXHdevLUTWbnHGfb6cuZtO2x2WUJ4juLd8MENoLyMMI9MMbsil+bRgQ5GO967eiXx/SP9SIwMYtInG3hi1mZOVtWaXZoQ7u3ILvhguPHn8d9DTEtz63EDHh/oZ6TFhvDVA314cFAaX2YVcP3UFWzMO252WUK4p6IdRpgrLxg/11iiKBpNAv0sfj5ePHFdW2bc15vaOs1tb69m6uJsafIlhC0VbYcPbwQvH2uYtza7IrchgX4evVKj+c/k/tzQuSmvLtzDyLdXs/fICbPLEsL1FW4zwtzb1wjzmFZmV+RWJNAvIDzQlyl3dmPq6G7kHjvJ8KkrePenA7K8UYgrVbjVGub+1jCXOXNbk0C/hJu6NGPBowPo1zKG57/fweh31sipSEJcrsNbjDD3DTQ+AI1OM7sitySB3gBxYQFMvzudv93Wme2Hyhn2+nI+W5uHWb3khXAp+evhwxvAN1jC3M4k0BtIKcUd6YnMf2wA3ZIi+J+vt3L3++s5XHba7NKEcF77l8FHN0NgFNz7A0Slml2RW5NAv0zNIwL5+N5ePH9zB9YfKGHoa8uZvaFARutCnGv3PKM3S0QS3DvP+C7sSgL9Cnh5KcZmpPDD5P60jQ/l8S82c99HmRSWSesAIQDY9pXRArdJe7jnP0bDLWF3EuiNkBITzIyJGTw9vB0/7T3Kta8u4/N1MrcuPNyGj2DWbyChp9E1MSjK7Io8hgR6I3l7KSb0T2X+owPo2Dycp2Zv5a531pJ7TE5GEh5o9Zsw52FIu1oOpzCBBLqNJEcH89l9vXhpRCe2HSxj2OvLmb5iP3Wybl14Aq1h6V9h/lPQ7kbj2Di/ILOr8jgS6DaklGJ0zyQWPD6AvmkxvDB3JyPeWsWeogqzSxPCfix1MPd3sPRF6DIabvsAfPzNrsojSaDbQdPwQKbfnc6UO7uSX3KK4VNXMGVRNtW10hNGuJmaSuMw58x3oe9kuOUt8PYxuyqPJYFuJ0opbu7anIWPDeBXHZvy2qI93PjGT2TllphdmhC2UVkGn4yEnXNg2Itw7XOglNlVeTQJdDuLDvFn6uhuTB+XTkVlDSPfWs1Ts7dSdqrG7NKEuHLlh+H96yF/DYx4BzIeMrsiAcjfjRzkmvZNyEiL5rWFe3h/VQ4LdxTyvze056YuzVAyqhGu5Ohe4/zPU8fgri+g5RCzKxJWMkJ3oGB/H56+oT1zftuX5pFBTJ6xibHvriPnqCxxFC6iIAveGwo1J2H8dxLmTkYC3QQdmoUz+4E+PHdzBzbnlzL09eW8sTibqto6s0sT4sJ2zTVOGfILhnsXQPPuZlckziGBbhJvL8W4jBQW/W4g17ZvwisL93D9lBWs2X/M7NKE+G9aGxuGZoyBuHYwYbH0MndSEugmaxIWwL/uuor37+lBVa2FO6et4fGZmzhSLn1hhBOw1MEPTxgbhtoONw6mCIkzuypxARLoTmJwmzgWPjaQhwan8f2Ww1z9yjKmr9hPjZxnKsxSdQJm3AXrpkHGb+GOj2T3p5OTQHcigX7e/GFYW+Y/NoDuyZG8MHcnw6euYPU+mYYRDlZ+GD64HrIXwPBXYNj/gZe32VWJS5BAd0ItYoL54J4eTBvbnVPVdYx+Zw0Pf75RDtMQjlG0HaZfA8f2weiZ0GOC2RWJBrpkoCul4pVS05VS6y/w+iCl1Cal1FLr1x9sX6bnUUoxtEM8ix4fyOQhrZi/vZAhryzjraX7pIWAsJ/d8+DdYaDr4J4foPVQsysSl6EhI/R+wLfAxXa/PKq1HmT9+rttShMAAb7ePHZtaxY9NpA+aTH8dd4urnt9Ocv3FJtdmnAnWsNPr8Hndxpnfk5YDE07m12VuEyXDHSt9SzgUu0Cxyqlfq+Uek4plWib0sTZkqKDmH53Ou+P70Gd1ox7bx0TPlzP/uITZpcmXF3NaZg9ERY9Ax1HGCPz8OZmVyWugGrI6TpKqUHAP7TW6ed5LQ4I0lrnKKU6AF8B7bXWv5gXUEpNBCYCJCUldc/NzW1k+Z6pqraO91fm8M8le6msqWNcRgqTh7QiPMjX7NKEqyk/ZKwvP7QBrn4a+v9eGmw5OaVU1vmyGGwQ6Oe5thDopbW+aFqnp6frzMzMS95bXFhxRRWvLtzNjPX5hAf68tg1rbmrVxK+3vJZt2iAgixjWWJVBYx8x1hnLpzexQL9iv7LV0oFK6VirX9+UikVZf1zFOAHFF1psaLhYkP9eWlEZ+Y+3J928WH8Zc52fjVlBUt3HzG7NOHsNs+E938FPn4wYaGEuZtoyCqXgcBYoKlS6mmlVCAwHnjeekkOMEUp9RQwBRirtZZtjg7UvlkYn93Xi2lju1NbZ2H8++sZ//469h6Rk5LEOepqYf6f4OuJkJAO9/0ITTqYXZWwkQZNudiDTLnYR3WthY9W5zBlcTanqusY0yuJyUNaER0iR4J5vBNH4Mt7IPcn6HGfcSiFj5/ZVYnL1Og5dHuQQLevYyeqeH1RNp+uzSXIz4dJA1O5t18LgvykBb5Hyl8HX4yD06Vw4+vQ5U6zKxJXSALdg+09coK/zdvFgh1FxIX689i1rbm9ewI+8sGpZ9Aa1k+HeU8ZSxFHfQLxncyuSjSCBLogM6eEl37YRVbucdJig/njdW25tn0TOS3JndWchu8fg82fQ6uhMGIaBEaaXZVoJJuvchGuJz0lilmTMvj32O5oYOLHWdz+9mqyco+bXZqwh5ID8O61sHkGDHrK6MkiYe72ZITugWrrLMzMzOf1RdkUV1QxrEMTnriuLWmxIWaXJmxhxxz49rdGs44R06Ufi5uRKRdxXqeqa5m+4gD/XraPyloLt12VwMNDWpIQKT2vXVJtFSx42uhf3uwquP19iEwxuyphYxLo4qKOnqjiXz/u5dM1eQCM7pnIQ1e3JC40wOTKRIMd2wez7oHDm6H3Q3DNM7Ik0U1JoIsGOVR6mjeWZPNFZgG+3oq7+6QwaUAakcESDE5t22yY84hxAMUtb0Hb682uSNiRBLq4LDlHTzJlcTbfbDpIsJ8Pv+nXggn9WxAaIM2/nEpNpXHWZ+Z7kNADbnsPIpLMrkrYmQS6uCJ7iip4dcEe5m0vJCLIl0kD07g7I4VAPzmKzHTFe2DWvVC0Ffo8AkP+DN7yP1xPIIEuGmVrQRmvLNzN0t3FxIT48+CgNO7qlUSArwS7w2ltjMjn/wl8A+HWt6H1MLOrEg4kgS5sYn1OCa8s2M2a/SXEhPgzaWAqY3oly4jdUU4eNZYj7vkB0q425stD482uSjiYBLqwqTX7jzF1cTar9h0jJsSP+/qn8uveyQT7S58Yu8leBN88AJVlcO2z0PN+8JJ9gZ5IAl3YxfqcEqYuzmZF9lGigv2Y0L8F4zJSCJFgt52aSlj0F1j7NsS1h5HTpd2th5NAF3aVlXucqYuzWbanmIggXyb0a8G4PimEyaqYxinaDl9NgCM7oNcDxtpyX9kb4Okk0IVDbMovZeribJbsOkJYgA/39mvB+D4pRATJOvbLUlcLq6bA0peN/iu3vAktrzG7KuEkJNCFQ20tKGPK4mwW7SwiyM+bu3omMaF/KvHhMrq8pOI9xlz5wUxofwsMfwWCY8yuSjgRCXRhil2F5by9dB/fbTmMl4IR3RK4f2AqqdIE7JcsdbDmLVjyvLEccfgr0HGk2VUJJySBLkyVX3KKd1bsZ+b6fKrrLPyqYzwPDGxJp4Rws0tzDsf2wbcPQd5qaDMcbngNQpuYXZVwUhLowikUV1Tx/soDfLw6l4qqWvq3iuGBQWlkpEZ75kEbFotxmtCiv4CXL1z/N+g8Cjzxn4VoMAl04VTKK2v4dE0e7/50gKMnquiSGMGkAakM7RCPt5eHhNmxffDdZMhZYXzgedMbENbM7KqEC5BAF06psqaOWVkFTFu+n7ySUyRFBXFv3xRuT090301KdTWw6g1jBYtPAAx9Hq4aJ6Ny0WAS6MKp1Vk0C7YX8s6K/WzIKyUswIcxvZO5OyPFvVbGHNxgtLkt2grtboLr/y5b98Vlk0AXLiMr9zjTV+xn/vZCvL0UN3Zuxm/6t6BDMxf+ALX6JPz4Iqx5E4LjYPg/oN2NZlclXNTFAt1N/14rXFX35Ei6J3cn79gp3lt5gC8y85m98SB90qK5r38qA1vH4uVK8+z7lsB3j0JpLnS/x9jtGRhhdlXCTckIXTi1stM1fL4ujw9W5lBYXknLuBDu7pPCiG7NnXue/cQRWPC/sGUGRLeEG6dCSl+zqxJuQKZchMurrrUwd+sh3v3pANsOlhMa4MMd6YmMy0gmOTrY7PJ+Zqkz+pUvfh5qTkHfyTDgD9KDRdiMBLpwG1prNuQd54NVufyw9TB1WjO4TRzj+6TQr2WMudMxBZkw93HjoObUQXD9PyCmlXn1CLckgS7cUlF5JZ+uyeWzdXkcPVFNamwwd2ekMLJ7gmNb+J4qgcXPQtaHENIErnsROoyQpYjCLiTQhVurqq3jP1sP88GqXDbnlxLi78Nt3RMYl5Fs374xFgts+tTY6Xm6FHpNgkFPQkCY/e4pPJ4EuvAYG/OO8+GqHOZuPUxNnaZvy2ju6pnMte2b4OdjwxN+DmbBD09CwTpI7G0004rvaLvfL8QFSKALj3OkopKZ6/KZsT6fg6WniQnx5470BEb3TCIxKujKf3FFISx6FjZ/BsGxcM2z0GW0HAcnHEYCXXisOotm+Z5iPl2bx5JdRWigf6tY7uqZxDXt4vDxbmAQ11TCmn/BilehtgoyHoT+v5fpFeFwEuhCAIdKTzNzfT4z1+dTWF5JXKg/d/ZIZFTPJJpHBJ7/h7SGnXOMNeWluUZ726HPQ3SaY4sXwqpRga6UigdeALporXuc53Uv4EXgBJAMvKu1XnOpoiTQhVlq6yws2XWEz9blsWxPMQq4um0cY3onM7DVWTtRC7fCvKeMjohx7eG6l4zliEKYqLFb//sB3wJdL/D6HUCY1vpJpVQUsEYp1U5rXXdl5QphXz7eXgztEM/QDvHkl5xixvo8Zq7PZ9HOI7SND+Xp/uH0y59mrGAJjDTWk3e/B7ydeGeqEDQg0LXWs5RSgy5yyXBggfXaEqVUJdAB2GKTCoWwo8SoIP4wrC2Th7RmftYuCr57kfQ586hRsK/FWJJu+QtB4XKmp3ANthhyxAEVZz0utz73C0qpicBEgKSkJBvcWggbqK3Cb/10blz+d/A5zuy6frxaezsFO2MJ2Z9Fn7Ro+rWKoU9aDGmxwZ55upJwCbYI9CNA6FmPw6zP/YLWehowDYw5dBvcW4grZ7HAtq9gyXNQmgepg1ma9BCPz6smPiyAWXd1Y1ZWASuyj7JgRxEA8WEB9EmLpk/LGPqkRdPsQh+mCmGCKwp0pVQwEKS1LgbmAgOAj61z6AHAdtuVKISNaQ37f4RFzxh9V5p0gl/PhpZDSDhSAfOWU1VbR3pKFOkpUWitySs5xU97j7Jq3zGW7ilm9saDALSICSYjLZq+aTH0To0iOsTf3PcmPNolA10pNRAYCzRVSj0NvAKMBzoBk4AvgG5Kqb8AScA4+UBUOK3cVbDkBchdCeGJcOs06HR7/cagtNgQRl6VwMirmtf/iFKK5OhgkqODGdMrGYtFs7uogpXWgP9240E+W5sHQLumYfRJi6Zvy2h6toh2bE8Z4fFkHbrwDAVZ8OMLxoETIU2MTUHd7wafxo+oa+osbCkoY/W+o6zce4ysvONU11rw9lJ0SQinb8sYMtKiuSopkgBfbxu8GeHJZGOR8FyFW43j33b/B4Kioe+j0GMC+DVi+/8lVNbUkZV7vH4Ev6WgFIsGfx8v0lMi6d0iml6p0XRJDMffRwJeXB45gk54nuLdRpDv+Ab8w+Hqp41uiP6hl/7ZRgrw9aZvyxj6tjSWO5ZX1rBufwkr9x1l9b5jvLJwD2AEfLekCHq1iKZXapSM4EWjyQhduJeiHbDiH7D9a/ANgt4PQMZDxgYhJ3H8ZDXrckpYu7+EtQeOseNwOVqDn7cXXRMj6JUaRa8W0VyVHEGQn4y5xH+TKRfh/g5tguV/h13fg1+IMa3S5xEIjja7sksqO11DZk4Jaw+UsHb/MbYdKqfOovHxUnROCKd3qjFFk54c6dznqAqHkEAX7it/nRHk2QuMqZXek4yplaAosyu7YieqasnMKWGNdQS/taCMWovG20vRsXk4vVpEkZ4cSXpKFFHBfmaXKxxMAl24F60h5ycjyA8sg8AoY1ql530QEG52dTZ3qrqWrNzj9VM0m/PLqK6zAJAWG0x6chTpKZH0SIkiOTpIdrK6OQl04R4sFsieDyunQN5qCI6Dvo9A+r3gF2x2dQ5TWVPH1oNlZOYcJzOnhMzc45SdrgEgJsSvPuDTU6Lo0CwM34b2fBcuQVa5CNdWWwVbvoBVb8DR3caGoF/9Ha4aC76et/U+wNebHilR9EiJAtKwWDR7i0/UB/z63BLmbS8EINDXm66JEfUBf1VSBKEBvua+AWE3MkIXzut0KWS+B2v/DScKIb4T9JkMHW4BbwmliykqryQz5zjrc0rIzC1hx6FyLBq8FLSNDyM9JZKrkiLplhRBUpRM07gSmXIRrqWsANa8BVkfQPUJSB1sTK2kDgYJnityoqqWTXml9QG/Ma+UU9VGh47oYD+6JUXQzRrwXRIiZDWNE5MpF+EaDm2CNW8aHRC1ho4joc/D0LSz2ZW5vBB/H/q1iqFfK2OzU22dhT1FJ9iYf5wNuaVszD/Oop1Gk1QvBW3iw+iWFFE/ik+NkbbBrkBG6MJcdbWw6ztY8zbkrwHfYKPHSu8HIEJ65jvS8ZPVbCooZWNeKRvzjrMpr5SKqloAIoJ86Zr4c8B3SYwgTObiTSEjdOF8TpUYUyrrp0P5QYhMgWEvQbcxbrn00BVEBvsxuE0cg9sY59NYLJp9xSfYkHecjXmlbMg7zrI9xWhtzHy1iguhW2IknRPD6ZIQQZv4UFlRYzIZoQvHKtoOa982Vq3UVkKLgcZovNVQ8JI+Js6uvLKGLfll1pA/zsb8UkpPGUsm/X28aN8sjC4JEXROCKdzgjFVU3/otrAJ+VBUmKuuxuh2uO4dyFkBPoHQZRT0vB+atDe7OtEIWmvyS06zuaCUzfmlbCkoY9uhsvoPXEP9fehkDfcuCeF0ToygWXiAzMc3ggS6MEdpPmz4EDZ8BCeKjPXjPSbAVeNcemu+uLg6i2bvkRP/FfK7CsupqTOyJibEzzqKj6ifrpEWBg0nc+jCcSx1sHeRsX48e4GxWqX1MGM3Z8trZFrFA3h7KdrEh9ImPpQ70hMBY3frrsIKNueXsrnACPklu49wZjyZEBlIp+bhdGweTodmYXRsHk6MHOd32STQhW1UFMLGjyHrQyjLt54K9EDH4PEAAAorSURBVDtjNC6rVTxegHXHatfEiPrnKipr2HawnC0FP0/V/LCtsP71+LAAOjYPo0MzI+g7Ng8jPkymay5GAl1cubpa2LfYCPLdP4ClFlIHwbD/gzbXy25OcVGhAb5kpEWTkfZzi+Oy0zXsOFTO9kNlbDtYxrZD5Sze9fNIPibEzxrwYXS0Bn1CZKCEvJUEurh8R7Nh4yeweYaxJT8oxlip0v0eiE4zuzrhwsIDfxnyJ6tq2VVYzraD5fUh/+9l+6m1GCkfFuBjHcH/PF2TEh2MtweurpFAFw1TVWGcArTxE8hfC8rbmBvvOsb4LqNxYSfB/j50T46ie/LPH6RX1tSxp6jCCPlDZWw/WMYHq3KorjXaCgf6etM6PpT2TUNp1zSMdk3DaBsf6vaNyWSVi7gwrSF3lRHiO76BmlMQ0wa6/Ro6j4LQJmZXKES9mjoLe4+cYNvBMnYermDn4XJ2FpbXr5MHSIwKpF18GO2bGSHfvmmYy03ZyCoXcXmKd8OWmbD1SyjNA79Q6HwHdP01JKRLgyzhlHy9vepH42dorSksrzTC/XAFOw6Vs/NwOQt3FtXPy4f6+9D2rJF8u6ZhtGkSSqCf663IkkAXhvLDRlOsLTOhcAsoL6O74eCnod2N4BdkdoVCXDalFE3DA2kaHsjVbX/+G+Wp6lp2F1b8PJI/XM7sDQc5UZULGA3KUmKC68O9TXwobZqEkhgV5NRz8xLonqyyHHZ+B1u/gAPLQVugWTe47mXoMEKmVITbCvLzsbYLjqx/zmLRFBw/zQ5rwO84bCypnLvlcP01Ab5etIoLpXWTUNrGh9LaGvRNwvydYtpG5tA9TU2lsfFn2yxjqWFtpdEYq/Mo6HQ7xLQyu0IhnMrJqlr2HjnB7qIKdhdWsMf6/UhFVf01YQE+9Zup2jQxAr9NfCgRQbbfAStz6J6uptJYL779a9g9D6orICgauo01glzmxYW4oGB/H7okGi2Dz3b8ZDV7ioyA32UN+jmbDlFeWVt/TVyo/88hb/3eMi7EbgeISKC7q/oQ/8YYiVdXQGAUdLwV2t8CLQbIUkMhGiEy2I9eqdH0Sv15zbzWmqLyKutovpzdhSfYU1TBJ2tzqayx1F/34KA0nriurc1rkkB3JzWVsG+JscRw13+sIR4pIS6EgyiliA8PID48gIGtY+ufr7No8ktOsauwgr1HKuicEHGR33LlJNBdXWUZZC+EXd9D9iIjxAMijIOUO9xi9BuXEBfCVN5eipSYYFJigoF4u91HAt0VlR8y+ovvmgsHVoClBoLjoOMIaHcTpEqIC+GJJNBdgdbGZp9d3xshfmiD8XxUGmQ8CG1vgObp4CXHfwnhySTQnVVtNeStNnqK7/4BSvYZzzfvDkP+bIR4TGtZnSKEqCeB7kzKDxsBnr0A9i+F6hPg7Qcp/SDjIaMlbVhTs6sUQjipBgW6UuoaYARwBNBa62fPeX08MAmotD71rtb6YxvW6Z4sdVCQCdnzjRAv3Go8H9bc2OTTaqixMsU/xNw6hRAu4ZKBrpQKAt4GOmitq5RSXymlhmitF59z6Z1a6xx7FOlWyg8bo++9i4x14qePG61ok3rDNc8YIR7XXqZShBCXrSEj9AwgV2t9Zp/rSmA4cG6g/1YpVQgEAf/UWpfYrkwXVn0SclbC/h9h349QvNN4PjgWWv8KWl0LaYON9eJCCNEIDQn0OKDirMfl1ufOtgyYq7UuVkpdD3wJDDn3FymlJgITAZKS3PScSUsdHN5khPe+H43DICw14O0PyRnQ5U4jwJt0klUpQgibakigHwFCz3ocZn2untb6wFkPlwBzlFLeWuu6c66bBkwDoznXFVXsbLSGkv1Gt8L9P8L+ZVBZarwW38k4mi1tMCRlgG+gubUKIdxaQwJ9NZCslPK3Trv0Bd5USkUBtVrrcqXUS8D/aq1rgVbAgXPD3G1oDcf2Qc4KyF0JOT9BhbW9ZlhzYzlh2mBjh2ZI7MV/lxBC2NAlA11rfUop9QAwVSlVDGzRWi9WSv0NKAFeBgqBt5RSB4BOwFh7Fu1QZwd4zk/G14lC47WQeGNJ4Zmv6JbyYaYQwjQNWraotV4ILDznuSfO+vMUG9dlHosFindB/hrjw8wLBnh/44R7CXAhhJOQjUXVp+BglhHgeWuhYJ3R8AokwIUQLsXzAr38sBHe+esgb41xfqbF2pA+tq3RZjapNyT2gqhUCXAhhMtw70CvrYaibdYR+DojyEvzjNd8Aoy+KH0eMQI8oQcERZlbrxBCNIL7BPqZ5YMHs4yvgkxj9F1XbbweHAdJvaDn/UaAx3cGH9uf9yeEEGZx3UA/efTn4D4T4mfWf/sGGafX97rfaCvbvDuEJ8j0iRDCrbleoO+ZD//5/c9TJ8rL6H3S/mYjuJt3N+bCvV3vrQkhRGO4XuqFNIFmV0HPiUZ4N+0CfsFmVyWEEKZzvUBv1hXu+NDsKoQQwulIdyghhHATEuhCCOEmJNCFEMJNSKALIYSbkEAXQgg3IYEuhBBuQgJdCCHchAS6EEK4CaW1OUd7Wk8/yjXl5o0TAxw1uwgHk/fs/jzt/YLrvudkrfV5z7c0LdBdlVIqU2udbnYdjiTv2f152vsF93zPMuUihBBuQgJdCCHchAT65ZtmdgEmkPfs/jzt/YIbvmeZQxdCCDchI3QhhHATEuhCCOEmXO+ACyeilHoaeFRrHWN2LfaklHoNOAWcALpgvOdCc6uyD6XUNcAI4AigtdbPmlySXSml0oAXgA1AAnBMa/2cuVXZn1IqEFgLLNBa/97semxFAv0KKaUGAZFm1+EgJ7XWTwMopf4I/Al42NySbE8pFQS8DXTQWlcppb5SSg3RWi82uzY7igJmaK2/BVBK7VBKzdVaZ5lcl729AGw0uwhbkymXK6CUagLcCbxhdi2OcCbMrbwwRuruKAPI1VpXWR+vBIabWI/daa3XnwlzKy/gpFn1OIJSaizGv9sDZtdiazJCvwCl1HygyXle+jNwM/B7INyhRdnRxd6v1nqO9ZoIYCgw0pG1OVAcUHHW43Lrcx5BKXUrMF9rvcvsWuxFKdUeaKe1/h+lVGez67E1CfQL0FoPO9/zSql0oAa4H2PKJVAp9STwldY624El2tSF3u8ZSqlw4E3gXq11iWOqcrgjQOhZj8Osz7k9pdRgYDDwqNm12NmtQKX1v9l+gJ9S6lGt9esm12UTsg69EZRSKUCmB3woGgO8DvxRa31QKTVSa/2V2XXZmnUOfQtnzaEDb7r5HDpKqeFAf+ApoClG86fV5lZlf0qpZ4AQd/pQVAL9CimlWgKTgAeAl4DXtNZuOfeolNqA8be5MyPzCq31jSaWZDdKqWuB24BioMYDVrl0B5YBmdangoF/aa0/MK0oB1BKjQQeAvww3u/nJpdkExLoQgjhJmSVixBCuAkJdCGEcBMS6EII4SYk0IUQwk1IoAshhJuQQBdCCDchgS6EEG7i/wFb4pQBLJ8FbgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(myx,np.exp(yvals_nd[0,:]))\n",
    "#plt.plot(myx,yvals_1d[4,:]/(1.-yvals_1d[4,:]))\n",
    "plt.plot(myx,np.exp(-(myx-epsilon)**2/2+(myx+epsilon)**2/2),label=\"analytic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x7fe7bb1f1ba8>"
      ]
     },
     "execution_count": 895,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(myx,central_nd,label=\"from N\",color='blue')\n",
    "plt.plot(myx,central_1d,label=\"from 1\",color='red')\n",
    "plt.plot(myx,np.exp(-(myx-epsilon)**2/2+(myx+epsilon)**2/2),label=\"analytic\",color='black')\n",
    "plt.legend(frameon=False)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylim([0,4])\n",
    "plt.ylabel(\"likelihood ratio\")\n",
    "plt.fill_between(myx,central_1d-spread_1d,central_1d+spread_1d,label=\"from 1\",alpha=0.1,color=\"red\")\n",
    "plt.fill_between(myx,central_nd-spread_nd,central_nd+spread_nd,label=\"from N\",alpha=0.02,color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Papers that claim ensembling is useful:\n",
    "\n",
    "#1810.00835\n",
    "#1910.11530\n",
    "#1912.10625\n",
    "#2007.14586\n",
    "#2011.04666"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BSM example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_sig=pd.read_hdf(\"/data1/bpnachman/anomaly/events_anomalydetection_DelphesPythia8_v2_Wprime_features.h5\")\n",
    "features_bg=pd.read_hdf(\"/data1/bpnachman/anomaly/events_anomalydetection_DelphesPythia8_v2_qcd_features.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(input_frame):\n",
    "    dataset = input_frame[[\"mj1\",\"tau1j1\",\"tau2j1\",\"mj2\",\"tau1j2\",\"tau2j2\"]]\n",
    "    dataset[\"mjj\"] = (((input_frame[\"pxj1\"]**2+input_frame[\"pyj1\"]**2+input_frame[\"pzj1\"]**2+input_frame[\"mj1\"]**2)**0.5+(input_frame[\"pxj2\"]**2+input_frame[\"pyj2\"]**2+input_frame[\"pzj2\"]**2+input_frame[\"mj2\"]**2)**0.5)**2-(input_frame[\"pxj1\"]+input_frame[\"pxj2\"])**2-(input_frame[\"pyj1\"]+input_frame[\"pyj2\"])**2-(input_frame[\"pzj1\"]+input_frame[\"pzj2\"])**2)**0.5/1000.\n",
    "    dataset[\"mjTwo\"] = dataset[[\"mj1\", \"mj2\"]].max(axis=1)\n",
    "    dataset[\"mjOne\"] = dataset[[\"mj1\", \"mj2\"]].min(axis=1)\n",
    "    dataset[\"mjDelta\"] = dataset[\"mjTwo\"] - dataset[\"mjOne\"]\n",
    "    dataset[\"tau1jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau1j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau1j2\"]\n",
    "    dataset[\"tau2jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
    "    dataset[\"tau1jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau1j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau1j2\"]\n",
    "    dataset[\"tau2jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
    "    dataset[\"tau21jOne\"] = dataset[\"tau2jOne\"]/dataset[\"tau1jOne\"]\n",
    "    dataset[\"tau21jTwo\"] = dataset[\"tau2jTwo\"]/dataset[\"tau1jTwo\"]\n",
    "    dataset[\"mjTwo\"] = dataset[\"mjTwo\"]/1000.\n",
    "    dataset[\"mjOne\"] = dataset[\"mjOne\"]/1000.\n",
    "    dataset[\"mjDelta\"] = dataset[\"mjDelta\"]/1000.\n",
    "    dataset = dataset.fillna(0)\n",
    "    dataset = dataset[[\"mjj\",\"mjOne\",\"mjDelta\",\"tau21jOne\",\"tau21jTwo\"]]\n",
    "    return dataset.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "dataset_bg=load_data(features_bg)\n",
    "dataset_bg=np.hstack((dataset_bg,np.zeros((len(dataset_bg),1))))\n",
    "\n",
    "dataset_sig=load_data(features_sig)\n",
    "dataset_sig=np.hstack((dataset_sig,np.ones((len(dataset_sig),1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR_low = 3.3\n",
    "SR_high = 3.7\n",
    "\n",
    "n_phys = 3\n",
    "\n",
    "X_sig_SR = dataset_sig[(dataset_sig[:,0] > SR_low)*(dataset_sig[:,0] < SR_high)][:,1:5]\n",
    "X_bg_SR = dataset_bg[(dataset_bg[:,0] > SR_low)*(dataset_bg[:,0] < SR_high)][:,1:5]\n",
    "\n",
    "X_sig_SR = X_sig_SR[0:len(X_sig_SR) - len(X_sig_SR) % n_phys]\n",
    "X_bg_SR = X_bg_SR[0:len(X_bg_SR) - len(X_bg_SR) % n_phys]\n",
    "\n",
    "X_1D_phys = np.concatenate([X_sig_SR,X_bg_SR])\n",
    "Y_1D_phys = np.concatenate([np.ones(len(X_sig_SR)),np.zeros(len(X_bg_SR))])\n",
    "\n",
    "X_nD_phys = np.reshape(X_1D_phys,[int(len(X_1D_phys)/n_phys),4*n_phys])\n",
    "Y_nD_phys = np.concatenate([np.ones(int(len(X_sig_SR)/n_phys)),np.zeros(int(len(X_bg_SR)/n_phys))])\n",
    "\n",
    "#Try standardizing?\n",
    "scaler = preprocessing.StandardScaler().fit(X_nD_phys)\n",
    "X_nD_phys = scaler.transform(X_nD_phys)\n",
    "\n",
    "scaler1D = preprocessing.StandardScaler().fit(X_1D_phys)\n",
    "X_1D_phys = scaler1D.transform(X_1D_phys)\n",
    "\n",
    "X_1D_train_phys, X_1D_val_phys, Y_1D_train_phys, Y_1D_val_phys = train_test_split(X_1D_phys, Y_1D_phys, test_size=0.5)\n",
    "X_nD_train_phys, X_nD_val_phys, Y_nD_train_phys, Y_nD_val_phys = train_test_split(X_nD_phys, Y_nD_phys, test_size=0.5)\n",
    "\n",
    "#Try sorting the n-dimensional case based on mJ1?\n",
    "X_nD_train_sort_phys = np.array([np.reshape(sorted(np.reshape(X_nD_train_phys[i],[n_phys,4]), key=lambda x: x[0]),[n_phys*4]) for i in range(len(X_nD_train_phys))])\n",
    "X_nD_val_sort_phys = np.array([np.reshape(sorted(np.reshape(X_nD_val_phys[i],[n_phys,4]), key=lambda x: x[0]),[n_phys*4]) for i in range(len(X_nD_val_phys))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "gs = gridspec.GridSpec(1, 1) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ax0.minorticks_on()\n",
    "\n",
    "plt.hist(X_sig_SR[:,0],bins=np.linspace(0,1,20),alpha=0.2,color=\"black\")\n",
    "plt.hist(X_sig_SR[:,1],bins=np.linspace(0,1,20),alpha=0.2,color=\"red\")\n",
    "plt.hist(X_sig_SR[:,2],bins=np.linspace(0,1,20),alpha=0.2,color=\"orange\")\n",
    "plt.hist(X_sig_SR[:,3],bins=np.linspace(0,1,20),alpha=0.2,color=\"blue\")\n",
    "\n",
    "plt.hist(X_bg_SR[:,0],bins=np.linspace(0,1,20),color=\"black\",histtype='step',label=r\"$m_{J_1}$ / TeV\")\n",
    "plt.hist(X_bg_SR[:,1],bins=np.linspace(0,1,20),color=\"red\",histtype='step',label=r\"$\\Delta m_J$ / TeV\")\n",
    "plt.hist(X_bg_SR[:,2],bins=np.linspace(0,1,20),color=\"orange\",histtype='step',label=r\"$\\tau_{21,1}$\")\n",
    "plt.hist(X_bg_SR[:,3],bins=np.linspace(0,1,20),color=\"blue\",histtype='step',label=r\"$\\tau_{21,2}$\")\n",
    "\n",
    "plt.xlabel(\"Observable\",fontsize=20)\n",
    "plt.ylabel(\"Events\",fontsize=20)\n",
    "leg = plt.legend(frameon=False,fontsize=20, handlelength=0.7)\n",
    "\n",
    "x = patches.Patch(color='black', label='Signal',fill=True)\n",
    "x2 = patches.Patch(color='black', label='Background',fill=False)\n",
    "\n",
    "leg2 = plt.legend(handles=[x,x2],loc=(0.25, 0.75),fontsize=20,frameon=False, handlelength=0.7)\n",
    "plt.gca().add_artist(leg)\n",
    "plt.title(r\"$BSM$, $X\\rightarrow YZ$ $versus$ $QCD$\",loc=\"right\",fontsize=20)\n",
    "\n",
    "plt.savefig(\"ensembleLearnPlots/BSM_Hist.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98323 samples, validate on 98324 samples\n",
      "Epoch 1/50\n",
      "98323/98323 [==============================] - 1s 5us/step - loss: 0.6619 - acc: 0.7017 - val_loss: 0.5880 - val_acc: 0.8551\n",
      "Epoch 2/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.5356 - acc: 0.8561 - val_loss: 0.4523 - val_acc: 0.8640\n",
      "Epoch 3/50\n",
      "98323/98323 [==============================] - 0s 1us/step - loss: 0.4118 - acc: 0.8640 - val_loss: 0.3560 - val_acc: 0.8710\n",
      "Epoch 4/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.3371 - acc: 0.8717 - val_loss: 0.3258 - val_acc: 0.8708\n",
      "Epoch 5/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.3220 - acc: 0.8743 - val_loss: 0.3167 - val_acc: 0.8750\n",
      "Epoch 6/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.3174 - acc: 0.8730 - val_loss: 0.3047 - val_acc: 0.8807\n",
      "Epoch 7/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.3094 - acc: 0.8815 - val_loss: 0.3030 - val_acc: 0.8842\n",
      "Epoch 8/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2998 - acc: 0.8848 - val_loss: 0.2953 - val_acc: 0.8854\n",
      "Epoch 9/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2963 - acc: 0.8840 - val_loss: 0.2920 - val_acc: 0.8853\n",
      "Epoch 10/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2882 - acc: 0.8876 - val_loss: 0.2844 - val_acc: 0.8896\n",
      "Epoch 11/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2807 - acc: 0.8913 - val_loss: 0.2781 - val_acc: 0.8921\n",
      "Epoch 12/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2776 - acc: 0.8918 - val_loss: 0.2748 - val_acc: 0.8933\n",
      "Epoch 13/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2709 - acc: 0.8955 - val_loss: 0.2670 - val_acc: 0.8974\n",
      "Epoch 14/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2674 - acc: 0.8975 - val_loss: 0.2678 - val_acc: 0.8967\n",
      "Epoch 15/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2761 - acc: 0.8939 - val_loss: 0.2738 - val_acc: 0.9005\n",
      "Epoch 16/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2762 - acc: 0.8976 - val_loss: 0.2633 - val_acc: 0.8996\n",
      "Epoch 17/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2738 - acc: 0.8986 - val_loss: 0.2668 - val_acc: 0.9026\n",
      "Epoch 18/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2611 - acc: 0.9036 - val_loss: 0.2561 - val_acc: 0.9054\n",
      "Epoch 19/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2546 - acc: 0.9048 - val_loss: 0.2524 - val_acc: 0.9058\n",
      "Epoch 20/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2543 - acc: 0.9042 - val_loss: 0.2563 - val_acc: 0.9018\n",
      "Epoch 21/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2542 - acc: 0.9032 - val_loss: 0.2525 - val_acc: 0.9036\n",
      "Epoch 22/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2624 - acc: 0.8987 - val_loss: 0.2514 - val_acc: 0.9065\n",
      "Epoch 23/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2516 - acc: 0.9052 - val_loss: 0.2451 - val_acc: 0.9089\n",
      "Epoch 24/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2470 - acc: 0.9061 - val_loss: 0.2422 - val_acc: 0.9091\n",
      "Epoch 25/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2430 - acc: 0.9087 - val_loss: 0.2421 - val_acc: 0.9079\n",
      "Epoch 26/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2427 - acc: 0.9069 - val_loss: 0.2424 - val_acc: 0.9074\n",
      "Epoch 27/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2565 - acc: 0.9000 - val_loss: 0.2428 - val_acc: 0.9062\n",
      "Epoch 28/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2476 - acc: 0.9058 - val_loss: 0.2417 - val_acc: 0.9095\n",
      "Epoch 29/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2393 - acc: 0.9098 - val_loss: 0.2349 - val_acc: 0.9116\n",
      "Epoch 30/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2335 - acc: 0.9117 - val_loss: 0.2339 - val_acc: 0.9113\n",
      "Epoch 31/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2340 - acc: 0.9114 - val_loss: 0.2320 - val_acc: 0.9130\n",
      "Epoch 32/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2316 - acc: 0.9126 - val_loss: 0.2295 - val_acc: 0.9142\n",
      "Epoch 33/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2298 - acc: 0.9136 - val_loss: 0.2294 - val_acc: 0.9143\n",
      "Epoch 34/50\n",
      "98323/98323 [==============================] - 0s 1us/step - loss: 0.2364 - acc: 0.9108 - val_loss: 0.2279 - val_acc: 0.9149\n",
      "Epoch 35/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2297 - acc: 0.9136 - val_loss: 0.2281 - val_acc: 0.9144\n",
      "Epoch 36/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2296 - acc: 0.9137 - val_loss: 0.2274 - val_acc: 0.9157\n",
      "Epoch 37/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2280 - acc: 0.9143 - val_loss: 0.2254 - val_acc: 0.9155\n",
      "Epoch 38/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2251 - acc: 0.9150 - val_loss: 0.2234 - val_acc: 0.9168\n",
      "Epoch 39/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2236 - acc: 0.9158 - val_loss: 0.2246 - val_acc: 0.9147\n",
      "Epoch 40/50\n",
      "98323/98323 [==============================] - 0s 1us/step - loss: 0.2295 - acc: 0.9106 - val_loss: 0.2246 - val_acc: 0.9154\n",
      "Epoch 41/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2241 - acc: 0.9159 - val_loss: 0.2218 - val_acc: 0.9171\n",
      "Epoch 42/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2326 - acc: 0.9116 - val_loss: 0.2301 - val_acc: 0.9122\n",
      "Epoch 43/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2299 - acc: 0.9122 - val_loss: 0.2255 - val_acc: 0.9151\n",
      "Epoch 44/50\n",
      "98323/98323 [==============================] - 0s 1us/step - loss: 0.2245 - acc: 0.9150 - val_loss: 0.2217 - val_acc: 0.9173\n",
      "Epoch 45/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2278 - acc: 0.9136 - val_loss: 0.2321 - val_acc: 0.9134\n",
      "Epoch 46/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2440 - acc: 0.9098 - val_loss: 0.2318 - val_acc: 0.9139\n",
      "Epoch 47/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2316 - acc: 0.9120 - val_loss: 0.2259 - val_acc: 0.9137\n",
      "Epoch 48/50\n",
      "98323/98323 [==============================] - 0s 1us/step - loss: 0.2257 - acc: 0.9135 - val_loss: 0.2210 - val_acc: 0.9162\n",
      "Epoch 49/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2262 - acc: 0.9164 - val_loss: 0.2318 - val_acc: 0.9145\n",
      "Epoch 50/50\n",
      "98323/98323 [==============================] - 0s 2us/step - loss: 0.2480 - acc: 0.9039 - val_loss: 0.2328 - val_acc: 0.9106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb986662e8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1D_phys = Sequential()\n",
    "model_1D_phys.add(Dense(64, input_dim=4, activation='relu')) \n",
    "model_1D_phys.add(Dense(64, activation='relu'))\n",
    "model_1D_phys.add(Dense(64, activation='relu'))\n",
    "model_1D_phys.add(Dense(64, activation='relu'))\n",
    "model_1D_phys.add(Dense(1, activation='sigmoid'))\n",
    "model_1D_phys.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_1D_phys.fit(X_1D_train_phys,Y_1D_train_phys, epochs=50, batch_size=int(0.1*len(X_1D_train_phys)),validation_data=(X_1D_val_phys,Y_1D_val_phys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32774 samples, validate on 32775 samples\n",
      "Epoch 1/500\n",
      "32774/32774 [==============================] - 0s 15us/step - loss: 0.5514 - acc: 0.8579 - val_loss: 0.3589 - val_acc: 0.9251\n",
      "Epoch 2/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.2593 - acc: 0.9348 - val_loss: 0.1565 - val_acc: 0.9479\n",
      "Epoch 3/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.1401 - acc: 0.9496 - val_loss: 0.1255 - val_acc: 0.9522\n",
      "Epoch 4/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.1217 - acc: 0.9543 - val_loss: 0.1169 - val_acc: 0.9555\n",
      "Epoch 5/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.1144 - acc: 0.9567 - val_loss: 0.1108 - val_acc: 0.9582\n",
      "Epoch 6/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.1081 - acc: 0.9588 - val_loss: 0.1063 - val_acc: 0.9602\n",
      "Epoch 7/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.1038 - acc: 0.9603 - val_loss: 0.1026 - val_acc: 0.9620\n",
      "Epoch 8/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.1004 - acc: 0.9610 - val_loss: 0.1001 - val_acc: 0.9621\n",
      "Epoch 9/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0967 - acc: 0.9620 - val_loss: 0.0961 - val_acc: 0.9640\n",
      "Epoch 10/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0930 - acc: 0.9636 - val_loss: 0.0947 - val_acc: 0.9644\n",
      "Epoch 11/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.1005 - acc: 0.9620 - val_loss: 0.0990 - val_acc: 0.9620\n",
      "Epoch 12/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0941 - acc: 0.9642 - val_loss: 0.0912 - val_acc: 0.9656\n",
      "Epoch 13/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0887 - acc: 0.9663 - val_loss: 0.0895 - val_acc: 0.9666\n",
      "Epoch 14/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0862 - acc: 0.9668 - val_loss: 0.0887 - val_acc: 0.9667\n",
      "Epoch 15/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0849 - acc: 0.9672 - val_loss: 0.0872 - val_acc: 0.9671\n",
      "Epoch 16/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0830 - acc: 0.9684 - val_loss: 0.0854 - val_acc: 0.9678\n",
      "Epoch 17/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0808 - acc: 0.9694 - val_loss: 0.0883 - val_acc: 0.9668\n",
      "Epoch 18/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0959 - acc: 0.9634 - val_loss: 0.1034 - val_acc: 0.9616\n",
      "Epoch 19/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0893 - acc: 0.9669 - val_loss: 0.0882 - val_acc: 0.9676\n",
      "Epoch 20/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0819 - acc: 0.9695 - val_loss: 0.0839 - val_acc: 0.9683\n",
      "Epoch 21/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0791 - acc: 0.9708 - val_loss: 0.0830 - val_acc: 0.9691\n",
      "Epoch 22/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0787 - acc: 0.9710 - val_loss: 0.0823 - val_acc: 0.9691\n",
      "Epoch 23/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0766 - acc: 0.9717 - val_loss: 0.0796 - val_acc: 0.9702\n",
      "Epoch 24/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0740 - acc: 0.9728 - val_loss: 0.0782 - val_acc: 0.9707\n",
      "Epoch 25/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0725 - acc: 0.9731 - val_loss: 0.0771 - val_acc: 0.9714\n",
      "Epoch 26/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0709 - acc: 0.9742 - val_loss: 0.0756 - val_acc: 0.9722\n",
      "Epoch 27/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0692 - acc: 0.9746 - val_loss: 0.0742 - val_acc: 0.9724\n",
      "Epoch 28/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0675 - acc: 0.9755 - val_loss: 0.0728 - val_acc: 0.9728\n",
      "Epoch 29/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0657 - acc: 0.9762 - val_loss: 0.0717 - val_acc: 0.9730\n",
      "Epoch 30/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0640 - acc: 0.9770 - val_loss: 0.0700 - val_acc: 0.9738\n",
      "Epoch 31/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0631 - acc: 0.9769 - val_loss: 0.0696 - val_acc: 0.9741\n",
      "Epoch 32/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0608 - acc: 0.9783 - val_loss: 0.0680 - val_acc: 0.9743\n",
      "Epoch 33/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0587 - acc: 0.9787 - val_loss: 0.0663 - val_acc: 0.9750\n",
      "Epoch 34/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0570 - acc: 0.9802 - val_loss: 0.0648 - val_acc: 0.9756\n",
      "Epoch 35/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0554 - acc: 0.9804 - val_loss: 0.0645 - val_acc: 0.9767\n",
      "Epoch 36/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0559 - acc: 0.9803 - val_loss: 0.0638 - val_acc: 0.9767\n",
      "Epoch 37/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0542 - acc: 0.9808 - val_loss: 0.0621 - val_acc: 0.9772\n",
      "Epoch 38/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0518 - acc: 0.9818 - val_loss: 0.0599 - val_acc: 0.9781\n",
      "Epoch 39/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0502 - acc: 0.9825 - val_loss: 0.0597 - val_acc: 0.9788\n",
      "Epoch 40/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0485 - acc: 0.9835 - val_loss: 0.0590 - val_acc: 0.9786\n",
      "Epoch 41/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0507 - acc: 0.9817 - val_loss: 0.0734 - val_acc: 0.9744\n",
      "Epoch 42/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0922 - acc: 0.9687 - val_loss: 0.0963 - val_acc: 0.9691\n",
      "Epoch 43/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0753 - acc: 0.9757 - val_loss: 0.0733 - val_acc: 0.9746\n",
      "Epoch 44/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0867 - acc: 0.9686 - val_loss: 0.0800 - val_acc: 0.9717\n",
      "Epoch 45/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.1073 - acc: 0.9653 - val_loss: 0.1013 - val_acc: 0.9670\n",
      "Epoch 46/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0869 - acc: 0.9710 - val_loss: 0.0817 - val_acc: 0.9719\n",
      "Epoch 47/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0681 - acc: 0.9767 - val_loss: 0.0703 - val_acc: 0.9752\n",
      "Epoch 48/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0610 - acc: 0.9782 - val_loss: 0.0650 - val_acc: 0.9764\n",
      "Epoch 49/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0568 - acc: 0.9795 - val_loss: 0.0628 - val_acc: 0.9779\n",
      "Epoch 50/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0558 - acc: 0.9796 - val_loss: 0.0619 - val_acc: 0.9776\n",
      "Epoch 51/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0536 - acc: 0.9806 - val_loss: 0.0608 - val_acc: 0.9779\n",
      "Epoch 52/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0518 - acc: 0.9811 - val_loss: 0.0593 - val_acc: 0.9784\n",
      "Epoch 53/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0499 - acc: 0.9819 - val_loss: 0.0578 - val_acc: 0.9792\n",
      "Epoch 54/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0506 - acc: 0.9820 - val_loss: 0.0594 - val_acc: 0.9788\n",
      "Epoch 55/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0600 - acc: 0.9785 - val_loss: 0.0661 - val_acc: 0.9768\n",
      "Epoch 56/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0562 - acc: 0.9805 - val_loss: 0.0603 - val_acc: 0.9785\n",
      "Epoch 57/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0511 - acc: 0.9813 - val_loss: 0.0583 - val_acc: 0.9788\n",
      "Epoch 58/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0490 - acc: 0.9822 - val_loss: 0.0566 - val_acc: 0.9795\n",
      "Epoch 59/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0472 - acc: 0.9832 - val_loss: 0.0558 - val_acc: 0.9800\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0459 - acc: 0.9837 - val_loss: 0.0551 - val_acc: 0.9800\n",
      "Epoch 61/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0452 - acc: 0.9842 - val_loss: 0.0549 - val_acc: 0.9802\n",
      "Epoch 62/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0442 - acc: 0.9844 - val_loss: 0.0545 - val_acc: 0.9807\n",
      "Epoch 63/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0437 - acc: 0.9847 - val_loss: 0.0573 - val_acc: 0.9787\n",
      "Epoch 64/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0654 - acc: 0.9752 - val_loss: 0.0809 - val_acc: 0.9727\n",
      "Epoch 65/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0595 - acc: 0.9780 - val_loss: 0.0669 - val_acc: 0.9767\n",
      "Epoch 66/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0523 - acc: 0.9812 - val_loss: 0.0620 - val_acc: 0.9787\n",
      "Epoch 67/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0484 - acc: 0.9825 - val_loss: 0.0582 - val_acc: 0.9785\n",
      "Epoch 68/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0459 - acc: 0.9836 - val_loss: 0.0564 - val_acc: 0.9800\n",
      "Epoch 69/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0444 - acc: 0.9841 - val_loss: 0.0554 - val_acc: 0.9800\n",
      "Epoch 70/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0433 - acc: 0.9843 - val_loss: 0.0544 - val_acc: 0.9804\n",
      "Epoch 71/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0424 - acc: 0.9851 - val_loss: 0.0551 - val_acc: 0.9802\n",
      "Epoch 72/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0487 - acc: 0.9824 - val_loss: 0.0645 - val_acc: 0.9775\n",
      "Epoch 73/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0490 - acc: 0.9826 - val_loss: 0.0611 - val_acc: 0.9775\n",
      "Epoch 74/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0464 - acc: 0.9840 - val_loss: 0.0564 - val_acc: 0.9804\n",
      "Epoch 75/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0427 - acc: 0.9850 - val_loss: 0.0548 - val_acc: 0.9809\n",
      "Epoch 76/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0481 - acc: 0.9829 - val_loss: 0.0601 - val_acc: 0.9790\n",
      "Epoch 77/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0475 - acc: 0.9831 - val_loss: 0.0567 - val_acc: 0.9803\n",
      "Epoch 78/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0439 - acc: 0.9844 - val_loss: 0.0547 - val_acc: 0.9806\n",
      "Epoch 79/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0420 - acc: 0.9849 - val_loss: 0.0571 - val_acc: 0.9799\n",
      "Epoch 80/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0652 - acc: 0.9763 - val_loss: 0.0797 - val_acc: 0.9708\n",
      "Epoch 81/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0592 - acc: 0.9787 - val_loss: 0.0559 - val_acc: 0.9796\n",
      "Epoch 82/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0616 - acc: 0.9777 - val_loss: 0.0622 - val_acc: 0.9776\n",
      "Epoch 83/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0540 - acc: 0.9807 - val_loss: 0.0594 - val_acc: 0.9788\n",
      "Epoch 84/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0473 - acc: 0.9828 - val_loss: 0.0584 - val_acc: 0.9784\n",
      "Epoch 85/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0582 - acc: 0.9799 - val_loss: 0.0650 - val_acc: 0.9780\n",
      "Epoch 86/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0535 - acc: 0.9819 - val_loss: 0.0561 - val_acc: 0.9804\n",
      "Epoch 87/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0462 - acc: 0.9847 - val_loss: 0.0547 - val_acc: 0.9804\n",
      "Epoch 88/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0442 - acc: 0.9845 - val_loss: 0.0532 - val_acc: 0.9809\n",
      "Epoch 89/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0423 - acc: 0.9855 - val_loss: 0.0523 - val_acc: 0.9815\n",
      "Epoch 90/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0411 - acc: 0.9862 - val_loss: 0.0517 - val_acc: 0.9819\n",
      "Epoch 91/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0403 - acc: 0.9866 - val_loss: 0.0513 - val_acc: 0.9820\n",
      "Epoch 92/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0397 - acc: 0.9869 - val_loss: 0.0509 - val_acc: 0.9821\n",
      "Epoch 93/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0397 - acc: 0.9861 - val_loss: 0.0510 - val_acc: 0.9820\n",
      "Epoch 94/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0396 - acc: 0.9866 - val_loss: 0.0510 - val_acc: 0.9822\n",
      "Epoch 95/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0396 - acc: 0.9863 - val_loss: 0.0507 - val_acc: 0.9824\n",
      "Epoch 96/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0383 - acc: 0.9869 - val_loss: 0.0502 - val_acc: 0.9826\n",
      "Epoch 97/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0375 - acc: 0.9875 - val_loss: 0.0503 - val_acc: 0.9823\n",
      "Epoch 98/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0389 - acc: 0.9870 - val_loss: 0.0509 - val_acc: 0.9820\n",
      "Epoch 99/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0379 - acc: 0.9871 - val_loss: 0.0502 - val_acc: 0.9824\n",
      "Epoch 100/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0369 - acc: 0.9875 - val_loss: 0.0503 - val_acc: 0.9825\n",
      "Epoch 101/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0366 - acc: 0.9879 - val_loss: 0.0500 - val_acc: 0.9827\n",
      "Epoch 102/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0360 - acc: 0.9882 - val_loss: 0.0503 - val_acc: 0.9824\n",
      "Epoch 103/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0374 - acc: 0.9876 - val_loss: 0.0512 - val_acc: 0.9825\n",
      "Epoch 104/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0367 - acc: 0.9875 - val_loss: 0.0500 - val_acc: 0.9825\n",
      "Epoch 105/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0354 - acc: 0.9885 - val_loss: 0.0495 - val_acc: 0.9824\n",
      "Epoch 106/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0350 - acc: 0.9885 - val_loss: 0.0492 - val_acc: 0.9827\n",
      "Epoch 107/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0346 - acc: 0.9890 - val_loss: 0.0490 - val_acc: 0.9830\n",
      "Epoch 108/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0342 - acc: 0.9889 - val_loss: 0.0489 - val_acc: 0.9828\n",
      "Epoch 109/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0339 - acc: 0.9892 - val_loss: 0.0490 - val_acc: 0.9831\n",
      "Epoch 110/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0341 - acc: 0.9887 - val_loss: 0.0492 - val_acc: 0.9826\n",
      "Epoch 111/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0338 - acc: 0.9894 - val_loss: 0.0490 - val_acc: 0.9828\n",
      "Epoch 112/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0333 - acc: 0.9892 - val_loss: 0.0490 - val_acc: 0.9827\n",
      "Epoch 113/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0331 - acc: 0.9896 - val_loss: 0.0487 - val_acc: 0.9827\n",
      "Epoch 114/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0327 - acc: 0.9897 - val_loss: 0.0486 - val_acc: 0.9828\n",
      "Epoch 115/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0326 - acc: 0.9894 - val_loss: 0.0488 - val_acc: 0.9829\n",
      "Epoch 116/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0323 - acc: 0.9898 - val_loss: 0.0486 - val_acc: 0.9831\n",
      "Epoch 117/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0321 - acc: 0.9898 - val_loss: 0.0485 - val_acc: 0.9829\n",
      "Epoch 118/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0321 - acc: 0.9895 - val_loss: 0.0491 - val_acc: 0.9829\n",
      "Epoch 119/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0320 - acc: 0.9900 - val_loss: 0.0494 - val_acc: 0.9832\n",
      "Epoch 120/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0341 - acc: 0.9883 - val_loss: 0.0520 - val_acc: 0.9820\n",
      "Epoch 121/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0332 - acc: 0.9892 - val_loss: 0.0527 - val_acc: 0.9820\n",
      "Epoch 122/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0452 - acc: 0.9855 - val_loss: 0.0619 - val_acc: 0.9796\n",
      "Epoch 123/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0443 - acc: 0.9864 - val_loss: 0.0539 - val_acc: 0.9826\n",
      "Epoch 124/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0371 - acc: 0.9883 - val_loss: 0.0522 - val_acc: 0.9825\n",
      "Epoch 125/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0357 - acc: 0.9876 - val_loss: 0.0509 - val_acc: 0.9822\n",
      "Epoch 126/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0335 - acc: 0.9892 - val_loss: 0.0495 - val_acc: 0.9827\n",
      "Epoch 127/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0323 - acc: 0.9896 - val_loss: 0.0487 - val_acc: 0.9832\n",
      "Epoch 128/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0315 - acc: 0.9901 - val_loss: 0.0488 - val_acc: 0.9830\n",
      "Epoch 129/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0313 - acc: 0.9901 - val_loss: 0.0488 - val_acc: 0.9830\n",
      "Epoch 130/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0308 - acc: 0.9902 - val_loss: 0.0484 - val_acc: 0.9831\n",
      "Epoch 131/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0303 - acc: 0.9902 - val_loss: 0.0482 - val_acc: 0.9833\n",
      "Epoch 132/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0298 - acc: 0.9907 - val_loss: 0.0483 - val_acc: 0.9833\n",
      "Epoch 133/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0296 - acc: 0.9908 - val_loss: 0.0482 - val_acc: 0.9835\n",
      "Epoch 134/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0292 - acc: 0.9908 - val_loss: 0.0482 - val_acc: 0.9833\n",
      "Epoch 135/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0292 - acc: 0.9910 - val_loss: 0.0508 - val_acc: 0.9819\n",
      "Epoch 136/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0469 - acc: 0.9832 - val_loss: 0.0696 - val_acc: 0.9777\n",
      "Epoch 137/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0432 - acc: 0.9843 - val_loss: 0.0595 - val_acc: 0.9806\n",
      "Epoch 138/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0373 - acc: 0.9870 - val_loss: 0.0552 - val_acc: 0.9819\n",
      "Epoch 139/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0344 - acc: 0.9881 - val_loss: 0.0523 - val_acc: 0.9821\n",
      "Epoch 140/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0327 - acc: 0.9892 - val_loss: 0.0512 - val_acc: 0.9825\n",
      "Epoch 141/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0315 - acc: 0.9895 - val_loss: 0.0504 - val_acc: 0.9825\n",
      "Epoch 142/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0308 - acc: 0.9900 - val_loss: 0.0501 - val_acc: 0.9827\n",
      "Epoch 143/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0303 - acc: 0.9900 - val_loss: 0.0497 - val_acc: 0.9830\n",
      "Epoch 144/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0296 - acc: 0.9904 - val_loss: 0.0494 - val_acc: 0.9828\n",
      "Epoch 145/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0292 - acc: 0.9904 - val_loss: 0.0495 - val_acc: 0.9833\n",
      "Epoch 146/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0289 - acc: 0.9907 - val_loss: 0.0492 - val_acc: 0.9831\n",
      "Epoch 147/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0286 - acc: 0.9907 - val_loss: 0.0489 - val_acc: 0.9834\n",
      "Epoch 148/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0287 - acc: 0.9907 - val_loss: 0.0489 - val_acc: 0.9833\n",
      "Epoch 149/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0288 - acc: 0.9905 - val_loss: 0.0496 - val_acc: 0.9830\n",
      "Epoch 150/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0285 - acc: 0.9906 - val_loss: 0.0489 - val_acc: 0.9837\n",
      "Epoch 151/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0278 - acc: 0.9911 - val_loss: 0.0485 - val_acc: 0.9838\n",
      "Epoch 152/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0274 - acc: 0.9912 - val_loss: 0.0485 - val_acc: 0.9833\n",
      "Epoch 153/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0271 - acc: 0.9913 - val_loss: 0.0483 - val_acc: 0.9837\n",
      "Epoch 154/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0268 - acc: 0.9915 - val_loss: 0.0482 - val_acc: 0.9835\n",
      "Epoch 155/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0265 - acc: 0.9916 - val_loss: 0.0482 - val_acc: 0.9836\n",
      "Epoch 156/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0262 - acc: 0.9918 - val_loss: 0.0482 - val_acc: 0.9837\n",
      "Epoch 157/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0260 - acc: 0.9919 - val_loss: 0.0488 - val_acc: 0.9838\n",
      "Epoch 158/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0260 - acc: 0.9917 - val_loss: 0.0481 - val_acc: 0.9837\n",
      "Epoch 159/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0256 - acc: 0.9919 - val_loss: 0.0491 - val_acc: 0.9839\n",
      "Epoch 160/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0321 - acc: 0.9889 - val_loss: 0.0573 - val_acc: 0.9814\n",
      "Epoch 161/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0302 - acc: 0.9897 - val_loss: 0.0523 - val_acc: 0.9830\n",
      "Epoch 162/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0276 - acc: 0.9907 - val_loss: 0.0491 - val_acc: 0.9834\n",
      "Epoch 163/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0257 - acc: 0.9919 - val_loss: 0.0483 - val_acc: 0.9835\n",
      "Epoch 164/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0252 - acc: 0.9920 - val_loss: 0.0479 - val_acc: 0.9839\n",
      "Epoch 165/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0248 - acc: 0.9924 - val_loss: 0.0478 - val_acc: 0.9839\n",
      "Epoch 166/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0247 - acc: 0.9922 - val_loss: 0.0484 - val_acc: 0.9836\n",
      "Epoch 167/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0247 - acc: 0.9923 - val_loss: 0.0491 - val_acc: 0.9837\n",
      "Epoch 168/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0243 - acc: 0.9922 - val_loss: 0.0491 - val_acc: 0.9837\n",
      "Epoch 169/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0243 - acc: 0.9923 - val_loss: 0.0485 - val_acc: 0.9838\n",
      "Epoch 170/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0236 - acc: 0.9927 - val_loss: 0.0487 - val_acc: 0.9840\n",
      "Epoch 171/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0245 - acc: 0.9922 - val_loss: 0.0497 - val_acc: 0.9841\n",
      "Epoch 172/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0239 - acc: 0.9925 - val_loss: 0.0488 - val_acc: 0.9837\n",
      "Epoch 173/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0233 - acc: 0.9926 - val_loss: 0.0553 - val_acc: 0.9816\n",
      "Epoch 174/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0574 - acc: 0.9788 - val_loss: 0.0705 - val_acc: 0.9780\n",
      "Epoch 175/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0420 - acc: 0.9853 - val_loss: 0.0555 - val_acc: 0.9818\n",
      "Epoch 176/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0336 - acc: 0.9892 - val_loss: 0.0505 - val_acc: 0.9826\n",
      "Epoch 177/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0302 - acc: 0.9896 - val_loss: 0.0488 - val_acc: 0.9836\n",
      "Epoch 178/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0281 - acc: 0.9909 - val_loss: 0.0480 - val_acc: 0.9838\n",
      "Epoch 179/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0273 - acc: 0.9912 - val_loss: 0.0477 - val_acc: 0.9837\n",
      "Epoch 180/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0267 - acc: 0.9914 - val_loss: 0.0476 - val_acc: 0.9836\n",
      "Epoch 181/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0259 - acc: 0.9918 - val_loss: 0.0477 - val_acc: 0.9836\n",
      "Epoch 182/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0254 - acc: 0.9918 - val_loss: 0.0476 - val_acc: 0.9836\n",
      "Epoch 183/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0250 - acc: 0.9921 - val_loss: 0.0478 - val_acc: 0.9837\n",
      "Epoch 184/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0247 - acc: 0.9921 - val_loss: 0.0479 - val_acc: 0.9838\n",
      "Epoch 185/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0245 - acc: 0.9922 - val_loss: 0.0483 - val_acc: 0.9838\n",
      "Epoch 186/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0240 - acc: 0.9924 - val_loss: 0.0480 - val_acc: 0.9839\n",
      "Epoch 187/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0235 - acc: 0.9925 - val_loss: 0.0485 - val_acc: 0.9835\n",
      "Epoch 188/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0238 - acc: 0.9921 - val_loss: 0.0497 - val_acc: 0.9835\n",
      "Epoch 189/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0237 - acc: 0.9924 - val_loss: 0.0486 - val_acc: 0.9835\n",
      "Epoch 190/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0228 - acc: 0.9928 - val_loss: 0.0484 - val_acc: 0.9837\n",
      "Epoch 191/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0224 - acc: 0.9930 - val_loss: 0.0483 - val_acc: 0.9836\n",
      "Epoch 192/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0221 - acc: 0.9930 - val_loss: 0.0485 - val_acc: 0.9835\n",
      "Epoch 193/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0218 - acc: 0.9933 - val_loss: 0.0516 - val_acc: 0.9832\n",
      "Epoch 194/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0404 - acc: 0.9872 - val_loss: 0.0664 - val_acc: 0.9813\n",
      "Epoch 195/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0424 - acc: 0.9867 - val_loss: 0.0649 - val_acc: 0.9785\n",
      "Epoch 196/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0349 - acc: 0.9873 - val_loss: 0.0531 - val_acc: 0.9827\n",
      "Epoch 197/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0267 - acc: 0.9908 - val_loss: 0.0500 - val_acc: 0.9839\n",
      "Epoch 198/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0248 - acc: 0.9921 - val_loss: 0.0486 - val_acc: 0.9835\n",
      "Epoch 199/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0235 - acc: 0.9923 - val_loss: 0.0482 - val_acc: 0.9835\n",
      "Epoch 200/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0227 - acc: 0.9924 - val_loss: 0.0482 - val_acc: 0.9836\n",
      "Epoch 201/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0221 - acc: 0.9930 - val_loss: 0.0482 - val_acc: 0.9836\n",
      "Epoch 202/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0217 - acc: 0.9930 - val_loss: 0.0483 - val_acc: 0.9837\n",
      "Epoch 203/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0213 - acc: 0.9930 - val_loss: 0.0485 - val_acc: 0.9840\n",
      "Epoch 204/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0210 - acc: 0.9931 - val_loss: 0.0485 - val_acc: 0.9835\n",
      "Epoch 205/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0207 - acc: 0.9935 - val_loss: 0.0486 - val_acc: 0.9838\n",
      "Epoch 206/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0203 - acc: 0.9935 - val_loss: 0.0490 - val_acc: 0.9836\n",
      "Epoch 207/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0210 - acc: 0.9930 - val_loss: 0.0504 - val_acc: 0.9834\n",
      "Epoch 208/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0210 - acc: 0.9933 - val_loss: 0.0644 - val_acc: 0.9794\n",
      "Epoch 209/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0928 - acc: 0.9759 - val_loss: 0.1286 - val_acc: 0.9683\n",
      "Epoch 210/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0696 - acc: 0.9793 - val_loss: 0.0730 - val_acc: 0.9787\n",
      "Epoch 211/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0433 - acc: 0.9854 - val_loss: 0.0559 - val_acc: 0.9820\n",
      "Epoch 212/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0325 - acc: 0.9886 - val_loss: 0.0499 - val_acc: 0.9831\n",
      "Epoch 213/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0289 - acc: 0.9899 - val_loss: 0.0479 - val_acc: 0.9838\n",
      "Epoch 214/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0274 - acc: 0.9902 - val_loss: 0.0476 - val_acc: 0.9837\n",
      "Epoch 215/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0263 - acc: 0.9909 - val_loss: 0.0469 - val_acc: 0.9840\n",
      "Epoch 216/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0252 - acc: 0.9912 - val_loss: 0.0469 - val_acc: 0.9843\n",
      "Epoch 217/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0244 - acc: 0.9916 - val_loss: 0.0470 - val_acc: 0.9841\n",
      "Epoch 218/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0237 - acc: 0.9920 - val_loss: 0.0471 - val_acc: 0.9840\n",
      "Epoch 219/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0231 - acc: 0.9922 - val_loss: 0.0481 - val_acc: 0.9838\n",
      "Epoch 220/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0300 - acc: 0.9899 - val_loss: 0.0538 - val_acc: 0.9821\n",
      "Epoch 221/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0284 - acc: 0.9901 - val_loss: 0.0503 - val_acc: 0.9836\n",
      "Epoch 222/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0261 - acc: 0.9904 - val_loss: 0.0485 - val_acc: 0.9837\n",
      "Epoch 223/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0237 - acc: 0.9920 - val_loss: 0.0476 - val_acc: 0.9839\n",
      "Epoch 224/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0226 - acc: 0.9926 - val_loss: 0.0475 - val_acc: 0.9836\n",
      "Epoch 225/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0219 - acc: 0.9926 - val_loss: 0.0527 - val_acc: 0.9829\n",
      "Epoch 226/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0378 - acc: 0.9871 - val_loss: 0.0632 - val_acc: 0.9816\n",
      "Epoch 227/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0323 - acc: 0.9882 - val_loss: 0.0544 - val_acc: 0.9825\n",
      "Epoch 228/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0273 - acc: 0.9902 - val_loss: 0.0503 - val_acc: 0.9834\n",
      "Epoch 229/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0243 - acc: 0.9917 - val_loss: 0.0516 - val_acc: 0.9829\n",
      "Epoch 230/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0541 - acc: 0.9811 - val_loss: 0.0848 - val_acc: 0.9730\n",
      "Epoch 231/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0494 - acc: 0.9825 - val_loss: 0.0683 - val_acc: 0.9797\n",
      "Epoch 232/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0367 - acc: 0.9869 - val_loss: 0.0560 - val_acc: 0.9815\n",
      "Epoch 233/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0296 - acc: 0.9899 - val_loss: 0.0527 - val_acc: 0.9831\n",
      "Epoch 234/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0267 - acc: 0.9907 - val_loss: 0.0508 - val_acc: 0.9829\n",
      "Epoch 235/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0252 - acc: 0.9914 - val_loss: 0.0499 - val_acc: 0.9836\n",
      "Epoch 236/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0240 - acc: 0.9917 - val_loss: 0.0492 - val_acc: 0.9835\n",
      "Epoch 237/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0231 - acc: 0.9925 - val_loss: 0.0490 - val_acc: 0.9837\n",
      "Epoch 238/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0224 - acc: 0.9926 - val_loss: 0.0494 - val_acc: 0.9836\n",
      "Epoch 239/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0257 - acc: 0.9911 - val_loss: 0.0516 - val_acc: 0.9835\n",
      "Epoch 240/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0259 - acc: 0.9905 - val_loss: 0.0507 - val_acc: 0.9838\n",
      "Epoch 241/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0235 - acc: 0.9921 - val_loss: 0.0495 - val_acc: 0.9842\n",
      "Epoch 242/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0219 - acc: 0.9923 - val_loss: 0.0489 - val_acc: 0.9837\n",
      "Epoch 243/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0216 - acc: 0.9930 - val_loss: 0.0502 - val_acc: 0.9842\n",
      "Epoch 244/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0232 - acc: 0.9919 - val_loss: 0.0508 - val_acc: 0.9834\n",
      "Epoch 245/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0222 - acc: 0.9927 - val_loss: 0.0499 - val_acc: 0.9839\n",
      "Epoch 246/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0206 - acc: 0.9932 - val_loss: 0.0519 - val_acc: 0.9838\n",
      "Epoch 247/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0390 - acc: 0.9878 - val_loss: 0.0664 - val_acc: 0.9803\n",
      "Epoch 248/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0324 - acc: 0.9894 - val_loss: 0.0563 - val_acc: 0.9826\n",
      "Epoch 249/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0267 - acc: 0.9906 - val_loss: 0.0536 - val_acc: 0.9827\n",
      "Epoch 250/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0236 - acc: 0.9922 - val_loss: 0.0512 - val_acc: 0.9832\n",
      "Epoch 251/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0218 - acc: 0.9930 - val_loss: 0.0529 - val_acc: 0.9831\n",
      "Epoch 252/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0397 - acc: 0.9861 - val_loss: 0.0675 - val_acc: 0.9792\n",
      "Epoch 253/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0383 - acc: 0.9870 - val_loss: 0.0561 - val_acc: 0.9827\n",
      "Epoch 254/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0292 - acc: 0.9906 - val_loss: 0.0518 - val_acc: 0.9831\n",
      "Epoch 255/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0258 - acc: 0.9911 - val_loss: 0.0497 - val_acc: 0.9834\n",
      "Epoch 256/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0237 - acc: 0.9918 - val_loss: 0.0487 - val_acc: 0.9839\n",
      "Epoch 257/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0223 - acc: 0.9926 - val_loss: 0.0487 - val_acc: 0.9841\n",
      "Epoch 258/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0214 - acc: 0.9929 - val_loss: 0.0487 - val_acc: 0.9841\n",
      "Epoch 259/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0207 - acc: 0.9933 - val_loss: 0.0488 - val_acc: 0.9840\n",
      "Epoch 260/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0201 - acc: 0.9936 - val_loss: 0.0490 - val_acc: 0.9840\n",
      "Epoch 261/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0196 - acc: 0.9938 - val_loss: 0.0493 - val_acc: 0.9840\n",
      "Epoch 262/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0205 - acc: 0.9935 - val_loss: 0.0516 - val_acc: 0.9835\n",
      "Epoch 263/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0203 - acc: 0.9937 - val_loss: 0.0507 - val_acc: 0.9836\n",
      "Epoch 264/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0194 - acc: 0.9944 - val_loss: 0.0509 - val_acc: 0.9838\n",
      "Epoch 265/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0243 - acc: 0.9922 - val_loss: 0.0555 - val_acc: 0.9830\n",
      "Epoch 266/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0237 - acc: 0.9919 - val_loss: 0.0527 - val_acc: 0.9836\n",
      "Epoch 267/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0203 - acc: 0.9930 - val_loss: 0.0533 - val_acc: 0.9829\n",
      "Epoch 268/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0258 - acc: 0.9904 - val_loss: 0.0576 - val_acc: 0.9822\n",
      "Epoch 269/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0261 - acc: 0.9904 - val_loss: 0.0555 - val_acc: 0.9821\n",
      "Epoch 270/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0222 - acc: 0.9921 - val_loss: 0.0526 - val_acc: 0.9838\n",
      "Epoch 271/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0199 - acc: 0.9934 - val_loss: 0.0523 - val_acc: 0.9832\n",
      "Epoch 272/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0192 - acc: 0.9940 - val_loss: 0.0515 - val_acc: 0.9836\n",
      "Epoch 273/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0304 - acc: 0.9894 - val_loss: 0.0630 - val_acc: 0.9805\n",
      "Epoch 274/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0279 - acc: 0.9898 - val_loss: 0.0569 - val_acc: 0.9825\n",
      "Epoch 275/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0231 - acc: 0.9916 - val_loss: 0.0535 - val_acc: 0.9834\n",
      "Epoch 276/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0212 - acc: 0.9927 - val_loss: 0.0525 - val_acc: 0.9831\n",
      "Epoch 277/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0197 - acc: 0.9936 - val_loss: 0.0562 - val_acc: 0.9825\n",
      "Epoch 278/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0461 - acc: 0.9831 - val_loss: 0.0800 - val_acc: 0.9735\n",
      "Epoch 279/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0391 - acc: 0.9853 - val_loss: 0.0636 - val_acc: 0.9809\n",
      "Epoch 280/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0288 - acc: 0.9893 - val_loss: 0.0545 - val_acc: 0.9822\n",
      "Epoch 281/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0232 - acc: 0.9921 - val_loss: 0.0508 - val_acc: 0.9835\n",
      "Epoch 282/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0208 - acc: 0.9930 - val_loss: 0.0499 - val_acc: 0.9836\n",
      "Epoch 283/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0198 - acc: 0.9935 - val_loss: 0.0496 - val_acc: 0.9835\n",
      "Epoch 284/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0190 - acc: 0.9940 - val_loss: 0.0583 - val_acc: 0.9816\n",
      "Epoch 285/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0743 - acc: 0.9791 - val_loss: 0.0934 - val_acc: 0.9753\n",
      "Epoch 286/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0591 - acc: 0.9811 - val_loss: 0.0731 - val_acc: 0.9785\n",
      "Epoch 287/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0725 - acc: 0.9752 - val_loss: 0.0858 - val_acc: 0.9722\n",
      "Epoch 288/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0691 - acc: 0.9761 - val_loss: 0.0818 - val_acc: 0.9737\n",
      "Epoch 289/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0568 - acc: 0.9806 - val_loss: 0.0687 - val_acc: 0.9780\n",
      "Epoch 290/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0474 - acc: 0.9831 - val_loss: 0.0595 - val_acc: 0.9793\n",
      "Epoch 291/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0407 - acc: 0.9856 - val_loss: 0.0552 - val_acc: 0.9806\n",
      "Epoch 292/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0375 - acc: 0.9870 - val_loss: 0.0534 - val_acc: 0.9810\n",
      "Epoch 293/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0355 - acc: 0.9879 - val_loss: 0.0529 - val_acc: 0.9818\n",
      "Epoch 294/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0438 - acc: 0.9850 - val_loss: 0.0577 - val_acc: 0.9795\n",
      "Epoch 295/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0392 - acc: 0.9851 - val_loss: 0.0563 - val_acc: 0.9801\n",
      "Epoch 296/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0354 - acc: 0.9873 - val_loss: 0.0527 - val_acc: 0.9817\n",
      "Epoch 297/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0327 - acc: 0.9883 - val_loss: 0.0515 - val_acc: 0.9817\n",
      "Epoch 298/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0313 - acc: 0.9892 - val_loss: 0.0506 - val_acc: 0.9819\n",
      "Epoch 299/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0301 - acc: 0.9896 - val_loss: 0.0502 - val_acc: 0.9824\n",
      "Epoch 300/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0293 - acc: 0.9900 - val_loss: 0.0500 - val_acc: 0.9822\n",
      "Epoch 301/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0285 - acc: 0.9906 - val_loss: 0.0499 - val_acc: 0.9822\n",
      "Epoch 302/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0277 - acc: 0.9908 - val_loss: 0.0506 - val_acc: 0.9830\n",
      "Epoch 303/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0398 - acc: 0.9864 - val_loss: 0.0565 - val_acc: 0.9814\n",
      "Epoch 304/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0348 - acc: 0.9882 - val_loss: 0.0550 - val_acc: 0.9821\n",
      "Epoch 305/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0310 - acc: 0.9890 - val_loss: 0.0512 - val_acc: 0.9831\n",
      "Epoch 306/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0308 - acc: 0.9889 - val_loss: 0.0511 - val_acc: 0.9832\n",
      "Epoch 307/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0287 - acc: 0.9905 - val_loss: 0.0507 - val_acc: 0.9833\n",
      "Epoch 308/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0308 - acc: 0.9890 - val_loss: 0.0566 - val_acc: 0.9825\n",
      "Epoch 309/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0331 - acc: 0.9882 - val_loss: 0.0558 - val_acc: 0.9823\n",
      "Epoch 310/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0304 - acc: 0.9894 - val_loss: 0.0524 - val_acc: 0.9833\n",
      "Epoch 311/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0279 - acc: 0.9902 - val_loss: 0.0506 - val_acc: 0.9831\n",
      "Epoch 312/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0264 - acc: 0.9909 - val_loss: 0.0495 - val_acc: 0.9836\n",
      "Epoch 313/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0254 - acc: 0.9912 - val_loss: 0.0490 - val_acc: 0.9838\n",
      "Epoch 314/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0246 - acc: 0.9918 - val_loss: 0.0489 - val_acc: 0.9838\n",
      "Epoch 315/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0240 - acc: 0.9922 - val_loss: 0.0489 - val_acc: 0.9837\n",
      "Epoch 316/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0235 - acc: 0.9922 - val_loss: 0.0490 - val_acc: 0.9836\n",
      "Epoch 317/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0230 - acc: 0.9926 - val_loss: 0.0490 - val_acc: 0.9837\n",
      "Epoch 318/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0227 - acc: 0.9928 - val_loss: 0.0497 - val_acc: 0.9835\n",
      "Epoch 319/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0271 - acc: 0.9905 - val_loss: 0.0527 - val_acc: 0.9834\n",
      "Epoch 320/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0254 - acc: 0.9910 - val_loss: 0.0507 - val_acc: 0.9837\n",
      "Epoch 321/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0231 - acc: 0.9924 - val_loss: 0.0504 - val_acc: 0.9833\n",
      "Epoch 322/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0222 - acc: 0.9930 - val_loss: 0.0499 - val_acc: 0.9840\n",
      "Epoch 323/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0216 - acc: 0.9934 - val_loss: 0.0498 - val_acc: 0.9842\n",
      "Epoch 324/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0211 - acc: 0.9936 - val_loss: 0.0497 - val_acc: 0.9840\n",
      "Epoch 325/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0206 - acc: 0.9938 - val_loss: 0.0497 - val_acc: 0.9840\n",
      "Epoch 326/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0203 - acc: 0.9939 - val_loss: 0.0500 - val_acc: 0.9840\n",
      "Epoch 327/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0201 - acc: 0.9939 - val_loss: 0.0501 - val_acc: 0.9841\n",
      "Epoch 328/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0198 - acc: 0.9942 - val_loss: 0.0507 - val_acc: 0.9839\n",
      "Epoch 329/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0240 - acc: 0.9918 - val_loss: 0.0549 - val_acc: 0.9832\n",
      "Epoch 330/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0236 - acc: 0.9917 - val_loss: 0.0531 - val_acc: 0.9835\n",
      "Epoch 331/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0211 - acc: 0.9932 - val_loss: 0.0525 - val_acc: 0.9835\n",
      "Epoch 332/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0202 - acc: 0.9935 - val_loss: 0.0518 - val_acc: 0.9836\n",
      "Epoch 333/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0196 - acc: 0.9939 - val_loss: 0.0517 - val_acc: 0.9838\n",
      "Epoch 334/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0191 - acc: 0.9942 - val_loss: 0.0514 - val_acc: 0.9842\n",
      "Epoch 335/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0187 - acc: 0.9944 - val_loss: 0.0512 - val_acc: 0.9842\n",
      "Epoch 336/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0183 - acc: 0.9945 - val_loss: 0.0511 - val_acc: 0.9842\n",
      "Epoch 337/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0180 - acc: 0.9947 - val_loss: 0.0525 - val_acc: 0.9839\n",
      "Epoch 338/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0301 - acc: 0.9900 - val_loss: 0.0583 - val_acc: 0.9835\n",
      "Epoch 339/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0256 - acc: 0.9907 - val_loss: 0.0520 - val_acc: 0.9840\n",
      "Epoch 340/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0211 - acc: 0.9931 - val_loss: 0.0508 - val_acc: 0.9840\n",
      "Epoch 341/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0194 - acc: 0.9937 - val_loss: 0.0505 - val_acc: 0.9847\n",
      "Epoch 342/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0184 - acc: 0.9943 - val_loss: 0.0508 - val_acc: 0.9845\n",
      "Epoch 343/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0180 - acc: 0.9946 - val_loss: 0.0506 - val_acc: 0.9847\n",
      "Epoch 344/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0176 - acc: 0.9947 - val_loss: 0.0506 - val_acc: 0.9847\n",
      "Epoch 345/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0174 - acc: 0.9950 - val_loss: 0.0506 - val_acc: 0.9848\n",
      "Epoch 346/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0170 - acc: 0.9950 - val_loss: 0.0507 - val_acc: 0.9847\n",
      "Epoch 347/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0167 - acc: 0.9951 - val_loss: 0.0507 - val_acc: 0.9848\n",
      "Epoch 348/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0165 - acc: 0.9953 - val_loss: 0.0508 - val_acc: 0.9847\n",
      "Epoch 349/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0162 - acc: 0.9955 - val_loss: 0.0511 - val_acc: 0.9847\n",
      "Epoch 350/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0161 - acc: 0.9955 - val_loss: 0.0516 - val_acc: 0.9847\n",
      "Epoch 351/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0159 - acc: 0.9954 - val_loss: 0.0515 - val_acc: 0.9845\n",
      "Epoch 352/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0185 - acc: 0.9941 - val_loss: 0.0533 - val_acc: 0.9837\n",
      "Epoch 353/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0180 - acc: 0.9942 - val_loss: 0.0521 - val_acc: 0.9841\n",
      "Epoch 354/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0165 - acc: 0.9951 - val_loss: 0.0518 - val_acc: 0.9845\n",
      "Epoch 355/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0158 - acc: 0.9952 - val_loss: 0.0517 - val_acc: 0.9846\n",
      "Epoch 356/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0153 - acc: 0.9954 - val_loss: 0.0517 - val_acc: 0.9846\n",
      "Epoch 357/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0150 - acc: 0.9956 - val_loss: 0.0517 - val_acc: 0.9847\n",
      "Epoch 358/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0148 - acc: 0.9957 - val_loss: 0.0519 - val_acc: 0.9848\n",
      "Epoch 359/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0146 - acc: 0.9959 - val_loss: 0.0521 - val_acc: 0.9849\n",
      "Epoch 360/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0144 - acc: 0.9959 - val_loss: 0.0521 - val_acc: 0.9848\n",
      "Epoch 361/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0142 - acc: 0.9959 - val_loss: 0.0523 - val_acc: 0.9846\n",
      "Epoch 362/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0145 - acc: 0.9961 - val_loss: 0.0530 - val_acc: 0.9851\n",
      "Epoch 363/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0141 - acc: 0.9959 - val_loss: 0.0526 - val_acc: 0.9848\n",
      "Epoch 364/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0138 - acc: 0.9961 - val_loss: 0.0534 - val_acc: 0.9849\n",
      "Epoch 365/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0161 - acc: 0.9947 - val_loss: 0.0556 - val_acc: 0.9840\n",
      "Epoch 366/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0159 - acc: 0.9948 - val_loss: 0.0545 - val_acc: 0.9850\n",
      "Epoch 367/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0143 - acc: 0.9953 - val_loss: 0.0541 - val_acc: 0.9843\n",
      "Epoch 368/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0141 - acc: 0.9959 - val_loss: 0.0540 - val_acc: 0.9850\n",
      "Epoch 369/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0134 - acc: 0.9963 - val_loss: 0.0552 - val_acc: 0.9848\n",
      "Epoch 370/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0289 - acc: 0.9915 - val_loss: 0.0701 - val_acc: 0.9831\n",
      "Epoch 371/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0278 - acc: 0.9912 - val_loss: 0.0593 - val_acc: 0.9838\n",
      "Epoch 372/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0215 - acc: 0.9932 - val_loss: 0.0557 - val_acc: 0.9832\n",
      "Epoch 373/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0185 - acc: 0.9940 - val_loss: 0.0536 - val_acc: 0.9847\n",
      "Epoch 374/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0168 - acc: 0.9954 - val_loss: 0.0527 - val_acc: 0.9844\n",
      "Epoch 375/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0159 - acc: 0.9955 - val_loss: 0.0522 - val_acc: 0.9847\n",
      "Epoch 376/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0151 - acc: 0.9957 - val_loss: 0.0521 - val_acc: 0.9848\n",
      "Epoch 377/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0146 - acc: 0.9958 - val_loss: 0.0524 - val_acc: 0.9848\n",
      "Epoch 378/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0143 - acc: 0.9959 - val_loss: 0.0529 - val_acc: 0.9850\n",
      "Epoch 379/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0139 - acc: 0.9962 - val_loss: 0.0564 - val_acc: 0.9843\n",
      "Epoch 380/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0306 - acc: 0.9892 - val_loss: 0.0719 - val_acc: 0.9789\n",
      "Epoch 381/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0284 - acc: 0.9903 - val_loss: 0.0618 - val_acc: 0.9848\n",
      "Epoch 382/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0221 - acc: 0.9927 - val_loss: 0.0561 - val_acc: 0.9843\n",
      "Epoch 383/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0181 - acc: 0.9943 - val_loss: 0.0544 - val_acc: 0.9847\n",
      "Epoch 384/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0164 - acc: 0.9946 - val_loss: 0.0532 - val_acc: 0.9841\n",
      "Epoch 385/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0148 - acc: 0.9957 - val_loss: 0.0528 - val_acc: 0.9847\n",
      "Epoch 386/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0139 - acc: 0.9957 - val_loss: 0.0528 - val_acc: 0.9850\n",
      "Epoch 387/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0133 - acc: 0.9961 - val_loss: 0.0527 - val_acc: 0.9850\n",
      "Epoch 388/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0129 - acc: 0.9964 - val_loss: 0.0527 - val_acc: 0.9848\n",
      "Epoch 389/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0126 - acc: 0.9964 - val_loss: 0.0528 - val_acc: 0.9851\n",
      "Epoch 390/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0123 - acc: 0.9965 - val_loss: 0.0530 - val_acc: 0.9851\n",
      "Epoch 391/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0121 - acc: 0.9966 - val_loss: 0.0531 - val_acc: 0.9849\n",
      "Epoch 392/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0119 - acc: 0.9968 - val_loss: 0.0533 - val_acc: 0.9849\n",
      "Epoch 393/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0117 - acc: 0.9970 - val_loss: 0.0534 - val_acc: 0.9850\n",
      "Epoch 394/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0115 - acc: 0.9968 - val_loss: 0.0538 - val_acc: 0.9850\n",
      "Epoch 395/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0115 - acc: 0.9968 - val_loss: 0.0540 - val_acc: 0.9850\n",
      "Epoch 396/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0114 - acc: 0.9970 - val_loss: 0.0539 - val_acc: 0.9850\n",
      "Epoch 397/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0111 - acc: 0.9971 - val_loss: 0.0543 - val_acc: 0.9849\n",
      "Epoch 398/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0109 - acc: 0.9971 - val_loss: 0.0546 - val_acc: 0.9848\n",
      "Epoch 399/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0107 - acc: 0.9973 - val_loss: 0.0548 - val_acc: 0.9849\n",
      "Epoch 400/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0105 - acc: 0.9974 - val_loss: 0.0550 - val_acc: 0.9848\n",
      "Epoch 401/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0103 - acc: 0.9974 - val_loss: 0.0553 - val_acc: 0.9848\n",
      "Epoch 402/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0555 - val_acc: 0.9848\n",
      "Epoch 403/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0101 - acc: 0.9977 - val_loss: 0.0558 - val_acc: 0.9848\n",
      "Epoch 404/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0100 - acc: 0.9977 - val_loss: 0.0559 - val_acc: 0.9847\n",
      "Epoch 405/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0098 - acc: 0.9976 - val_loss: 0.0562 - val_acc: 0.9847\n",
      "Epoch 406/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0097 - acc: 0.9976 - val_loss: 0.0564 - val_acc: 0.9847\n",
      "Epoch 407/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0571 - val_acc: 0.9845\n",
      "Epoch 408/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0120 - acc: 0.9962 - val_loss: 0.0600 - val_acc: 0.9847\n",
      "Epoch 409/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0108 - acc: 0.9970 - val_loss: 0.0584 - val_acc: 0.9838\n",
      "Epoch 410/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0101 - acc: 0.9973 - val_loss: 0.0582 - val_acc: 0.9851\n",
      "Epoch 411/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0094 - acc: 0.9975 - val_loss: 0.0581 - val_acc: 0.9846\n",
      "Epoch 412/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0092 - acc: 0.9979 - val_loss: 0.0579 - val_acc: 0.9846\n",
      "Epoch 413/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0089 - acc: 0.9980 - val_loss: 0.0582 - val_acc: 0.9846\n",
      "Epoch 414/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0091 - acc: 0.9978 - val_loss: 0.0595 - val_acc: 0.9850\n",
      "Epoch 415/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0090 - acc: 0.9978 - val_loss: 0.0590 - val_acc: 0.9843\n",
      "Epoch 416/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0087 - acc: 0.9980 - val_loss: 0.0590 - val_acc: 0.9848\n",
      "Epoch 417/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0084 - acc: 0.9980 - val_loss: 0.0591 - val_acc: 0.9845\n",
      "Epoch 418/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0083 - acc: 0.9980 - val_loss: 0.0593 - val_acc: 0.9846\n",
      "Epoch 419/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0082 - acc: 0.9983 - val_loss: 0.0596 - val_acc: 0.9847\n",
      "Epoch 420/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0618 - val_acc: 0.9850\n",
      "Epoch 421/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0195 - acc: 0.9950 - val_loss: 0.0730 - val_acc: 0.9829\n",
      "Epoch 422/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0199 - acc: 0.9945 - val_loss: 0.0688 - val_acc: 0.9841\n",
      "Epoch 423/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0160 - acc: 0.9957 - val_loss: 0.0644 - val_acc: 0.9835\n",
      "Epoch 424/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0135 - acc: 0.9966 - val_loss: 0.0628 - val_acc: 0.9837\n",
      "Epoch 425/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0174 - acc: 0.9946 - val_loss: 0.0704 - val_acc: 0.9838\n",
      "Epoch 426/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0226 - acc: 0.9930 - val_loss: 0.0727 - val_acc: 0.9809\n",
      "Epoch 427/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0190 - acc: 0.9940 - val_loss: 0.0632 - val_acc: 0.9851\n",
      "Epoch 428/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0138 - acc: 0.9961 - val_loss: 0.0604 - val_acc: 0.9839\n",
      "Epoch 429/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0120 - acc: 0.9969 - val_loss: 0.0598 - val_acc: 0.9839\n",
      "Epoch 430/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0111 - acc: 0.9971 - val_loss: 0.0596 - val_acc: 0.9841\n",
      "Epoch 431/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0105 - acc: 0.9973 - val_loss: 0.0596 - val_acc: 0.9844\n",
      "Epoch 432/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0100 - acc: 0.9975 - val_loss: 0.0597 - val_acc: 0.9842\n",
      "Epoch 433/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0097 - acc: 0.9978 - val_loss: 0.0602 - val_acc: 0.9841\n",
      "Epoch 434/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0601 - val_acc: 0.9839\n",
      "Epoch 435/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0092 - acc: 0.9979 - val_loss: 0.0607 - val_acc: 0.9844\n",
      "Epoch 436/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0090 - acc: 0.9980 - val_loss: 0.0605 - val_acc: 0.9840\n",
      "Epoch 437/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0087 - acc: 0.9981 - val_loss: 0.0610 - val_acc: 0.9844\n",
      "Epoch 438/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0612 - val_acc: 0.9842\n",
      "Epoch 439/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0083 - acc: 0.9981 - val_loss: 0.0614 - val_acc: 0.9841\n",
      "Epoch 440/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0082 - acc: 0.9984 - val_loss: 0.0616 - val_acc: 0.9840\n",
      "Epoch 441/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0080 - acc: 0.9984 - val_loss: 0.0622 - val_acc: 0.9840\n",
      "Epoch 442/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0078 - acc: 0.9984 - val_loss: 0.0623 - val_acc: 0.9838\n",
      "Epoch 443/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0077 - acc: 0.9984 - val_loss: 0.0626 - val_acc: 0.9840\n",
      "Epoch 444/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0076 - acc: 0.9985 - val_loss: 0.0630 - val_acc: 0.9840\n",
      "Epoch 445/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0075 - acc: 0.9984 - val_loss: 0.0632 - val_acc: 0.9838\n",
      "Epoch 446/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0073 - acc: 0.9987 - val_loss: 0.0636 - val_acc: 0.9838\n",
      "Epoch 447/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0072 - acc: 0.9986 - val_loss: 0.0640 - val_acc: 0.9832\n",
      "Epoch 448/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0105 - acc: 0.9969 - val_loss: 0.0686 - val_acc: 0.9835\n",
      "Epoch 449/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0095 - acc: 0.9975 - val_loss: 0.0658 - val_acc: 0.9833\n",
      "Epoch 450/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0082 - acc: 0.9980 - val_loss: 0.0655 - val_acc: 0.9836\n",
      "Epoch 451/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0076 - acc: 0.9983 - val_loss: 0.0652 - val_acc: 0.9836\n",
      "Epoch 452/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0070 - acc: 0.9986 - val_loss: 0.0652 - val_acc: 0.9836\n",
      "Epoch 453/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0068 - acc: 0.9987 - val_loss: 0.0658 - val_acc: 0.9837\n",
      "Epoch 454/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0069 - acc: 0.9987 - val_loss: 0.0658 - val_acc: 0.9835\n",
      "Epoch 455/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0066 - acc: 0.9989 - val_loss: 0.0666 - val_acc: 0.9829\n",
      "Epoch 456/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0174 - acc: 0.9942 - val_loss: 0.0755 - val_acc: 0.9834\n",
      "Epoch 457/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0131 - acc: 0.9960 - val_loss: 0.0691 - val_acc: 0.9837\n",
      "Epoch 458/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0097 - acc: 0.9973 - val_loss: 0.0660 - val_acc: 0.9832\n",
      "Epoch 459/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0083 - acc: 0.9983 - val_loss: 0.0652 - val_acc: 0.9840\n",
      "Epoch 460/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0074 - acc: 0.9984 - val_loss: 0.0647 - val_acc: 0.9837\n",
      "Epoch 461/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0069 - acc: 0.9986 - val_loss: 0.0653 - val_acc: 0.9838\n",
      "Epoch 462/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0065 - acc: 0.9987 - val_loss: 0.0742 - val_acc: 0.9812\n",
      "Epoch 463/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0380 - acc: 0.9886 - val_loss: 0.0970 - val_acc: 0.9799\n",
      "Epoch 464/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0285 - acc: 0.9912 - val_loss: 0.0775 - val_acc: 0.9816\n",
      "Epoch 465/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0190 - acc: 0.9938 - val_loss: 0.0683 - val_acc: 0.9822\n",
      "Epoch 466/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0145 - acc: 0.9955 - val_loss: 0.0663 - val_acc: 0.9828\n",
      "Epoch 467/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0123 - acc: 0.9963 - val_loss: 0.0633 - val_acc: 0.9825\n",
      "Epoch 468/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0120 - acc: 0.9964 - val_loss: 0.0672 - val_acc: 0.9829\n",
      "Epoch 469/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0112 - acc: 0.9966 - val_loss: 0.0800 - val_acc: 0.9775\n",
      "Epoch 470/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0705 - acc: 0.9784 - val_loss: 0.0892 - val_acc: 0.9791\n",
      "Epoch 471/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0391 - acc: 0.9878 - val_loss: 0.0746 - val_acc: 0.9810\n",
      "Epoch 472/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0271 - acc: 0.9908 - val_loss: 0.0638 - val_acc: 0.9823\n",
      "Epoch 473/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0200 - acc: 0.9931 - val_loss: 0.0598 - val_acc: 0.9823\n",
      "Epoch 474/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0167 - acc: 0.9945 - val_loss: 0.0583 - val_acc: 0.9828\n",
      "Epoch 475/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0148 - acc: 0.9951 - val_loss: 0.0573 - val_acc: 0.9834\n",
      "Epoch 476/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0135 - acc: 0.9957 - val_loss: 0.0573 - val_acc: 0.9832\n",
      "Epoch 477/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0130 - acc: 0.9960 - val_loss: 0.0597 - val_acc: 0.9834\n",
      "Epoch 478/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0183 - acc: 0.9940 - val_loss: 0.0633 - val_acc: 0.9836\n",
      "Epoch 479/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0188 - acc: 0.9940 - val_loss: 0.0613 - val_acc: 0.9834\n",
      "Epoch 480/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0151 - acc: 0.9956 - val_loss: 0.0597 - val_acc: 0.9830\n",
      "Epoch 481/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0137 - acc: 0.9962 - val_loss: 0.0591 - val_acc: 0.9835\n",
      "Epoch 482/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0125 - acc: 0.9968 - val_loss: 0.0584 - val_acc: 0.9835\n",
      "Epoch 483/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0115 - acc: 0.9968 - val_loss: 0.0585 - val_acc: 0.9835\n",
      "Epoch 484/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0108 - acc: 0.9971 - val_loss: 0.0584 - val_acc: 0.9836\n",
      "Epoch 485/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0587 - val_acc: 0.9836\n",
      "Epoch 486/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0097 - acc: 0.9977 - val_loss: 0.0588 - val_acc: 0.9837\n",
      "Epoch 487/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0094 - acc: 0.9977 - val_loss: 0.0591 - val_acc: 0.9838\n",
      "Epoch 488/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0090 - acc: 0.9977 - val_loss: 0.0596 - val_acc: 0.9840\n",
      "Epoch 489/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0087 - acc: 0.9979 - val_loss: 0.0599 - val_acc: 0.9838\n",
      "Epoch 490/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0083 - acc: 0.9980 - val_loss: 0.0604 - val_acc: 0.9842\n",
      "Epoch 491/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0081 - acc: 0.9980 - val_loss: 0.0606 - val_acc: 0.9836\n",
      "Epoch 492/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0079 - acc: 0.9981 - val_loss: 0.0612 - val_acc: 0.9842\n",
      "Epoch 493/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0076 - acc: 0.9983 - val_loss: 0.0615 - val_acc: 0.9841\n",
      "Epoch 494/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0074 - acc: 0.9984 - val_loss: 0.0619 - val_acc: 0.9840\n",
      "Epoch 495/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0073 - acc: 0.9984 - val_loss: 0.0623 - val_acc: 0.9840\n",
      "Epoch 496/500\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.9985 - val_loss: 0.0627 - val_acc: 0.9841\n",
      "Epoch 497/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0069 - acc: 0.9985 - val_loss: 0.0631 - val_acc: 0.9840\n",
      "Epoch 498/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0067 - acc: 0.9986 - val_loss: 0.0635 - val_acc: 0.9839\n",
      "Epoch 499/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0066 - acc: 0.9987 - val_loss: 0.0638 - val_acc: 0.9839\n",
      "Epoch 500/500\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0064 - acc: 0.9988 - val_loss: 0.0642 - val_acc: 0.9839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fec67c93160>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nD_phys = Sequential()\n",
    "model_nD_phys.add(Dense(64, input_dim=4*n_phys, activation='relu')) \n",
    "model_nD_phys.add(Dense(64, activation='relu'))\n",
    "model_nD_phys.add(Dense(128, activation='relu'))\n",
    "model_nD_phys.add(Dense(64, activation='relu'))\n",
    "model_nD_phys.add(Dense(1, activation='sigmoid'))\n",
    "model_nD_phys.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_nD_phys.fit(X_nD_train_phys,Y_nD_train_phys, epochs=500, batch_size=int(0.1*len(X_nD_train_phys)),validation_data=(X_nD_val_phys,Y_nD_val_phys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32774 samples, validate on 32775 samples\n",
      "Epoch 1/50\n",
      "32774/32774 [==============================] - 1s 18us/step - loss: 0.6195 - acc: 0.6646 - val_loss: 0.4613 - val_acc: 0.8647\n",
      "Epoch 2/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.3638 - acc: 0.9003 - val_loss: 0.2165 - val_acc: 0.9499\n",
      "Epoch 3/50\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.1623 - acc: 0.9552 - val_loss: 0.1145 - val_acc: 0.9577\n",
      "Epoch 4/50\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.1082 - acc: 0.9590 - val_loss: 0.1026 - val_acc: 0.9617\n",
      "Epoch 5/50\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.1041 - acc: 0.9609 - val_loss: 0.0979 - val_acc: 0.9632\n",
      "Epoch 6/50\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0975 - acc: 0.9634 - val_loss: 0.0922 - val_acc: 0.9651\n",
      "Epoch 7/50\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0904 - acc: 0.9655 - val_loss: 0.0903 - val_acc: 0.9661\n",
      "Epoch 8/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0920 - acc: 0.9652 - val_loss: 0.0889 - val_acc: 0.9665\n",
      "Epoch 9/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0861 - acc: 0.9669 - val_loss: 0.0836 - val_acc: 0.9690\n",
      "Epoch 10/50\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0814 - acc: 0.9691 - val_loss: 0.0801 - val_acc: 0.9704\n",
      "Epoch 11/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0896 - acc: 0.9670 - val_loss: 0.0834 - val_acc: 0.9681\n",
      "Epoch 12/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0829 - acc: 0.9684 - val_loss: 0.0786 - val_acc: 0.9702\n",
      "Epoch 13/50\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0819 - acc: 0.9688 - val_loss: 0.0788 - val_acc: 0.9706\n",
      "Epoch 14/50\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0819 - acc: 0.9694 - val_loss: 0.0838 - val_acc: 0.9678\n",
      "Epoch 15/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0791 - acc: 0.9701 - val_loss: 0.0771 - val_acc: 0.9706\n",
      "Epoch 16/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0734 - acc: 0.9729 - val_loss: 0.0748 - val_acc: 0.9717\n",
      "Epoch 17/50\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0773 - acc: 0.9713 - val_loss: 0.0755 - val_acc: 0.9723\n",
      "Epoch 18/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0751 - acc: 0.9716 - val_loss: 0.0743 - val_acc: 0.9724\n",
      "Epoch 19/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0720 - acc: 0.9730 - val_loss: 0.0712 - val_acc: 0.9728\n",
      "Epoch 20/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0685 - acc: 0.9739 - val_loss: 0.0688 - val_acc: 0.9742\n",
      "Epoch 21/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0662 - acc: 0.9751 - val_loss: 0.0674 - val_acc: 0.9745\n",
      "Epoch 22/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0660 - acc: 0.9755 - val_loss: 0.0668 - val_acc: 0.9748\n",
      "Epoch 23/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0643 - acc: 0.9758 - val_loss: 0.0656 - val_acc: 0.9751\n",
      "Epoch 24/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0626 - acc: 0.9768 - val_loss: 0.0646 - val_acc: 0.9756\n",
      "Epoch 25/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0611 - acc: 0.9779 - val_loss: 0.0632 - val_acc: 0.9762\n",
      "Epoch 26/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0599 - acc: 0.9781 - val_loss: 0.0663 - val_acc: 0.9754\n",
      "Epoch 27/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0705 - acc: 0.9738 - val_loss: 0.0693 - val_acc: 0.9747\n",
      "Epoch 28/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0670 - acc: 0.9759 - val_loss: 0.0661 - val_acc: 0.9752\n",
      "Epoch 29/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0628 - acc: 0.9770 - val_loss: 0.0625 - val_acc: 0.9770\n",
      "Epoch 30/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0591 - acc: 0.9790 - val_loss: 0.0603 - val_acc: 0.9772\n",
      "Epoch 31/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0586 - acc: 0.9789 - val_loss: 0.0620 - val_acc: 0.9766\n",
      "Epoch 32/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0573 - acc: 0.9799 - val_loss: 0.0601 - val_acc: 0.9775\n",
      "Epoch 33/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0554 - acc: 0.9804 - val_loss: 0.0587 - val_acc: 0.9781\n",
      "Epoch 34/50\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0544 - acc: 0.9809 - val_loss: 0.0581 - val_acc: 0.9783\n",
      "Epoch 35/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0534 - acc: 0.9812 - val_loss: 0.0572 - val_acc: 0.9783\n",
      "Epoch 36/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0525 - acc: 0.9815 - val_loss: 0.0566 - val_acc: 0.9788\n",
      "Epoch 37/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0517 - acc: 0.9817 - val_loss: 0.0576 - val_acc: 0.9780\n",
      "Epoch 38/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0670 - acc: 0.9753 - val_loss: 0.0778 - val_acc: 0.9709\n",
      "Epoch 39/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0690 - acc: 0.9749 - val_loss: 0.0629 - val_acc: 0.9769\n",
      "Epoch 40/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0572 - acc: 0.9788 - val_loss: 0.0588 - val_acc: 0.9783\n",
      "Epoch 41/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0550 - acc: 0.9796 - val_loss: 0.0573 - val_acc: 0.9786\n",
      "Epoch 42/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0526 - acc: 0.9814 - val_loss: 0.0565 - val_acc: 0.9791\n",
      "Epoch 43/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0514 - acc: 0.9822 - val_loss: 0.0555 - val_acc: 0.9789\n",
      "Epoch 44/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0521 - acc: 0.9817 - val_loss: 0.0577 - val_acc: 0.9787\n",
      "Epoch 45/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0512 - acc: 0.9816 - val_loss: 0.0552 - val_acc: 0.9797\n",
      "Epoch 46/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0495 - acc: 0.9825 - val_loss: 0.0542 - val_acc: 0.9800\n",
      "Epoch 47/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0483 - acc: 0.9826 - val_loss: 0.0535 - val_acc: 0.9802\n",
      "Epoch 48/50\n",
      "32774/32774 [==============================] - 0s 4us/step - loss: 0.0476 - acc: 0.9830 - val_loss: 0.0530 - val_acc: 0.9806\n",
      "Epoch 49/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0468 - acc: 0.9835 - val_loss: 0.0529 - val_acc: 0.9807\n",
      "Epoch 50/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0462 - acc: 0.9838 - val_loss: 0.0523 - val_acc: 0.9807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb9020ca90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nD_sort_phys = Sequential()\n",
    "model_nD_sort_phys.add(Dense(64, input_dim=4*n_phys, activation='relu')) \n",
    "model_nD_sort_phys.add(Dense(64, activation='relu'))\n",
    "model_nD_sort_phys.add(Dense(128, activation='relu'))\n",
    "model_nD_sort_phys.add(Dense(64, activation='relu'))\n",
    "model_nD_sort_phys.add(Dense(1, activation='sigmoid'))\n",
    "model_nD_sort_phys.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_nD_sort_phys.fit(X_nD_train_sort_phys,Y_nD_train_phys, epochs=50, batch_size=int(0.1*len(X_nD_train_sort_phys)),validation_data=(X_nD_val_sort_phys,Y_nD_val_phys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_1D_phys = model_1D_phys.predict(X_1D_val_phys,batch_size=int(0.1*len(X_1D_train_phys)))\n",
    "scores_nD_phys = model_nD_phys.predict(X_nD_val_phys,batch_size=int(0.1*len(X_nD_train_phys)))\n",
    "scores_nD_sort_phys = model_nD_sort_phys.predict(X_nD_val_sort_phys,batch_size=int(0.1*len(X_nD_train_sort_phys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores_1D_fromnD_phys = model_1D_phys.predict(np.reshape(X_nD_val_phys,[n_phys*len(X_nD_val_phys),4]),batch_size=int(0.1*len(X_nD_train_phys)))\n",
    "scores_1D_fromnD_phys = model_1D_phys.predict(scaler1D.transform(np.reshape(scaler.inverse_transform(X_nD_val_phys),[n_phys*len(X_nD_val_phys),4])),batch_size=int(0.1*len(X_nD_train_phys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_1D_fromnD_phys = np.reshape(scores_1D_fromnD_phys,[int(len(scores_1D_fromnD_phys)/n_phys),n_phys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_up_phys = np.array([np.prod(scores_1D_fromnD_phys[i,:] / (1.-scores_1D_fromnD_phys[i,:])) for i in range(len(scores_1D_fromnD_phys))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_1D_phys, tpr_1D_phys, _ = roc_curve(Y_1D_val_phys, scores_1D_phys)\n",
    "fpr_nD_phys, tpr_nD_phys, _ = roc_curve(Y_nD_val_phys, scores_nD_phys)\n",
    "fpr_nD_sort_phys, tpr_nD_sort_phys, _ = roc_curve(Y_nD_val_phys, scores_nD_sort_phys)\n",
    "fpr_nD_from1D_phys, tpr_nD_from1D_phys, _ = roc_curve(Y_nD_val_phys, scaled_up_phys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7feb7c3f5e10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tpr_1D_phys,1./fpr_1D_phys,label=\"1D\")\n",
    "plt.plot(tpr_nD_phys,1./fpr_nD_phys,label=\"N = \"+str(n_phys))\n",
    "plt.plot(tpr_nD_from1D_phys,1./fpr_nD_from1D_phys,label=\"$(1D)^{\"+str(n_phys)+\"}$\")\n",
    "plt.plot([1,0],[0,1],ls=\":\",color=\"grey\")\n",
    "plt.xlabel(\"True Positive Rate\")\n",
    "plt.ylabel(\"1 / False Positive Rate\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maybe try with a PFN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import energyflow as ef\n",
    "from energyflow.archs import PFN, EFN\n",
    "from energyflow.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32775, 12)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_nD_val_phys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nD_val_phys_pfn = np.reshape(X_nD_val_phys,[len(X_nD_val_phys),n_phys,4])\n",
    "X_nD_train_phys_pfn = np.reshape(X_nD_train_phys,[len(X_nD_train_phys),n_phys,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0232516 ,  0.57254116, -0.6975219 , -1.11152641],\n",
       "       [ 0.14183378,  0.83389831, -0.90795728, -1.09508294],\n",
       "       [-0.39255246,  1.12209154, -1.10957885, -1.11872501]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_nD_val_phys_pfn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi_sizes, F_sizes = (100, 100, 128), (100, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    500         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 128)          0           mask[0][0]                       \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sum_dropout (Dropout)           (None, 128)          0           sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 100)          12900       sum_dropout[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 100)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_0_dropout (Dropout)       (None, 100)          0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          10100       dense_0_dropout[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1_dropout (Dropout)       (None, 100)          0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          10100       dense_1_dropout[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 100)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2_dropout (Dropout)       (None, 100)          0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            202         dense_2_dropout[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 56,830\n",
      "Trainable params: 56,830\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pfn = PFN(input_dim=X_nD_val_phys_pfn.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes,F_dropouts=0.1,latent_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32774 samples, validate on 32775 samples\n",
      "Epoch 1/200\n",
      "32774/32774 [==============================] - 1s 42us/step - loss: 0.6590 - acc: 0.7792 - val_loss: 0.1494 - val_acc: 0.9526\n",
      "Epoch 2/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.1760 - acc: 0.9416 - val_loss: 0.1067 - val_acc: 0.9605\n",
      "Epoch 3/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.1271 - acc: 0.9536 - val_loss: 0.0883 - val_acc: 0.9678\n",
      "Epoch 4/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.1018 - acc: 0.9618 - val_loss: 0.0756 - val_acc: 0.9725\n",
      "Epoch 5/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0917 - acc: 0.9679 - val_loss: 0.0664 - val_acc: 0.9752\n",
      "Epoch 6/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0808 - acc: 0.9706 - val_loss: 0.0596 - val_acc: 0.9784\n",
      "Epoch 7/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0729 - acc: 0.9742 - val_loss: 0.0561 - val_acc: 0.9796\n",
      "Epoch 8/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0675 - acc: 0.9762 - val_loss: 0.0528 - val_acc: 0.9806\n",
      "Epoch 9/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0641 - acc: 0.9776 - val_loss: 0.0502 - val_acc: 0.9815\n",
      "Epoch 10/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0604 - acc: 0.9789 - val_loss: 0.0510 - val_acc: 0.9804\n",
      "Epoch 11/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0774 - acc: 0.9726 - val_loss: 0.0632 - val_acc: 0.9757\n",
      "Epoch 12/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0691 - acc: 0.9757 - val_loss: 0.0873 - val_acc: 0.9680\n",
      "Epoch 13/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.1218 - acc: 0.9588 - val_loss: 0.0877 - val_acc: 0.9688\n",
      "Epoch 14/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0889 - acc: 0.9695 - val_loss: 0.0590 - val_acc: 0.9784\n",
      "Epoch 15/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0667 - acc: 0.9757 - val_loss: 0.0552 - val_acc: 0.9800\n",
      "Epoch 16/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0640 - acc: 0.9766 - val_loss: 0.0511 - val_acc: 0.9812\n",
      "Epoch 17/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0590 - acc: 0.9786 - val_loss: 0.0484 - val_acc: 0.9824\n",
      "Epoch 18/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0563 - acc: 0.9808 - val_loss: 0.0478 - val_acc: 0.9826\n",
      "Epoch 19/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0554 - acc: 0.9809 - val_loss: 0.0478 - val_acc: 0.9828\n",
      "Epoch 20/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0547 - acc: 0.9799 - val_loss: 0.0464 - val_acc: 0.9829\n",
      "Epoch 21/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0520 - acc: 0.9808 - val_loss: 0.0458 - val_acc: 0.9837\n",
      "Epoch 22/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0508 - acc: 0.9819 - val_loss: 0.0447 - val_acc: 0.9838\n",
      "Epoch 23/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0485 - acc: 0.9827 - val_loss: 0.0437 - val_acc: 0.9841\n",
      "Epoch 24/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0490 - acc: 0.9828 - val_loss: 0.0463 - val_acc: 0.9834\n",
      "Epoch 25/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0634 - acc: 0.9775 - val_loss: 0.0654 - val_acc: 0.9745\n",
      "Epoch 26/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0629 - acc: 0.9772 - val_loss: 0.0504 - val_acc: 0.9816\n",
      "Epoch 27/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0553 - acc: 0.9810 - val_loss: 0.0471 - val_acc: 0.9823\n",
      "Epoch 28/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0519 - acc: 0.9812 - val_loss: 0.0437 - val_acc: 0.9840\n",
      "Epoch 29/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0493 - acc: 0.9826 - val_loss: 0.0443 - val_acc: 0.9843\n",
      "Epoch 30/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0481 - acc: 0.9823 - val_loss: 0.0427 - val_acc: 0.9849\n",
      "Epoch 31/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0458 - acc: 0.9835 - val_loss: 0.0420 - val_acc: 0.9849\n",
      "Epoch 32/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0477 - acc: 0.9826 - val_loss: 0.0444 - val_acc: 0.9847\n",
      "Epoch 33/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0468 - acc: 0.9828 - val_loss: 0.0423 - val_acc: 0.9845\n",
      "Epoch 34/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0441 - acc: 0.9842 - val_loss: 0.0422 - val_acc: 0.9848\n",
      "Epoch 35/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0428 - acc: 0.9845 - val_loss: 0.0409 - val_acc: 0.9852\n",
      "Epoch 36/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0447 - acc: 0.9834 - val_loss: 0.0428 - val_acc: 0.9852\n",
      "Epoch 37/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0439 - acc: 0.9840 - val_loss: 0.0404 - val_acc: 0.9857\n",
      "Epoch 38/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0426 - acc: 0.9847 - val_loss: 0.0409 - val_acc: 0.9858\n",
      "Epoch 39/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0445 - acc: 0.9840 - val_loss: 0.0440 - val_acc: 0.9838\n",
      "Epoch 40/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0418 - acc: 0.9850 - val_loss: 0.0418 - val_acc: 0.9856\n",
      "Epoch 41/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0415 - acc: 0.9851 - val_loss: 0.0396 - val_acc: 0.9858\n",
      "Epoch 42/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0406 - acc: 0.9851 - val_loss: 0.0389 - val_acc: 0.9859\n",
      "Epoch 43/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0401 - acc: 0.9860 - val_loss: 0.0387 - val_acc: 0.9863\n",
      "Epoch 44/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0396 - acc: 0.9855 - val_loss: 0.0390 - val_acc: 0.9860\n",
      "Epoch 45/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0415 - acc: 0.9849 - val_loss: 0.0446 - val_acc: 0.9847\n",
      "Epoch 46/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0412 - acc: 0.9860 - val_loss: 0.0394 - val_acc: 0.9858\n",
      "Epoch 47/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0384 - acc: 0.9861 - val_loss: 0.0389 - val_acc: 0.9862\n",
      "Epoch 48/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0404 - acc: 0.9854 - val_loss: 0.0393 - val_acc: 0.9860\n",
      "Epoch 49/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0393 - acc: 0.9857 - val_loss: 0.0646 - val_acc: 0.9770\n",
      "Epoch 50/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.1167 - acc: 0.9577 - val_loss: 0.0772 - val_acc: 0.9701\n",
      "Epoch 51/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0647 - acc: 0.9771 - val_loss: 0.0606 - val_acc: 0.9780\n",
      "Epoch 52/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0587 - acc: 0.9794 - val_loss: 0.0493 - val_acc: 0.9822\n",
      "Epoch 53/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0520 - acc: 0.9809 - val_loss: 0.0463 - val_acc: 0.9833\n",
      "Epoch 54/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0488 - acc: 0.9827 - val_loss: 0.0432 - val_acc: 0.9847\n",
      "Epoch 55/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0462 - acc: 0.9840 - val_loss: 0.0412 - val_acc: 0.9854\n",
      "Epoch 56/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0428 - acc: 0.9850 - val_loss: 0.0396 - val_acc: 0.9854\n",
      "Epoch 57/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0412 - acc: 0.9855 - val_loss: 0.0387 - val_acc: 0.9860\n",
      "Epoch 58/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0406 - acc: 0.9855 - val_loss: 0.0381 - val_acc: 0.9862\n",
      "Epoch 59/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0401 - acc: 0.9857 - val_loss: 0.0396 - val_acc: 0.9858\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0471 - acc: 0.9842 - val_loss: 0.0409 - val_acc: 0.9853\n",
      "Epoch 61/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0417 - acc: 0.9854 - val_loss: 0.0386 - val_acc: 0.9860\n",
      "Epoch 62/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0389 - acc: 0.9860 - val_loss: 0.0387 - val_acc: 0.9861\n",
      "Epoch 63/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0396 - acc: 0.9862 - val_loss: 0.0391 - val_acc: 0.9861\n",
      "Epoch 64/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0388 - acc: 0.9857 - val_loss: 0.0374 - val_acc: 0.9867\n",
      "Epoch 65/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0384 - acc: 0.9862 - val_loss: 0.0366 - val_acc: 0.9869\n",
      "Epoch 66/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0381 - acc: 0.9863 - val_loss: 0.0364 - val_acc: 0.9870\n",
      "Epoch 67/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0358 - acc: 0.9870 - val_loss: 0.0370 - val_acc: 0.9867\n",
      "Epoch 68/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0371 - acc: 0.9865 - val_loss: 0.0374 - val_acc: 0.9870\n",
      "Epoch 69/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0364 - acc: 0.9866 - val_loss: 0.0365 - val_acc: 0.9872\n",
      "Epoch 70/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0360 - acc: 0.9872 - val_loss: 0.0359 - val_acc: 0.9872\n",
      "Epoch 71/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0360 - acc: 0.9869 - val_loss: 0.0358 - val_acc: 0.9870\n",
      "Epoch 72/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0336 - acc: 0.9871 - val_loss: 0.0364 - val_acc: 0.9869\n",
      "Epoch 73/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0389 - acc: 0.9862 - val_loss: 0.0404 - val_acc: 0.9853\n",
      "Epoch 74/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0378 - acc: 0.9860 - val_loss: 0.0372 - val_acc: 0.9867\n",
      "Epoch 75/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0365 - acc: 0.9868 - val_loss: 0.0371 - val_acc: 0.9866\n",
      "Epoch 76/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0363 - acc: 0.9867 - val_loss: 0.0380 - val_acc: 0.9867\n",
      "Epoch 77/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0364 - acc: 0.9868 - val_loss: 0.0365 - val_acc: 0.9865\n",
      "Epoch 78/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0348 - acc: 0.9869 - val_loss: 0.0355 - val_acc: 0.9872\n",
      "Epoch 79/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0344 - acc: 0.9873 - val_loss: 0.0361 - val_acc: 0.9869\n",
      "Epoch 80/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0388 - acc: 0.9862 - val_loss: 0.0414 - val_acc: 0.9851\n",
      "Epoch 81/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0388 - acc: 0.9859 - val_loss: 0.0383 - val_acc: 0.9868\n",
      "Epoch 82/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0363 - acc: 0.9870 - val_loss: 0.0367 - val_acc: 0.9871\n",
      "Epoch 83/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0356 - acc: 0.9867 - val_loss: 0.0401 - val_acc: 0.9852\n",
      "Epoch 84/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0543 - acc: 0.9789 - val_loss: 0.0547 - val_acc: 0.9809\n",
      "Epoch 85/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0492 - acc: 0.9822 - val_loss: 0.0454 - val_acc: 0.9831\n",
      "Epoch 86/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0425 - acc: 0.9847 - val_loss: 0.0418 - val_acc: 0.9856\n",
      "Epoch 87/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0413 - acc: 0.9850 - val_loss: 0.0383 - val_acc: 0.9865\n",
      "Epoch 88/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0366 - acc: 0.9866 - val_loss: 0.0371 - val_acc: 0.9868\n",
      "Epoch 89/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0358 - acc: 0.9873 - val_loss: 0.0355 - val_acc: 0.9870\n",
      "Epoch 90/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0389 - acc: 0.9866 - val_loss: 0.0383 - val_acc: 0.9865\n",
      "Epoch 91/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0362 - acc: 0.9873 - val_loss: 0.0356 - val_acc: 0.9870\n",
      "Epoch 92/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0341 - acc: 0.9873 - val_loss: 0.0355 - val_acc: 0.9871\n",
      "Epoch 93/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0336 - acc: 0.9878 - val_loss: 0.0349 - val_acc: 0.9872\n",
      "Epoch 94/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0339 - acc: 0.9875 - val_loss: 0.0348 - val_acc: 0.9875\n",
      "Epoch 95/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0329 - acc: 0.9882 - val_loss: 0.0344 - val_acc: 0.9874\n",
      "Epoch 96/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0332 - acc: 0.9882 - val_loss: 0.0350 - val_acc: 0.9877\n",
      "Epoch 97/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0325 - acc: 0.9880 - val_loss: 0.0344 - val_acc: 0.9876\n",
      "Epoch 98/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0319 - acc: 0.9881 - val_loss: 0.0340 - val_acc: 0.9879\n",
      "Epoch 99/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0315 - acc: 0.9888 - val_loss: 0.0340 - val_acc: 0.9877\n",
      "Epoch 100/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0316 - acc: 0.9884 - val_loss: 0.0339 - val_acc: 0.9878\n",
      "Epoch 101/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0313 - acc: 0.9885 - val_loss: 0.0342 - val_acc: 0.9878\n",
      "Epoch 102/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0334 - acc: 0.9879 - val_loss: 0.0374 - val_acc: 0.9871\n",
      "Epoch 103/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0333 - acc: 0.9877 - val_loss: 0.0360 - val_acc: 0.9871\n",
      "Epoch 104/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0316 - acc: 0.9886 - val_loss: 0.0339 - val_acc: 0.9878\n",
      "Epoch 105/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0311 - acc: 0.9887 - val_loss: 0.0367 - val_acc: 0.9868\n",
      "Epoch 106/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0453 - acc: 0.9834 - val_loss: 0.0519 - val_acc: 0.9819\n",
      "Epoch 107/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0437 - acc: 0.9841 - val_loss: 0.0397 - val_acc: 0.9858\n",
      "Epoch 108/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0378 - acc: 0.9865 - val_loss: 0.0366 - val_acc: 0.9869\n",
      "Epoch 109/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0345 - acc: 0.9875 - val_loss: 0.0345 - val_acc: 0.9875\n",
      "Epoch 110/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0340 - acc: 0.9878 - val_loss: 0.0347 - val_acc: 0.9873\n",
      "Epoch 111/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0426 - acc: 0.9840 - val_loss: 0.0425 - val_acc: 0.9850\n",
      "Epoch 112/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0409 - acc: 0.9852 - val_loss: 0.0376 - val_acc: 0.9870\n",
      "Epoch 113/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0616 - acc: 0.9770 - val_loss: 0.0652 - val_acc: 0.9788\n",
      "Epoch 114/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0551 - acc: 0.9809 - val_loss: 0.0477 - val_acc: 0.9821\n",
      "Epoch 115/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0437 - acc: 0.9837 - val_loss: 0.0412 - val_acc: 0.9856\n",
      "Epoch 116/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0403 - acc: 0.9858 - val_loss: 0.0370 - val_acc: 0.9868\n",
      "Epoch 117/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0370 - acc: 0.9863 - val_loss: 0.0362 - val_acc: 0.9871\n",
      "Epoch 118/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0364 - acc: 0.9874 - val_loss: 0.0346 - val_acc: 0.9878\n",
      "Epoch 119/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0343 - acc: 0.9873 - val_loss: 0.0344 - val_acc: 0.9878\n",
      "Epoch 120/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0336 - acc: 0.9882 - val_loss: 0.0339 - val_acc: 0.9881\n",
      "Epoch 121/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0333 - acc: 0.9878 - val_loss: 0.0338 - val_acc: 0.9880\n",
      "Epoch 122/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0329 - acc: 0.9885 - val_loss: 0.0363 - val_acc: 0.9875\n",
      "Epoch 123/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0387 - acc: 0.9862 - val_loss: 0.0413 - val_acc: 0.9853\n",
      "Epoch 124/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0373 - acc: 0.9864 - val_loss: 0.0376 - val_acc: 0.9867\n",
      "Epoch 125/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0341 - acc: 0.9873 - val_loss: 0.0359 - val_acc: 0.9867\n",
      "Epoch 126/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0331 - acc: 0.9878 - val_loss: 0.0345 - val_acc: 0.9878\n",
      "Epoch 127/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0327 - acc: 0.9886 - val_loss: 0.0334 - val_acc: 0.9882\n",
      "Epoch 128/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0313 - acc: 0.9888 - val_loss: 0.0332 - val_acc: 0.9884\n",
      "Epoch 129/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0321 - acc: 0.9889 - val_loss: 0.0332 - val_acc: 0.9883\n",
      "Epoch 130/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0310 - acc: 0.9885 - val_loss: 0.0332 - val_acc: 0.9882\n",
      "Epoch 131/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0311 - acc: 0.9886 - val_loss: 0.0329 - val_acc: 0.9885\n",
      "Epoch 132/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0296 - acc: 0.9893 - val_loss: 0.0328 - val_acc: 0.9886\n",
      "Epoch 133/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0307 - acc: 0.9890 - val_loss: 0.0328 - val_acc: 0.9886\n",
      "Epoch 134/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0302 - acc: 0.9895 - val_loss: 0.0328 - val_acc: 0.9885\n",
      "Epoch 135/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0298 - acc: 0.9893 - val_loss: 0.0326 - val_acc: 0.9886\n",
      "Epoch 136/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0290 - acc: 0.9891 - val_loss: 0.0331 - val_acc: 0.9881\n",
      "Epoch 137/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0294 - acc: 0.9897 - val_loss: 0.0326 - val_acc: 0.9885\n",
      "Epoch 138/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0291 - acc: 0.9897 - val_loss: 0.0335 - val_acc: 0.9881\n",
      "Epoch 139/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0304 - acc: 0.9888 - val_loss: 0.0347 - val_acc: 0.9882\n",
      "Epoch 140/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0303 - acc: 0.9889 - val_loss: 0.0349 - val_acc: 0.9880\n",
      "Epoch 141/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0308 - acc: 0.9894 - val_loss: 0.0336 - val_acc: 0.9885\n",
      "Epoch 142/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0399 - acc: 0.9855 - val_loss: 0.0417 - val_acc: 0.9846\n",
      "Epoch 143/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0378 - acc: 0.9866 - val_loss: 0.0385 - val_acc: 0.9861\n",
      "Epoch 144/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0335 - acc: 0.9874 - val_loss: 0.0359 - val_acc: 0.9872\n",
      "Epoch 145/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0325 - acc: 0.9885 - val_loss: 0.0343 - val_acc: 0.9881\n",
      "Epoch 146/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0316 - acc: 0.9887 - val_loss: 0.0335 - val_acc: 0.9882\n",
      "Epoch 147/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0298 - acc: 0.9893 - val_loss: 0.0356 - val_acc: 0.9869\n",
      "Epoch 148/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0485 - acc: 0.9827 - val_loss: 0.0480 - val_acc: 0.9857\n",
      "Epoch 149/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0431 - acc: 0.9847 - val_loss: 0.0395 - val_acc: 0.9844\n",
      "Epoch 150/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0364 - acc: 0.9868 - val_loss: 0.0361 - val_acc: 0.9875\n",
      "Epoch 151/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0339 - acc: 0.9881 - val_loss: 0.0345 - val_acc: 0.9875\n",
      "Epoch 152/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0325 - acc: 0.9879 - val_loss: 0.0337 - val_acc: 0.9881\n",
      "Epoch 153/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0313 - acc: 0.9884 - val_loss: 0.0330 - val_acc: 0.9881\n",
      "Epoch 154/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0295 - acc: 0.9893 - val_loss: 0.0328 - val_acc: 0.9884\n",
      "Epoch 155/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0295 - acc: 0.9894 - val_loss: 0.0327 - val_acc: 0.9884\n",
      "Epoch 156/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0291 - acc: 0.9893 - val_loss: 0.0330 - val_acc: 0.9886\n",
      "Epoch 157/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0293 - acc: 0.9894 - val_loss: 0.0325 - val_acc: 0.9886\n",
      "Epoch 158/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0284 - acc: 0.9893 - val_loss: 0.0326 - val_acc: 0.9888\n",
      "Epoch 159/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0286 - acc: 0.9897 - val_loss: 0.0330 - val_acc: 0.9886\n",
      "Epoch 160/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0288 - acc: 0.9895 - val_loss: 0.0347 - val_acc: 0.9885\n",
      "Epoch 161/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0298 - acc: 0.9893 - val_loss: 0.0347 - val_acc: 0.9879\n",
      "Epoch 162/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0292 - acc: 0.9893 - val_loss: 0.0340 - val_acc: 0.9885\n",
      "Epoch 163/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0288 - acc: 0.9898 - val_loss: 0.0328 - val_acc: 0.9886\n",
      "Epoch 164/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0274 - acc: 0.9897 - val_loss: 0.0412 - val_acc: 0.9860\n",
      "Epoch 165/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0535 - acc: 0.9820 - val_loss: 0.0571 - val_acc: 0.9797\n",
      "Epoch 166/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0446 - acc: 0.9838 - val_loss: 0.0440 - val_acc: 0.9852\n",
      "Epoch 167/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0371 - acc: 0.9870 - val_loss: 0.0385 - val_acc: 0.9863\n",
      "Epoch 168/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0326 - acc: 0.9883 - val_loss: 0.0351 - val_acc: 0.9882\n",
      "Epoch 169/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0302 - acc: 0.9891 - val_loss: 0.0343 - val_acc: 0.9881\n",
      "Epoch 170/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0305 - acc: 0.9891 - val_loss: 0.0336 - val_acc: 0.9886\n",
      "Epoch 171/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0298 - acc: 0.9893 - val_loss: 0.0334 - val_acc: 0.9884\n",
      "Epoch 172/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0284 - acc: 0.9896 - val_loss: 0.0333 - val_acc: 0.9886\n",
      "Epoch 173/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0287 - acc: 0.9898 - val_loss: 0.0332 - val_acc: 0.9885\n",
      "Epoch 174/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0286 - acc: 0.9895 - val_loss: 0.0329 - val_acc: 0.9886\n",
      "Epoch 175/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0286 - acc: 0.9896 - val_loss: 0.0327 - val_acc: 0.9886\n",
      "Epoch 176/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0278 - acc: 0.9899 - val_loss: 0.0331 - val_acc: 0.9888\n",
      "Epoch 177/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0303 - acc: 0.9890 - val_loss: 0.0353 - val_acc: 0.9878\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0304 - acc: 0.9891 - val_loss: 0.0335 - val_acc: 0.9888\n",
      "Epoch 179/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0289 - acc: 0.9896 - val_loss: 0.0329 - val_acc: 0.9883\n",
      "Epoch 180/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0284 - acc: 0.9898 - val_loss: 0.0325 - val_acc: 0.9887\n",
      "Epoch 181/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0276 - acc: 0.9899 - val_loss: 0.0327 - val_acc: 0.9885\n",
      "Epoch 182/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0276 - acc: 0.9897 - val_loss: 0.0327 - val_acc: 0.9891\n",
      "Epoch 183/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0270 - acc: 0.9903 - val_loss: 0.0328 - val_acc: 0.9884\n",
      "Epoch 184/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0271 - acc: 0.9902 - val_loss: 0.0325 - val_acc: 0.9890\n",
      "Epoch 185/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0265 - acc: 0.9906 - val_loss: 0.0323 - val_acc: 0.9890\n",
      "Epoch 186/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0266 - acc: 0.9904 - val_loss: 0.0324 - val_acc: 0.9891\n",
      "Epoch 187/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0265 - acc: 0.9902 - val_loss: 0.0326 - val_acc: 0.9886\n",
      "Epoch 188/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0263 - acc: 0.9902 - val_loss: 0.0329 - val_acc: 0.9894\n",
      "Epoch 189/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0262 - acc: 0.9907 - val_loss: 0.0325 - val_acc: 0.9886\n",
      "Epoch 190/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0260 - acc: 0.9902 - val_loss: 0.0326 - val_acc: 0.9891\n",
      "Epoch 191/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0252 - acc: 0.9907 - val_loss: 0.0326 - val_acc: 0.9883\n",
      "Epoch 192/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0254 - acc: 0.9905 - val_loss: 0.0325 - val_acc: 0.9889\n",
      "Epoch 193/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0254 - acc: 0.9905 - val_loss: 0.0324 - val_acc: 0.9889\n",
      "Epoch 194/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0251 - acc: 0.9905 - val_loss: 0.0327 - val_acc: 0.9886\n",
      "Epoch 195/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0260 - acc: 0.9900 - val_loss: 0.0330 - val_acc: 0.9886\n",
      "Epoch 196/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0251 - acc: 0.9909 - val_loss: 0.0326 - val_acc: 0.9890\n",
      "Epoch 197/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0253 - acc: 0.9907 - val_loss: 0.0325 - val_acc: 0.9888\n",
      "Epoch 198/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0253 - acc: 0.9908 - val_loss: 0.0328 - val_acc: 0.9888\n",
      "Epoch 199/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0249 - acc: 0.9909 - val_loss: 0.0328 - val_acc: 0.9886\n",
      "Epoch 200/200\n",
      "32774/32774 [==============================] - 0s 5us/step - loss: 0.0246 - acc: 0.9911 - val_loss: 0.0329 - val_acc: 0.9889\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 200\n",
    "batch_size = int(0.1*len(X_nD_train_phys_pfn)) #was 5000\n",
    "historyf = pfn.fit(X_nD_train_phys_pfn, to_categorical(Y_nD_train_phys,2),\n",
    "          epochs=num_epoch,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_nD_val_phys_pfn, to_categorical(Y_nD_val_phys,2)),\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe9308cae10>]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(historyf.history['val_loss'][5:-1])\n",
    "plt.plot(historyf.history['loss'][5:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_nD_phys_pfn = pfn.predict(X_nD_val_phys_pfn,batch_size=int(0.1*len(X_nD_train_phys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_nD_phys_pfn, tpr_nD_phys_pfn, _ = roc_curve(Y_nD_val_phys, scores_nD_phys_pfn[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save everything\n",
    "np.save(\"ensemblelearning/Y_1D_val_phys\",Y_1D_val_phys)\n",
    "np.save(\"ensemblelearning/X_1D_val_phys\",Y_1D_val_phys)\n",
    "np.save(\"ensemblelearning/Y_1D_train_phys\",Y_1D_train_phys)\n",
    "np.save(\"ensemblelearning/X_1D_train_phys\",X_1D_train_phys)\n",
    "\n",
    "np.save(\"ensemblelearning/Y_nD_val_phys\",Y_nD_val_phys)\n",
    "np.save(\"ensemblelearning/X_nD_val_phys\",Y_nD_val_phys)\n",
    "np.save(\"ensemblelearning/Y_nD_train_phys\",Y_nD_train_phys)\n",
    "np.save(\"ensemblelearning/X_nD_train_phys\",X_nD_train_phys)\n",
    "\n",
    "model_json = model_1D_phys.to_json()\n",
    "with open(\"ensemblelearning/model_1D_phys.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model_1D_phys.save_weights(\"ensemblelearning/model_1D_phys.h5\")\n",
    "\n",
    "model_json = model_nD_phys.to_json()\n",
    "with open(\"ensemblelearning/model_nD_phys.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model_nD_phys.save_weights(\"ensemblelearning/model_nD_phys.h5\")\n",
    "\n",
    "model_json = model_nD_sort_phys.to_json()\n",
    "with open(\"ensemblelearning/model_nD_sort_phys.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model_nD_sort_phys.save_weights(\"ensemblelearning/model_nD_sort_phys.h5\")\n",
    "\n",
    "model_json = pfn.model.to_json()\n",
    "with open(\"ensemblelearning/model_pfn.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "pfn.model.save_weights(\"ensemblelearning/model_pfn.h5\")\n",
    "\n",
    "#This needs to be run later\n",
    "#model_json = pfn_v2.model.to_json()\n",
    "#with open(\"ensemblelearning/model_pfn_v2.json\", \"w\") as json_file:\n",
    "#    json_file.write(model_json)\n",
    "#pfn_v2.model.save_weights(\"ensemblelearning/model_pfn_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  if sys.path[0] == '':\n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  del sys.path[0]\n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "gs = gridspec.GridSpec(1, 1) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ax0.minorticks_on()\n",
    "\n",
    "plt.plot(tpr_1D_phys,1./fpr_1D_phys,label=\"$f_{1}$\",color=\"blue\")\n",
    "plt.plot(tpr_nD_phys,1./fpr_nD_phys,label=\"$f_{\"+str(n_phys)+\"}$\",color=\"red\")\n",
    "plt.plot(tpr_nD_sort_phys,1./fpr_nD_sort_phys,label=\"$f_{\"+str(n_phys)+\"}$${}^{sorted}$\",ls=\":\",color=\"red\")\n",
    "plt.plot(tpr_nD_phys_pfn,1./fpr_nD_phys_pfn,label=\"$f_{\"+str(n_phys)+\"}$${}^{PFN}$\",ls=\"--\",color=\"red\")\n",
    "plt.plot(tpr_nD_from1D_phys,1./fpr_nD_from1D_phys,label=\"$f_{\\{\"+str(n_phys)+\"\\}}$\",color=\"black\")\n",
    "plt.plot([1,0],[0,1],ls=\":\",color=\"grey\")\n",
    "plt.xlabel(\"True Positive Rate\",fontsize=20)\n",
    "plt.ylabel(\"1 / False Positive Rate\",fontsize=20)\n",
    "plt.yscale(\"log\")\n",
    "plt.legend(frameon=False,fontsize=20)\n",
    "plt.title(r\"$BSM$, $X\\rightarrow YZ$ $versus$ $QCD$\",loc=\"right\",fontsize=20)\n",
    "\n",
    "plt.savefig(\"ensembleLearnPlots/BSM_ROC.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, use a custom PFN loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    500         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_3 (TimeDistributed)       (None, None, 1)      129         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, 1)      0           tdist_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 1)            0           mask[0][0]                       \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            2           sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 1)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,659\n",
      "Trainable params: 23,659\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Phi_sizes, F_sizes = (100, 100, 128, 1), []\n",
    "pfn_v2 = PFN(input_dim=X_nD_val_phys_pfn.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes, F_acts='linear', output_dim=1, output_act='linear', Phi_acts=['relu','relu','relu','linear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7feb082e06d8>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7feb0805eb70>\n",
      "<keras.layers.core.Activation object at 0x7feb0805ea20>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7feb082060b8>\n",
      "<keras.layers.core.Activation object at 0x7feb082067b8>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe94c343b70>\n",
      "<keras.layers.core.Activation object at 0x7fe94c343dd8>\n",
      "<keras.layers.wrappers.TimeDistributed object at 0x7fe94c302c18>\n",
      "<keras.layers.core.Lambda object at 0x7feb08307be0>\n",
      "<keras.layers.core.Activation object at 0x7fe94c302b00>\n",
      "<keras.layers.merge.Dot object at 0x7feb082e0c88>\n"
     ]
    }
   ],
   "source": [
    "pfn_v2.model.layers.pop()\n",
    "pfn_v2.model.layers.pop()\n",
    "for layer in pfn_v2.model.layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myloss(y_true, y_pred):\n",
    "    \n",
    "    return binary_crossentropy(y_true,K.exp(y_pred)/(1.+K.exp(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfn_v2.model.compile(loss=lambda y_true, y_pred: myloss(y_true, y_pred), optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    500         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_3 (TimeDistributed)       (None, None, 1)      129         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, 1)      0           tdist_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 1)            0           mask[0][0]                       \n",
      "                                                                 activation_11[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 23,657\n",
      "Trainable params: 23,657\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pfn_v2.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32774 samples, validate on 32775 samples\n",
      "Epoch 1/50\n",
      "32774/32774 [==============================] - 1s 21us/step - loss: 0.2541 - acc: 0.1344 - val_loss: 0.1095 - val_acc: 0.0467\n",
      "Epoch 2/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0998 - acc: 0.0346 - val_loss: 0.0879 - val_acc: 0.0256\n",
      "Epoch 3/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0874 - acc: 0.0216 - val_loss: 0.0832 - val_acc: 0.0204\n",
      "Epoch 4/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0817 - acc: 0.0196 - val_loss: 0.0770 - val_acc: 0.0195\n",
      "Epoch 5/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0750 - acc: 0.0194 - val_loss: 0.0707 - val_acc: 0.0190\n",
      "Epoch 6/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0688 - acc: 0.0202 - val_loss: 0.0657 - val_acc: 0.0198\n",
      "Epoch 7/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0640 - acc: 0.0209 - val_loss: 0.0616 - val_acc: 0.0197\n",
      "Epoch 8/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0601 - acc: 0.0208 - val_loss: 0.0580 - val_acc: 0.0186\n",
      "Epoch 9/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0569 - acc: 0.0192 - val_loss: 0.0552 - val_acc: 0.0178\n",
      "Epoch 10/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0538 - acc: 0.0181 - val_loss: 0.0530 - val_acc: 0.0166\n",
      "Epoch 11/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0514 - acc: 0.0168 - val_loss: 0.0511 - val_acc: 0.0161\n",
      "Epoch 12/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0498 - acc: 0.0157 - val_loss: 0.0496 - val_acc: 0.0150\n",
      "Epoch 13/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0486 - acc: 0.0159 - val_loss: 0.0483 - val_acc: 0.0143\n",
      "Epoch 14/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0464 - acc: 0.0151 - val_loss: 0.0468 - val_acc: 0.0142\n",
      "Epoch 15/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0452 - acc: 0.0147 - val_loss: 0.0458 - val_acc: 0.0135\n",
      "Epoch 16/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0441 - acc: 0.0144 - val_loss: 0.0449 - val_acc: 0.0136\n",
      "Epoch 17/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0432 - acc: 0.0140 - val_loss: 0.0442 - val_acc: 0.0132\n",
      "Epoch 18/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0424 - acc: 0.0138 - val_loss: 0.0441 - val_acc: 0.0129\n",
      "Epoch 19/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0421 - acc: 0.0132 - val_loss: 0.0436 - val_acc: 0.0127\n",
      "Epoch 20/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0412 - acc: 0.0132 - val_loss: 0.0427 - val_acc: 0.0127\n",
      "Epoch 21/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0402 - acc: 0.0127 - val_loss: 0.0424 - val_acc: 0.0118\n",
      "Epoch 22/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0396 - acc: 0.0124 - val_loss: 0.0415 - val_acc: 0.0125\n",
      "Epoch 23/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0391 - acc: 0.0125 - val_loss: 0.0411 - val_acc: 0.0116\n",
      "Epoch 24/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0385 - acc: 0.0120 - val_loss: 0.0408 - val_acc: 0.0111\n",
      "Epoch 25/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0380 - acc: 0.0121 - val_loss: 0.0404 - val_acc: 0.0117\n",
      "Epoch 26/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0375 - acc: 0.0126 - val_loss: 0.0396 - val_acc: 0.0119\n",
      "Epoch 27/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0369 - acc: 0.0120 - val_loss: 0.0390 - val_acc: 0.0108\n",
      "Epoch 28/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0361 - acc: 0.0117 - val_loss: 0.0400 - val_acc: 0.0111\n",
      "Epoch 29/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0361 - acc: 0.0107 - val_loss: 0.0381 - val_acc: 0.0108\n",
      "Epoch 30/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0352 - acc: 0.0111 - val_loss: 0.0381 - val_acc: 0.0108\n",
      "Epoch 31/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0349 - acc: 0.0113 - val_loss: 0.0373 - val_acc: 0.0102\n",
      "Epoch 32/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0346 - acc: 0.0112 - val_loss: 0.0368 - val_acc: 0.0107\n",
      "Epoch 33/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0339 - acc: 0.0107 - val_loss: 0.0365 - val_acc: 0.0106\n",
      "Epoch 34/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0335 - acc: 0.0103 - val_loss: 0.0362 - val_acc: 0.0108\n",
      "Epoch 35/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0333 - acc: 0.0103 - val_loss: 0.0361 - val_acc: 0.0099\n",
      "Epoch 36/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0331 - acc: 0.0107 - val_loss: 0.0361 - val_acc: 0.0099\n",
      "Epoch 37/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0323 - acc: 0.0101 - val_loss: 0.0355 - val_acc: 0.0097\n",
      "Epoch 38/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0319 - acc: 0.0101 - val_loss: 0.0351 - val_acc: 0.0102\n",
      "Epoch 39/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0315 - acc: 0.0101 - val_loss: 0.0356 - val_acc: 0.0102\n",
      "Epoch 40/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0314 - acc: 0.0099 - val_loss: 0.0352 - val_acc: 0.0103\n",
      "Epoch 41/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0312 - acc: 0.0096 - val_loss: 0.0343 - val_acc: 0.0094\n",
      "Epoch 42/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0305 - acc: 0.0096 - val_loss: 0.0341 - val_acc: 0.0096\n",
      "Epoch 43/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0306 - acc: 0.0088 - val_loss: 0.0349 - val_acc: 0.0089\n",
      "Epoch 44/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0308 - acc: 0.0091 - val_loss: 0.0371 - val_acc: 0.0088\n",
      "Epoch 45/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0314 - acc: 0.0092 - val_loss: 0.0346 - val_acc: 0.0078\n",
      "Epoch 46/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0299 - acc: 0.0087 - val_loss: 0.0351 - val_acc: 0.0081\n",
      "Epoch 47/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0306 - acc: 0.0088 - val_loss: 0.0344 - val_acc: 0.0084\n",
      "Epoch 48/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0299 - acc: 0.0088 - val_loss: 0.0331 - val_acc: 0.0089\n",
      "Epoch 49/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0291 - acc: 0.0091 - val_loss: 0.0332 - val_acc: 0.0094\n",
      "Epoch 50/50\n",
      "32774/32774 [==============================] - 0s 3us/step - loss: 0.0288 - acc: 0.0093 - val_loss: 0.0329 - val_acc: 0.0093\n"
     ]
    }
   ],
   "source": [
    "historyf_v2 = pfn_v2.fit(X_nD_train_phys_pfn, Y_nD_train_phys,\n",
    "          epochs=50,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_nD_val_phys_pfn, Y_nD_val_phys),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_nD_phys_pfn_v2 = pfn_v2.predict(X_nD_val_phys_pfn,batch_size=int(0.1*len(X_nD_train_phys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_nD_phys_pfn_v2, tpr_nD_phys_pfn_v2, _ = roc_curve(Y_nD_val_phys, scores_nD_phys_pfn_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7feb08339c50>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tpr_nD_phys_pfn,1./fpr_nD_phys_pfn,label=\"N = \"+str(n_phys)+\" (PFN)\")\n",
    "plt.plot(tpr_nD_phys_pfn_v2,1./fpr_nD_phys_pfn_v2,label=\"N = \"+str(n_phys)+\" (PFN v2)\")\n",
    "plt.plot([1,0],[0,1],ls=\":\",color=\"grey\")\n",
    "plt.xlabel(\"True Positive Rate\")\n",
    "plt.ylabel(\"1 / False Positive Rate\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input (None, None, 4)\n",
      "tdist_0 (None, None, 100)\n",
      "activation_8 (None, None, 100)\n",
      "tdist_1 (None, None, 100)\n",
      "activation_9 (None, None, 100)\n",
      "tdist_2 (None, None, 128)\n",
      "activation_10 (None, None, 128)\n",
      "tdist_3 (None, None, 1)\n",
      "mask (None, None)\n",
      "activation_11 (None, None, 1)\n",
      "sum (None, 1)\n"
     ]
    }
   ],
   "source": [
    "for layer in pfn_v2.model.layers:\n",
    "    print(layer.name,layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "myPhi = Model(input = pfn_v2.model.input,output = pfn_v2.model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPhi_preds = myPhi.predict(X_nD_val_phys_pfn,batch_size=int(0.1*len(X_nD_train_phys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_Phi = np.reshape(myPhi_preds,[n_phys*len(myPhi_preds)])\n",
    "Y_Phi = [[Y_nD_val_phys[i],Y_nD_val_phys[i],Y_nD_val_phys[i]] for i in range(len(Y_nD_val_phys))]\n",
    "Y_Phi = np.reshape(Y_Phi,[n_phys*len(Y_Phi)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_Phi, tpr_Phi, _ = roc_curve(Y_Phi, preds_Phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  if sys.path[0] == '':\n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n",
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "gs = gridspec.GridSpec(1, 1) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ax0.minorticks_on()\n",
    "\n",
    "plt.plot(tpr_1D_phys,1./fpr_1D_phys,label=\"$f_{1}$\",color=\"blue\")\n",
    "plt.plot(tpr_Phi,1./fpr_Phi,label=r\"$f_{3\\rightarrow 1}$\",color=\"orange\")\n",
    "\n",
    "plt.plot(tpr_nD_phys_pfn,1./fpr_nD_phys_pfn,label=\"$f_{\"+str(n_phys)+\"}$${}^{PFN}$\",color=\"green\")\n",
    "plt.plot(tpr_nD_phys_pfn_v2,1./fpr_nD_phys_pfn_v2,label=\"$f_{\"+str(n_phys)+\"}$${}^{PFN}$ (fixed F)\",color=\"orange\",ls=\":\")\n",
    "\n",
    "plt.xlabel(\"True Positive Rate\",fontsize=20)\n",
    "plt.ylabel(\"1 / False Positive Rate\",fontsize=20)\n",
    "plt.yscale(\"log\")\n",
    "plt.legend(frameon=False,fontsize=20)\n",
    "\n",
    "plt.title(r\"$BSM$, $X\\rightarrow YZ$ $versus$ $QCD$\",loc=\"right\",fontsize=20)\n",
    "plt.savefig(\"ensembleLearnPlots/BSM_ROC2.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fe9286d6358>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(scores_nD_phys_pfn[:,1],np.exp(scores_nD_phys_pfn_v2)/(1+np.exp(scores_nD_phys_pfn_v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = scores_nD_phys_pfn[:,1]\n",
    "new = np.exp(scores_nD_phys_pfn_v2)/(1+np.exp(scores_nD_phys_pfn_v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_,_,_=plt.hist(orig-new[:,0],bins=np.linspace(-0.2,0.2,100))\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's do a harder classification task - top quark mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_0 = np.load('/data0/bpnachman/topmass/SRGN_Mt_default.npz')\n",
    "test_dataset_1 = np.load('/data0/bpnachman/topmass/SRGN_Mt_unknown.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X):\n",
    "    return X / 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_test_G = preprocess_data(test_dataset_0['generator'])\n",
    "X0_test_S = preprocess_data(test_dataset_0['simulation'])\n",
    "X1_test_G = preprocess_data(test_dataset_1['generator'])\n",
    "X1_test_S = preprocess_data(test_dataset_1['simulation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGcCAYAAAAs8CFkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeXxU1fn48c8DBQQMCSiIFTEgxA0FJWwqQqAqWypUqRRlEWyoGy4/2lq1gAt8bbVfwBaXUJG1olBBIy74RRSVsAiBFgFRMCgiCsouIMrz++PeiZPJnWTuZCaZic/79ZrXwL3nnHvuRJkn557nHFFVjDHGGGOSVbXK7oAxxhhjTHlYMGOMMcaYpGbBjDHGGGOSmgUzxhhjjElqFswYY4wxJqlZMGOMMcaYpGbBjDHGGGOSmgUzxhhjjElqFswYY4wxCUxE7hIRFZHfVHZfEpUFM8YYYyIiIrvcL9VIX7+r7D4HiMiZIjJeRApE5BsROSoihSIyTURaV3b/ynCR+766PI2IyBtBP5uRpZR7Oqjc0+W5ZkX5WWV3wBhjTOITkbrA5JDDPwPuBb4D/sej2mvx7ldZRESA+3D6WRN4G3gXOAS0AQYD14nICFWdWmkdLd1FwAHgoxi08z3Oz+0CrwIi0gG4AfgBqA68X85rVgixvZmMMcZEwx3RWAusVtXMyu5PKDeQmQoMxflSvk5VN4eU6Y4TdAnQTlULKrqfpXGDyP3AO6ratRztnAl8DCwDzgQ+VdX2IWWqASuB04FPgA5Ae1VdFe11K4o9ZjLGGBOtQABT6uMPcQwVkbdF5GsROew+7hniUfZi9/HGYyLyGxF5R0T2icgREVkpIlk++vdHnEBmNdA5NJABUNXFwBM4oxB3hPTlHrcv/Tz6eYZ77oWQ4wNFZLaIbBaRAyKyR0RWicgNYT6bLLedR0SkvYi86D4GUxE5D2f0qBohn7GI1HfLqohMFJEaZXwWwT+rAuA8N3gJNgJoC/wBJ+A5BvynnPfXWUReEJEt7s/wK/fnOL48ZUNZMGOMMSZabd33sI8iRKQ2zsjHM0AaMN39c2NgmojcE1IlMD/kcmAm8A3wFPAO0A54RUSaltUxt8z9wBGgv6oeKaX46+57pzB98QrWAsFB0UiOiKTg3F9zt7//AF4AmgFTReSPHu0ErtHKrXMc537/BWzix8+4qA/uo6ACIMu9tztU9Vgp9xfc39XAGqAOTsASaPNkYByQj/Mo7mTgv6p6NNr7c3+2S917WAz8L5AH1AJ6RFvWk6ray172spe97OX7BawAFLiolDLz3TL3hBxvCHyNE2zUDzo+1S2/D7g0pM5j7rlHI+jbRLfsxAjKXuCW/Srk+CfArjB1/set0yfo2IlAY4+yp+LMednkcW62284BoKPH+Wnu+bPcv9+FM0fpP0CGj5/VEred84Br3D9fHXT+nzjzZC4ErnbPPxXSRsT3B5yCMz/nHaCmR52Toykb7mUjM8YYY3wTkcAk0u+A9WHK9AH6AnNVtdijAlXdBbyM85v3RUGnAn++VVXfDWnyn+77uRF0sa/7PiuCsie573sDB0SkAZBO+EdogZGONYEDqnpQVXeGFlTVL4AdQAOPdgL3e7uqLg9z/gCwW0ReBP6GM2rTQT0em3lx5w5dCHyLM9oT6PMF7vkOwDCc4KWAMCNuPu/vbJxHd5tV9TuPOrujLOvJspmMMcZE4zzgBJzJvyW+gFw57vtfwpz/2n2vDiAitXAClc9wRizClS91fogbiJyB89v+2tLKujq678GTfwNBRrhHaBfhjOTsCLpufeBWoDdwFlCP4tM5ik0udif3ZgBf4YzAhN7HCcA57vnVOCMYOao6JYJ7CpYBpALLVPUHYKuI7AUucOfNTMb5bO9zywcCtWL37vP+PsAZXRsmIg1xfp6LVHWPR//8lPVkwYwxxphoRDL5twuwX1XDlTnVff/UfT8fJ1B5XVWPe5RPDykfzsnu+wFV/b60gu6oxXXuX+cHnSoxVyWoTnOcUYjXgo5dACzCCThWAnNw5vscw5lTMhhYF9JUa5xgYGGY+22N8z1dC/g5MCuKQAa8g5O1OJ93Ds69/lZVv3HPXQQcJWjEze/9qepuEbkUGAP0ArKBH0TkDeBeVV0TTdlwLJgxxhgTjVIn/7qTResRkg0TdL46TrDzFfChezgwGlIY5pq93fdFZfRtn/ueJiJ1VPXbUsoOxBll+hj4d9DxC913ry/SXu578EjETJwJzlmq+lZwYRF5wP1j6GcVuN8VYfoW+Iz/H848l+tFZLWqTgxTPhyvwLMA5/MfD6wCnnb72gznsdtKLT6p2Pf9qep6oL+I1AQuwwmc+gPtROQ0DZpc7KesF5szY4wxJhphRy5cR3Eyc+qHOT8UZ2TmGXVnefLjl3taaGH30VEOsB14sbSOqeqXOJN3BScrypOIZACP40x8zQn58j4bOKaq20Lq1MJJYQY30BGR03Hmn7zl8UWfhrMIHZT8rCJ5lBU4P8Ct/zcR+VW4ewrDK5hZg/P5pOHMTwr8DEoEqeW4PwBU9TtV/T9V/TXOgoUn4YzwlKtsMAtmjDHG+BLJ5F93Hs0q4HQR+UVI/e7AJJwRmOCVgwNfpNe480kC5U/EmfR6Es5E2dLSrAMCoxf/KyI/97iHPsB7QApwi6ouCSnyHVDDDXgCderiZFu1cg8FRmYC/WkevN6LiJwEPAc0wXv+zkXudf4b5h4uAg7jZAkdAvrgzCeaJSKhaeSe3DkxbXBWPN4YdOoVoB/QTVVXBh33eiTl6/5E5EJxFukL7UsLnM/uU5yg1FfZ0thjJmOMMX5FMvkXnC0EXgdeFpHncTJeWgNXAtuAy1V1HxQFSK1w5l2kAv8RkZdw5otchTNn5E+q+kKJq3j7O04wMATY5GYCfYqTEn4JzkTjL4G+qvqSR/3Xcda1eVtE5uOkJXfHeWz2Bc46LVvBycwSkTeBbsAKEfk/nFGnnjgp0ceBDcFBWNBk5/94fYbu45ZWQIE7aRdV3SkivXCCsJdEpJOqflzG53CO2/f3gufluPNjFniULzEyE8X9jQSGiMhKnMm9X+HMq/mle35YUF/8lA0v0hx1e9nLXvayl71UFZw03hLrkIQp2wV4Ezjovv6Ls5hdSki51m6bTwAtgVdxlvE/APwfcEWUfb0KJwX8S5zRA3VffwXqlVLvBJzRox04Kc3v4zxeSnO/vN8KKd8QmAHscvu8DGdS7IXu9Z4OKd+2tM8w6PyTHueycEZ0PqKMNVjcPigwKcLP62v3fqtHe384afEzceZC7Xf7WoiTWt8ypN2Iy5b2sr2ZjDHGVDp3OfypwAhVzY3jdf4f8CjwBnCl2pdglWBzZowxxiSCwGTXeG/0OAFnVOFy4JY4X8tUEJszY4wxJhFchJNVFG4ybEyo6nERGQwMAmqLSDWNZE6GSWj2mMkYY0ylcjNu9gOFqtqqrPLGhLJgxhhjjDFJzebMGGOMMSap2ZyZJFWvXj3NyMgos9y+fftITU0ts9yuXbto2LBhRNeOtM3KKhfpvUTaXjz6WFn3Eutyfsom+r3Y/ysVd914tFlV/vuCqnMv8fi3ePXq1ftVtWThyl6vwF7RvU4++WSNxG9/+9uIyrVt2zaicn7arKxykd5LpO35KZvo9xLrcn7KJvq92P8rFXfdeLRZVf77Uq069xKPf4uBXerxnWiPmZJUWlqJrUs8ZWdnx/zakbZZWeUi5ae9qnIv8ehfVbkX+3+lYq9bVe7F/vsqP5/t7fU6aBOAk1RmZqa+/364vcmiao9YtleZ7F4SU1W5l6pyH2D3kqiqyr3E4z7cXcMzQ4/byIwBICcnp7K7EDN2L4mpqtxLVbkPsHtJVFXlXiryPmxkJknFemTGGGOMSXQ2MmOMMcaYKsmCGWOMMcYkNQtmktS+ffvIyckhLy+vsrtijDHGxFVeXl5gDo7ngjQ2ZyZJ2ZwZY4wxPzU2Z8YYY4wxVZIFM8YYY4xJahbMGGOMMSapWTBjjDHGmKRmwYwxxhhjktrPKrsDxpiqa8Ibm4v9/eN1K5j+0O0MuW8SLVp3iKrNOy/PiEXXjDFViI3MGGMqTIvWHRhy3ySmP3Q7H69bUdndMcZUERbMGGMqlAU0xphYs2AmSdkKwCaZWUBjjPGjrBWALZhJUqmpqeTm5pKdnV3ZXTEmKhbQGBMbe/bsYdy4cVxyySU0bNiQGjVqUL9+fdq2bcuIESOYN28ehw4diqrtwsJCRKTE66233ipRduzYscXKdO3atXw3FiQ7O5vc3FyAfV7nLZgxxlQaC2hMec2bN4/bbruNzp07U69ePUSE66+/3rPstGnTPL+Yg1/Vq1cvVufrr7/mn//8J/369aNFixbUrl2b1NRULr30Up5++mmOHz/uq7/p6elhr924cWPf9//qq6/SvHlzFixYwB/+8Ac2bdrEgQMHWLFiBYMGDWL+/Pn079+fzMwSOwBE3F9VZfz48QC0a9cOVfUMVMaOHcuuXbuoUaMGGzdu9Ax44qXSs5lEpBrQHfglcClwBk6/PgNeASao6g6PehnAOCALqA2sB/5XVZ8r5Vo9gD8BFwHfA+8BY1R1dSl9uxXIAc4E9gALgXtV9aswdeoB9wNXA42AT4EZwF9U9ViYOr7vxZiqIjigKU+WUzIJzfIqSyAL7ODeb+LUo+T10EMPsW7dOk488USaNGnCpk2bwpZt06YNY8aM8Tz3zjvv8Oabb9KzZ89ix+fOnctNN93EqaeeSlZWFk2bNuXLL7/khRde4MYbb+TVV19l7ty5iEjEfU5NTeWOO+4ocfzEE0+MuA2AxYsXk52dTVZWFgsXLqRmzZpF5zIyMsjIyKB79+5cfPHFHDvm+fUTsUGDBnHfffexatUqNm7cyDnnnONZ7tlnn6VNmzacffbZ5bqeX5UezAANgEXAZuBmYAXOF3pf4B/AYBFpq6rbAxVEpDXwDrAG6Ah8BdwBzBGRM1V1fOhFRGQY8DTwd6AfUAd4DFgmIleq6lsefXsG+A0wAngOOAt4FlglIh1UdWfINerhBEj1gQHAaqAHMBO4WESyVfWHkDq+78WYquanGND4Efh8TEkTJkygSZMmtGjRgrfffpusrKywZdu0aUObNm08z3Xq1AkgMC+jSEZGBi+99BK9e/emWrUfH2aMHz+e9u3b8+9//5sXXniBq6++OuI+p6WlMXbs2IjLezl69CiDBw8GYMqUKcUCmWDnn38+Q4cO5dVXXy3X9Zo0aUL37t154403mD59Og8//LBnuZkzZxb1qyIl0mOmoaq6WFUPquouVZ0CPIkzuvHbQCF3tGQ6Tt9/raofq+p+VX0AeBl4UERaBTcsIqcBk4GVwO2q+o0bHA3CGW2ZISK1QupcDQwGJqrqM6r6raoWANcBTXECoVDjgFZAjqq+q6qHVXU+MAboiRMUBV/D970Yk0w6fppLzUV/5oFftaHmoj/T8dPcsK/r66/jud9fwdHnb2Js3wvClv+pinWAt2TJEkSEUaNGsWbNGvr27UuDBg1ITU2lX79+7Nzp/K62YcMGBg4cSKNGjUhNTaVPnz58+umnMe1LeWRlZdGyZUtfIyOh1q9fz/LlyznttNPo3bt3sXPdunUjOzu7WCAD0LhxY373u98BVOjjlIBnn32WHTt2cNlll5Genl5q2ZtvvpmRI0d6npsxYwYdO3akbt26pKSkcMkll/Dcc94PBYYMGQLArFmzPB+vbdq0ibVr1zJgwAB/NxMDiRDM7MN5vOL1wPwj9z0t6Fg3oDXwssejnqk493R7yPGbgBOAZ1RVAwdV9RDOiMvpwDUhde4MapOgOquB/wDXiEiTwHERSQFuBL4AQkPgaYAGtVmeezEmaazZ9Bn3PZnHQ7/L5qKzTy+zfOFeZe4H39P/vJ+Rnhb9l5Mp25o1awDYvHkzl156KdWrV2f48OE0bdqUBQsWMGzYMPLy8mjfvj0HDx5kyJAhZGRksHDhwkr5zTuennrqKQCGDx9eYs5MaWrUqAHAz37m7yHH0aNHmTVrFuPHj2fSpEksWbKEH374oeyKQV5//XUA2rdvX2bZc845xzOYufXWWxkyZAjdunVj+/btFBYWkpWVxYABA3jooYdKlO/Xrx8pKSl8/vnnLF68uMT5GTNm0KtXL04++WRf9xILlf6YyZ1H8laY0x3d9+BPLRA253uUzw8pE2mdkW6Z2QAiUh+4GNirql4PYPOBC4BeQOBXxW44AdOK4IAJQFW/FpHNwFkikqGqgQfm0dyLMUnDTyATCHzG33wV6WnCundeo3XnHjRo3KTMusa/QDCzcuVKli9fzgUXXADA6NGjadq0KYsWLaKgoIA33nij6BHMd999R4sWLVi6dClHjhzhhBNO8HXNiRMnsnfv3ojLt2nThr59+/q6hl+HDx9m1qxZVKtWjRtvvDHiet9//z0zZswAoEePHr6uuXPnTgYNGlTsWLNmzXjmmWfo0qVLRG1s3ux8jTRpEt3/H3l5eUyePJnOnTsXTe4FZw7S0qVLGTt2LNdcc02xuS916tShf//+TJ06lenTp3P55ZcXnVNVZs+ezYQJE6LqT3lVejATSkROwJkEPBy4FrhfVV8KKnK++14YWldVd4rIEeBUETnJDSKqA+eGqxN07PygY+cBEqZ8uDph+xV0/Cy3XCCY8XUvYdo1JmH5DWSCy7fu3MMCmjgKBDPTpk0rCmQAUlJSSE9PZ+3atTzyyCNFgQxAzZo1Oeuss/jss884dOhQVMHMtm3bIi4/ZMiQuAczzz//PHv37qV3796cfnrZ/60G3H333axfv55evXpx5ZVXRlzvhhtuoHPnzpx33nmkpKSwdetW/vGPf5Cbm0vPnj3Jz8+ndevWZbazf/9+AGrXrh3xtYM98cQTAJ4B3IABA3jnnXeYOXMm48aNK3ZuyJAhTJ06lfnz53PgwAFSUlIA51HbwYMH6dOnT1T9Ka9EeMxUxM02OgxswpmbMhh4IKRYIHdtT5hmAjnop7jv9YGagKqqV3763pDykVyjouqE3osxSSXaQAagQeMmRQHNNzu3l9KC8evQoUNs3ryZZs2aeY4qbNu2jQYNGnDttdd6nktJSeGkk04qOjZq1KiIRicKCwtR1Yhf06ZNK9d9RsJdu4QRI0aUUfJHjz32GH/72984++yzmTlzpq/rjRkzhm7dunHKKadQp04dWrVqxZNPPsldd93F4cOHI54YXK9ePcAZWfIyZ86cEqnfwZ/nypUrATwnRAeCuvfff7/Euc6dO9O8eXO+/fZb5s2bV3R85syZXHvttWEnIsdbQgUzqvoaUB0nDXoiTvbRayJyUlCxQBgaLs/sO/e9TpTlE70OALt27SIzM7PoFfgf0phkUtacmtCAZs2mzyqhl1XPunXrOH78eLHHBAGFhYXs2bOHrl27Fs0JCTh48CBbtmwp8QW4atWqiOZuJJoNGzawbNkymjRpQq9evSKqM3nyZG6//XbOPfdclixZQoMGDWLSl8Bk4qVLl0ZUPiPD2XA13GTsAQMGFAWFgYm7wfbtc35Xbt26dYmg55e//CUAX375ZYl6IlI0Z2r69OmAE1DNmzcvbnOpcnNzi77rAM8JOQn3mElVjwNbgUfcxyyPAZOAwCpIgTC0hkd1cEZhAL6Nsnyi1wGgYcOGnlGzMcki0snBgYBm/osvM/eD77nlkQrsZBUVeMTktZDa6tWrw54rKCjg+PHjXHTRRQAcO3aMunXrcuzYMZYuXcqDDz7IueeeywcffOB53USbM+N34u/EiRO58847adWqFYsXL6ZRo0Yx60ugrUhX6u3Rowdz5swhP99rymXZ0tLS2L17Nx999BEtWrTwVXfw4MHcf//9LF26lMLCQpYtW0bjxo3p2LFj2ZWjkJOTU5QyLyK7vcokXDAT4mmcYGagiIxws4924sxpqR+mTmDfhkBIuQdnhKOmiKR6PGpKCymPew1KuUYs6/i5F2OqhPJkOZnyCwQzbdu2LXEuEMx4nSsoKAAoCmaqV69Ofn4+mZmZrFixgqZNm1KrVq0S9QISac7MkSNHmDlzJtWqVWP48OFllv/LX/7C3XffTZs2bXjjjTdinrETCEqaN28eUfkBAwZw77338t577/Hhhx9y1lln+bpehw4dWLhwIYWFhZ7BzPLly6lTp06x+VQBzZo1o3PnzixdupSZM2eybNmySs9wS6jHTKFU9VtgF85k3DPdw/9135uFlheRxjgZRV8EJsy6i9RtCFcHSA9pF+ADnFTq9NDCpdQJ269o6njdizFVgd9AJjjLqd9VlTO5MNYqe+uGNWvWULNmTVq1KrmMVSCYCQQsofWCz1WrVo0vvviClJQU2rVrR+PGjalfP9zvZok1Z2bu3Lns2bOHXr16lTnx98EHH+Tuu++mbdu2LF68OKJAZsuWLWzatKnYyrsffPAB33xTchXnbdu2ceuttwKE3YohVK1atZgxY0ZRFla4uTOAZ9r3zTffDOD5GX/++ed07dqVtWvXhm0z8OjqqaeeYvHixRH3O14q/dccEbkPuEhVf+VxribOCsEA+933V3BWyPUaz+oUVCbYK0Abt07oT6dEHVXdIyL5OKv2nu2Rnt0JJ9gJXk/mTeAo0F5EJDg9253zkwFsCUrLjvZejEla0QYykZZPFpW50vHRo0fZsGEDF1xwgedkzTVr1nDGGWd4fmGvWbOG2rVrF1vKvqCgoGjeRWVYsGABCxYsACha6C8/P5+hQ4cCcPLJJ/Poo4+WqBeYZxi64m+o6dOnM3r0aKpXr07nzp157LGS66Wmp6cXXS+ge/fubNu2jU8++aRoUbu5c+fy8MMPk5WVRbNmzUhJSWHLli0sXLiQI0eO0KtXL0aNGhXxvXfr1o2XXnqJgQMH0qFDB0aPHk3Xrl2LHiGtXLmS6dOnM3/+fBo1akTLli2L6vbq1Ys77riDSZMmcdpppzFixAgaN27MqlWruO222+jSpQu/+c1vwl67f//+3HbbbXz++ed06dKlzIX74q3SgxmcPnQWkTRVDX2YOhBnQvAGVS10jy3GGdHoIyKNQhabGwYcp+TqvE8CdwE3iMhTgUBDROoCvwa2A/NC6kzEWWtmGPCHwEERaYuzxsy/VbVoNqKqHhCRp3G2ZOhJ8SBkKM7o0sSQa0RzL8YkjW92bi9Kq7ZA5keVuXXD+vXrOXbsmOdjpG3btrF7924uu+yyEueOHj3Kxo0badu2bbH5JWvXruXCCy+Ma59Ls3bt2qKJqAFbt25l69atAJxxxhklgpmNGzfy7rvvRjTx95NPPgGc0Y2JE0P/CXd06dKlRDDjJSsriw8//JCCggLy8/M5dOgQaWlpXHrppQwaNIhBgwb5Dgp79erF1q1bmTx5Mo8++ig5OTns37+funXrcvrpp9OmTRtmz55N3759S6RxT5gwgfbt2zN58mQmT55MtWrVaNasGYMHD+aWW24pMQE8WEpKCv369WP27NmV/ogJQELWd6v4DoiMAcbi7Gn0J5yRkxNx9mb6C86jsCtV9b2gOhcCS3H2PhqO8yjqdpw07tGq+qDHdX6Ls8Dd393r1Xb/3AfoqaolljMUkVk4wU7w3kz/cvvXIXQDTBFJBZbhzHUJ3ptphnu8t6p+H1LH970AZGZmqk0ANolufI80WnfuQeFejVkg02l4yd+yk82ENzYXbR7pJ6C58/KMOPfMvxYtWnD33Xf7WnDOmGiJyGpVLTE7PRFGZv6Ks67MtcAUoAnOaMxnOCvyPqKqW4MrqGqBiLQDHsLZb6k2zjyXgar6rNdFVHWKiGwH7sHZyfp7nADjYlUNFxUMBlYBo4AncNaKWQjco6olJuWq6j4RuRhn1+xn+XHX7L/i7Jr9vUcd3/diTLIIzkIaf/NVP/kRmYA7L8+AyzOYPGpQ2YUT3Pfff8+mTZvYsWMHderUIS0trexKxsRYpY/MmOjYyIxJBpN/fy33PP4i/c/7Gf2u6lPmSr6RBDJVYWSmKpk9ezZ//OMf2bFjByNGjChaWdaYeAg3MmPBTJKyYMYkg/opdXjod9kR7bUU6YiMBTPG/HSFC2YSOjXbhLdv3z5ycnLIy8ur7K4YE1YgMClra4KfwqMlY0z08vLyAplnqV7nbWQmSdnIjEkG+U8XTzP9Zuf2EiM0fgMZG5kx5qfLRmaMMZXOa68lv1lOxhgTyoIZY0yFCt5r6Z7HX/Sdrm2MMaEsmDHGVLjgvZbS08peJCx4BMcYY0IlwjozxpifkOC9lqLKclryP6W2/9barfS//1/MHTOQrm3K3rQvUH7X3sh2KzbGJB4bmTHGVJjQwCTWWU7RBjJzxwyM6n6MMYnBghljTIUIF5iEC2gqMpCJpLwxJnFZMGOMibuyApPyZjlZIGPMT5vNmTHGxFWkgUlwlpOfvZwskDHG2MhMkrIVgE0y8DvC4jfLyQIZY34abAXgKspWADbJILA3k9/dskvLcurU/CQgDoFM1p8iuyljTKWxFYCNMRUumkAmkiwnG5ExxgSzYMYYEzfRBDIB4QIaC2SMMaEsmDHGVJpospwskDGmuD179jBu3DguueQSGjZsSI0aNahfvz5t27ZlxIgRzJs3j0OHolsUsrCwEBEp8XrrrbdKlB07dmyxMl27di3fjflgwYwxplJEk+V0z+MvVo1AZsn/lPl6a8JvaZhWl7cm/PbH46aEefPmcdttt9G5c2fq1auHiHD99dd7lp02bZrnF3Pwq3r16iXqpaenhy3fuHFj333evn07w4YN4+c//zm1atUiPT2dO+64gz179vhu69VXX6V58+YsWLCAP/zhD2zatIkDBw6wYsUKBg0axPz58+nfvz+ZmSWmmUQkPT0dVWX8+PEAtGvXDlX1DFTGjh3Lrl27qFGjBhs3bvQMeOLFUrONMRWuPFlO8Qhk3lq7la5ZEXW9QiR0IJZgHnroIdatW8eJJ55IkyZN2LRpU9iybdq0YcyYMZ7n3nnnHd5880169uzpeT41NZU77rijxPETTzzRV3+3bNnCxRdfzFdffcVVV13F2WefzcqVK5k0aRKvvfYa7733HieddFJEbS1evJjs7GyysrJYuHAhNWvWLDqXkZFBRkYG3bt35+KLL0WUYlQAACAASURBVObYsWO++hlq0KBB3HfffaxatYqNGzdyzjnneJZ79tlnadOmDWeffXa5rueXBTPGmArlN5AJ3cupLFHvzXTnlIj6H28WyPgzYcIEmjRpQosWLXj77bfJygoflbZp04Y2bdp4nuvUqRNAIP23hLS0NMaOHVvu/t5888189dVXPPbYY9x2221Fx++66y4mTJjAvffey5NPPllmO0ePHmXw4MEATJkypVggE+z8889n6NChvPrqq+Xqd5MmTejevTtvvPEG06dP5+GHH/YsN3PmzKJ+VSR7zGSMqTDRBjLBWU4Ll61j/F/+wsJl68jf+nWx1+RX1tJv9GzG/rYPteqlljhfWvlEUJGBzJIlSxARRo0axZo1a+jbty8NGjQgNTWVfv36sXPnTgA2bNjAwIEDadSoEampqfTp04dPP/00rn3zIysri5YtWyJSdqAbzvr161m+fDmnnXYavXv3jmHvitu6dSuLFi0iPT2dW265pdi5+++/n7p16zJz5syI5rc8++yz7Nixg8suu4z09PRSy958882MHDnS89yMGTPo2LEjdevWJSUlhUsuuYTnnnvOs+yQIUMAmDVrFsePHy9xftOmTaxdu5YBAwaU2f9Ys2DGGBM35dlrKd57OfktH28VPSKzZs0aADZv3syll15K9erVGT58OE2bNmXBggUMGzaMvLw82rdvz8GDBxkyZAgZGRksXLiwUn7zjqennnoKgOHDh3vOmQFnJGTWrFmMHz+eSZMmsWTJEn744Qdf13nzzTcBuOKKK6hWrfjXbyCQ+Pbbb1m+fHmZbb3++usAtG/fvsyy55xzjmcwc+uttzJkyBC6devG9u3bKSwsJCsriwEDBvDQQw+VKN+vXz9SUlL4/PPPWbx4cYnzM2bMoFevXpx88sll9inW7DFTkgqsAJydnU12dnZld8cYT4GF7wr3akwDjeCAJh7tV7TKeLQUCGZWrlzJ8uXLueCCCwAYPXo0TZs2ZdGiRRQUFPDGG28UPYL57rvvaNGiBUuXLuXIkSOccMIJvq45ceJE9u7dG3H5Nm3a0LdvX1/X8Ovw4cPMmjWLatWqceONN4Ytt3PnTgYNGlTsWLNmzXjmmWfo0qVLRNf68MMPAWc+i5eWLVuyaNEiNm/eTPfu3Utta/PmzYDz+CcaeXl5TJ48mc6dOxdN7gVnDtLSpUsZO3Ys11xzTbG5L3Xq1KF///5MnTqV6dOnc/nllxedU1Vmz57NhAkToupPJP11V7z3XAHYgpkklZqaSm5ubmV3w5hSRbPXUrz3crJAxhEIZqZNm1YUyIAzQpCens7atWt55JFHigIZgJo1a3LWWWfx2WefcejQoaiCmW3btkVcfsiQIXEPZp5//nn27t1L7969Of107/8ebrjhBjp37sx5551HSkoKW7du5R//+Ae5ubn07NmT/Px8WrduXea19u3bBzj/fnsJHI8k4Nu/fz8AtWvXLrOslyeeeALAM4AbMGAA77zzDjNnzmTcuHHFzg0ZMoSpU6cyf/58Dhw4QEpKCgBvvfUWBw8epE+f+DyyDfziPmXKlH1e5+0xkzEmbvzutRTvvZwskHEcOnSIzZs306xZM3r06FHi/LZt22jQoAHXXnut57mUlJRiGTejRo3ybCdUYWEhqhrxa9q0aeW6z0gEfikcMWJE2DJjxoyhW7dunHLKKdSpU4dWrVrx5JNPctddd3H48OGYTAwGZ3QDiGj+T7169QBnZMnLnDlzSqSRB3+eK1euBPCcEB0I6ry2zOncuTPNmzfn22+/Zd68eUXHZ86cybXXXht2InK8WTBjjImbQBZSv6v6hN2aIKA8WU7xaD/eosm6ipV169Zx/PjxYo8JAgoLC9mzZw9du3alRo0axc4dPHiQLVu2lPgCXLVqVURzNxLNhg0bWLZsGU2aNKFXr16+6//ud78DYOnSpRGVD4y8BEZoQgVGW8KN3AQLPKoKNxl7wIABRUFhYOJusEAfWrduXSLo+eUvfwnAl19+WaKeiBTNmZo+fTrgBFTz5s2r1LlU9pjJGBM3wYFD8ByX0M0jYzF5N5btx1tlp48HHjF5LaS2evXqsOcKCgo4fvw4F110EQDHjh2jbt26HDt2jKVLl/Lggw9y7rnn8sEHH3heN9HmzEQy8bc0jRo1Aoh4dd2zzjoL+HG+S6iPPvoICD+nJliPHj2YM2cO+fn5EV07VFpaGrt37+ajjz6iRYsWvuoOHjyY+++/n6VLl1JYWMiyZcto3LgxHTt2jKovsWDBjDEmbsJlIQUHHPHIcipP+xUh2i0ZYiUQzLRt27bEuUAw43WuoKAAoCiYqV69Ovn5+WRmZrJixQqaNm1KrVq1wl43kebMHDlyhJkzZ1KtWjWGDx8eVRuBQKJ588geEQbWwFm0aBHHjx8vltF04MAB3nvvPWrXrh1RUDBgwADuvfde3nvvPT788MOiQClSHTp0YOHChRQWFnoGM8uXL6dOnTrF5lMFNGvWjM6dO7N06VJmzpzJsmXLKj3DzR4zGWMqjNdeS/HKcoqm/YpS2VsyrFmzhpo1a9KqVasS5wLBTCBgCa0XfK5atWp88cUXpKSk0K5dOxo3bkz9+vXDXjeR5szMnTuXPXv20KtXr7ATfwE++OADvvnmmxLHt23bxq233grguX3Cli1b2LRpU7GVd88880yuuOIKCgsLmTx5crHyY8aM4dChQwwePJi6deuW2f9atWoxY8aMoiyscHNnAM8U8ptvvhnA8zP+/PPP6dq1K2vXrg3bZuDR1VNPPcXixYvDbiFRUWxkxhhToeKdhRRt+xWpMgOZo0ePsmHDBi644ALPyZpr1qzhjDPO8FwrZM2aNdSuXbvYUvYFBQVF8y4qw4IFC1iwYAFA0UJ/+fn5DB06FICTTz6ZRx99tES9wMTfcCv+BsydO5eHH36YrKwsmjVrRkpKClu2bGHhwoUcOXKEXr16MWrUqBL1unfvzrZt2/jkk0+KLWr3+OOPc/HFFzNy5EgWL17MOeecw4oVK1iyZAkZGRklsodK061bN1566SUGDhxIhw4dGD16NF27di16hLRy5UqmT5/O/PnzadSoES1btiyq26tXL+644w4mTZrEaaedxogRI2jcuDGrVq3itttuo0uXLvzmN78Je+3+/ftz22238fnnn9OlS5cyF+6LNwtmjDEVLhGznDqVWarixDPLaf369Rw7dszzMdK2bdvYvXs3l112WYlzR48eZePGjbRt27bY/JK1a9dy4YUXxrSPfqxdu7ZoImrA1q1b2brVmTB9xhlnlAhmNm7cyLvvvhvRxN+srCw+/PBDCgoKyM/P59ChQ6SlpXHppZcyaNAgBg0a5CuQO/PMM3n//fcZPXo0r732Gq+88gqnnnoqI0eOZMyYMTRo0CDitsAJSrZu3crkyZN59NFHycnJYf/+/dStW5fTTz+dNm3aMHv2bPr27VsijXvChAm0b9+eyZMnM3nyZKpVq0azZs0YPHgwt9xyS4kJ4MFSUlLo168fs2fPrvRHTAASSAUzySUzM1O90uaMSST5T5f8jTU4MElPk7CTdr3K+x3B8dP+ngPf+rs5A0CLFi24++67S11wzphYEZHVqlpidrrNmUlSgRWA3RURjUkKXnsteW1NEK58PNs30fn+++/ZtGkTO3bs8JWpZIwfeXl5gUeCnnnrFswkqcAKwLaVgUkWlbXXUqzaN97GjRvHnDlzaNKkCX/6058quzumisrOzg7Mc0rMFYDFkS0ic0TkUxH5TkT2ishSERkUpk6hiGiY18elXKuHiLwtIgdEZI+IvCwiJR8c/1i+moiMFJH1InJYRHaIyBQRaVRKnXoiMsG9lyMisllE7hORsA8fRSRDROaKyG4ROSQiK0Sk5NKbxiSpeGchVZUsp2R03XXXsX37do4fP160RL4xFa3SgxngXuAl4CTgKiAN6ATsAWaIyNQw9bYCH3q8tngVFpFhwKvAOuAM4HzgO2CZiHQNc41ngEeBv7n96w10BlaJSGOPa9QD3gP6AwOB+sAfgbuBF0WkxKpMItIaeB9oCHQETgUWAnNE5J4w/TImaUSThXTP4y/GfNPIaNs3xiS+RAhmTgC+BPqpaoGqfquqG3ECgq3ADSLSzaNed1U92+N1ZWhBETkNmAysBG5X1W9UdTswiB+Dplohda4GBgMTVfUZt18FwHVAU+Axjz6NA1oBOar6rqoeVtX5wBigJ1Bs8w8RqQZMx/k5/FpVP1bV/ar6APAy8KCIlFwIwpgkkWh7Lflt3xiTHBIhmPkcmK6qB4MPqup3wBvuX39RzmvchBM0PaNB6Vuqegh4DjgduCakzp3ue7GRIVVdDfwHuEZEitIjRCQFuBH4AmcEKNg0QIPaDOgGtAZeVtWvQs5Nxfn53F727RmTmBJpryW/7RtjkkelBzOq+oSq/jHM6QPue3l/hertvnttYpEfUgYRqQ9cDOxV1U1h6ggQvEBBN5yAaUVwwASgql8Dm4EWIhK86YavfhmTbCoiCyke7RtjkkulBzNlCHzxe21JOkJE1orIQXdC73IRucl9dFPEnadyrvvXQo92AsfODzp2Hk6w4lU+XJ3zQ86Vq46q7gSOAKeKyElh2jQmoSVCFpLf9o0xyafcwYyIXCoi/ysi40TkzFh0ym23AXAlUAC85lGkE5CDMzH3bJyA53FgQchE2/pATUBV1SulK7AwwilBxwKTe/eE6V5F1Qn095Qw541JaomU5WSMSV4Rb2cgIr2AwAptLVV1q4j0dI+J+7pFRDJVNWx6tA9/xZlnMjj0sQ0wDHjXnVcDzrybP7iPcK4CbgUmuecC6zcfw1ugjTpBxxK5jjFVQrz3WvLbvjEmefkZmRkALMMNZNxjf3HfRwO/wsk+KveqSSJyHTAUuE5V14eeV9U3gwKZYLnue/BGEYGtRMOt8xLYaS14LfNErgPArl27yMzMLHoFNk0zJhkkYpaTMSYx5ebmFn3XASV3QMXfRpPtgP6BQEZEMnHSkJ9T1XHuse3AnPJ0WkQuB/6Jk978gs/qgTVmzg46tgdnhKOmiKR6PGpKc9+/DDq2030Pt5d9LOucV0qdwLLNX4aeaNiwIbY3k0lG5clCiudeTrc84vtWjDEVICcnp2h3cxHZ7VXGz8jM6TiL0gVcjfMYKDh1+b/Az/1180ci8gtgAXCLqoZbLK/UJkIPqOoPwAb3r8086qS77/8NOvYBzr2lhxYupU7gz17X8F3HXZTvBOALNxvKmKRXkXst+W3fGJO8/AQzX+OsnIuI/AxnhduvgcVBZerx40RXX0SkO04gMzI4kBGR84KX9heRUSIy3asNIDAB+cOQ46+47x096nQKKYOq7sFJjU4TkbPD1FGKryfzJnAUaC8h+8G72UgZwBZV3Rxtv4xJNom815JtaWBM1eEnmHkXeMKdCPwk0ARnsbvjQWV+Q5jtBErjrvD7InCHqj4dcrodzqJ3AScCV7qL1IUKlJsVcvxJnDTnG4IDDRGpC/wa2A7MC6kz0X0fFtLXtsAFwAuq+lnguKoeAJ7G2Y6gZ0hbQ3FGjSaGHF+MMzrTx2O/p2HAcbxXGjYmKSTqXksWyBhTtfiZM/MAsIIfs5d24E4AFpFzcJbsvxrwtZ+QiGThLN2/D/iF+6gpWDN+nCgLzojIKcB8Ebkb55FQA+AunAXmXgf+HtyAqn4mIiNxJghPEpGxOJlEf8dJ7e6pqkdC6swVkdnAHSKyEWel4LNwAqXtwEiP27kH6ArkisgAYDXQAxgLLMIJqoKvcVxEhuCklT8vIsOBXTir/vYBRqvqfzw/OGOSQEVkIcWrfWNM8og4mFHVD0XkPJysJcWZ+BuYiHMc2Ag8BMzw2YchOIFFbSDcTtFvB/35r8Amt+y/cObyHMMJam4FnnTnyYT2f4o7Qfke4FPge5zsrItVNdxM2sHAKmAU8ATOI7SFwD2qWmJSrqruE5GLgfuBZ4FG7rX+CvxFVb/3qFMgIu1wPruV7ufwATBQVZ8N0y9jkkKi7bVkgYwxVZOUXMIlyoZETgzdX8nET2Zmplo2k0l09VPq8NDvsuOahRSr9jsNf9TfzRljKpyIrFbVzNDjEc+ZEZGysovyRWSriHhNZjXG/AQlyl5LNiJjTNXmZwLwkDLO3wwswSasVoh9+/aRk5NDXl5e2YWNqSSJsNeSBTLGJL+8vLzAWjOpXucjfswkIsdVtdTgR0TqAF+p6ol+O2r8scdMJhnkPz2qxLFvdm4veiRUuFdjnoUUbfv2mMmYxBfuMVPYCcAi0pTii8apiHTGY2E61wlAFs7aM8YY46mi9lry274xJnmVls10A066dWDoRoC3ymhPgD+Xv1vGmKosEbOcOpVZyhiTqEoLZt4K+nMgSHkgTFnF2QPpfVXNj03XjDFVUUXtteS3fdubyZjkFTaYUdW3CVrfRURGq+r9FdIrY0yV5BWYBCbtegUcsZgcHGn7xpjk5SebKdwGisYYU6bK2mvJspyMqfoiDmZUdVsk5UTkzei7Y4ypiip7r6Xytm+MSWx+9mYq4u4CXYeSmU0CdClvp4wxVUei7LVkWU7GVF0RBzMiUgt4BLgOSItbj4wxVUai7bXkt31jTHLwMzIzCcjB2VByCXCQH9O2AwQYFJuumdIEVgDOzs4mO9smL5rEVBFZSPFq3xiTOPLy8gIr3pd7BeBdwHhVnVBGuTJXCjblZysAm2Qw+ffXRv2oKHgl33hkOYW2bysAG5P4yr3RJM4cmacjKJflo01jTBWWCFlIfts3xiQfP8HM+0DjCMpFNtRjjPnJS6QsJ2NM8vIzZ+b3wAQRGaKqu0sptwSoXr5uGWOqukTLcjLGJC8/wczvgHrAdhFZAewADselV8aYKi0Rs5yMMcnLTzAzNOjPnUspZ/8qGGPCqqi9lvy2b3szGZO8/C6aV9aWBgJsibIvxpgqriL3WvLbvjEmefkJZj6MZEsDEVlajv4YY6qQb3ZuLwo44pGFFBzQxHpysDEmefjZm+mcCMtZarYxBiBh91qyQMaYqiXavZnqAOcDp6jqSyJygqoeiW3XTGlsBWATaxPe2BzzNhNxryULZIxJPmWtAOxrpV4RaSwiM4GvgWXAC+6pLiKyWUS6l6ezJnKpqank5uZaIGNi5uN1K2LeZqLttWSBjDHJKTs7m9zcXIB9XucjDmZE5BRgBc5Gk/uBAn7cNft94HUgT0QuLE+HjTGVY/pDt8c8oAlkIfW7qk+ZK+2WJ8spHu0bY5KHn5GZMcBRoLuqnhK8N4Kqfq2qtwF/Bf4U4z4aYyrAkPsmxTygCQQOZW0dUN45L7Fu3xiTXPwEM72AQaq6pJQyTwEdytclY0xlaNG6Q8wDmkTYa8kCGWOqPj/BzCnAmjLKHAAaRd8dY0xlikdAE6wi91qKpn1jTHLyE8x8DbQuo0wH4Mvou2OMqWwVFdDMf/Fl7nn8xZinU0fbvjEmeflJzX4N+JeI/FZV3w49KSItgMnAwlh1zhhTcTp+mlv055pffkb1Y99y9PmbyDjaJ+zWAQGJloUUTfudyixljElUfkZmxgJpwJsi8pGIzAMQkRnuqr8bcTaifDDmvTTGVJh4ZwklavvGmOTlZwXg7UAXnJTsM4Ff4aRmXw9cCqwGuqrqzjj00xhTAeKdJZTI7RtjkpevRfNUdaObkt0BuA24D7gVaKeqHVU19kuIGk+BFYDdFRGNKbd4Zwkle/vGmMqTl5dHTk4OhFkBWFQ1ooZEZLCqzohh30w5ZGZm6vvvv1/Z3TBVSP2UOqV+sX+zc3vR5o6FezXmeyFVdvudhj9a5nWMMZVLRFYHr3MX4GcC8DMi8oKqHoxhv4wxCaKy90JK1PaNMYnPz2MmAXaKyEwRidnO2OLIFpE5IvKpiHwnIntFZKmIDCqlXoaIzBWR3SJySERWiMi1ZVyrh4i8LSIHRGSPiLwsIm1LKV9NREaKyHoROSwiO0RkioiEXUtHROqJyAT3Xo64e1bdJyI1YnkvxsRasmYhxbN9Y0xy8DVnBmgDfAbMEJFPRGSsiKSXsw/3Ai8BJwFX4WRMdQL2uNeZGlpBRFrj7AfVEOgInIqTEj5HRO7xuoiIDANeBdYBZ+Ds+v0dsExEuobp2zPAo8Df3P71BjoDq0Skscc16gHvAf2BgUB94I/A3cCLIlI9FvdiTGVI1CykeLVvjEkefoKZ+1X1Y1W9BycYuBk4B9ggIotF5HoRqR1FH07AWWivn6oWqOq3qroRJyDYCtwgIt0ChUWkGjDd7fuv3T7tV9UHgJeBB0WkVfAFROQ0nDVwVgK3q+o3bnbWIH4MmmqF1LkaGAxMVNVn3H4V4Gy02RR4zONexgGtgBxVfVdVD6vqfJx9rXoCI0Ku4ftejKkMiZyFFI/2jTHJxU9q9v1Bfz6uqq+q6rXAacB84M/AFyLylM8+fA5MD52Lo6rfAW+4f/1F0KluOCsRv6yqX4W0NRXnnm4POX4TTtD0jAbNeFbVQ8BzwOnANSF17gxqM7hfq4H/ANeISNFKYiKSAtwIfIEzAhRsGqBBbZbnXoypUMmeheS3fWNM8vH7mKkY97FJF+AKoDnOonnD/LShqk+o6h/DnD4QuFTQsd7ue75H+fyQMlHVEZH6wMXAXlXdFKaO4Gy+GdANJ2BaERwwgbOrOLAZaCEiGeW8F2MqTLz3Qkqk9o0xySvibCYR2aqqzd0/n4sTtFyPM9dDgI9wRiCmx7B/gS/+pUHHznffC0MLq+pOETkCnCoiJ6nq127AdW64OkHHzg86dh7OPXmVD1cnbL+Cjp/llgusx+PrXsK0a0xcJHsWkt/2jTHJy09qdrqI5OAEMe1wvuwP4gQwU1X1vVh2TEQaAFfirDgc/GtTYOLtnjBV9+GMkJyCszlmfaAmoKq6z6P8Xvf9FB/XqKg6ofdiTIVI9iykaNo3xiQvv4+ZnsAJZN4BbgAaq+rwWAcyrr/izDMZHPLYJjDJ+FiYet+573WiLJ/odQDYtWsXmZmZRa/c3NzQIsZEJdmzkKJt3xiTmHJzc4u+64CTvcr4GZkBGI8ziXZreTtXGhG5DhiKk+GzPuT0Yfc93LotNd33b6Msn+h1AGjYsCG2ArCJtVjMSQnMQWnduUeJ3bYTuX1jTGLKyckJbGWAiOz2KuNnZGabqv65AgKZy4F/4qQ3v+BRJLCRZf0wTQT2bfjSfd+DM8IhIuK1p0NaSPlIrlFRdULvxZi4SfYspFhPDjbGJA8/qdnNQo+5i8TFjIj8AlgA3KKqJRbLc/3XfffqT2OcOSZfBCbMquoPwIZwdYD0kHYBPsB5xJUeWriUOmH7FU0dr3sxJp6SNQspHu0bY5KL79RsERkuIu+IyCHgG/dYFxH5p7s4XVREpDtOIDMyOJARkfNClvZ/xX3v6NFMp5AyUdVR1T04qdFpInJ2mDpK8fVk3gSOAu1FpNgMRRE5CScza0vIzuLR3IsxcRHrQCA4C+mex19MuvaNMckj4mBGRGqKyGtALnAJzuTVwJf2DiATeFdETvXbCXeF3xeBO1T16ZDT7XAWvQtYjDOi0cdjj6RhwHFKrs77JHAEZzXhokBDROoCvwa2A/NC6kwMajO4r22BC4AXVPWzwHFVPQA8jbMdQc+QtobifFYTQ45Hcy/GxEWyZiHFs31jTHLwMzLz/3D2JXoIZx2WovknqvoRcBGwGmcvooi5m1a+jLNA3i/cDSeLXhQPZFDV48AQnJGR50XkTHdzxz8DfYCxqvqfkDqfASOB9sAkEWngjiLNxNlzaaiqHgmpMxeYDdwhIjeISB0RuRCYhRP8jPS4nXtwHmnlisilIlJbRPoBY4FFOEFVue7FmHhJ1iykeLVvjEkefoKZ64BhqjpGVTe6IxFF3C/m0ZQclSjLEJxRnsbAtR6v9qEV3D2S2gG7cfZb2gn8Ehioqg96XURVp+Cs2Hsh8CnOvJgTgItVdXGYvg0Gfg+Mwnmk9iqwDMhU1R0e19iHs3LwPOBZnLVl/uq+slX1+1jcizHxUJX3WrJAxpiqTUJW3g9fUORboL6qHg069oOqVg/6e21gt6rWjXlPTTGZmZlqqdkmlvKfHsU3O7eXSHuO5eTaRG6/0/BHy7y2MaZyichqVc0MPe5nZOYwEDqvI1RLPNZEMcYkh2TPQipv+8aY5ORn0bxlwOMicp2q7g89KSLVcBbVeydWnTPh7du3j5ycHLKzs8nOtgW/TOxUlb2W/LZvjElceXl55OXlQdB83WB+gpnxOBs+fioic4F1ACJyA846KdcBTXDmjJg4S01NtS0MTNwkexZSNO13KrOUMaayBH5xnzJlitcei74WzcsHBuEEQMOBSTjpxv8E7sPZPXugqq4ud6+NMZUm2bOQom3fGJO8fC2ap6pzgDOBu4EXgP8D/o2T8XOmqv475j00xlSYZM9CKk/7xpjk5XsFYFX9UlX/qqr9VfUKVf21qv5NVXfFo4PGmIpRVfdailX7xpjE5TuYMcZUTcmchWRZTsb8tPmZAGyMqcKSNQvJspyMMTYyY4wBSNospHi2b4xJDjYyY4yJSHCWUHqalFhpN1z5aLKQEqF9Y0zysJEZY0yZEjkLKR7tG2OSS9hgRkRmisgPIpJRkR0ykQmsAOyuiGhM3CR7FpLf9o0xiScvL4+cnBwIswJw2I0mRWQb8P9UdZ7799Gq+kC8Omr8sY0mTazlPz2qxLFIAofgzR0L92pMs5Aqsv17XttbZnvGmMoVbqPJ0ubMNAReDPr7GKDMYCZ0J21jTHJK9iwkv+0bY5JXaXNmdgPnBf090qn/liJgTJJL9iykaNo3xiSv0kZmFgOLReT/gEOAisjTlB2s2L8KxiSxZM9Cirb9Wx4ps6gxJkGVFsz8CWcfpv7u3xW4IYI2LZgxJknFYnJtYFKtV8CRyO0bY5JX2MdMqrpTVS8D6gHN3cPNyng192jKGJMENCeudwAAIABJREFUkj0LKdZbIBhjkkeZi+ap6kHgoIh8qqrbyiovIp/GpGfGmAoVr72Q4pGFFO/2jTHJJWxqtklslpptYm3y76+NeSDwzc7tcctCinX7nZqf5Fn+rbVb6X//v5g7ZiBd25Q9+Fys/J1TyixvjIlcNKnZpTXWCGgLpAF7gPdVdXf5umiMqUzJmoUUz/bLFchEUN4YExu+tjMQkYYi8jywA3gZmAUsBL4QkTki0jAOfTQebAVgE2tlrYRbniykflf1Sbr2LZAxJnFEvQJwiYIi9YHlQEvga2AzTsp2XSADOAn4COigqraUZpzZYyYTawvHDYhrFlLwSr6J2H7wY6aYBTJZfyqzrjEmcuEeM/kZmbkXqAP0UNWGqnqJql6hqpcAjYCe7vl7Y9JjY0yFSvYspFi1byMyxiQfP8FMX2CQqi4KPaGO14EhwK9i1TljTMUKDQhine6c6O1bIGNMcvIzAfg04L0yyrzjljPGJKmqsteS3/YtkDEmefkZmdkHpJdRprlbzhiTxJI9Cyma9i2QMSZ5+Qlm3gKeEpE0r5PuBOEncfZ0MsYkqWTPQoq2fQtkjElefh4zPQCsBLaJyCJgEz9mM50DXI6zCWX7WHfSGFMxqtJeS37bt0DGmOQV8ciMqm4AsnECmKuBe4Bx7vuvgP1Ab1XdFId+GmPiLNmzkBIxy8kYUzF8b2cgIrWAq4B2OIvX7MUZsXlJVb+LeQ+NJ1tnxsRa/ZQ6pX6xB6/jEo+9kKpi+3sOfFtm28aYyIVbZ8b2ZkpSLVu21KysLLKzs8nOzq7s7pgqIJK9mZJpr6VEaP+WR54rs31jTNny8vLIy8tjypQpH6tqy9DzUe3NZCpfamoqubm5ld0NU4UkaxZSMrdvjIlM4Bf3KVOmeGZMWzBjjIlIcJZQepqEnVQbWj6aLKSq0n7vMmsZY2LB10aT8SYiJ4vIcyKiIjK0lHKFbhmv18el1OshIm+LyAER2SMiL4tI21LKVxORkSKyXkQOi8gOEZni7hoerk49EZkgIp+KyBER2Swi94lIjVLqZIjIXBHZLSKHRGSFiFwbrrwxFS30iz3cpNpw5X+q7RtjKkbCBDMicjXwAXBFhFW2Ah96vLaEaX8Y8CqwDjgDOB/4DlgmIl3DXOMZ4FHgbzgbafYGOgOrRKSxxzXq4ayS3B8YCNQH/gjcDbwoItU96rQG3gcaAh2BU3F2Ip8jIveU8RkYE3fJnoVUme0bYypGQgQzInIT8HdgGPBihNW6q+rZHq8rPdo/DZiMk3V1u6p+o6rbgUHAHmCGm6UVXOdqYDAwUVWfUdVvVbUAuA5oCjzm0adxQCsgR1XfVdXDqjofGIOzEeeIkGtUA6bj/Bx+raofq+p+VX0AeBl4UERaRfh5GBNzyb7XUmW3b4ypGAkRzAD/Bc5T1YVxav8m4ATgGQ1K31LVQ8BzwOnANSF17nTfpwYfVNXVwH+Aa0Sk6FcvEUkBbgS+wBkBCjYN0KA2A7oBrYGXVfWrkHNTcX4+t5d9e8bEXjR7Id3z+IsxDwSSvX1jTPxFHMyIyHER+UFE/hXrTrijGHti3W6QwDy8fI9z+SFlAlszXAzsDbMIYD7Oase9go51wwmYVmhIvruqfg1sBlqISEa0/TKmoiR7llCitW+MiS+/IzOPAL+PR0eiMEJE1orIQXdC73IRucl9dFPEnadyrvvXQo92AsfODzp2Hk6w4lU+XJ3zQ86Vq46q7gSOAKeKyElh2jQm5qrKXkuJ0r4xJv78BDMHgAdU9fN4dcanTkAOzsTcs4GlwOPAgpCJtvWBmoCqqld++l73/ZSgY4HJveFGiyqqTqC/p4Q5b0xMJUuWULK0b4ypGH6CmRVARlmFROTN6LsTsWHAFaq6UlWPqurnqvoHnMnD2cCtQWVru+/HwrQV2IKhTpLUAWDXrl1kZmYWvWwBPVNeyZQllCztG2PKLzc3t+i7DjjZq4yfRfP+BEwUkevdTKBwuvhoMyqqGi5gysXZN2owMMk9dth9D7fOS033PXgTlUSuA/z/9s483I6qytvvAoEwJQQIQyMSpogDEiAiQVsScMIQkFbEBoWAcrsRRGmDKEITEPXDgIAI2olhUhGMA3qZWhsIiMQgYAhzhBghSBDIQGSWrO+PXYdU6ladc+rcM1Sd83ufp55Kau/9q7XPvvfUurv22gtGjBiBcjOJZtKqKKFW5EIqi/6xU2tWFULUoK+vj76+PgDM7Jm0OnmcmWMJD90FZnYH8DirHsZFobLHzE6xa0sJMxxrm9mwlFdNG0Xnp2LXFkfn4Rn3aWabt1VpMyyljRAtoZVRQq3IhVQGfSFEe8jjzEyK/XuvKvU6mblyQBiCu79mZg8Ao4FtgbmJKiOj872xa/cT+jGSdNLaVP69bc42+6a1iTblGwI8GUVDCdFSyhglVHZ9IURzyBvNtG2NY7umWpeCmU02s8syirePzg8nrl8XnfdMaTM2UYcoTHw2sJGZ7ZTRxll9P5mbgJeBPcxstW+9KBppFPCou89v1C4hWknZooTKri+EaB55nJmH3f2vNY6FhKiiVrIB8MFok7okx0TnHyWuf58Q5nxk3NEws/WBjwOLgJ8l2pwXnY+KX4xyOb0D+IW7v77Cz91XADMI6Qj2S2hNIswanZe4fiNhdmb/lHxPRwErSd9pWIimU6YoobLrCyGaS93OjLu/pc564xs3pz5TCKHKvzSzMWa2rpltZWbnEDaY+19CaoS4TY8DxwN7AOeb2cZRioMfEkK7J7n7S4k2M4EfA18wsyPNbD0z25XgKC2K9JKcDDwATDOz90S2HQRMAX5DcKri91gJHBH16admtn2UqPJUYH9girvPa/SDEiIPZYoSKrO+EKL5NJTOIHqwv8vMDoj+P2QwRpjZyErWa8LDHeCS6NrCRPVvAZ8AngOuAJYADxLW8RwHTHD3AaHO7j6dsGPvrsBjhHUxQ4C93P3GDNMOJ2wSODm6z/XA7cAYd/9byj2WR3b8DPgJYW+Zb0XHRHf/Z0qbPwHvBJ4h5I5aDBwAHOruX8uwS4iWUPZcSEXXF0K0BkvsvF+9cliUOpWQx6iyEd0bzOyDhNmQY6o4BqKJjBkzxhWaLZrJ7BmTX//3ksWLWhYl1Ev6Yz99ds37CiHqx8zucvcxyet5cjNtTtg47zDCrMifWBU9dCfh9U5/9CpGCFFiyh4lVDR9IURryfOa6TRCtM6+7r553DNy92fd/XOE1ylfabKNIoXly5fT19dHf39/p00RXUbZo4SKpi+EGDz9/f2VjfOGpZXX/ZopWrtyiLvPiV17zd3XjP1/S+AP7r7NYIwWtdFrJtFsZs+YnPpgX7J40es74W68xRtXa9OMNSndrK/XTEI0l0G/ZiJEEN1do84KIBliLIQoAWWPEiqivhCiPeSZmVkEfMTd74xdS87M7AvMcPeRzTZUrI5mZkSzGb7helUf7PEZiGbnQupW/aUrBqRVE0IMgqyZmTzpDG4ArjCzo939lpQb7ABcCFzbuJlCiE7RDbmQiqYvhGgPeZyZKYTXTDeZ2QLgHgAzu5yQd2gs8DSgvVGEKCFljBIqu74QojnU7cy4+yIz25uwa+5urMqD9MnofAdwuLsvTmsvhCg38SiekRtZ5qLXZP1GooS6RX9CzVZCiGaQZ2YGd38QGGNm7ySkBhhG2OV2jrvf1QL7hBAFIO3BXln02qoooW7QF0K0h4bSGbj7H939Qnf/hrtfJEdGiO6liFFCZdEXQrSHXDMzFcxsL2A0YWZmOfAnd5/dTMOEEJ0nT66iVkQJlV1fCNEecjkzZvZeYDqwQ0rZw8DR7v77JtkmqlDZAXjixIlMnDix0+aILqTIUUJl0hdCDJ7+/v7KjvepOwDX7cyY2Z6E/EtrE/IyPQw8D6wP7ESYqfmtmY1z9zsGabeowbBhw5g2bVqnzRBdStmjhIqmL4QYHJU/3KdPn748rTzPzMw3CA7Mwe7+52ShmY0CfhrVe18jxgohOk8ZooTKpC+EaD15FgDvQQi9HuDIALj7fOAIYM9mGCaEaD+DXfyatai2V/WFEO0hjzPzCvBgjToPAP9s3BwhRKcoU5RQWfSFEO0hjzNzKzAgH0KCMcAfGzdHCNEpWhUltGTxoqY5GmXTF0K0hzxrZk4EZpjZKe5+a7LQzMYB3wb6mmSbECKFc387v2laj9wzh8vO/DxHnHJ+08ORyx6F1Ax9IUR7yHRmzOymlMvDgZvN7O/A48A/gA2ArYHNgMeAs4B9m2+qEAJgz8eyo9jyziCs/dTjrPnqC7z802MYeeD+NesXLUqo7PpCiOZQbWZmXJWyzaMjyTbAmwZjkBCiMYoWxSN9IUS7qLpmxt3XyHsAShUrRAspQxSP9IUQ7aSaM3NLg5qNthM5qOwAHO2IKHqIMkTxSF8I0Uz6+/vp6+uDjB2Azd2bekMze5O7P9ZUUTGAMWPG+J133tlpM0QHuPbrn2hpLqElixdJv0n6Yz99ds17CiHqx8zucvcBkdUNJZqswV+ANVugK4SgHFE80hdCtJO8iSaHAO8HRgHrofUxQnSEskfx9Jq+EKK15Ek0uTvQT4hiqvbb29z3VkKI1Sh7FE+v6QshWk+eHYC/C7wMfAk4EBifcuzTbAOFEKtT5iieXtMXQrSHPM7MaOAj7n6Ou/e7+y0pxyzCxnlCiBZR1iieXtQXQrSHuqOZzOxRYDd3X95ak0Q9KJqpd5k9Y3Lq9SJF8Ug/6C9d8UJNbSFE/TQjmmkqcDhwQY0bLXD37XLaJ4QYJEWN4ullfSFEe6jbmXH375vZJDObBvweeBJ4KaXqNs0yTgiRj6JF8UhfCNEO8kQzDQM+BuwHfLplFom6qOwAPHHiRCZOVHZeUbwoHunfwISarYQQ9dDf31/Z8X5wOwCb2eXAIcANwJ+BFWnVgFPdXZvmtRitmeld0tbMpD1442s4kg/sZix+lX5t/Ql77ZJaf9bcBRx8+hXMPO1Qxo2u/VZ+tfonTK9ZX4huJWvNTJ5opg8DH3f3A919srufnnJMYRAb6ZnZpmZ2lZm5mU2qUXeUmc00s2fM7Hkzm2Nmh9Ro8yEzu8XMVpjZUjO7Jto/J6v+GmZ2vJndZ2YvmtnfzGy6mW1Wpc1QMzvXzB4zs5fMbL6ZnWJmazWzL0JUKGIUj/TJnPEZlCNTR30hepE8zowB/1erUpQ5Ozdm9lHgfuADddTdBbgTGAHsCWwJXAtcaWYnZ7Q5CrgeuIewrmdn4BXgdjMbl3GrS4CzgXOATYAJwL8CfzSzLVLuMZSwnuhg4FBgOHAS8GXgV2Y2YMaqkb4IUaHWgzf5wG7Wg1r69eknkSMjRGvI85rpf4Cfu/tvatS72N2PymWE2THAqcDRBEfgCOBId780pe4awN3ADsB27v73WFk/YQZpF3e/L3Z9K+ARYB6wp0edNrP1gUcJTs2O7v5yrM1HgZ8BU939S7HruxOcj5nu/vGEbRcAxwET3P262PUvEpyiY939osH0pYJeM/UulddMeR6kSxYvalkUj/Sz9cdut8nr/26aIzP+KzXbCtGtNOM1038BR5jZMWa2jZmtnVHviAbsuxd4m7tfW0fdfYBdgGviD/+Iiwl9+nzi+jHAEOASj3lv7v48cBWwNWFxc5wTYprE2txFcIo+ZmavzyOb2YbAZwhRXtcntC4lpHk4IXG9kb4IUfoonl7T14yMEK0ljzPzHPAJQlqDBcCLZvZa8mjECHe/zd2X1lm9EiAwO6VsdqJOQ23MbDiwF7DM3R/KaGOEmZMK+xAcpjmemO5y92eB+cAOZjZqkH0RPc5gomwOOnD/mlvvS7+5+nJkhGg9edfM3Frj+F2zDUxh5+i8MFng7osJe99saWabAETrVN6a1SZ2befYtbcR+ptWP6tNpl2NtEnrixDAoNZ0dDpXUa/py5ERoj3k2QEYdx9fq46ZrWzcnLqoLLzNmslZTpgh2Rx4lrAId23AM1IxLIvOm+e4R7vaJPsiRFOjeOJhya2IEpJ+qL/O0GHMXrDqVzgtLLxa/Thja34LC9F75JmZqXfV2ZGNGJKDdaPzqxnlr0Tn9RqsX/Q2oscpQxSP9FurL4RYnTzpDM6qs95ljZtTFy9G56x9WyoLkysZ3vLWL3obAJ5++mnGjFm1oLuvr4++vr4MGdFLFDlXkfQHry9ErzFt2jSmTZtW+e+maXVyvWaqBzN7zt2HNls3xmLCmpbhGeWVrY6fis5LCTMca5vZsJRXTRsl6lfuQZV7NLNNnr68zogRI1BotkhStCge6Tdff2zNWkJ0F/E/1s3smbQ6eXIzvbeeasD69Wo2yL3AvsC2A24eNrIbAjwZRRDh7q+Z2QPA6KjN3ESzkTHdCvcTQqlHkk5am8q/B9hVo03dfRGiGmXIVST9wesfO7WmtBA9R541M7OAm2scNzXZvjQqm9HtmVI2NlGnoTZRmPhsYCMz2ymjjbP6fjI3AS8De5jZan9iRdFIo4BH3X3+IPsiepwyRPFIv3X6QoiB5E09cEbKcTZwJeF1zk3RtVZyI2FGY/+UHElHASuB7ySuf58Q5nxk3NGIdgD+OLCIsNtvnPNimsTa7A68A/iFuz9eue7uK4AZhHQE+yW0JhFmrc5LXG+kL6LHKXOuIum3Xl+IXiSXM5ORXPIkdz8MeCMhfPj3LbF0lQ0rCbsMO/BTM9s+Su54KrA/MMXd5yXaPA4cD+wBnG9mG0cpDn5IyLk0yd1fSrSZCfwY+IKZHWlm65nZrsCPCM7P8SnmnQw8AEwzs/eY2bpmdhAwBfgNwakaVF+EKHKUjfQ7qy9Er5InN9MmtdZumNm2wFXuvkcuI8xGAn/JKP6ru49MabMTcCYwnhDifD/wbXf/SZX77EdwOHYF/gncDvy3u6eupI1yJ30O6AO2J+wVcy1wsrsPWJQbtRkGnA58FNgMeAy4HDjL3V/JaJO7L8rN1LvMnjG5tLmKpD94/bGfPrvmvYToVrJyM+UJza5nEepy4O15DIu0FxJew+Rp8xAD8ynVanM9A/MmVau/Ejg/Ouptsxz4QnTU2yZ3X0RvU8QoG+l3Tl+IXqdpodnRWpQTyd7NVgjRBIoaZSP9zugLIXKsmTGzm6occ4BngC8RMkQLIVpEUaNspN9+fSFEIM8C4HFVjrcDjwNfBk5tlnEim+XLl9PX10d/f3+nTRFtpqxRNtJvrr4QvUR/f39l47xhaeV5FgCvdPe8odyiRWgBcO8ye8bk1Ovx5IULl3lTo2ykXxz9k29YllouRC8w6AXAQKtzLgkhBkFRcwlJv7n6QoiB1D3T4u51ZcM2s8MbN0cIMRiKFmUj/ebrCyEG0orXRpe0QFMIUYN4FMxBB+5fc43FYKJspN85fSHEQHI5M2a2u5l928z6zezGtMimVhkqhMimaFE20m+dvhBiIHlCsz8BzCFsBjeBsFvtuJRDCNFGihZlI/326AshVpFnZuY04FbgXcBQd18j7SDnTr5CiMYpey4h6Q9OXwgRyBPNtC3wIXf/a416inoSog0ULcpG+p3RF0Lkm5l5AlhRq1K9UU9icGjTvN6miFE20u+cvhDdTjM3zfsvYC13P6tGvQXuvl1eQ0U+tGle73LhiYc0/KqilbmEpN8efWXNFr1M1qZ5eWZm7gbGmdnVZnakmX3QzN6bPIBtmma1EGIARY2ykX779YUQgTzOzE3AB4ADgB8A1wE3pxxCiBZS9Cgb6bdHXwixily5mYDTa1UDTnX3NQdrmKiOXjP1Llm5meIUKZeQ9Jurr9dMopfJes3U9ESTSkjZHuTM9C61nJk8f+EvWbyopVE20m++vpwZ0cs0Y83M2DrrbZtDUwjRRIoWZSP95usLIQaSJ9HknDrr1dqHRgjRAoqaS0j6zdUXQgwkz6Z5QogCsGTxogFhvc1YnFpZlJoWNiz94uhz8zdr6s+au4CDT7+CmacdyrjRtXfKmDV3AeNOmF6znhBFRWtbhCgZRY+ykX5n9RtxZA4+/Yqa9YQoMnJmSop2AO5dypxLSPqt1W/UkZl52qE16wrRSZq2A7AoFopm6l1mz5hcyCgb6ZdbX1FSogw0I5pJCFEQihhlI/3u1Rei6GgBsBAlIx4F08pcQtLvLX0hyoxmZoQoGWXOJST94uoLUWbkzAhRMsoaZSP9YusLUWa0ALikaAFw75KVzqCouYSkXw59LQAWZWDQuZlEsZAz07tUy83UjVE20m+PvpwZUQYUzSRED1C0KBjpl0tfiLKiaCYhuoRujbKRfnv0hSgzmpkpKdoBWMTp5igb6bdHX4giox2AuxStmeldkmtmqj244otGK3/BN3MLful3j/7SFS/UrCtEp9GaGSG6kLLnEpJ+cfSFKDOlnZkxs0uBI6pU2drdV5t/NbNRwNeB8cC6wH3At939qir3+RDwFWA34J/A74HT3P2ujPprAMcBfcD2wFLgWuCr7v73jDZDgdOBjwKbAY8BlwNnufuraW00M9O7VGZmihIFI/3u0Fc0kygD3Tozsxh4OONYzQkws12AO4ERwJ7AlgQn40ozOzlN3MyOAq4H7gG2AXYGXgFuN7NxGTZdApwNnANsAkwA/hX4o5ltkXKPoQQH6WDgUGA4cBLwZeBXZrZm7Y9B9BpFi4KRfnfrC1F0yu7MfMXdd8o4nqpUimZLLiP09+Pu/oi7P+fuZwDXAF8zs7fHhc1sK+BC4A7g8+6+JJrp+RRhtuVyM1sn0eajwOHAee5+ibu/4O5/Ag4D3gR8J6UPXwfeDvS5+23u/qK7/xI4DdgP+I/Bf0yimxhMFMxBB+6fuWhU+tIXoqyU3Zmpl32AXYBrUl71XEz4HD6fuH4MMAS4xGPv4tz9eeAqYGvgY4k2J8Q0ibW5C5gHfMzMXo+jNLMNgc8ATxJmgOJcCnhMUwiAQa25KGOUjfQ7py9EWegVZ2ZCdJ6dUjY7UaehNmY2HNgLWObuD2W0MeDDsWv7EBymOXGHCcDdnwXmAztEa32EAAbmZsqi07l+pF9ufSHKRNmdmfFmdrOZPWNmL5rZg2b2zcixiLNzdF6YFHD3xcBLwJZmtglAtE7lrVltYtd2jl17G8FZSauf1SbTriptRI9TtCgY6XefvhBlo+w7AO8NfAH4LbAW8G/ABcDHzezdkaMCUFl4uzRDZzlhhmRz4FnCIty1AXf35Sn1l0XnzWPXat2jWW2EqEq9D67KA69VUTbSL6e+EGWkzDMz5wJj3f1qd3/e3Ze5+8XAV4HtgO/F6q4bnVPDnAkRSgDrNVi/nW0AePrppxkzZszrx7Rp0zIkRC9RtCgY6ZdLX4giMm3atNefdcCmaXVKOzPj7vdkFE0Hvg0cYGYbufsy4MWobK2MNmtH58oWmHnrt7MNACNGjED7zIg4Rcv1I/1y6c8692gOPv0KZp52KONGb1dTf9bcBbXrj/9KTR0hatHX11dJZYCZPZNWp8wzM6lE0UZPEfq2Y3S58ropuZamQiXXQyWceylhVsTMLC0PxEaJ+vXco1ltRI9ThigY6ZdPv+mOjBBtpOucmYjkfOq90XnbARXDRnZDgCejCCLc/TXggaw2wMiELsD9hFDqkcnKVdpk2lWljehxih4FI/1y6k85en/WGTqM2QuerXpceN1cDvrvH6fWv/b2e/jGWWdx7e33MHvBszVtFaJZlNKZMbO9zOzPGWUbEFICrAQeiS5fF533TGkyNlGHxP/rauPuSwnh1xuZ2U4ZbZzV95O5CXgZ2MPMVnPAosiqUcCj7j4/RU/0KEWOgpG+9KvNAAnRKkqZmylKJXAzsIe7/zFRNhmYCvS7+wHRtTWAuYSFwdvFN84zs37C3i+7uvu82PWtCfu8zAP2rOwDY2brE5ykfwI7uvtLsTYHAz8Fprr7l2LXdyekUvi5u6+20Z6ZXQh8Fpjg7tfFrn+RkBbhc+7+3eRnoNxMvcvsGZNLketH+tL/wR3/qKkrRB66LTdTxQO70swmmNmw6Pg0cAYhUeNnX6/svpKQlNKBn5rZ9mY21MxOBfYHpsQdmajN48DxwB7A+Wa2cZTi4IeEnEuT4o5M1GYm8GPgC2Z2pJmtZ2a7Aj8CFkV6SU4mvNKaZmbvMbN1zewgYArwG+D7DX9KomspWhSM9KWfpi9EuyirM3MrIfP1jcA3Cc7LYuCLhPxHuyYzZkc5kt4JPEPIt7QYOAA41N2/lnYTd59ONGsT3eN+wvqavdz9xgzbDgdOBCYDSwivlW4Hxrj731LusZywc/DPgJ8Q9pb5VnRMdHd9I4jVKHuuH+n3jr4Q7aKUr5mEXjP1MsM3XG+1B8uSxYsyw26bsSZC+tJvVH/sp8+u2UaIPHTbayYhepaiRcFIX/qN1Beimaw5ZcqUTtsgGmDq1KlT7rvvPgDe/OY3d9ga0U5ee3zOgGvrbjCUYZtsxj2/u4Fhm2zGg4uWN/VBJH3pN6K/9W4fqNlWiHro7+/nnHPO4e67735hypQpFyTL9ZqppOg1U+8ye8bkzLJuiYKRfnfo6zWTaDZ6zSRED9AtUTDS7059IVpFaXMzCSFWp2i5fqQvfSHahWZmhOgCipjrR/rSF6JdyJkRouR0axSM9LtDX4h2oAXAJUULgHuX+ALgeh4s8X1EFi7zpofbSl/6WWgBsGg2WQuA5cyUFDkzvUvFmenmKBjpd4f+lOnXMPO0Qxk3erua9WfNXcDBp19RX/3xX6mpJ7qTLGdGC4CFKCFFi1KRvvTT9H95xmHNd2SESEHOjBAlo2hRKtKXfpb+OkOHMXvBs3Xpn/mfE3n+hRV846yzauofO76m2aLH0ALgkrJ8+XL6+vro7+/vtCmizRQpSkX60u+Evug9+vv76evrAxiWVq41MyVFa2bKwbm/nd9Qu0fumcNlZ36eI045nx12eddqZWv/5tRBr4lISy7YzFw80pd+K/WPnXpVTX3RnWgBcJchZ6YcZKUeKHuUivSiNZX2AAAURElEQVSl30l9RUn1LnJmugw5M+UgzZnphigV6Uu/k/pyZnoX5WYSogB0S5SK9KVfRH3RuyiaSYg20U1RKtKXftH0RW+jmRkh2kC3RJFIX/pF1BdCa2ZKitbMlIPZMyZ3VRSJ9KVfBP2TTzrp9Wt5N9zLrK9dhUuBFgB3GXJmysGFJx7SVVEk0pd+EfQn7LUL0ERHBuTMlAQ5M12GnJlyMGz9IV0VRSJ96XerviKkyoGimboM7QBcDooS5SF96Uu/fn1RPLQDcJeimZlycO3XP9GyKI8z/3NiS6NIpC/9XtLXzEw50MyMEB2g01Ee0pe+9DUj0wvImRGixWR94TYrykP60pf+4PVFudFrppKi10zlIJ7OoBuiSKQv/W7VV/LKcqBopi5Dzkw5SOZmKmOUh/SlL/3G9LUOp/lozYwQBaDsUR7Sl770lSuqiCg3kxBtovLFWZRcNtKXvvRbqz+2pqpoFpqZEaINlD3KQ/rSl35+fdE+tGampGjNTDmolZupW3LlSF/60h+of+yHR9fUbyQlw7gTptes161oAXCXseOOO/r48eOZOHEiEydO7LQ5IoN6cjMVPcpD+tKXfrH0l654oaZ2t9Hf309/fz/Tp09/xN13TJbLmSkpmpkpB8M3XK+UURjSl770i6vfy2HkimYSogOUNQpD+tKXfnn1exFFMxUAMxsKnA58FNgMeAy4HDjL3V/tpG1icJQ1CkP60pd+cfX5+iearl/2V1eamekwkSPze+Bg4FBgOHAS8GXgV2a2ZgfNEy2mqFEY0pe+9HtLv+xozUyHMbMLgOOACe5+Xez6F4GzgWPd/aJkO62ZKQfJHYDjFDkKQ/rSl770B6vfirU9imYqIGa2IfB3YCmwlccGw8w2AZ4GHk1buS1nphxkOTNFjZKQvvSlL/1m6bfi1ZWcmQJiZgcCVwNXu/tBKeUPAW8G3uzu8+NlzXZmpk2bRl9fX9P0OkmR+pLmzOT5C+eK/lt48W8PdkUUxoff/XaOP2Rcae2v6F99yzw+svc7Smt/nLS+lMn+tL6U1f64/okX/JKpnzuotPZX9Nfacd+mfxcrmqmY7BydF2aUV67vnCxYvnx5XTfo769vF8pp06bVVS+PZqfq1duXevXy1K1Vr/KLfsj7d6/ri+FXf3i0riiG2+Y+upp+1hdVpV6FrCiJZL2k/XH9rLpJ/TvvX5Dd0Zj+Sd+9uq4v2tvmPlpXlEfcvmqfT1o/0vR/feu8qvbH9at9NnH9d21FXVEql107p64HUeW+tT6fZF+yPp+sfiT1a/U3rv/CS69UrVvRv+Kel+uK4vn1rfPqelDHbaz2+aT1ZTA//08t/ltV++P6m260QV3fD/13PVHo74dWfBcDw9IuypnpLFtE56UZ5cui8+YDCpYtS15KJecPSVM1O1WvXtrtzMR/0Z98trYzevdDj/O3p5fxjc8eyEEH7p+56A/gtnmP1vdFPm/ggz1NP14vzf7VHnQpddP0X/jHc5n2x+vvMuqNdX2RX33rvEz70/pc84s80Y9qn081+1d70GV8Nkn9NYZtVZf+Jf2z63P0Yj8Pg7E/rlfN/or+jX/I4ehV+Wzi9Xfd6U112f/8S6/U5+glfh6yPp+sn4dGf/6vnzWn7s9//SFrZ9aL17+kf3bhvx/qIed3+0ZpF/WaqYOY2QzgKOBkd/9mSvnlwKeAE9397ETZi8DK2KWngWdSbjMMqGcaZ9OM9mnUq9mpevX2pV69PHWL3pdm18tTt+h90e9K++7bCs1u+fmC7ulLs/qxKTAi+vca7r5usoL2meksL0bntTLKK+75gFVUaYMphBBC9CJ6zdRZFkfn4Rnllem0p9pgixBCCFFK5Mx0lnuj87YZ5SMT9YQQQgiRQM5MZ7kJeBnYw8xWW4oe7TMzirDPzPy0xoPFzIaa2blm9piZvWRm883sFDPLeu3VUczsUjPzKseA/b3NbJSZzTSzZ8zseTObY2aHtNnuTc3sqsjGSTXq5rbXzD5kZreY2QozW2pm15jZ7k3txKp71dUXM1tYZZwe6VRfLDDRzK6Mfu5fMbNlZnarmX2qSrtCjUsj/SjwmKxhZu83swvM7E9mtsTMnjOz+81sqpn9S0a7Qo1Jo30p6rhk3HNixbYqdTozLu6uo4MHcCHgwIcT178YXT+uRfcdSpjxWQS8B1gXOAj4B3AdsGanP5sUmy8FngQeyjg2T9TfBXgOmAXsEPX5v6PP9eQ22fxRwmvCpdF9J1Wpm9tewgJyB74DbAy8EfgFwUke18G+LAQezRin/+1UX4BTonv8FtgVWA94C/Cr6PrFZRiXBvtR1DHZNLrHw8C+wAaExZ5HR/d5Cnhj0cdkEH0p5Lik3HND4PHovp5Rp2Pj0vQO68j9AzIMuJ+BTsUK4H+BN7TovhdQ3Yn6bKc/mxSbL6XKAzRRdw1gLsE52yxR1g+8Bry9xfYeA/wNmBDZnukANGIvsBVhEfkcosjE6Pr6hPVYjwHrtLsvUf2FwMgc+m3pC3BmpLdB4vra0QPFgX2KPi55+1HwMak4AGNTys6Pyk4v+pg00pcij0vKfS8CZpPhzHR6XPSaqcO4+3JgL+BnwE8Ie8t8Kzomuvs/m31PC2kUPkOY5bg+UXwp4Yf1hGbft83sQ/gr4Rp3/3ui7GLCL97nW2zDvcDb3P3aOuo2Yu8xwBDgEo++AQDc/XngKmBr4GMN2p4kT18aoV19eQK4zN3/Eb/o7q8QZjkA3hcrKuq45O1HI7RrTJYD4wkPtCR/js7xvUWKOiaQvy+N0M7fewDM7N2EGZSjq1Tr6LjImSkA7r7c3b/g7lu7+zruvqO7fy36YmoF+xB+gObEf4AiW54F5gM7mNmoFt2/HUyIzrNTymYn6rQEd7/N3bM2REzSiL1t62POvjRCW/ri7t9z95MyildE5/j6tUKOSwP9aIR2jcmr7j7L3VemFO8ZnW8cpF1F7UsjtPW7zczWBqYDU939vibb1bS+yJnpTRpOo1AAxpvZzdHishfN7EEz+6aZJcPbM/vo7ouBl4AtLSy0LgK57DWzNYG3ZrWhGGP4H2Y218z+ES3s+4OZHWNmq33vFKgvFef91ti1Mo5LWj8qFH5MzGyImb3ZzL4FHEJ4LfPrWJXSjEkdfalQ5HE5heArnFmjXkfHRc5Mb9JwGoUCsDfh3fM2wJbAVOB44E4z2yJWr1YfK7tNFqWPee0dTlgf4dGryiRFGMOxQB+wCbAT4eF6EXB19EVWoeN9MbONgQ8CfwJuiBWValyq9KNCocfEzD5EWEPxEHAYcDhwRqJaKcakzr5UKOS4mNlbgS8BR7v7yzWqd3Rc5Mz0JpXdg1/NKK+83lqvDbbk4VzCwrqr3f15d1/m7hcDXwW2A74Xq1u2Pua1t+j9Owr4gLvf4e4vu/sT7v4lQrTNROC4WN0i9OVbhLVihydevZZtXLL6ASUYE3e/AVgT2B44D5gB3JCYQS3FmNTZFyjouESzQj8ALnX339XRpKPjImemN2k4jUIncfd73P3JlKLphC/wA8yssriubH3Ma2+h++fuN2Ws+aqk0T08dq2jfTGzw4BJwGEpawJKMy41+lGaMXH3le6+wN2nAicB7yfMxjZqW5H7UuRxOZYwA561NitJR8dFzkxv0lVpFKKV708Rfp53jC7X6mMljXxR+pjX3qWEv1zMzIal1C/qGFbS7e4Uu9axvpjZ+wl/ffa5+y9SqpRiXOroRzUKNSYJZkTnQ81s/ejfpRiTFNL6Uo2OjYuZbQ18nbDPWb3JMTs6LnJmepNuTKOQjNzI7GO0tmYI8GQUvVUEctnr7q8BD2S1obhjOCDCplN9MbP3AVcDx0avK9Mo/LjU2Y+qEskLRfn5cvcXgKcJNm6fuGdhxySNjL5Uo5Pjsi9hk7xfJHclft24VddmJe7ZkXGRM9ObdDSNQiOY2V5m9ueMsg2AzYCVQGX77+ui854pTcYm6hSBRuwtZB/NbLKZXZZRXPkSfzhxva19MbN9CQ7A8XEHwMzelth6vdDjUm8/ijwmFlKopM4mRWHBG0f/fW4QdhWyL0UdF3e/1N0t7YjVqVwbNwi7mtcXb/IugTrKcdChNAqDsHdcZNc7U8omR2W/jl1bA5hH9d0o39FG+y+l9g7AuewlbCiVtXvmk4Stx4d0oC9TCFPOG6aUXRO1/a9O9YWwz9I/gM+klE0CZpVhXHL2o7BjEtn2NLBRRj8cuL8kY5K3L4Udlyp9rLYDcMfGpSWd1VH8gw6lURiEvXtHv0SPEjZRGhYdnyYsEPsrA3Oe7Br1Zxbhr5yhwKmRzqlttv9SaqcAyG0vYUdOZ1Vek60IeU1eAfbtRF+A06Ly/wPGRD9bWwHnRNdvANbqRF8Iu7O+EH1RXplyzCHmBBR1XPL2o+BjUrHtNuBfCa83tiTsDvsc4eH47qKPSSN9KfK4VOljqjPT6XFpWYd1FP8gOAPnEbzflwnbbZ8KrN1p21JsNcLszDSC97+c4NE/APw/YOOMdjsRUkU8S/jy/yPw722yeWTlFz/lWNgse4H9gN9FX5TLCNOyYzrVl+gL+ZDoC2l+NE7PEXb0PJYqSUxb3RdWOWLVjllFH5e8/Sj4mMRteyi6z4uRnd8DtivL70revhR5XBL3mlTl52xcEcbFIiEhhBBCiFKiBcBCCCGEKDVyZoQQQghRauTMCCGEEKLUyJkRQgghRKmRMyOEEEKIUiNnRgghhBClRs6MEEIIIUqNnBkhhBBClBo5M0IIUQUzG5fMHGxm+2fUHW5mXzWz35vZ02b2qpktNbO7zOx/zOxjZrZ+g3aMTLHDzWxcSt0piTqzouvHpbQf2Yg9QhQJOTNCCFEfl/mqTMHXJAvNbD9gAfAR4FuEbd03BN4F/JCQ+2wmcGcjN3f3hR6yFp8cXfpjZMuslLpTgBHAq8BbPMps7O7f9VXZj29pxA4hioicGSGEGCRmti8hM/CdhESCv3L3Z939JXef7+7nAfsScs+sNcjb/RBYCbzTzN5Spd6/A3Pd/aFB3k+IwiNnRgghBoGZrQNcHv33aHd/Ja2eu99LSBA5KNx9EXBj9N8jqlT9VMwuIboaOTNCiLZhZuOjdRpnm9luZna1mS0xs+Vm9ksz2yKq91Yzu8LM/h6VXWNmb+q0/Rn8O/AvwK3uvrBG3YuA76QVmNnhZvYHM3vezFZE624OydC5LDp/0swGfI+b2U7AaODKunogRMmRMyOEaCe7RedRwG3Aa8AM4DHCWpOLzWwicAewAeGhPR+YQHFnGT4Yne+oVdHdH3T3Ac6MmX2X0NebgDcCI4GbgSvN7JQUqV8CK4CtCK+vkhwOXOfuz9TTASHKzhs6bYAQoqeoODN7AHu6+zwAMzuD4NB8ANgVeL+7z47K1gYeAd5rZkPc/aX2m12VUdF5USONI+ftWOB37n5yrOgUM3svMMXMfhZf++LuL5jZTOAowqum38b0DDgMOKERe4QoI5qZEUK0k4ozM6niyAC4+wpgIbAmcGLFkYnKXgEeBgx4PazZzL5uZjdXu5mZnWVmv61WpwkMjc4vNtj+mOj8g5SyKwmfyadSyiqvmg4ysw1j18cRZrUGRFwJ0a3ImRFCtIVof5VRwF/c/YaUKtsAS4CrMspWuPuzsWujgbk1bltPncHyXHReN63QzD6RsrfLpFiVPaJzmp2PR+cxKWW/I4SCrwd8LHb9U8BVWQuRhehG5MwIIdrFLoTvnAEzJdHGbcOBWe7+aqJsA2B7Bj7sRwN/quOeteoMlvnROXWBsrtfGdvb5bKUKsOi8z1Jpwf4dVS2eYqus2od0REAZrYuwbEp6voiIVqCnBkhRLuovGJK2zRu9ypluxK+q+6uXDCzEYQIotfM7MYoAmiume0Rq7MFwQmYG/2/38yuipXvYWYvNLojb4zKLNPYBtsvi847xjblSx6jM9peDjhhPdFIwsZ8i939Dw3aIkQpkTMjhGgXFWfmrpSy3auU7Rqd70659kXgjEh7ETDTzN4Qq/MiYb0NwBOE6B8A3P0OwiZ276u/C6lcGWm/28ze3ED7OdF5ZFqhme1pZu9IK3P3vxBeNxnh9ZL2lhE9iZwZIUS72A14BbgvpazizNydUrZbStlowlb9/+but7j7w8CXCK96to/VudfdX4v+/wQh7DnO84Rt/xvG3V8mhEKvBH4QverJYs2UaxdF50nJAjPbCphF6EsWlVdX/0EI0/5RdYuF6D7kzAghWk60S+5bCc5F2sLU3YC/ZuyLshthhuXB2LVdgV8kNql7ITpXHIbk4t8ngH+JQpcxsx0JC4t/l683A3H3m4ADgJ2BOVFCyU3N7A1mtoWZHWBmPyeETP8d+HOs7XXAecChUfTVdma2npntDVxPyKH0kyq3n0no+1bA7XVs3CdE1yFnRgjRDt5OyEk04DWSmW0DbJpRtg7wFmBebIYFgqOSnMUZQ3ht9EisTtKZWQsYETk05wH90azOoImcku0IzsVkwsLglwivub5BcMgOA0a6++8TbU+Iyt4NzAMWE3YKvhz4SHJRdKLtCsImeqBXTKJH0aZ5QoiW4+53EdZ1pJX9tUrZyyQSM5rZesCOxF7ZRM7JF4AfufsrUZ0dWD2S6Yno/EbCJnVvA97ZSH+ycPclwNeiI2/bn1B9BqZa208Cn2ykrRDdgJwZIUTZeAchgufwaNO8Z4AphPUyH4nq7BKd58XaVZyZMwmvg/Z296dbbq0QouXoNZMQomyMBh4Fvgr8lOCwrAu8K7bmZhfgz+5eWUeDuy8lrC3ZEXivuy/Ied8jYnvA7D/YTnQCMzsutofN3p22R4hmYWHfJSGEEEKIcqKZGSGEEEKUGjkzQgghhCg1cmaEEEIIUWrkzAghhBCi1MiZEUIIIUSpkTMjhBBCiFIjZ0YIIYQQpUbOjBBCCCFKjZwZIYQQQpSa/w/5DsPO41NWrAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "gs = gridspec.GridSpec(1, 1) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ax0.minorticks_on()\n",
    "\n",
    "_,_,_=plt.hist(X0_test_S[:,0]*1000,bins=np.linspace(0,400,20),alpha=0.5,label=\"$m_t = 172.5$ GeV\",hatch='\\\\')\n",
    "_,_,_=plt.hist(X1_test_S[:,0]*1000,bins=np.linspace(0,400,20),alpha=0.5,label=\"$m_t = 175.0$ GeV\",hatch='//')\n",
    "plt.xlabel(r\"$m_{bl\\nu}$ [GeV]\",fontsize=20)\n",
    "plt.legend(frameon=False,fontsize=20,handlelength=0.7)\n",
    "plt.ylabel(\"number of events\",fontsize=20)\n",
    "\n",
    "plt.title(r\"$Top$ $Quark$ $Mass$\",loc=\"right\",fontsize=20)\n",
    "plt.savefig(\"ensembleLearnPlots/Top_Features.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top = 20\n",
    "\n",
    "X0_test_S = preprocess_data(test_dataset_0['generator'])\n",
    "X1_test_S = preprocess_data(test_dataset_1['generator'])\n",
    "\n",
    "X0_test_S = X0_test_S[0:len(X0_test_S) - len(X0_test_S) % n_top]\n",
    "X1_test_S = X1_test_S[0:len(X1_test_S) - len(X1_test_S) % n_top]\n",
    "\n",
    "X_1D_top = np.concatenate([X0_test_S,X1_test_S])\n",
    "Y_1D_top = np.concatenate([np.ones(len(X0_test_S)),np.zeros(len(X1_test_S))])\n",
    "    \n",
    "X_nD_top = np.reshape(X_1D_top,[int(len(X_1D_top)/n_top),4*n_top])\n",
    "Y_nD_top = np.concatenate([np.ones(int(len(X0_test_S)/n_top)),np.zeros(int(len(X1_test_S)/n_top))])\n",
    "\n",
    "scaler_top = preprocessing.StandardScaler().fit(X_nD_top)\n",
    "X_nD_top = scaler_top.transform(X_nD_top)\n",
    "\n",
    "scaler_1D_top = preprocessing.StandardScaler().fit(X_1D_top)\n",
    "X_1D_top = scaler_1D_top.transform(X_1D_top)\n",
    "\n",
    "X_1D_top_train, X_1D_top_val, Y_1D_top_train, Y_1D_top_val = train_test_split(X_1D_top, Y_1D_top, test_size=0.5)\n",
    "X_nD_top_train, X_nD_top_val, Y_nD_top_train, Y_nD_top_val = train_test_split(X_nD_top, Y_nD_top, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/20\n",
      "1452070/1452070 [==============================] - 2s 1us/step - loss: 0.6936 - acc: 0.5084 - val_loss: 0.6930 - val_acc: 0.5119\n",
      "Epoch 2/20\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6927 - acc: 0.5147 - val_loss: 0.6928 - val_acc: 0.5144\n",
      "Epoch 3/20\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6925 - acc: 0.5167 - val_loss: 0.6925 - val_acc: 0.5173\n",
      "Epoch 4/20\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6923 - acc: 0.5185 - val_loss: 0.6924 - val_acc: 0.5169\n",
      "Epoch 5/20\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6922 - acc: 0.5183 - val_loss: 0.6923 - val_acc: 0.5181\n",
      "Epoch 6/20\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6922 - acc: 0.5193 - val_loss: 0.6922 - val_acc: 0.5185\n",
      "Epoch 7/20\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6921 - acc: 0.5199 - val_loss: 0.6922 - val_acc: 0.5195\n",
      "Epoch 8/20\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6920 - acc: 0.5208 - val_loss: 0.6921 - val_acc: 0.5197\n",
      "Epoch 9/20\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6919 - acc: 0.5215 - val_loss: 0.6920 - val_acc: 0.5203\n",
      "Epoch 10/20\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6919 - acc: 0.5218 - val_loss: 0.6919 - val_acc: 0.5211\n",
      "Epoch 11/20\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6917 - acc: 0.5227 - val_loss: 0.6919 - val_acc: 0.5229\n",
      "Epoch 12/20\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6917 - acc: 0.5236 - val_loss: 0.6918 - val_acc: 0.5235\n",
      "Epoch 13/20\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6916 - acc: 0.5238 - val_loss: 0.6917 - val_acc: 0.5234\n",
      "Epoch 14/20\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6915 - acc: 0.5248 - val_loss: 0.6916 - val_acc: 0.5234\n",
      "Epoch 15/20\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6914 - acc: 0.5247 - val_loss: 0.6915 - val_acc: 0.5245\n",
      "Epoch 16/20\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6913 - acc: 0.5259 - val_loss: 0.6915 - val_acc: 0.5245\n",
      "Epoch 17/20\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6912 - acc: 0.5261 - val_loss: 0.6914 - val_acc: 0.5248\n",
      "Epoch 18/20\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6911 - acc: 0.5268 - val_loss: 0.6913 - val_acc: 0.5262\n",
      "Epoch 19/20\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6910 - acc: 0.5270 - val_loss: 0.6912 - val_acc: 0.5257\n",
      "Epoch 20/20\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6910 - acc: 0.5276 - val_loss: 0.6911 - val_acc: 0.5268\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/20\n",
      "72603/72603 [==============================] - 1s 10us/step - loss: 0.7036 - acc: 0.5103 - val_loss: 0.6984 - val_acc: 0.5130\n",
      "Epoch 2/20\n",
      "72603/72603 [==============================] - 0s 2us/step - loss: 0.6939 - acc: 0.5272 - val_loss: 0.6963 - val_acc: 0.5182\n",
      "Epoch 3/20\n",
      "72603/72603 [==============================] - 0s 2us/step - loss: 0.6923 - acc: 0.5322 - val_loss: 0.6964 - val_acc: 0.5171\n",
      "Epoch 4/20\n",
      "72603/72603 [==============================] - 0s 2us/step - loss: 0.6920 - acc: 0.5317 - val_loss: 0.6970 - val_acc: 0.5152\n",
      "Epoch 5/20\n",
      "72603/72603 [==============================] - 0s 2us/step - loss: 0.6927 - acc: 0.5296 - val_loss: 0.6979 - val_acc: 0.5148\n",
      "Epoch 6/20\n",
      "72603/72603 [==============================] - 0s 2us/step - loss: 0.6932 - acc: 0.5305 - val_loss: 0.6977 - val_acc: 0.5156\n",
      "Epoch 7/20\n",
      "72603/72603 [==============================] - 0s 2us/step - loss: 0.6979 - acc: 0.5222 - val_loss: 0.6979 - val_acc: 0.5173\n",
      "Epoch 8/20\n",
      "72603/72603 [==============================] - 0s 2us/step - loss: 0.6946 - acc: 0.5323 - val_loss: 0.7016 - val_acc: 0.5167\n",
      "Epoch 9/20\n",
      "72603/72603 [==============================] - 0s 2us/step - loss: 0.6935 - acc: 0.5344 - val_loss: 0.6984 - val_acc: 0.5185\n",
      "Epoch 10/20\n",
      "72603/72603 [==============================] - 0s 2us/step - loss: 0.6928 - acc: 0.5331 - val_loss: 0.6991 - val_acc: 0.5191\n",
      "Epoch 11/20\n",
      "72603/72603 [==============================] - 0s 2us/step - loss: 0.6932 - acc: 0.5312 - val_loss: 0.7004 - val_acc: 0.5162\n",
      "Epoch 12/20\n",
      "72603/72603 [==============================] - 0s 2us/step - loss: 0.6974 - acc: 0.5253 - val_loss: 0.7012 - val_acc: 0.5161\n",
      "Epoch 13/20\n",
      "72603/72603 [==============================] - 0s 2us/step - loss: 0.6959 - acc: 0.5304 - val_loss: 0.7067 - val_acc: 0.5172\n",
      "Epoch 14/20\n",
      "72603/72603 [==============================] - 0s 2us/step - loss: 0.6978 - acc: 0.5306 - val_loss: 0.7004 - val_acc: 0.5163\n",
      "Epoch 15/20\n",
      "72603/72603 [==============================] - 0s 2us/step - loss: 0.6929 - acc: 0.5311 - val_loss: 0.7006 - val_acc: 0.5118\n",
      "Epoch 16/20\n",
      "72603/72603 [==============================] - 0s 2us/step - loss: 0.6923 - acc: 0.5317 - val_loss: 0.6983 - val_acc: 0.5182\n",
      "Epoch 17/20\n",
      "72603/72603 [==============================] - 0s 2us/step - loss: 0.6920 - acc: 0.5373 - val_loss: 0.6990 - val_acc: 0.5198\n",
      "Epoch 18/20\n",
      "72603/72603 [==============================] - 0s 2us/step - loss: 0.6909 - acc: 0.5352 - val_loss: 0.6975 - val_acc: 0.5178\n",
      "Epoch 19/20\n",
      "72603/72603 [==============================] - 0s 2us/step - loss: 0.6920 - acc: 0.5357 - val_loss: 0.6985 - val_acc: 0.5188\n",
      "Epoch 20/20\n",
      "72603/72603 [==============================] - 0s 2us/step - loss: 0.6938 - acc: 0.5298 - val_loss: 0.7033 - val_acc: 0.5082\n"
     ]
    }
   ],
   "source": [
    "model1D_top = Sequential()\n",
    "model1D_top.add(Dense(128, activation='relu',input_shape =(4,))) \n",
    "model1D_top.add(Dense(128, activation='relu'))\n",
    "model1D_top.add(Dense(1, activation='sigmoid'))\n",
    "model1D_top.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist_top_model1D= model1D_top.fit(X_1D_top_train, Y_1D_top_train, epochs=20, batch_size=int(0.1*len(X_1D_top_train)),validation_data=(X_1D_top_val, Y_1D_top_val))\n",
    "\n",
    "modelnD_top = Sequential()\n",
    "modelnD_top.add(Dense(128, activation='relu',input_shape =(4*n_top,))) \n",
    "modelnD_top.add(Dense(128, activation='relu'))\n",
    "modelnD_top.add(Dense(1, activation='sigmoid'))\n",
    "modelnD_top.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist_top_modelnD= modelnD_top.fit(X_nD_top_train, Y_nD_top_train, epochs=20, batch_size=int(0.1*len(X_nD_top_train)),validation_data=(X_nD_top_val, Y_nD_top_val))\n",
    "\n",
    "scores_1D_top = model1D_top.predict(X_1D_top_val)\n",
    "scores_nD_top = modelnD_top.predict(X_nD_top_val)\n",
    "\n",
    "scores_1D_fromnD_top = model1D_top.predict(scaler_1D_top.transform(np.reshape(scaler_top.inverse_transform(X_nD_top_val),[n_top*len(X_nD_top_val),4])),batch_size=int(0.1*len(X_nD_top_train)))\n",
    "#scores_1D_fromnD_top = model1D_top.predict(np.reshape(X_nD_top_val,[n*len(X_nD_top_val)]))\n",
    "scores_1D_fromnD_top = np.reshape(scores_1D_fromnD_top,[int(len(scores_1D_fromnD_top)/n_top),n_top])\n",
    "\n",
    "scaled_up_top = np.array([np.prod(scores_1D_fromnD_top[i,:] / (1.-scores_1D_fromnD_top[i,:])) for i in range(len(scores_1D_fromnD_top))])\n",
    "\n",
    "fpr_1D_top, tpr_1D_top, _ = roc_curve(Y_1D_top_val, scores_1D_top)\n",
    "fpr_nD_top, tpr_nD_top, _ = roc_curve(Y_nD_top_val, scores_nD_top)\n",
    "fpr_nD_from1D_top, tpr_nD_from1D_top, _ = roc_curve(Y_nD_top_val, scaled_up_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe947221e80>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bpnachman/anaconda3/envs/shared_env2/lib/python3.6/site-packages/IPython/core/pylabtools.py:132: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tpr_1D_top,1-fpr_1D_top-(1-tpr_1D_top),label=\"1D\")\n",
    "plt.plot(tpr_nD_top,1-fpr_nD_top-(1-tpr_nD_top),label=\"N = 10\")\n",
    "plt.plot(tpr_nD_from1D_top,1-fpr_nD_from1D_top-(1-tpr_nD_from1D_top),label=\"$(1D)^{10}$\")\n",
    "plt.plot([0,1],[0,0],ls=\":\",color=\"grey\")\n",
    "plt.xlabel(\"True Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate - False Positive Rate\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    500         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 128)          0           mask[0][0]                       \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 100)          12900       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 100)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          10100       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          10100       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 100)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            202         activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 56,830\n",
      "Trainable params: 56,830\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/100\n",
      "72603/72603 [==============================] - 1s 14us/step - loss: 6.7238 - acc: 0.4977 - val_loss: 1.9882 - val_acc: 0.4780\n",
      "Epoch 2/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 1.6262 - acc: 0.5005 - val_loss: 0.8245 - val_acc: 0.5038\n",
      "Epoch 3/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.8521 - acc: 0.5087 - val_loss: 0.7695 - val_acc: 0.5088\n",
      "Epoch 4/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.7466 - acc: 0.5175 - val_loss: 0.7380 - val_acc: 0.5155\n",
      "Epoch 5/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.7182 - acc: 0.5256 - val_loss: 0.7132 - val_acc: 0.5206\n",
      "Epoch 6/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.7072 - acc: 0.5306 - val_loss: 0.7111 - val_acc: 0.5261\n",
      "Epoch 7/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.7015 - acc: 0.5353 - val_loss: 0.7073 - val_acc: 0.5289\n",
      "Epoch 8/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6980 - acc: 0.5406 - val_loss: 0.6993 - val_acc: 0.5380\n",
      "Epoch 9/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6933 - acc: 0.5454 - val_loss: 0.6965 - val_acc: 0.5394\n",
      "Epoch 10/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6903 - acc: 0.5495 - val_loss: 0.6961 - val_acc: 0.5409\n",
      "Epoch 11/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6883 - acc: 0.5527 - val_loss: 0.6952 - val_acc: 0.5437\n",
      "Epoch 12/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6860 - acc: 0.5546 - val_loss: 0.6908 - val_acc: 0.5508\n",
      "Epoch 13/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6835 - acc: 0.5603 - val_loss: 0.6881 - val_acc: 0.5518\n",
      "Epoch 14/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6822 - acc: 0.5607 - val_loss: 0.6878 - val_acc: 0.5518\n",
      "Epoch 15/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6818 - acc: 0.5628 - val_loss: 0.6864 - val_acc: 0.5553\n",
      "Epoch 16/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6805 - acc: 0.5651 - val_loss: 0.6887 - val_acc: 0.5547\n",
      "Epoch 17/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6807 - acc: 0.5656 - val_loss: 0.6885 - val_acc: 0.5520\n",
      "Epoch 18/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6783 - acc: 0.5719 - val_loss: 0.6828 - val_acc: 0.5613\n",
      "Epoch 19/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6780 - acc: 0.5722 - val_loss: 0.6827 - val_acc: 0.5632\n",
      "Epoch 20/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6753 - acc: 0.5765 - val_loss: 0.6905 - val_acc: 0.5532\n",
      "Epoch 21/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6811 - acc: 0.5699 - val_loss: 0.6941 - val_acc: 0.5452\n",
      "Epoch 22/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6768 - acc: 0.5745 - val_loss: 0.6796 - val_acc: 0.5683\n",
      "Epoch 23/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6736 - acc: 0.5805 - val_loss: 0.6908 - val_acc: 0.5546\n",
      "Epoch 24/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6737 - acc: 0.5799 - val_loss: 0.6791 - val_acc: 0.5705\n",
      "Epoch 25/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6732 - acc: 0.5811 - val_loss: 0.6816 - val_acc: 0.5690\n",
      "Epoch 26/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6733 - acc: 0.5814 - val_loss: 0.6803 - val_acc: 0.5712\n",
      "Epoch 27/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6715 - acc: 0.5829 - val_loss: 0.6842 - val_acc: 0.5654\n",
      "Epoch 28/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6694 - acc: 0.5886 - val_loss: 0.6762 - val_acc: 0.5776\n",
      "Epoch 29/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6695 - acc: 0.5868 - val_loss: 0.6765 - val_acc: 0.5751\n",
      "Epoch 30/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6720 - acc: 0.5836 - val_loss: 0.7129 - val_acc: 0.5328\n",
      "Epoch 31/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6811 - acc: 0.5715 - val_loss: 0.6748 - val_acc: 0.5780\n",
      "Epoch 32/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6706 - acc: 0.5844 - val_loss: 0.6978 - val_acc: 0.5497\n",
      "Epoch 33/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6698 - acc: 0.5867 - val_loss: 0.6741 - val_acc: 0.5811\n",
      "Epoch 34/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6681 - acc: 0.5903 - val_loss: 0.6734 - val_acc: 0.5824\n",
      "Epoch 35/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6679 - acc: 0.5910 - val_loss: 0.6742 - val_acc: 0.5798\n",
      "Epoch 36/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6672 - acc: 0.5919 - val_loss: 0.6732 - val_acc: 0.5818\n",
      "Epoch 37/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6654 - acc: 0.5947 - val_loss: 0.6769 - val_acc: 0.5775\n",
      "Epoch 38/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6664 - acc: 0.5921 - val_loss: 0.6731 - val_acc: 0.5820\n",
      "Epoch 39/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6668 - acc: 0.5928 - val_loss: 0.6835 - val_acc: 0.5660\n",
      "Epoch 40/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6665 - acc: 0.5935 - val_loss: 0.6807 - val_acc: 0.5711\n",
      "Epoch 41/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6678 - acc: 0.5894 - val_loss: 0.6770 - val_acc: 0.5774\n",
      "Epoch 42/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6613 - acc: 0.6016 - val_loss: 0.6797 - val_acc: 0.5726\n",
      "Epoch 43/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6607 - acc: 0.6038 - val_loss: 0.6717 - val_acc: 0.5842\n",
      "Epoch 44/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6615 - acc: 0.6015 - val_loss: 0.6698 - val_acc: 0.5885\n",
      "Epoch 45/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6605 - acc: 0.6027 - val_loss: 0.6761 - val_acc: 0.5774\n",
      "Epoch 46/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6698 - acc: 0.5888 - val_loss: 0.6735 - val_acc: 0.5820\n",
      "Epoch 47/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6608 - acc: 0.6013 - val_loss: 0.6715 - val_acc: 0.5846\n",
      "Epoch 48/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6600 - acc: 0.6039 - val_loss: 0.6688 - val_acc: 0.5889\n",
      "Epoch 49/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6637 - acc: 0.5995 - val_loss: 0.6786 - val_acc: 0.5751\n",
      "Epoch 50/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6585 - acc: 0.6055 - val_loss: 0.6687 - val_acc: 0.5911\n",
      "Epoch 51/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6596 - acc: 0.6044 - val_loss: 0.6726 - val_acc: 0.5844\n",
      "Epoch 52/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6560 - acc: 0.6091 - val_loss: 0.6680 - val_acc: 0.5921\n",
      "Epoch 53/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6564 - acc: 0.6097 - val_loss: 0.6672 - val_acc: 0.5921\n",
      "Epoch 54/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6556 - acc: 0.6111 - val_loss: 0.6671 - val_acc: 0.5929\n",
      "Epoch 55/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6554 - acc: 0.6084 - val_loss: 0.6686 - val_acc: 0.5917\n",
      "Epoch 56/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6658 - acc: 0.5952 - val_loss: 0.6830 - val_acc: 0.5715\n",
      "Epoch 57/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6579 - acc: 0.6055 - val_loss: 0.6660 - val_acc: 0.5947\n",
      "Epoch 58/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6621 - acc: 0.6001 - val_loss: 0.6770 - val_acc: 0.5798\n",
      "Epoch 59/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6693 - acc: 0.5937 - val_loss: 0.6812 - val_acc: 0.5729\n",
      "Epoch 60/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6556 - acc: 0.6099 - val_loss: 0.6655 - val_acc: 0.5946\n",
      "Epoch 61/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6571 - acc: 0.6075 - val_loss: 0.6700 - val_acc: 0.5886\n",
      "Epoch 62/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6562 - acc: 0.6077 - val_loss: 0.6671 - val_acc: 0.5920\n",
      "Epoch 63/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6569 - acc: 0.6064 - val_loss: 0.6684 - val_acc: 0.5915\n",
      "Epoch 64/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6562 - acc: 0.6086 - val_loss: 0.6656 - val_acc: 0.5957\n",
      "Epoch 65/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6499 - acc: 0.6167 - val_loss: 0.6656 - val_acc: 0.5969\n",
      "Epoch 66/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6492 - acc: 0.6190 - val_loss: 0.6630 - val_acc: 0.5999\n",
      "Epoch 67/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6514 - acc: 0.6162 - val_loss: 0.6627 - val_acc: 0.6010\n",
      "Epoch 68/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6525 - acc: 0.6140 - val_loss: 0.6643 - val_acc: 0.5975\n",
      "Epoch 69/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6480 - acc: 0.6194 - val_loss: 0.6695 - val_acc: 0.5892\n",
      "Epoch 70/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6566 - acc: 0.6077 - val_loss: 0.6726 - val_acc: 0.5877\n",
      "Epoch 71/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6524 - acc: 0.6136 - val_loss: 0.6642 - val_acc: 0.5973\n",
      "Epoch 72/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6503 - acc: 0.6164 - val_loss: 0.6638 - val_acc: 0.5987\n",
      "Epoch 73/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6519 - acc: 0.6149 - val_loss: 0.6794 - val_acc: 0.5806\n",
      "Epoch 74/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6503 - acc: 0.6172 - val_loss: 0.6615 - val_acc: 0.6012\n",
      "Epoch 75/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6545 - acc: 0.6111 - val_loss: 0.6755 - val_acc: 0.5851\n",
      "Epoch 76/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6590 - acc: 0.6054 - val_loss: 0.6632 - val_acc: 0.6010\n",
      "Epoch 77/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6477 - acc: 0.6209 - val_loss: 0.6628 - val_acc: 0.5993\n",
      "Epoch 78/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6431 - acc: 0.6254 - val_loss: 0.6759 - val_acc: 0.5870\n",
      "Epoch 79/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6474 - acc: 0.6216 - val_loss: 0.6693 - val_acc: 0.5932\n",
      "Epoch 80/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6538 - acc: 0.6121 - val_loss: 0.6985 - val_acc: 0.5653\n",
      "Epoch 81/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6545 - acc: 0.6119 - val_loss: 0.6696 - val_acc: 0.5935\n",
      "Epoch 82/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6416 - acc: 0.6293 - val_loss: 0.6573 - val_acc: 0.6083\n",
      "Epoch 83/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6395 - acc: 0.6322 - val_loss: 0.6697 - val_acc: 0.5940\n",
      "Epoch 84/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6500 - acc: 0.6184 - val_loss: 0.6763 - val_acc: 0.5851\n",
      "Epoch 85/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6429 - acc: 0.6264 - val_loss: 0.6601 - val_acc: 0.6033\n",
      "Epoch 86/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6431 - acc: 0.6251 - val_loss: 0.6675 - val_acc: 0.5960\n",
      "Epoch 87/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6396 - acc: 0.6316 - val_loss: 0.6579 - val_acc: 0.6076\n",
      "Epoch 88/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6401 - acc: 0.6302 - val_loss: 0.6553 - val_acc: 0.6110\n",
      "Epoch 89/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6438 - acc: 0.6268 - val_loss: 0.6558 - val_acc: 0.6106\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6398 - acc: 0.6296 - val_loss: 0.6639 - val_acc: 0.5999\n",
      "Epoch 91/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6381 - acc: 0.6315 - val_loss: 0.6552 - val_acc: 0.6106\n",
      "Epoch 92/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6395 - acc: 0.6324 - val_loss: 0.6692 - val_acc: 0.5947\n",
      "Epoch 93/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6386 - acc: 0.6333 - val_loss: 0.6558 - val_acc: 0.6102\n",
      "Epoch 94/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6350 - acc: 0.6361 - val_loss: 0.6535 - val_acc: 0.6151\n",
      "Epoch 95/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6440 - acc: 0.6268 - val_loss: 0.6576 - val_acc: 0.6087\n",
      "Epoch 96/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6360 - acc: 0.6348 - val_loss: 0.6535 - val_acc: 0.6144\n",
      "Epoch 97/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6391 - acc: 0.6311 - val_loss: 0.6629 - val_acc: 0.6050\n",
      "Epoch 98/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6383 - acc: 0.6313 - val_loss: 0.6687 - val_acc: 0.5977\n",
      "Epoch 99/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6372 - acc: 0.6322 - val_loss: 0.6524 - val_acc: 0.6146\n",
      "Epoch 100/100\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6344 - acc: 0.6349 - val_loss: 0.6578 - val_acc: 0.6099\n"
     ]
    }
   ],
   "source": [
    "X_nD_val_top_pfn = np.reshape(X_nD_top_val,[len(X_nD_top_val),n_top,4])\n",
    "X_nD_train_top_pfn = np.reshape(X_nD_top_train,[len(X_nD_top_train),n_top,4])\n",
    "\n",
    "Phi_sizes_top, F_sizes_top = (100, 100, 128), (100, 100, 100)\n",
    "pfn_top = PFN(input_dim=X_nD_val_top_pfn.shape[-1], Phi_sizes=Phi_sizes_top, F_sizes=F_sizes_top)\n",
    "num_epoch = 100\n",
    "batch_size = 5000 #was 5000\n",
    "historyf_top = pfn_top.fit(X_nD_train_top_pfn, to_categorical(Y_nD_top_train,2),\n",
    "          epochs=num_epoch,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_nD_val_top_pfn, to_categorical(Y_nD_top_val,2)),\n",
    "        verbose=1)\n",
    "scores_nD_tops_pfn = pfn_top.predict(X_nD_val_top_pfn,batch_size=int(0.1*len(X_nD_top_train)))\n",
    "fpr_nD_top_pfn, tpr_nD_top_pfn, _ = roc_curve(Y_nD_top_val, scores_nD_tops_pfn[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save everything\n",
    "np.save(\"ensemblelearning/Y_1D_top_val\",Y_1D_top_val)\n",
    "np.save(\"ensemblelearning/Y_1D_top_val\",Y_1D_top_val)\n",
    "np.save(\"ensemblelearning/Y_1D_top_train\",Y_1D_top_train)\n",
    "np.save(\"ensemblelearning/X_1D_top_train\",X_1D_top_train)\n",
    "\n",
    "np.save(\"ensemblelearning/Y_nD_top_val\",Y_nD_top_val)\n",
    "np.save(\"ensemblelearning/Y_nD_top_val\",Y_nD_top_val)\n",
    "np.save(\"ensemblelearning/Y_nD_top_train\",Y_nD_top_train)\n",
    "np.save(\"ensemblelearning/X_nD_top_train\",X_nD_top_train)\n",
    "\n",
    "model_json = model1D_top.to_json()\n",
    "with open(\"ensemblelearning/model1D_top.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model1D_top.save_weights(\"ensemblelearning/model1D_top.h5\")\n",
    "\n",
    "model_json = modelnD_top.to_json()\n",
    "with open(\"ensemblelearning/modelnD_top.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "modelnD_top.save_weights(\"ensemblelearning/modelnD_top.h5\")\n",
    "\n",
    "model_json = pfn_top.model.to_json()\n",
    "with open(\"ensemblelearning/model_pfn_top.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "pfn_top.model.save_weights(\"ensemblelearning/model_pfn_top.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "gs = gridspec.GridSpec(1, 1) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ax0.minorticks_on()\n",
    "\n",
    "plt.plot(tpr_1D_top,1-fpr_1D_top-(1-tpr_1D_top),label=\"$f_{1}$\")\n",
    "plt.plot(tpr_nD_top,1-fpr_nD_top-(1-tpr_nD_top),label=\"$f_{\"+str(n_top)+\"}$\")\n",
    "plt.plot(tpr_nD_from1D_top,1-fpr_nD_from1D_top-(1-tpr_nD_from1D_top),label=\"$f_{\\{\"+str(n_top)+\"\\}}$\")\n",
    "plt.plot(tpr_nD_top_pfn,1-fpr_nD_top_pfn-(1-tpr_nD_top_pfn),label=\"$f_{\"+str(n_top)+\"}$${}^{PFN}$\")\n",
    "plt.plot([0,1],[0,0],ls=\":\",color=\"grey\")\n",
    "plt.xlabel(\"True Positive Rate\",fontsize=20)\n",
    "plt.ylabel(\"True Positive - False Positive Rate\",fontsize=20)\n",
    "plt.legend(frameon=False,fontsize=20,loc=(0.4,0.3))\n",
    "\n",
    "plt.title(r\"$Top$ $Quark$ $Mass$, 172.5 $versus$ 175 GeV\",loc=\"right\",fontsize=20)\n",
    "plt.savefig(\"ensembleLearnPlots/Top_ROC.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    500         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    12928       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 128)          0           mask[0][0]                       \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 100)          12900       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 100)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          10100       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          10100       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 100)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            202         activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 56,830\n",
      "Trainable params: 56,830\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "on epoch 0\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 1s 15us/step - loss: 4.6393 - acc: 0.5046 - val_loss: 0.9677 - val_acc: 0.5170\n",
      "on epoch 1\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.9896 - acc: 0.5098 - val_loss: 0.8002 - val_acc: 0.5242\n",
      "on epoch 2\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.8077 - acc: 0.5203 - val_loss: 0.7828 - val_acc: 0.5223\n",
      "on epoch 3\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.7481 - acc: 0.5276 - val_loss: 0.7338 - val_acc: 0.5327\n",
      "on epoch 4\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.7151 - acc: 0.5389 - val_loss: 0.7145 - val_acc: 0.5394\n",
      "on epoch 5\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.7050 - acc: 0.5468 - val_loss: 0.7133 - val_acc: 0.5401\n",
      "on epoch 6\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6993 - acc: 0.5533 - val_loss: 0.7000 - val_acc: 0.5476\n",
      "on epoch 7\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.7016 - acc: 0.5511 - val_loss: 0.7197 - val_acc: 0.5350\n",
      "on epoch 8\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6994 - acc: 0.5530 - val_loss: 0.6957 - val_acc: 0.5527\n",
      "on epoch 9\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.7120 - acc: 0.5460 - val_loss: 0.7195 - val_acc: 0.5387\n",
      "on epoch 10\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.7019 - acc: 0.5495 - val_loss: 0.6955 - val_acc: 0.5523\n",
      "on epoch 11\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6859 - acc: 0.5638 - val_loss: 0.7437 - val_acc: 0.5206\n",
      "on epoch 12\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.7089 - acc: 0.5506 - val_loss: 0.6922 - val_acc: 0.5559\n",
      "on epoch 13\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6864 - acc: 0.5642 - val_loss: 0.6893 - val_acc: 0.5585\n",
      "on epoch 14\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6901 - acc: 0.5617 - val_loss: 0.7690 - val_acc: 0.5118\n",
      "on epoch 15\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6982 - acc: 0.5599 - val_loss: 0.6884 - val_acc: 0.5615\n",
      "on epoch 16\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6805 - acc: 0.5721 - val_loss: 0.6828 - val_acc: 0.5667\n",
      "on epoch 17\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6760 - acc: 0.5803 - val_loss: 0.6820 - val_acc: 0.5695\n",
      "on epoch 18\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6825 - acc: 0.5707 - val_loss: 0.6870 - val_acc: 0.5619\n",
      "on epoch 19\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6776 - acc: 0.5758 - val_loss: 0.6812 - val_acc: 0.5704\n",
      "on epoch 20\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6801 - acc: 0.5730 - val_loss: 0.7409 - val_acc: 0.5292\n",
      "on epoch 21\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.7123 - acc: 0.5509 - val_loss: 0.6833 - val_acc: 0.5674\n",
      "on epoch 22\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6764 - acc: 0.5776 - val_loss: 0.6783 - val_acc: 0.5729\n",
      "on epoch 23\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6694 - acc: 0.5872 - val_loss: 0.6843 - val_acc: 0.5681\n",
      "on epoch 24\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6748 - acc: 0.5812 - val_loss: 0.6771 - val_acc: 0.5757\n",
      "on epoch 25\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6734 - acc: 0.5829 - val_loss: 0.6766 - val_acc: 0.5766\n",
      "on epoch 26\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6737 - acc: 0.5825 - val_loss: 0.6770 - val_acc: 0.5762\n",
      "on epoch 27\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6926 - acc: 0.5653 - val_loss: 0.6860 - val_acc: 0.5665\n",
      "on epoch 28\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6759 - acc: 0.5787 - val_loss: 0.6783 - val_acc: 0.5757\n",
      "on epoch 29\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6765 - acc: 0.5788 - val_loss: 0.7161 - val_acc: 0.5429\n",
      "on epoch 30\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6724 - acc: 0.5861 - val_loss: 0.6754 - val_acc: 0.5797\n",
      "on epoch 31\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6822 - acc: 0.5732 - val_loss: 0.7055 - val_acc: 0.5484\n",
      "on epoch 32\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6756 - acc: 0.5830 - val_loss: 0.6775 - val_acc: 0.5762\n",
      "on epoch 33\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6741 - acc: 0.5814 - val_loss: 0.6775 - val_acc: 0.5771\n",
      "on epoch 34\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6643 - acc: 0.5968 - val_loss: 0.6742 - val_acc: 0.5812\n",
      "on epoch 35\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6671 - acc: 0.5920 - val_loss: 0.6755 - val_acc: 0.5801\n",
      "on epoch 36\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6632 - acc: 0.5988 - val_loss: 0.6868 - val_acc: 0.5658\n",
      "on epoch 37\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6665 - acc: 0.5941 - val_loss: 0.6780 - val_acc: 0.5770\n",
      "on epoch 38\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6762 - acc: 0.5827 - val_loss: 0.6789 - val_acc: 0.5769\n",
      "on epoch 39\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6769 - acc: 0.5834 - val_loss: 0.6718 - val_acc: 0.5857\n",
      "on epoch 40\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6620 - acc: 0.6001 - val_loss: 0.6720 - val_acc: 0.5870\n",
      "on epoch 41\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6778 - acc: 0.5788 - val_loss: 0.6832 - val_acc: 0.5736\n",
      "on epoch 42\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6752 - acc: 0.5828 - val_loss: 0.6854 - val_acc: 0.5676\n",
      "on epoch 43\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6621 - acc: 0.6000 - val_loss: 0.6910 - val_acc: 0.5654\n",
      "on epoch 44\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6693 - acc: 0.5913 - val_loss: 0.6740 - val_acc: 0.5831\n",
      "on epoch 45\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6639 - acc: 0.5986 - val_loss: 0.6898 - val_acc: 0.5623\n",
      "on epoch 46\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6693 - acc: 0.5906 - val_loss: 0.6845 - val_acc: 0.5716\n",
      "on epoch 47\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6613 - acc: 0.6028 - val_loss: 0.6709 - val_acc: 0.5868\n",
      "on epoch 48\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6720 - acc: 0.5882 - val_loss: 0.6882 - val_acc: 0.5646\n",
      "on epoch 49\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6602 - acc: 0.6028 - val_loss: 0.6691 - val_acc: 0.5904\n",
      "on epoch 50\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6582 - acc: 0.6056 - val_loss: 0.6966 - val_acc: 0.5638\n",
      "on epoch 51\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6644 - acc: 0.5982 - val_loss: 0.6814 - val_acc: 0.5732\n",
      "on epoch 52\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6656 - acc: 0.5961 - val_loss: 0.6748 - val_acc: 0.5826\n",
      "on epoch 53\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6599 - acc: 0.6032 - val_loss: 0.6679 - val_acc: 0.5939\n",
      "on epoch 54\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6560 - acc: 0.6092 - val_loss: 0.6688 - val_acc: 0.5918\n",
      "on epoch 55\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6565 - acc: 0.6094 - val_loss: 0.6681 - val_acc: 0.5929\n",
      "on epoch 56\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6584 - acc: 0.6070 - val_loss: 0.6718 - val_acc: 0.5884\n",
      "on epoch 57\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6581 - acc: 0.6061 - val_loss: 0.6691 - val_acc: 0.5920\n",
      "on epoch 58\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6523 - acc: 0.6163 - val_loss: 0.6741 - val_acc: 0.5857\n",
      "on epoch 59\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6590 - acc: 0.6056 - val_loss: 0.6655 - val_acc: 0.5958\n",
      "on epoch 60\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6542 - acc: 0.6093 - val_loss: 0.6656 - val_acc: 0.5973\n",
      "on epoch 61\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6630 - acc: 0.6010 - val_loss: 0.6749 - val_acc: 0.5854\n",
      "on epoch 62\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6644 - acc: 0.6006 - val_loss: 0.6773 - val_acc: 0.5826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on epoch 63\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6593 - acc: 0.6036 - val_loss: 0.6675 - val_acc: 0.5943\n",
      "on epoch 64\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6555 - acc: 0.6087 - val_loss: 0.6905 - val_acc: 0.5668\n",
      "on epoch 65\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6510 - acc: 0.6161 - val_loss: 0.6646 - val_acc: 0.5997\n",
      "on epoch 66\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6545 - acc: 0.6106 - val_loss: 0.6636 - val_acc: 0.5995\n",
      "on epoch 67\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6494 - acc: 0.6181 - val_loss: 0.6623 - val_acc: 0.6013\n",
      "on epoch 68\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6506 - acc: 0.6161 - val_loss: 0.6621 - val_acc: 0.6017\n",
      "on epoch 69\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6560 - acc: 0.6097 - val_loss: 0.6649 - val_acc: 0.5983\n",
      "on epoch 70\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6486 - acc: 0.6205 - val_loss: 0.6985 - val_acc: 0.5670\n",
      "on epoch 71\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6552 - acc: 0.6129 - val_loss: 0.6649 - val_acc: 0.5995\n",
      "on epoch 72\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6565 - acc: 0.6104 - val_loss: 0.6925 - val_acc: 0.5698\n",
      "on epoch 73\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6622 - acc: 0.6041 - val_loss: 0.6794 - val_acc: 0.5836\n",
      "on epoch 74\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6489 - acc: 0.6185 - val_loss: 0.6664 - val_acc: 0.5981\n",
      "on epoch 75\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6454 - acc: 0.6249 - val_loss: 0.6658 - val_acc: 0.5991\n",
      "on epoch 76\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6445 - acc: 0.6252 - val_loss: 0.6603 - val_acc: 0.6045\n",
      "on epoch 77\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6467 - acc: 0.6211 - val_loss: 0.7068 - val_acc: 0.5629\n",
      "on epoch 78\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6697 - acc: 0.5982 - val_loss: 0.6942 - val_acc: 0.5720\n",
      "on epoch 79\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6701 - acc: 0.5950 - val_loss: 0.6953 - val_acc: 0.5724\n",
      "on epoch 80\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6568 - acc: 0.6093 - val_loss: 0.6663 - val_acc: 0.5966\n",
      "on epoch 81\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6419 - acc: 0.6273 - val_loss: 0.6643 - val_acc: 0.6017\n",
      "on epoch 82\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6471 - acc: 0.6214 - val_loss: 0.6833 - val_acc: 0.5812\n",
      "on epoch 83\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6486 - acc: 0.6212 - val_loss: 0.6612 - val_acc: 0.6046\n",
      "on epoch 84\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6386 - acc: 0.6318 - val_loss: 0.6626 - val_acc: 0.6045\n",
      "on epoch 85\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6408 - acc: 0.6294 - val_loss: 0.6549 - val_acc: 0.6137\n",
      "on epoch 86\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6386 - acc: 0.6326 - val_loss: 0.6556 - val_acc: 0.6122\n",
      "on epoch 87\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6381 - acc: 0.6322 - val_loss: 0.6550 - val_acc: 0.6130\n",
      "on epoch 88\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6359 - acc: 0.6356 - val_loss: 0.6535 - val_acc: 0.6141\n",
      "on epoch 89\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6433 - acc: 0.6262 - val_loss: 0.6540 - val_acc: 0.6155\n",
      "on epoch 90\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6413 - acc: 0.6284 - val_loss: 0.6592 - val_acc: 0.6100\n",
      "on epoch 91\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6381 - acc: 0.6331 - val_loss: 0.6650 - val_acc: 0.6032\n",
      "on epoch 92\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6373 - acc: 0.6318 - val_loss: 0.6568 - val_acc: 0.6123\n",
      "on epoch 93\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6486 - acc: 0.6201 - val_loss: 0.6519 - val_acc: 0.6166\n",
      "on epoch 94\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6376 - acc: 0.6325 - val_loss: 0.6863 - val_acc: 0.5851\n",
      "on epoch 95\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6394 - acc: 0.6310 - val_loss: 0.6509 - val_acc: 0.6186\n",
      "on epoch 96\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6342 - acc: 0.6345 - val_loss: 0.6528 - val_acc: 0.6172\n",
      "on epoch 97\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6326 - acc: 0.6381 - val_loss: 0.6550 - val_acc: 0.6146\n",
      "on epoch 98\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6338 - acc: 0.6368 - val_loss: 0.6511 - val_acc: 0.6190\n",
      "on epoch 99\n",
      "Train on 72603 samples, validate on 72604 samples\n",
      "Epoch 1/1\n",
      "72603/72603 [==============================] - 0s 4us/step - loss: 0.6321 - acc: 0.6394 - val_loss: 0.6532 - val_acc: 0.6167\n"
     ]
    }
   ],
   "source": [
    "Phi_sizes_top, F_sizes_top = (100, 100, 128), (100, 100, 100)\n",
    "pfn_top_1e = PFN(input_dim=X_nD_val_top_pfn.shape[-1], Phi_sizes=Phi_sizes_top, F_sizes=F_sizes_top)\n",
    "num_epoch = 100\n",
    "batch_size = 5000 #was 5000\n",
    "\n",
    "tprs_pfn = []\n",
    "fprs_pfn = []\n",
    "vallosses_pfn = []\n",
    "trainlosses_pfn = []\n",
    "for i in range(num_epoch):\n",
    "    print(\"on epoch\",i)\n",
    "    historyf_top_1e = pfn_top_1e.fit(X_nD_train_top_pfn, to_categorical(Y_nD_top_train,2),epochs=1,batch_size=batch_size,validation_data=(X_nD_val_top_pfn, to_categorical(Y_nD_top_val,2)),verbose=1)\n",
    "    scores_nD_tops_pfn_1e = pfn_top_1e.predict(X_nD_val_top_pfn,batch_size=int(0.1*len(X_nD_top_train)))\n",
    "    fpr_nD_top_pfn_1e, tpr_nD_top_pfn_1e, _ = roc_curve(Y_nD_top_val, scores_nD_tops_pfn_1e[:,1])\n",
    "    tprs_pfn+=[tpr_nD_top_pfn_1e]\n",
    "    fprs_pfn+=[fpr_nD_top_pfn_1e]\n",
    "    vallosses_pfn+=[historyf_top_1e.history['val_loss'][0]]\n",
    "    trainlosses_pfn+=[historyf_top_1e.history['loss'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on epoch 0\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 2s 1us/step - loss: 0.6935 - acc: 0.5089 - val_loss: 0.6929 - val_acc: 0.5137\n",
      "on epoch 1\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6927 - acc: 0.5142 - val_loss: 0.6926 - val_acc: 0.5144\n",
      "on epoch 2\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6924 - acc: 0.5175 - val_loss: 0.6924 - val_acc: 0.5172\n",
      "on epoch 3\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6923 - acc: 0.5180 - val_loss: 0.6923 - val_acc: 0.5176\n",
      "on epoch 4\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6922 - acc: 0.5187 - val_loss: 0.6922 - val_acc: 0.5182\n",
      "on epoch 5\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6921 - acc: 0.5201 - val_loss: 0.6922 - val_acc: 0.5196\n",
      "on epoch 6\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6920 - acc: 0.5207 - val_loss: 0.6921 - val_acc: 0.5212\n",
      "on epoch 7\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6919 - acc: 0.5216 - val_loss: 0.6920 - val_acc: 0.5213\n",
      "on epoch 8\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6918 - acc: 0.5220 - val_loss: 0.6919 - val_acc: 0.5219\n",
      "on epoch 9\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6918 - acc: 0.5227 - val_loss: 0.6919 - val_acc: 0.5228\n",
      "on epoch 10\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6917 - acc: 0.5236 - val_loss: 0.6918 - val_acc: 0.5222\n",
      "on epoch 11\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6916 - acc: 0.5237 - val_loss: 0.6917 - val_acc: 0.5232\n",
      "on epoch 12\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6916 - acc: 0.5246 - val_loss: 0.6917 - val_acc: 0.5236\n",
      "on epoch 13\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6915 - acc: 0.5248 - val_loss: 0.6917 - val_acc: 0.5218\n",
      "on epoch 14\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6914 - acc: 0.5251 - val_loss: 0.6915 - val_acc: 0.5257\n",
      "on epoch 15\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6913 - acc: 0.5260 - val_loss: 0.6914 - val_acc: 0.5239\n",
      "on epoch 16\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6912 - acc: 0.5265 - val_loss: 0.6913 - val_acc: 0.5253\n",
      "on epoch 17\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6911 - acc: 0.5260 - val_loss: 0.6913 - val_acc: 0.5266\n",
      "on epoch 18\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6911 - acc: 0.5271 - val_loss: 0.6912 - val_acc: 0.5257\n",
      "on epoch 19\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6910 - acc: 0.5273 - val_loss: 0.6911 - val_acc: 0.5266\n",
      "on epoch 20\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6909 - acc: 0.5277 - val_loss: 0.6910 - val_acc: 0.5262\n",
      "on epoch 21\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6908 - acc: 0.5281 - val_loss: 0.6909 - val_acc: 0.5274\n",
      "on epoch 22\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6907 - acc: 0.5288 - val_loss: 0.6908 - val_acc: 0.5273\n",
      "on epoch 23\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6906 - acc: 0.5289 - val_loss: 0.6907 - val_acc: 0.5285\n",
      "on epoch 24\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6905 - acc: 0.5291 - val_loss: 0.6907 - val_acc: 0.5286\n",
      "on epoch 25\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6904 - acc: 0.5298 - val_loss: 0.6905 - val_acc: 0.5288\n",
      "on epoch 26\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6903 - acc: 0.5300 - val_loss: 0.6904 - val_acc: 0.5290\n",
      "on epoch 27\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6902 - acc: 0.5301 - val_loss: 0.6903 - val_acc: 0.5294\n",
      "on epoch 28\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6902 - acc: 0.5304 - val_loss: 0.6903 - val_acc: 0.5294\n",
      "on epoch 29\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6900 - acc: 0.5310 - val_loss: 0.6902 - val_acc: 0.5294\n",
      "on epoch 30\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6900 - acc: 0.5313 - val_loss: 0.6902 - val_acc: 0.5303\n",
      "on epoch 31\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6900 - acc: 0.5305 - val_loss: 0.6901 - val_acc: 0.5297\n",
      "on epoch 32\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6899 - acc: 0.5314 - val_loss: 0.6900 - val_acc: 0.5304\n",
      "on epoch 33\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6898 - acc: 0.5313 - val_loss: 0.6900 - val_acc: 0.5304\n",
      "on epoch 34\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6898 - acc: 0.5320 - val_loss: 0.6900 - val_acc: 0.5301\n",
      "on epoch 35\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6897 - acc: 0.5318 - val_loss: 0.6899 - val_acc: 0.5308\n",
      "on epoch 36\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6896 - acc: 0.5321 - val_loss: 0.6898 - val_acc: 0.5314\n",
      "on epoch 37\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6896 - acc: 0.5323 - val_loss: 0.6898 - val_acc: 0.5312\n",
      "on epoch 38\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6896 - acc: 0.5321 - val_loss: 0.6898 - val_acc: 0.5310\n",
      "on epoch 39\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6895 - acc: 0.5326 - val_loss: 0.6897 - val_acc: 0.5314\n",
      "on epoch 40\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6895 - acc: 0.5328 - val_loss: 0.6897 - val_acc: 0.5317\n",
      "on epoch 41\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6895 - acc: 0.5328 - val_loss: 0.6897 - val_acc: 0.5313\n",
      "on epoch 42\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6895 - acc: 0.5329 - val_loss: 0.6897 - val_acc: 0.5306\n",
      "on epoch 43\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6895 - acc: 0.5323 - val_loss: 0.6897 - val_acc: 0.5317\n",
      "on epoch 44\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6895 - acc: 0.5324 - val_loss: 0.6898 - val_acc: 0.5308\n",
      "on epoch 45\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6895 - acc: 0.5325 - val_loss: 0.6896 - val_acc: 0.5312\n",
      "on epoch 46\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6894 - acc: 0.5330 - val_loss: 0.6897 - val_acc: 0.5316\n",
      "on epoch 47\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6894 - acc: 0.5329 - val_loss: 0.6896 - val_acc: 0.5320\n",
      "on epoch 48\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6893 - acc: 0.5333 - val_loss: 0.6896 - val_acc: 0.5323\n",
      "on epoch 49\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6893 - acc: 0.5330 - val_loss: 0.6896 - val_acc: 0.5319\n",
      "on epoch 50\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6893 - acc: 0.5336 - val_loss: 0.6895 - val_acc: 0.5322\n",
      "on epoch 51\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6893 - acc: 0.5333 - val_loss: 0.6896 - val_acc: 0.5314\n",
      "on epoch 52\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6893 - acc: 0.5333 - val_loss: 0.6896 - val_acc: 0.5316\n",
      "on epoch 53\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6893 - acc: 0.5336 - val_loss: 0.6895 - val_acc: 0.5319\n",
      "on epoch 54\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6893 - acc: 0.5330 - val_loss: 0.6895 - val_acc: 0.5314\n",
      "on epoch 55\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6893 - acc: 0.5330 - val_loss: 0.6896 - val_acc: 0.5312\n",
      "on epoch 56\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6893 - acc: 0.5337 - val_loss: 0.6895 - val_acc: 0.5318\n",
      "on epoch 57\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6892 - acc: 0.5338 - val_loss: 0.6895 - val_acc: 0.5326\n",
      "on epoch 58\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6893 - acc: 0.5336 - val_loss: 0.6895 - val_acc: 0.5324\n",
      "on epoch 59\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6892 - acc: 0.5338 - val_loss: 0.6895 - val_acc: 0.5327\n",
      "on epoch 60\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6892 - acc: 0.5336 - val_loss: 0.6895 - val_acc: 0.5321\n",
      "on epoch 61\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6892 - acc: 0.5339 - val_loss: 0.6894 - val_acc: 0.5327\n",
      "on epoch 62\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6892 - acc: 0.5336 - val_loss: 0.6895 - val_acc: 0.5318\n",
      "on epoch 63\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6892 - acc: 0.5336 - val_loss: 0.6894 - val_acc: 0.5323\n",
      "on epoch 64\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6892 - acc: 0.5341 - val_loss: 0.6895 - val_acc: 0.5309\n",
      "on epoch 65\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6892 - acc: 0.5336 - val_loss: 0.6894 - val_acc: 0.5324\n",
      "on epoch 66\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6891 - acc: 0.5339 - val_loss: 0.6895 - val_acc: 0.5325\n",
      "on epoch 67\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6892 - acc: 0.5337 - val_loss: 0.6895 - val_acc: 0.5314\n",
      "on epoch 68\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6892 - acc: 0.5341 - val_loss: 0.6894 - val_acc: 0.5325\n",
      "on epoch 69\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6891 - acc: 0.5343 - val_loss: 0.6894 - val_acc: 0.5321\n",
      "on epoch 70\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6892 - acc: 0.5339 - val_loss: 0.6895 - val_acc: 0.5330\n",
      "on epoch 71\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6892 - acc: 0.5340 - val_loss: 0.6894 - val_acc: 0.5326\n",
      "on epoch 72\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6891 - acc: 0.5340 - val_loss: 0.6894 - val_acc: 0.5325\n",
      "on epoch 73\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6891 - acc: 0.5346 - val_loss: 0.6894 - val_acc: 0.5324\n",
      "on epoch 74\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6891 - acc: 0.5342 - val_loss: 0.6894 - val_acc: 0.5330\n",
      "on epoch 75\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6891 - acc: 0.5345 - val_loss: 0.6894 - val_acc: 0.5326\n",
      "on epoch 76\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6891 - acc: 0.5344 - val_loss: 0.6894 - val_acc: 0.5326\n",
      "on epoch 77\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6890 - acc: 0.5345 - val_loss: 0.6894 - val_acc: 0.5321\n",
      "on epoch 78\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6891 - acc: 0.5341 - val_loss: 0.6893 - val_acc: 0.5330\n",
      "on epoch 79\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6890 - acc: 0.5346 - val_loss: 0.6893 - val_acc: 0.5328\n",
      "on epoch 80\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6890 - acc: 0.5344 - val_loss: 0.6893 - val_acc: 0.5333\n",
      "on epoch 81\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6890 - acc: 0.5344 - val_loss: 0.6893 - val_acc: 0.5328\n",
      "on epoch 82\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6890 - acc: 0.5346 - val_loss: 0.6893 - val_acc: 0.5328\n",
      "on epoch 83\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6890 - acc: 0.5345 - val_loss: 0.6893 - val_acc: 0.5326\n",
      "on epoch 84\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6890 - acc: 0.5352 - val_loss: 0.6893 - val_acc: 0.5325\n",
      "on epoch 85\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6890 - acc: 0.5344 - val_loss: 0.6893 - val_acc: 0.5334\n",
      "on epoch 86\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6890 - acc: 0.5349 - val_loss: 0.6893 - val_acc: 0.5331\n",
      "on epoch 87\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6890 - acc: 0.5342 - val_loss: 0.6893 - val_acc: 0.5331\n",
      "on epoch 88\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6890 - acc: 0.5348 - val_loss: 0.6893 - val_acc: 0.5328\n",
      "on epoch 89\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6889 - acc: 0.5349 - val_loss: 0.6893 - val_acc: 0.5326\n",
      "on epoch 90\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6889 - acc: 0.5349 - val_loss: 0.6894 - val_acc: 0.5320\n",
      "on epoch 91\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6889 - acc: 0.5350 - val_loss: 0.6893 - val_acc: 0.5329\n",
      "on epoch 92\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6889 - acc: 0.5348 - val_loss: 0.6893 - val_acc: 0.5324\n",
      "on epoch 93\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6889 - acc: 0.5347 - val_loss: 0.6893 - val_acc: 0.5335\n",
      "on epoch 94\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6889 - acc: 0.5349 - val_loss: 0.6893 - val_acc: 0.5329\n",
      "on epoch 95\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6889 - acc: 0.5346 - val_loss: 0.6893 - val_acc: 0.5321\n",
      "on epoch 96\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6889 - acc: 0.5350 - val_loss: 0.6893 - val_acc: 0.5330\n",
      "on epoch 97\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6889 - acc: 0.5350 - val_loss: 0.6892 - val_acc: 0.5328\n",
      "on epoch 98\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6889 - acc: 0.5350 - val_loss: 0.6894 - val_acc: 0.5321\n",
      "on epoch 99\n",
      "Train on 1452070 samples, validate on 1452070 samples\n",
      "Epoch 1/1\n",
      "1452070/1452070 [==============================] - 1s 1us/step - loss: 0.6889 - acc: 0.5352 - val_loss: 0.6893 - val_acc: 0.5333\n"
     ]
    }
   ],
   "source": [
    "tprs = []\n",
    "fprs = []\n",
    "vallosses = []\n",
    "trainlosses = []\n",
    "\n",
    "model1D_top_1e = Sequential()\n",
    "model1D_top_1e.add(Dense(128, activation='relu',input_shape =(4,))) \n",
    "model1D_top_1e.add(Dense(128, activation='relu'))\n",
    "model1D_top_1e.add(Dense(1, activation='sigmoid'))\n",
    "model1D_top_1e.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    print(\"on epoch\",i)\n",
    "\n",
    "    hist_top_model1D_1e= model1D_top_1e.fit(X_1D_top_train, Y_1D_top_train, epochs=1, batch_size=int(0.1*len(X_1D_top_train)),validation_data=(X_1D_top_val, Y_1D_top_val))\n",
    "    scores_1D_top_1e = model1D_top_1e.predict(X_1D_top_val,batch_size=int(0.1*len(X_1D_top_train)))\n",
    "\n",
    "    scores_1D_fromnD_top_1e = model1D_top_1e.predict(scaler_1D_top.transform(np.reshape(scaler_top.inverse_transform(X_nD_top_val),[n_top*len(X_nD_top_val),4])),batch_size=int(0.1*len(X_nD_top_train)))\n",
    "    scores_1D_fromnD_top_1e = np.reshape(scores_1D_fromnD_top_1e,[int(len(scores_1D_fromnD_top_1e)/n_top),n_top])\n",
    "    scaled_up_top_1e = np.array([np.prod(scores_1D_fromnD_top_1e[i,:] / (1.-scores_1D_fromnD_top_1e[i,:])) for i in range(len(scores_1D_fromnD_top_1e))])\n",
    "\n",
    "    fpr_nD_from1D_top_1e, tpr_nD_from1D_top_1e, _ = roc_curve(Y_nD_top_val, scaled_up_top_1e)\n",
    "    \n",
    "    tprs+=[tpr_nD_from1D_top_1e]\n",
    "    fprs+=[fpr_nD_from1D_top_1e]\n",
    "    vallosses+=[hist_top_model1D_1e.history['val_loss'][0]]\n",
    "    trainlosses+=[hist_top_model1D_1e.history['loss'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx #array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "fprat50s = [fprs[i][find_nearest(tprs[i],0.5)] for i in range(len(tprs))]\n",
    "fprat50s_pfn = [fprs_pfn[i][find_nearest(tprs_pfn[i],0.5)] for i in range(len(fprs_pfn))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "gs = gridspec.GridSpec(1, 1) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ax0.minorticks_on()\n",
    "\n",
    "#plt.plot(fprat50s/fprat50s[0],label=\"$f_{\\{20\\}}$\")\n",
    "#plt.plot(fprat50s_pfn/fprat50s_pfn[0],label=\"$f_{20}$ (PFN)\")\n",
    "\n",
    "plt.plot(fprat50s/fprat50s[0],label=\"$f_{\\{20\\}}$\")\n",
    "plt.plot(fprat50s_pfn/fprat50s_pfn[0],label=\"$f_{20}$${}^{PFN}$\")\n",
    "\n",
    "plt.legend(frameon=False,fontsize=20)\n",
    "plt.xlabel(\"epoch\",fontsize=20)\n",
    "plt.ylabel(\"FPR at 50% TPR normalized at 1\",fontsize=20)\n",
    "\n",
    "plt.title(r\"$Top$ $Quark$ $Mass$, 172.5 $versus$ 175 GeV\",loc=\"right\",fontsize=20)\n",
    "plt.savefig(\"ensembleLearnPlots/Top_LearningRate.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try doing maximum likelihood as a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0 = 0.2\n",
    "thetas = np.random.uniform(theta0-0.01,theta0+0.01,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC = np.random.normal(thetas,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.normal(0.5,0.5,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_MC = np.c_[MC,thetas]\n",
    "X_data = np.c_[data,thetas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_,_,_=plt.hist(MC,bins=np.linspace(-3,3,50),alpha=0.5)\n",
    "_,_,_=plt.hist(data,bins=np.linspace(-3,3,50),alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_MLE_train, X_MLE_val, Y_MLE_train, Y_MLE_val = train_test_split(np.concatenate([X_data,X_MC]), np.concatenate([np.ones(len(X_data)),np.zeros(len(X_MC))]), test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomLoss(y_true, y_pred):\n",
    "    return -y_true*K.log(y_pred+0.000001) + (1.-y_true)*y_pred\n",
    "    #return -y_true*K.log(y_pred+0.0001) - (1.-y_true)*K.log(1-y_pred+0.0001) #binary_crossentropy(y_true,y_pred)\n",
    "    #return binary_crossentropy(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/20\n",
      "100000/100000 [==============================] - 7s 68us/step - loss: 0.6880 - acc: 0.5503 - val_loss: 0.4525 - val_acc: 0.4645\n",
      "Epoch 2/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4476 - acc: 0.3123 - val_loss: 0.4608 - val_acc: 0.2191\n",
      "Epoch 3/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4498 - acc: 0.2371 - val_loss: 0.4456 - val_acc: 0.2908\n",
      "Epoch 4/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4352 - acc: 0.3393 - val_loss: 0.4428 - val_acc: 0.3857\n",
      "Epoch 5/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4363 - acc: 0.4226 - val_loss: 0.4365 - val_acc: 0.4563\n",
      "Epoch 6/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4295 - acc: 0.4585 - val_loss: 0.4342 - val_acc: 0.4235\n",
      "Epoch 7/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4293 - acc: 0.4096 - val_loss: 0.4328 - val_acc: 0.4295\n",
      "Epoch 8/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4314 - acc: 0.4249 - val_loss: 0.4672 - val_acc: 0.4973\n",
      "Epoch 9/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4805 - acc: 0.5002 - val_loss: 0.4665 - val_acc: 0.4863\n",
      "Epoch 10/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4408 - acc: 0.3887 - val_loss: 0.4352 - val_acc: 0.3220\n",
      "Epoch 11/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4254 - acc: 0.3553 - val_loss: 0.4271 - val_acc: 0.3970\n",
      "Epoch 12/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4223 - acc: 0.4100 - val_loss: 0.4269 - val_acc: 0.4077\n",
      "Epoch 13/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4241 - acc: 0.4064 - val_loss: 0.4242 - val_acc: 0.4077\n",
      "Epoch 14/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4230 - acc: 0.4180 - val_loss: 0.4257 - val_acc: 0.4063\n",
      "Epoch 15/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4220 - acc: 0.4009 - val_loss: 0.4339 - val_acc: 0.4258\n",
      "Epoch 16/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4295 - acc: 0.4190 - val_loss: 0.4242 - val_acc: 0.3927\n",
      "Epoch 17/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4188 - acc: 0.3803 - val_loss: 0.4226 - val_acc: 0.3756\n",
      "Epoch 18/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4164 - acc: 0.3858 - val_loss: 0.4191 - val_acc: 0.3889\n",
      "Epoch 19/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4152 - acc: 0.3940 - val_loss: 0.4197 - val_acc: 0.3988\n",
      "Epoch 20/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4150 - acc: 0.3947 - val_loss: 0.4179 - val_acc: 0.3781\n"
     ]
    }
   ],
   "source": [
    "model_MLE = Sequential()\n",
    "model_MLE.add(Dense(64, activation='elu',input_shape =(2,))) \n",
    "model_MLE.add(Dense(128, activation='elu'))\n",
    "model_MLE.add(Dense(64, activation='elu'))\n",
    "model_MLE.add(Dense(1, activation='relu')) #was sigmoid\n",
    "model_MLE.compile(loss=lambda y_true, y_pred: CustomLoss(y_true, y_pred), optimizer='adam', metrics=['accuracy'])\n",
    "hist_MLE = model_MLE.fit(X_MLE_train, Y_MLE_train, epochs=20, batch_size=int(0.1*len(X_MLE_train)),validation_data=(X_MLE_val, Y_MLE_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe8d99fbbe0>"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#xx = np.linspace(-3,3,100)\n",
    "#preds_test = model_MLE.predict(np.c_[xx,0.5*np.ones(len(xx))])\n",
    "#plt.plot(xx,preds_test/(1-preds_test))\n",
    "#plt.plot(xx,np.exp(-((xx-0.5)**2-(xx+0.5)**2)/(2*0.5**2)))\n",
    "#plt.ylim([0,2])\n",
    "#plt.axvline(0,ls=\":\",color=\"grey\")\n",
    "#plt.axhline(1,ls=\":\",color=\"grey\")\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "xx = np.linspace(-3,3,100)\n",
    "preds_test = model_MLE.predict(np.c_[xx,theta0*np.ones(len(xx))])\n",
    "plot1 = plt.plot(xx,preds_test,label=\"learned\",ls=\"-\",color='green')\n",
    "plot2 = plt.plot(xx,np.exp(-((xx-0.5)**2-(xx-theta0)**2)/(2*0.5**2)),label=\"exact\",color='orange')\n",
    "plt.ylim([0,2])\n",
    "plt.axvline(0,ls=\":\",color=\"grey\")\n",
    "plt.axhline(1,ls=\":\",color=\"grey\")\n",
    "plt.xlabel(r\"$x$\")\n",
    "plt.ylabel(\"likelihood ratio\")\n",
    "plt.title(r\"$\\mu_{MC} = \"+str(theta0)+r\", \\mu_{data}=0.5$, loss =\"+\"%0.2f\" % hist_MLE.history['val_loss'][-1],loc=\"right\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "_,_,_=plt.hist(MC,bins=np.linspace(-3,3,50),alpha=0.3,label=\"MC\",color='red')\n",
    "_,_,_=plt.hist(data,bins=np.linspace(-3,3,50),alpha=0.3,label=\"Data\")\n",
    "ax2.tick_params(axis='y', labelcolor=\"red\")\n",
    "ax2.set_ylabel(\"histogram\",color='red')\n",
    "leg = plt.legend([plot1[0],plot2[0]],['learned','exact'], loc=\"lower left\",)\n",
    "plt.legend()\n",
    "plt.gca().add_artist(leg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 8s 82us/step - loss: 1.6977 - acc: 0.5693 - val_loss: 1.2469 - val_acc: 0.5413\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 1.1698 - acc: 0.4846 - val_loss: 1.0061 - val_acc: 0.4337\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.8717 - acc: 0.4358 - val_loss: 0.6358 - val_acc: 0.4626\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5122 - acc: 0.5040 - val_loss: 0.4425 - val_acc: 0.5320\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4398 - acc: 0.5257 - val_loss: 0.4408 - val_acc: 0.5045\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4334 - acc: 0.4722 - val_loss: 0.4349 - val_acc: 0.4171\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4329 - acc: 0.3951 - val_loss: 0.4415 - val_acc: 0.3661\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4363 - acc: 0.3744 - val_loss: 0.4382 - val_acc: 0.3775\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4323 - acc: 0.3927 - val_loss: 0.4358 - val_acc: 0.3944\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4312 - acc: 0.4069 - val_loss: 0.4336 - val_acc: 0.4353\n"
     ]
    }
   ],
   "source": [
    "N = 100000\n",
    "\n",
    "theta0 = 0.2\n",
    "\n",
    "X_MC = np.random.normal(theta0,0.5,N)\n",
    "X_data = np.random.normal(0.5,0.5,N)\n",
    "\n",
    "X_MLE_train, X_MLE_val, Y_MLE_train, Y_MLE_val = train_test_split(np.concatenate([X_data,X_MC]), np.concatenate([np.ones(len(X_data)),np.zeros(len(X_MC))]), test_size=0.5)\n",
    "\n",
    "def CustomLoss(y_true, y_pred):\n",
    "    return -y_true*K.log(y_pred+0.00000001) + (1.-y_true)*y_pred\n",
    "\n",
    "model_MLE = Sequential()\n",
    "model_MLE.add(Dense(64, activation='elu',input_shape =(1,))) \n",
    "model_MLE.add(Dense(128, activation='elu'))\n",
    "model_MLE.add(Dense(64, activation='elu'))\n",
    "model_MLE.add(Dense(1, activation='relu')) #was sigmoid\n",
    "model_MLE.compile(loss=lambda y_true, y_pred: CustomLoss(y_true, y_pred), optimizer='adam', metrics=['accuracy'])\n",
    "hist_MLE = model_MLE.fit(X_MLE_train, Y_MLE_train, epochs=10, batch_size=int(0.1*len(X_MLE_train)),validation_data=(X_MLE_val, Y_MLE_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe8d851b080>"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "xx = np.linspace(-3,3,100)\n",
    "preds_test = model_MLE.predict(xx)\n",
    "plot1 = plt.plot(xx,preds_test,label=\"learned\",ls=\"-\",color='green')\n",
    "plot2 = plt.plot(xx,np.exp(-((xx-0.5)**2-(xx-theta0)**2)/(2*0.5**2)),label=\"exact\",color='orange')\n",
    "plt.ylim([0,2])\n",
    "plt.axvline(0,ls=\":\",color=\"grey\")\n",
    "plt.axhline(1,ls=\":\",color=\"grey\")\n",
    "plt.xlabel(r\"$x$\")\n",
    "plt.ylabel(\"likelihood ratio\")\n",
    "plt.title(r\"$\\mu_{MC} = \"+str(theta0)+r\", \\mu_{data}=0.5$, loss =\"+\"%0.2f\" % hist_MLE.history['val_loss'][-1],loc=\"right\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "_,_,_=plt.hist(MC,bins=np.linspace(-3,3,50),alpha=0.3,label=\"MC\",color='red')\n",
    "_,_,_=plt.hist(data,bins=np.linspace(-3,3,50),alpha=0.3,label=\"Data\")\n",
    "ax2.tick_params(axis='y', labelcolor=\"red\")\n",
    "ax2.set_ylabel(\"histogram\",color='red')\n",
    "leg = plt.legend([plot1[0],plot2[0]],['learned','exact'], loc=\"lower left\",)\n",
    "plt.legend()\n",
    "plt.gca().add_artist(leg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/20\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 1.0489 - acc: 0.4680 - val_loss: 0.7685 - val_acc: 0.2978\n",
      "Epoch 2/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.7907 - acc: 0.2797 - val_loss: 0.7110 - val_acc: 0.3148\n",
      "Epoch 3/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6579 - acc: 0.3891 - val_loss: 0.6314 - val_acc: 0.4673\n",
      "Epoch 4/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6050 - acc: 0.4865 - val_loss: 0.5696 - val_acc: 0.4685\n",
      "Epoch 5/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5374 - acc: 0.4467 - val_loss: 0.5191 - val_acc: 0.4165\n",
      "Epoch 6/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4999 - acc: 0.4268 - val_loss: 0.4710 - val_acc: 0.4619\n",
      "Epoch 7/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4599 - acc: 0.4736 - val_loss: 0.4585 - val_acc: 0.4615\n",
      "Epoch 8/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4449 - acc: 0.4830 - val_loss: 0.4299 - val_acc: 0.5157\n",
      "Epoch 9/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4272 - acc: 0.5193 - val_loss: 0.4273 - val_acc: 0.5113\n",
      "Epoch 10/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4263 - acc: 0.4980 - val_loss: 0.4260 - val_acc: 0.4837\n",
      "Epoch 11/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4215 - acc: 0.4959 - val_loss: 0.4211 - val_acc: 0.5104\n",
      "Epoch 12/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4198 - acc: 0.5070 - val_loss: 0.4204 - val_acc: 0.4993\n",
      "Epoch 13/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4194 - acc: 0.4928 - val_loss: 0.4196 - val_acc: 0.4996\n",
      "Epoch 14/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4187 - acc: 0.5027 - val_loss: 0.4193 - val_acc: 0.4986\n",
      "Epoch 15/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4179 - acc: 0.4901 - val_loss: 0.4185 - val_acc: 0.4861\n",
      "Epoch 16/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4171 - acc: 0.4899 - val_loss: 0.4179 - val_acc: 0.4934\n",
      "Epoch 17/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4166 - acc: 0.4892 - val_loss: 0.4174 - val_acc: 0.4869\n",
      "Epoch 18/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4162 - acc: 0.4876 - val_loss: 0.4170 - val_acc: 0.4863\n",
      "Epoch 19/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4158 - acc: 0.4836 - val_loss: 0.4166 - val_acc: 0.4829\n",
      "Epoch 20/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4155 - acc: 0.4808 - val_loss: 0.4163 - val_acc: 0.4819\n",
      "0.2 -0.16716159565326016 0.9992383172480829\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/20\n",
      "100000/100000 [==============================] - 1s 7us/step - loss: 1.2102 - acc: 0.5036 - val_loss: 0.7583 - val_acc: 0.3636\n",
      "Epoch 2/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.8207 - acc: 0.3112 - val_loss: 0.8086 - val_acc: 0.3091\n",
      "Epoch 3/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.7411 - acc: 0.3617 - val_loss: 0.6766 - val_acc: 0.4342\n",
      "Epoch 4/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6561 - acc: 0.4755 - val_loss: 0.6238 - val_acc: 0.5030\n",
      "Epoch 5/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5971 - acc: 0.4961 - val_loss: 0.5591 - val_acc: 0.4809\n",
      "Epoch 6/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5453 - acc: 0.4664 - val_loss: 0.5313 - val_acc: 0.4572\n",
      "Epoch 7/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5059 - acc: 0.4793 - val_loss: 0.4719 - val_acc: 0.5106\n",
      "Epoch 8/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4646 - acc: 0.5078 - val_loss: 0.4653 - val_acc: 0.5002\n",
      "Epoch 9/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4647 - acc: 0.5014 - val_loss: 0.4674 - val_acc: 0.4994\n",
      "Epoch 10/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4637 - acc: 0.5014 - val_loss: 0.4634 - val_acc: 0.5002\n",
      "Epoch 11/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4609 - acc: 0.5031 - val_loss: 0.4621 - val_acc: 0.5018\n",
      "Epoch 12/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4606 - acc: 0.5040 - val_loss: 0.4621 - val_acc: 0.5010\n",
      "Epoch 13/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4604 - acc: 0.5037 - val_loss: 0.4620 - val_acc: 0.5017\n",
      "Epoch 14/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4603 - acc: 0.5040 - val_loss: 0.4619 - val_acc: 0.5011\n",
      "Epoch 15/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4602 - acc: 0.5031 - val_loss: 0.4618 - val_acc: 0.5003\n",
      "Epoch 16/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4601 - acc: 0.5027 - val_loss: 0.4618 - val_acc: 0.5001\n",
      "Epoch 17/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4601 - acc: 0.5028 - val_loss: 0.4617 - val_acc: 0.5001\n",
      "Epoch 18/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4600 - acc: 0.5022 - val_loss: 0.4617 - val_acc: 0.4996\n",
      "Epoch 19/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4600 - acc: 0.5020 - val_loss: 0.4616 - val_acc: 0.4999\n",
      "Epoch 20/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4599 - acc: 0.5022 - val_loss: 0.4616 - val_acc: 0.4996\n",
      "0.3 -0.07943042061724129 1.0006211767743907\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/20\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 1.5607 - acc: 0.3427 - val_loss: 0.8545 - val_acc: 0.1830\n",
      "Epoch 2/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.8534 - acc: 0.1527 - val_loss: 0.8607 - val_acc: 0.1333\n",
      "Epoch 3/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.8865 - acc: 0.1273 - val_loss: 0.8539 - val_acc: 0.1269\n",
      "Epoch 4/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.8516 - acc: 0.1289 - val_loss: 0.8081 - val_acc: 0.1354\n",
      "Epoch 5/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.8123 - acc: 0.1390 - val_loss: 0.7875 - val_acc: 0.1442\n",
      "Epoch 6/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.7950 - acc: 0.1444 - val_loss: 0.7717 - val_acc: 0.1434\n",
      "Epoch 7/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.7742 - acc: 0.1398 - val_loss: 0.7551 - val_acc: 0.1349\n",
      "Epoch 8/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.7532 - acc: 0.1294 - val_loss: 0.7281 - val_acc: 0.1226\n",
      "Epoch 9/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.7136 - acc: 0.1147 - val_loss: 0.6853 - val_acc: 0.1068\n",
      "Epoch 10/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6709 - acc: 0.0989 - val_loss: 0.6454 - val_acc: 0.0891\n",
      "Epoch 11/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6240 - acc: 0.0805 - val_loss: 0.5897 - val_acc: 0.0673\n",
      "Epoch 12/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5653 - acc: 0.0528 - val_loss: 0.5316 - val_acc: 0.0352\n",
      "Epoch 13/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5168 - acc: 0.0183 - val_loss: 0.4977 - val_acc: 0.0042\n",
      "Epoch 14/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4977 - acc: 0.0022 - val_loss: 0.4894 - val_acc: 7.8000e-04\n",
      "Epoch 15/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 4.7000e-04 - val_loss: 0.4900 - val_acc: 3.0000e-04\n",
      "Epoch 16/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4969 - acc: 2.2000e-04 - val_loss: 0.4901 - val_acc: 2.8000e-04\n",
      "Epoch 17/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4960 - acc: 3.0000e-04 - val_loss: 0.4891 - val_acc: 5.6000e-04\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4956 - acc: 6.9000e-04 - val_loss: 0.4888 - val_acc: 8.6000e-04\n",
      "Epoch 19/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4954 - acc: 9.1000e-04 - val_loss: 0.4889 - val_acc: 9.8000e-04\n",
      "Epoch 20/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 9.2000e-04 - val_loss: 0.4888 - val_acc: 9.7000e-04\n",
      "0.4 -0.000248424700563259 0.9842188748883454\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/20\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 1.3035 - acc: 0.4585 - val_loss: 1.0011 - val_acc: 0.3341\n",
      "Epoch 2/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 1.0244 - acc: 0.3177 - val_loss: 0.9382 - val_acc: 0.3475\n",
      "Epoch 3/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.8664 - acc: 0.4171 - val_loss: 0.8245 - val_acc: 0.4803\n",
      "Epoch 4/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.8037 - acc: 0.4914 - val_loss: 0.7746 - val_acc: 0.4908\n",
      "Epoch 5/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.7237 - acc: 0.4940 - val_loss: 0.6440 - val_acc: 0.4994\n",
      "Epoch 6/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5850 - acc: 0.5009 - val_loss: 0.5313 - val_acc: 0.5000\n",
      "Epoch 7/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5139 - acc: 0.5006 - val_loss: 0.5025 - val_acc: 0.4997\n",
      "Epoch 8/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5013 - acc: 0.5003 - val_loss: 0.5036 - val_acc: 0.4997\n",
      "Epoch 9/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5031 - acc: 0.5003 - val_loss: 0.5037 - val_acc: 0.4997\n",
      "Epoch 10/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5019 - acc: 0.5003 - val_loss: 0.5020 - val_acc: 0.4997\n",
      "Epoch 11/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5010 - acc: 0.5003 - val_loss: 0.5015 - val_acc: 0.4997\n",
      "Epoch 12/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5008 - acc: 0.5003 - val_loss: 0.5015 - val_acc: 0.4997\n",
      "Epoch 13/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5008 - acc: 0.5003 - val_loss: 0.5014 - val_acc: 0.4997\n",
      "Epoch 14/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5007 - acc: 0.5003 - val_loss: 0.5014 - val_acc: 0.4997\n",
      "Epoch 15/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5006 - acc: 0.5003 - val_loss: 0.5013 - val_acc: 0.4997\n",
      "Epoch 16/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5006 - acc: 0.5003 - val_loss: 0.5013 - val_acc: 0.4997\n",
      "Epoch 17/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5005 - acc: 0.5003 - val_loss: 0.5012 - val_acc: 0.4997\n",
      "Epoch 18/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5005 - acc: 0.5003 - val_loss: 0.5011 - val_acc: 0.4997\n",
      "Epoch 19/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5004 - acc: 0.5003 - val_loss: 0.5011 - val_acc: 0.4997\n",
      "Epoch 20/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5004 - acc: 0.5003 - val_loss: 0.5011 - val_acc: 0.4997\n",
      "0.5 -0.004061319231411753 1.0056127970139646\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/20\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 1.6756 - acc: 0.2962 - val_loss: 1.0225 - val_acc: 0.1310\n",
      "Epoch 2/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 1.0510 - acc: 0.1103 - val_loss: 1.0892 - val_acc: 0.0980\n",
      "Epoch 3/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 1.0946 - acc: 0.0943 - val_loss: 1.0640 - val_acc: 0.0935\n",
      "Epoch 4/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 1.0343 - acc: 0.0934 - val_loss: 0.9850 - val_acc: 0.0950\n",
      "Epoch 5/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.9687 - acc: 0.0959 - val_loss: 0.9325 - val_acc: 0.0972\n",
      "Epoch 6/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.9271 - acc: 0.0971 - val_loss: 0.9031 - val_acc: 0.0964\n",
      "Epoch 7/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.8971 - acc: 0.0930 - val_loss: 0.8646 - val_acc: 0.0872\n",
      "Epoch 8/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.8453 - acc: 0.0805 - val_loss: 0.8023 - val_acc: 0.0714\n",
      "Epoch 9/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.7627 - acc: 0.0605 - val_loss: 0.6956 - val_acc: 0.0461\n",
      "Epoch 10/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6499 - acc: 0.0307 - val_loss: 0.5961 - val_acc: 0.0141\n",
      "Epoch 11/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5696 - acc: 0.0056 - val_loss: 0.5374 - val_acc: 4.8000e-04\n",
      "Epoch 12/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5238 - acc: 1.2000e-04 - val_loss: 0.5059 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5017 - acc: 0.0000e+00 - val_loss: 0.4930 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4932 - acc: 0.0000e+00 - val_loss: 0.4895 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4914 - acc: 0.0000e+00 - val_loss: 0.4889 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4913 - acc: 0.0000e+00 - val_loss: 0.4891 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4913 - acc: 0.0000e+00 - val_loss: 0.4890 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4913 - acc: 0.0000e+00 - val_loss: 0.4890 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4912 - acc: 0.0000e+00 - val_loss: 0.4889 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4912 - acc: 0.0000e+00 - val_loss: 0.4889 - val_acc: 0.0000e+00\n",
      "0.6 -0.010146319715301997 0.991120891188653\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/20\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 1.4593 - acc: 0.4219 - val_loss: 1.1993 - val_acc: 0.3328\n",
      "Epoch 2/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 1.2370 - acc: 0.3158 - val_loss: 1.1657 - val_acc: 0.3419\n",
      "Epoch 3/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 1.0849 - acc: 0.3869 - val_loss: 1.0366 - val_acc: 0.4269\n",
      "Epoch 4/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 1.0256 - acc: 0.4302 - val_loss: 1.0002 - val_acc: 0.4346\n",
      "Epoch 5/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.9785 - acc: 0.4355 - val_loss: 0.9546 - val_acc: 0.4382\n",
      "Epoch 6/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.9241 - acc: 0.4418 - val_loss: 0.8736 - val_acc: 0.4497\n",
      "Epoch 7/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.8250 - acc: 0.4540 - val_loss: 0.7586 - val_acc: 0.4625\n",
      "Epoch 8/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.7000 - acc: 0.4696 - val_loss: 0.6270 - val_acc: 0.4815\n",
      "Epoch 9/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5874 - acc: 0.4855 - val_loss: 0.5348 - val_acc: 0.4950\n",
      "Epoch 10/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5089 - acc: 0.4998 - val_loss: 0.4848 - val_acc: 0.5057\n",
      "Epoch 11/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4774 - acc: 0.5047 - val_loss: 0.4722 - val_acc: 0.5093\n",
      "Epoch 12/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4725 - acc: 0.5097 - val_loss: 0.4722 - val_acc: 0.5103\n",
      "Epoch 13/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4717 - acc: 0.5096 - val_loss: 0.4709 - val_acc: 0.5116\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4700 - acc: 0.5085 - val_loss: 0.4688 - val_acc: 0.5079\n",
      "Epoch 15/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4685 - acc: 0.5070 - val_loss: 0.4678 - val_acc: 0.5086\n",
      "Epoch 16/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4676 - acc: 0.5059 - val_loss: 0.4669 - val_acc: 0.5074\n",
      "Epoch 17/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4669 - acc: 0.5058 - val_loss: 0.4661 - val_acc: 0.5060\n",
      "Epoch 18/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4662 - acc: 0.5055 - val_loss: 0.4654 - val_acc: 0.5066\n",
      "Epoch 19/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4656 - acc: 0.5041 - val_loss: 0.4649 - val_acc: 0.5071\n",
      "Epoch 20/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4652 - acc: 0.5049 - val_loss: 0.4642 - val_acc: 0.5052\n",
      "0.7 -0.08068898214116356 1.010673223987831\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/20\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 1.5962 - acc: 0.2011 - val_loss: 1.3752 - val_acc: 0.0698\n",
      "Epoch 2/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 1.3890 - acc: 0.0651 - val_loss: 1.2904 - val_acc: 0.0671\n",
      "Epoch 3/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 1.1911 - acc: 0.0735 - val_loss: 1.1151 - val_acc: 0.0835\n",
      "Epoch 4/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 1.0819 - acc: 0.0845 - val_loss: 1.0196 - val_acc: 0.0794\n",
      "Epoch 5/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.9523 - acc: 0.0624 - val_loss: 0.8415 - val_acc: 0.0415\n",
      "Epoch 6/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.7453 - acc: 0.0227 - val_loss: 0.6427 - val_acc: 0.0059\n",
      "Epoch 7/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5862 - acc: 0.0014 - val_loss: 0.5265 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4886 - acc: 1.1000e-04 - val_loss: 0.4556 - val_acc: 8.5000e-04\n",
      "Epoch 9/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4340 - acc: 0.0083 - val_loss: 0.4246 - val_acc: 0.0181\n",
      "Epoch 10/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4148 - acc: 0.0231 - val_loss: 0.4207 - val_acc: 0.0307\n",
      "Epoch 11/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4136 - acc: 0.0317 - val_loss: 0.4222 - val_acc: 0.0344\n",
      "Epoch 12/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4138 - acc: 0.0349 - val_loss: 0.4213 - val_acc: 0.0298\n",
      "Epoch 13/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4133 - acc: 0.0267 - val_loss: 0.4236 - val_acc: 0.0142\n",
      "Epoch 14/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4141 - acc: 0.0194 - val_loss: 0.4211 - val_acc: 0.0397\n",
      "Epoch 15/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4133 - acc: 0.0300 - val_loss: 0.4201 - val_acc: 0.0185\n",
      "Epoch 16/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4122 - acc: 0.0240 - val_loss: 0.4190 - val_acc: 0.0309\n",
      "Epoch 17/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4117 - acc: 0.0272 - val_loss: 0.4189 - val_acc: 0.0284\n",
      "Epoch 18/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4114 - acc: 0.0288 - val_loss: 0.4188 - val_acc: 0.0296\n",
      "Epoch 19/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4112 - acc: 0.0271 - val_loss: 0.4185 - val_acc: 0.0287\n",
      "Epoch 20/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4111 - acc: 0.0274 - val_loss: 0.4183 - val_acc: 0.0261\n",
      "0.8 -0.1853843141064264 1.0173079602545878\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/20\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 1.7150 - acc: 0.3872 - val_loss: 1.3476 - val_acc: 0.3428\n",
      "Epoch 2/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 1.4111 - acc: 0.3256 - val_loss: 1.3642 - val_acc: 0.3362\n",
      "Epoch 3/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 1.2559 - acc: 0.3636 - val_loss: 1.1365 - val_acc: 0.3877\n",
      "Epoch 4/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 1.1081 - acc: 0.3839 - val_loss: 1.0604 - val_acc: 0.3813\n",
      "Epoch 5/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 1.0068 - acc: 0.3852 - val_loss: 0.9195 - val_acc: 0.3992\n",
      "Epoch 6/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.8343 - acc: 0.4201 - val_loss: 0.7289 - val_acc: 0.4532\n",
      "Epoch 7/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.6622 - acc: 0.4769 - val_loss: 0.5879 - val_acc: 0.4946\n",
      "Epoch 8/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5388 - acc: 0.4991 - val_loss: 0.4838 - val_acc: 0.4998\n",
      "Epoch 9/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4476 - acc: 0.5054 - val_loss: 0.4107 - val_acc: 0.5150\n",
      "Epoch 10/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.3880 - acc: 0.5250 - val_loss: 0.3700 - val_acc: 0.5368\n",
      "Epoch 11/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.3599 - acc: 0.4962 - val_loss: 0.3568 - val_acc: 0.4577\n",
      "Epoch 12/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.3537 - acc: 0.4400 - val_loss: 0.3561 - val_acc: 0.4141\n",
      "Epoch 13/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.3532 - acc: 0.4148 - val_loss: 0.3568 - val_acc: 0.3991\n",
      "Epoch 14/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.3852 - acc: 0.4416 - val_loss: 0.3733 - val_acc: 0.4503\n",
      "Epoch 15/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4024 - acc: 0.3156 - val_loss: 0.3710 - val_acc: 0.3574\n",
      "Epoch 16/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.3753 - acc: 0.4598 - val_loss: 0.3568 - val_acc: 0.4529\n",
      "Epoch 17/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.3613 - acc: 0.3969 - val_loss: 0.3577 - val_acc: 0.4114\n",
      "Epoch 18/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.3826 - acc: 0.4846 - val_loss: 0.3613 - val_acc: 0.4547\n",
      "Epoch 19/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.3630 - acc: 0.3801 - val_loss: 0.3604 - val_acc: 0.3801\n",
      "Epoch 20/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.3534 - acc: 0.4243 - val_loss: 0.3535 - val_acc: 0.4197\n",
      "0.9 -0.31731253729873876 1.0231339835889148\n",
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/20\n",
      "100000/100000 [==============================] - 1s 5us/step - loss: 1.6169 - acc: 0.3470 - val_loss: 1.5145 - val_acc: 0.3182\n",
      "Epoch 2/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 1.2581 - acc: 0.3570 - val_loss: 1.0286 - val_acc: 0.3535\n",
      "Epoch 3/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.8902 - acc: 0.3928 - val_loss: 0.6720 - val_acc: 0.4836\n",
      "Epoch 4/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.5670 - acc: 0.4960 - val_loss: 0.4687 - val_acc: 0.4998\n",
      "Epoch 5/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.3954 - acc: 0.5387 - val_loss: 0.3399 - val_acc: 0.5891\n",
      "Epoch 6/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.3051 - acc: 0.4912 - val_loss: 0.2878 - val_acc: 0.4072\n",
      "Epoch 7/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.2772 - acc: 0.4081 - val_loss: 0.2834 - val_acc: 0.3734\n",
      "Epoch 8/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.2776 - acc: 0.3563 - val_loss: 0.2842 - val_acc: 0.3917\n",
      "Epoch 9/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.2750 - acc: 0.3898 - val_loss: 0.2902 - val_acc: 0.4225\n",
      "Epoch 10/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.2767 - acc: 0.3831 - val_loss: 0.2825 - val_acc: 0.3520\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.2753 - acc: 0.4047 - val_loss: 0.2860 - val_acc: 0.4257\n",
      "Epoch 12/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.2767 - acc: 0.3606 - val_loss: 0.2761 - val_acc: 0.3808\n",
      "Epoch 13/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.3013 - acc: 0.3608 - val_loss: 0.3709 - val_acc: 0.2383\n",
      "Epoch 14/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.2986 - acc: 0.4074 - val_loss: 0.2771 - val_acc: 0.4127\n",
      "Epoch 15/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.2771 - acc: 0.3881 - val_loss: 0.2855 - val_acc: 0.4656\n",
      "Epoch 16/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.2740 - acc: 0.4207 - val_loss: 0.2760 - val_acc: 0.3512\n",
      "Epoch 17/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.2957 - acc: 0.4233 - val_loss: 0.3182 - val_acc: 0.4537\n",
      "Epoch 18/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.3140 - acc: 0.2919 - val_loss: 0.2757 - val_acc: 0.4051\n",
      "Epoch 19/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.2862 - acc: 0.3681 - val_loss: 0.2983 - val_acc: 0.3128\n",
      "Epoch 20/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.2736 - acc: 0.3942 - val_loss: 0.2917 - val_acc: 0.3440\n",
      "1.0 -0.5243510083724454 1.1070758286130618\n"
     ]
    }
   ],
   "source": [
    "N = 100000\n",
    "\n",
    "term1 = []\n",
    "term2 = []\n",
    "for theta0 in [0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.]:\n",
    "\n",
    "    X_MC = np.random.normal(theta0,0.5,N)\n",
    "    X_data = np.random.normal(0.5,0.5,N)\n",
    "\n",
    "    X_MLE_train, X_MLE_val, Y_MLE_train, Y_MLE_val = train_test_split(np.concatenate([X_data,X_MC]), np.concatenate([np.ones(len(X_data)),np.zeros(len(X_MC))]), test_size=0.5)\n",
    "\n",
    "    def CustomLoss(y_true, y_pred):\n",
    "        return -y_true*K.log(y_pred**2+0.00000001) + (1.-y_true)*y_pred**2\n",
    "\n",
    "    K.clear_session()\n",
    "    \n",
    "    model_MLE = Sequential()\n",
    "    model_MLE.add(Dense(64, activation='elu',input_shape =(1,))) \n",
    "    model_MLE.add(Dense(128, activation='elu'))\n",
    "    model_MLE.add(Dense(64, activation='elu'))\n",
    "    model_MLE.add(Dense(1, activation='linear')) #was sigmoid\n",
    "    model_MLE.compile(loss=lambda y_true, y_pred: CustomLoss(y_true, y_pred), optimizer='adam', metrics=['accuracy'])\n",
    "    hist_MLE = model_MLE.fit(X_MLE_train, Y_MLE_train, epochs=20, batch_size=int(0.1*len(X_MLE_train)),validation_data=(X_MLE_val, Y_MLE_val))\n",
    "\n",
    "    preds = model_MLE.predict(X_MLE_val)**2\n",
    "    preds = -Y_MLE_val*np.log(preds[:,0]+0.00000001) + (1.-Y_MLE_val)*preds[:,0]\n",
    "    print(theta0,np.mean(preds[Y_MLE_val==1]),np.mean(preds[Y_MLE_val==0]))\n",
    "    term1+=[np.mean(preds[Y_MLE_val==1])]\n",
    "    term2+=[np.mean(preds[Y_MLE_val==0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe7e0679438>"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "gs = gridspec.GridSpec(1, 1) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ax0.minorticks_on()\n",
    "\n",
    "plt.plot([0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.],term1,label=\"$E[-log(f)]$ (data, $\\mu=0.5$)\")\n",
    "plt.plot([0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.],term2,label=\"$E[f]$ (MC)\")\n",
    "plt.xlabel(\"$\\mu_{MC}$\",fontsize=20)\n",
    "plt.ylabel(\"Loss value\",fontsize=20)\n",
    "plt.legend(frameon=False,fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples, validate on 100000 samples\n",
      "Epoch 1/20\n",
      "100000/100000 [==============================] - 10s 100us/step - loss: 1.9439 - acc: 0.4832 - val_loss: 1.1185 - val_acc: 0.4162\n",
      "Epoch 2/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.8440 - acc: 0.3225 - val_loss: 0.5953 - val_acc: 0.2169\n",
      "Epoch 3/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.5360 - acc: 0.1462 - val_loss: 0.5254 - val_acc: 0.0854\n",
      "Epoch 4/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.5181 - acc: 0.0693 - val_loss: 0.4956 - val_acc: 0.0649\n",
      "Epoch 5/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4808 - acc: 0.0697 - val_loss: 0.4689 - val_acc: 0.0700\n",
      "Epoch 6/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4600 - acc: 0.0459 - val_loss: 0.4501 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4418 - acc: 0.0000e+00 - val_loss: 0.4347 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4282 - acc: 0.0000e+00 - val_loss: 0.4239 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4192 - acc: 0.0000e+00 - val_loss: 0.4176 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4142 - acc: 0.0000e+00 - val_loss: 0.4143 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4118 - acc: 0.0000e+00 - val_loss: 0.4130 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4109 - acc: 0.0000e+00 - val_loss: 0.4125 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4106 - acc: 0.0000e+00 - val_loss: 0.4122 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4104 - acc: 0.0000e+00 - val_loss: 0.4120 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "100000/100000 [==============================] - 0s 1us/step - loss: 0.4103 - acc: 0.0000e+00 - val_loss: 0.4119 - val_acc: 8.1000e-04\n",
      "Epoch 16/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4101 - acc: 0.0011 - val_loss: 0.4118 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4101 - acc: 0.0021 - val_loss: 0.4117 - val_acc: 0.0060\n",
      "Epoch 18/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4100 - acc: 0.0064 - val_loss: 0.4117 - val_acc: 0.0081\n",
      "Epoch 19/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4100 - acc: 0.0059 - val_loss: 0.4117 - val_acc: 0.0065\n",
      "Epoch 20/20\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 0.4099 - acc: 0.0092 - val_loss: 0.4116 - val_acc: 0.0091\n"
     ]
    }
   ],
   "source": [
    "N = 100000\n",
    "\n",
    "theta0 = 0.2\n",
    "\n",
    "X_MC = np.random.normal(theta0,0.5,N)\n",
    "X_data = np.random.normal(0.5,0.5,N)\n",
    "\n",
    "X_MLE_train, X_MLE_val, Y_MLE_train, Y_MLE_val = train_test_split(np.concatenate([X_data,X_MC]), np.concatenate([np.ones(len(X_data)),np.zeros(len(X_MC))]), test_size=0.5)\n",
    "\n",
    "def CustomLoss(y_true, y_pred):\n",
    "    return -y_true*K.log(y_pred**2+0.00000001) + (1.-y_true)*y_pred**2\n",
    "    #return -y_true*K.log(K.exp(y_pred)) + (1.-y_true)*K.exp(y_pred)\n",
    "\n",
    "model_MLE = Sequential()\n",
    "model_MLE.add(Dense(64, activation='relu',input_shape =(1,))) \n",
    "model_MLE.add(Dense(128, activation='relu'))\n",
    "model_MLE.add(Dense(64, activation='relu'))\n",
    "model_MLE.add(Dense(1, activation='linear')) #was sigmoid\n",
    "model_MLE.compile(loss=lambda y_true, y_pred: CustomLoss(y_true, y_pred), optimizer='adam', metrics=['accuracy'])\n",
    "hist_MLE = model_MLE.fit(X_MLE_train, Y_MLE_train, epochs=20, batch_size=int(0.1*len(X_MLE_train)),validation_data=(X_MLE_val, Y_MLE_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe8d0ceada0>"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "xx = np.linspace(-3,3,100)\n",
    "preds_test = model_MLE.predict(xx)**2\n",
    "plot1 = plt.plot(xx,preds_test,label=\"learned\",ls=\"-\",color='green')\n",
    "plot2 = plt.plot(xx,np.exp(-((xx-0.5)**2-(xx-theta0)**2)/(2*0.5**2)),label=\"exact\",color='orange')\n",
    "plt.ylim([0,2])\n",
    "plt.axvline(0,ls=\":\",color=\"grey\")\n",
    "plt.axhline(1,ls=\":\",color=\"grey\")\n",
    "plt.xlabel(r\"$x$\")\n",
    "plt.ylabel(\"likelihood ratio\")\n",
    "plt.title(r\"quadratic, $\\mu_{MC} = \"+str(theta0)+r\", \\mu_{data}=0.5$, loss =\"+\"%0.2f\" % hist_MLE.history['val_loss'][-1],loc=\"right\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "_,_,_=plt.hist(MC,bins=np.linspace(-3,3,50),alpha=0.3,label=\"MC\",color='red')\n",
    "_,_,_=plt.hist(data,bins=np.linspace(-3,3,50),alpha=0.3,label=\"Data\")\n",
    "ax2.tick_params(axis='y', labelcolor=\"red\")\n",
    "ax2.set_ylabel(\"histogram\",color='red')\n",
    "leg = plt.legend([plot1[0],plot2[0]],['learned','exact'], loc=\"lower left\",)\n",
    "plt.legend()\n",
    "plt.gca().add_artist(leg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.6882 - acc: 0.3783 - val_loss: 0.7517 - val_acc: 0.2415\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6947 - acc: 0.2113 - val_loss: 0.6722 - val_acc: 0.1865\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6754 - acc: 0.1793 - val_loss: 0.6809 - val_acc: 0.1718\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6799 - acc: 0.1710 - val_loss: 0.6769 - val_acc: 0.1693\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6713 - acc: 0.1713 - val_loss: 0.6649 - val_acc: 0.1722\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6614 - acc: 0.1755 - val_loss: 0.6557 - val_acc: 0.1767\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6533 - acc: 0.1793 - val_loss: 0.6485 - val_acc: 0.1796\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6483 - acc: 0.1820 - val_loss: 0.6468 - val_acc: 0.1814\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6458 - acc: 0.1830 - val_loss: 0.6423 - val_acc: 0.1815\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6412 - acc: 0.1824 - val_loss: 0.6376 - val_acc: 0.1802\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6337 - acc: 0.1806 - val_loss: 0.6276 - val_acc: 0.1777\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6254 - acc: 0.1779 - val_loss: 0.6210 - val_acc: 0.1751\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6181 - acc: 0.1754 - val_loss: 0.6135 - val_acc: 0.1726\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6067 - acc: 0.1721 - val_loss: 0.6006 - val_acc: 0.1690\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5946 - acc: 0.1684 - val_loss: 0.5886 - val_acc: 0.1651\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5816 - acc: 0.1641 - val_loss: 0.5712 - val_acc: 0.1600\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5648 - acc: 0.1577 - val_loss: 0.5528 - val_acc: 0.1531\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5436 - acc: 0.1496 - val_loss: 0.5274 - val_acc: 0.1425\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5102 - acc: 0.1341 - val_loss: 0.4845 - val_acc: 0.1193\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4686 - acc: 0.1057 - val_loss: 0.4491 - val_acc: 0.0863\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4393 - acc: 0.0728 - val_loss: 0.4300 - val_acc: 0.0567\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4289 - acc: 0.0521 - val_loss: 0.4267 - val_acc: 0.0472\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4263 - acc: 0.0383 - val_loss: 0.4249 - val_acc: 0.0285\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4260 - acc: 0.0265 - val_loss: 0.4248 - val_acc: 0.0246\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4251 - acc: 0.0258 - val_loss: 0.4238 - val_acc: 0.0251\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4242 - acc: 0.0262 - val_loss: 0.4227 - val_acc: 0.0271\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4231 - acc: 0.0293 - val_loss: 0.4217 - val_acc: 0.0303\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4225 - acc: 0.0325 - val_loss: 0.4212 - val_acc: 0.0327\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4219 - acc: 0.0336 - val_loss: 0.4207 - val_acc: 0.0328\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4214 - acc: 0.0323 - val_loss: 0.4202 - val_acc: 0.0304\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4209 - acc: 0.0316 - val_loss: 0.4198 - val_acc: 0.0315\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4204 - acc: 0.0313 - val_loss: 0.4193 - val_acc: 0.0299\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4199 - acc: 0.0304 - val_loss: 0.4188 - val_acc: 0.0299\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4195 - acc: 0.0304 - val_loss: 0.4184 - val_acc: 0.0297\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4190 - acc: 0.0302 - val_loss: 0.4179 - val_acc: 0.0296\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4186 - acc: 0.0295 - val_loss: 0.4175 - val_acc: 0.0284\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4181 - acc: 0.0286 - val_loss: 0.4171 - val_acc: 0.0280\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4177 - acc: 0.0283 - val_loss: 0.4167 - val_acc: 0.0268\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4173 - acc: 0.0272 - val_loss: 0.4163 - val_acc: 0.0263\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4168 - acc: 0.0269 - val_loss: 0.4159 - val_acc: 0.0263\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4165 - acc: 0.0268 - val_loss: 0.4155 - val_acc: 0.0260\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4161 - acc: 0.0262 - val_loss: 0.4151 - val_acc: 0.0250\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4157 - acc: 0.0256 - val_loss: 0.4147 - val_acc: 0.0248\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4154 - acc: 0.0253 - val_loss: 0.4144 - val_acc: 0.0241\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4151 - acc: 0.0241 - val_loss: 0.4141 - val_acc: 0.0231\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4148 - acc: 0.0235 - val_loss: 0.4138 - val_acc: 0.0229\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4145 - acc: 0.0228 - val_loss: 0.4135 - val_acc: 0.0221\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4142 - acc: 0.0217 - val_loss: 0.4133 - val_acc: 0.0209\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4140 - acc: 0.0212 - val_loss: 0.4130 - val_acc: 0.0206\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4137 - acc: 0.0209 - val_loss: 0.4128 - val_acc: 0.0199\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.4460 - acc: 0.5538 - val_loss: 0.7189 - val_acc: 0.5005\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6813 - acc: 0.4123 - val_loss: 0.6873 - val_acc: 0.3376\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6958 - acc: 0.3237 - val_loss: 0.6927 - val_acc: 0.3200\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6675 - acc: 0.3392 - val_loss: 0.6373 - val_acc: 0.3639\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6207 - acc: 0.3899 - val_loss: 0.6043 - val_acc: 0.4143\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5910 - acc: 0.4294 - val_loss: 0.5780 - val_acc: 0.4401\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5670 - acc: 0.4412 - val_loss: 0.5575 - val_acc: 0.4387\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5428 - acc: 0.4396 - val_loss: 0.5277 - val_acc: 0.4390\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5133 - acc: 0.4444 - val_loss: 0.4961 - val_acc: 0.4478\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4817 - acc: 0.4572 - val_loss: 0.4626 - val_acc: 0.4660\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4561 - acc: 0.4706 - val_loss: 0.4409 - val_acc: 0.4800\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4316 - acc: 0.4967 - val_loss: 0.4221 - val_acc: 0.5078\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4210 - acc: 0.5102 - val_loss: 0.4212 - val_acc: 0.5083\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4211 - acc: 0.5039 - val_loss: 0.4213 - val_acc: 0.4972\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4202 - acc: 0.4964 - val_loss: 0.4199 - val_acc: 0.4960\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4192 - acc: 0.4979 - val_loss: 0.4193 - val_acc: 0.4955\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4192 - acc: 0.4942 - val_loss: 0.4193 - val_acc: 0.4919\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4190 - acc: 0.4952 - val_loss: 0.4187 - val_acc: 0.5004\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4185 - acc: 0.5025 - val_loss: 0.4187 - val_acc: 0.4985\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4180 - acc: 0.4941 - val_loss: 0.4182 - val_acc: 0.4872\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4175 - acc: 0.4878 - val_loss: 0.4176 - val_acc: 0.4884\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4171 - acc: 0.4914 - val_loss: 0.4172 - val_acc: 0.4911\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4168 - acc: 0.4899 - val_loss: 0.4169 - val_acc: 0.4863\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4165 - acc: 0.4868 - val_loss: 0.4166 - val_acc: 0.4858\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4162 - acc: 0.4870 - val_loss: 0.4164 - val_acc: 0.4849\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4159 - acc: 0.4855 - val_loss: 0.4161 - val_acc: 0.4832\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4157 - acc: 0.4834 - val_loss: 0.4159 - val_acc: 0.4815\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4155 - acc: 0.4822 - val_loss: 0.4157 - val_acc: 0.4784\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4153 - acc: 0.4789 - val_loss: 0.4155 - val_acc: 0.4789\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4150 - acc: 0.4816 - val_loss: 0.4152 - val_acc: 0.4803\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4148 - acc: 0.4799 - val_loss: 0.4149 - val_acc: 0.4773\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4145 - acc: 0.4777 - val_loss: 0.4147 - val_acc: 0.4751\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4142 - acc: 0.4762 - val_loss: 0.4144 - val_acc: 0.4743\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4140 - acc: 0.4751 - val_loss: 0.4142 - val_acc: 0.4729\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4137 - acc: 0.4744 - val_loss: 0.4139 - val_acc: 0.4711\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4135 - acc: 0.4701 - val_loss: 0.4137 - val_acc: 0.4684\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4132 - acc: 0.4707 - val_loss: 0.4135 - val_acc: 0.4696\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4130 - acc: 0.4704 - val_loss: 0.4133 - val_acc: 0.4669\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4128 - acc: 0.4670 - val_loss: 0.4130 - val_acc: 0.4646\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4125 - acc: 0.4655 - val_loss: 0.4128 - val_acc: 0.4637\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4123 - acc: 0.4648 - val_loss: 0.4126 - val_acc: 0.4614\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4121 - acc: 0.4617 - val_loss: 0.4124 - val_acc: 0.4596\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4119 - acc: 0.4614 - val_loss: 0.4122 - val_acc: 0.4597\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4117 - acc: 0.4599 - val_loss: 0.4121 - val_acc: 0.4564\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4115 - acc: 0.4572 - val_loss: 0.4119 - val_acc: 0.4550\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4114 - acc: 0.4562 - val_loss: 0.4117 - val_acc: 0.4536\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4112 - acc: 0.4542 - val_loss: 0.4116 - val_acc: 0.4506\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4110 - acc: 0.4535 - val_loss: 0.4115 - val_acc: 0.4516\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4109 - acc: 0.4517 - val_loss: 0.4114 - val_acc: 0.4465\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4108 - acc: 0.4475 - val_loss: 0.4113 - val_acc: 0.4463\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.1296 - acc: 0.5064 - val_loss: 0.6824 - val_acc: 0.3491\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7425 - acc: 0.2947 - val_loss: 0.7431 - val_acc: 0.2838\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6797 - acc: 0.3282 - val_loss: 0.6137 - val_acc: 0.3965\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6064 - acc: 0.4426 - val_loss: 0.5976 - val_acc: 0.4737\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5849 - acc: 0.4703 - val_loss: 0.5556 - val_acc: 0.4604\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5304 - acc: 0.4555 - val_loss: 0.4980 - val_acc: 0.4505\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4776 - acc: 0.4593 - val_loss: 0.4516 - val_acc: 0.4743\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4359 - acc: 0.5011 - val_loss: 0.4248 - val_acc: 0.5228\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4263 - acc: 0.5148 - val_loss: 0.4254 - val_acc: 0.5080\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4256 - acc: 0.5004 - val_loss: 0.4229 - val_acc: 0.4992\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4227 - acc: 0.5033 - val_loss: 0.4215 - val_acc: 0.5088\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4221 - acc: 0.5089 - val_loss: 0.4212 - val_acc: 0.5036\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4231 - acc: 0.4892 - val_loss: 0.4216 - val_acc: 0.4933\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4216 - acc: 0.5039 - val_loss: 0.4208 - val_acc: 0.5091\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4211 - acc: 0.5014 - val_loss: 0.4200 - val_acc: 0.4946\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4205 - acc: 0.4963 - val_loss: 0.4195 - val_acc: 0.4997\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4201 - acc: 0.4992 - val_loss: 0.4191 - val_acc: 0.4955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4196 - acc: 0.4928 - val_loss: 0.4187 - val_acc: 0.4934\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4192 - acc: 0.4930 - val_loss: 0.4184 - val_acc: 0.4932\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4189 - acc: 0.4910 - val_loss: 0.4181 - val_acc: 0.4909\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4187 - acc: 0.4917 - val_loss: 0.4178 - val_acc: 0.4896\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4184 - acc: 0.4863 - val_loss: 0.4176 - val_acc: 0.4862\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4181 - acc: 0.4867 - val_loss: 0.4172 - val_acc: 0.4878\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4179 - acc: 0.4860 - val_loss: 0.4170 - val_acc: 0.4862\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4176 - acc: 0.4848 - val_loss: 0.4168 - val_acc: 0.4841\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4174 - acc: 0.4828 - val_loss: 0.4166 - val_acc: 0.4832\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4173 - acc: 0.4831 - val_loss: 0.4163 - val_acc: 0.4814\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4170 - acc: 0.4809 - val_loss: 0.4161 - val_acc: 0.4807\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4168 - acc: 0.4794 - val_loss: 0.4160 - val_acc: 0.4799\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4167 - acc: 0.4773 - val_loss: 0.4158 - val_acc: 0.4776\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4165 - acc: 0.4796 - val_loss: 0.4155 - val_acc: 0.4775\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4163 - acc: 0.4755 - val_loss: 0.4154 - val_acc: 0.4757\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4161 - acc: 0.4764 - val_loss: 0.4152 - val_acc: 0.4752\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4159 - acc: 0.4742 - val_loss: 0.4150 - val_acc: 0.4734\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4158 - acc: 0.4711 - val_loss: 0.4148 - val_acc: 0.4716\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4156 - acc: 0.4744 - val_loss: 0.4147 - val_acc: 0.4739\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4154 - acc: 0.4692 - val_loss: 0.4146 - val_acc: 0.4675\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4153 - acc: 0.4710 - val_loss: 0.4144 - val_acc: 0.4700\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4152 - acc: 0.4664 - val_loss: 0.4142 - val_acc: 0.4679\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4150 - acc: 0.4682 - val_loss: 0.4141 - val_acc: 0.4664\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4149 - acc: 0.4662 - val_loss: 0.4140 - val_acc: 0.4654\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4147 - acc: 0.4656 - val_loss: 0.4138 - val_acc: 0.4638\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4146 - acc: 0.4621 - val_loss: 0.4137 - val_acc: 0.4654\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4145 - acc: 0.4637 - val_loss: 0.4136 - val_acc: 0.4609\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4144 - acc: 0.4620 - val_loss: 0.4135 - val_acc: 0.4588\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4143 - acc: 0.4597 - val_loss: 0.4134 - val_acc: 0.4605\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4141 - acc: 0.4595 - val_loss: 0.4133 - val_acc: 0.4563\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4141 - acc: 0.4567 - val_loss: 0.4132 - val_acc: 0.4587\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4140 - acc: 0.4583 - val_loss: 0.4131 - val_acc: 0.4548\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4139 - acc: 0.4554 - val_loss: 0.4131 - val_acc: 0.4537\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 1s 3us/step - loss: 1.2704 - acc: 0.3411 - val_loss: 0.6612 - val_acc: 0.1889\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6867 - acc: 0.1599 - val_loss: 0.7201 - val_acc: 0.1436\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7050 - acc: 0.1467 - val_loss: 0.6596 - val_acc: 0.1554\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6405 - acc: 0.1643 - val_loss: 0.6222 - val_acc: 0.1745\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6096 - acc: 0.1754 - val_loss: 0.5917 - val_acc: 0.1720\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5744 - acc: 0.1641 - val_loss: 0.5522 - val_acc: 0.1521\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5315 - acc: 0.1413 - val_loss: 0.5141 - val_acc: 0.1299\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4996 - acc: 0.1220 - val_loss: 0.4738 - val_acc: 0.1083\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4588 - acc: 0.0936 - val_loss: 0.4354 - val_acc: 0.0684\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4313 - acc: 0.0388 - val_loss: 0.4297 - val_acc: 0.0158\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4303 - acc: 0.0149 - val_loss: 0.4274 - val_acc: 0.0176\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4267 - acc: 0.0219 - val_loss: 0.4217 - val_acc: 0.0286\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4229 - acc: 0.0325 - val_loss: 0.4213 - val_acc: 0.0376\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4225 - acc: 0.0398 - val_loss: 0.4210 - val_acc: 0.0407\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4221 - acc: 0.0395 - val_loss: 0.4201 - val_acc: 0.0373\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4213 - acc: 0.0349 - val_loss: 0.4194 - val_acc: 0.0324\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4209 - acc: 0.0304 - val_loss: 0.4189 - val_acc: 0.0307\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4204 - acc: 0.0304 - val_loss: 0.4184 - val_acc: 0.0305\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4199 - acc: 0.0297 - val_loss: 0.4181 - val_acc: 0.0300\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4195 - acc: 0.0296 - val_loss: 0.4177 - val_acc: 0.0302\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4191 - acc: 0.0299 - val_loss: 0.4173 - val_acc: 0.0304\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4188 - acc: 0.0298 - val_loss: 0.4170 - val_acc: 0.0300\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4185 - acc: 0.0298 - val_loss: 0.4167 - val_acc: 0.0307\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4183 - acc: 0.0303 - val_loss: 0.4165 - val_acc: 0.0315\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4181 - acc: 0.0308 - val_loss: 0.4162 - val_acc: 0.0308\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4178 - acc: 0.0295 - val_loss: 0.4160 - val_acc: 0.0294\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4196 - acc: 0.0200 - val_loss: 0.4222 - val_acc: 0.0060\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4209 - acc: 0.0103 - val_loss: 0.4167 - val_acc: 0.0194\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4176 - acc: 0.0255 - val_loss: 0.4151 - val_acc: 0.0312\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4170 - acc: 0.0324 - val_loss: 0.4150 - val_acc: 0.0328\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4165 - acc: 0.0307 - val_loss: 0.4146 - val_acc: 0.0283\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4164 - acc: 0.0251 - val_loss: 0.4145 - val_acc: 0.0240\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4162 - acc: 0.0245 - val_loss: 0.4143 - val_acc: 0.0260\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4161 - acc: 0.0259 - val_loss: 0.4142 - val_acc: 0.0269\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4160 - acc: 0.0264 - val_loss: 0.4141 - val_acc: 0.0266\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4159 - acc: 0.0254 - val_loss: 0.4140 - val_acc: 0.0253\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4158 - acc: 0.0251 - val_loss: 0.4139 - val_acc: 0.0261\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4157 - acc: 0.0246 - val_loss: 0.4138 - val_acc: 0.0248\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4155 - acc: 0.0241 - val_loss: 0.4136 - val_acc: 0.0250\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4155 - acc: 0.0243 - val_loss: 0.4136 - val_acc: 0.0247\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4153 - acc: 0.0239 - val_loss: 0.4135 - val_acc: 0.0239\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4153 - acc: 0.0235 - val_loss: 0.4134 - val_acc: 0.0246\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4152 - acc: 0.0231 - val_loss: 0.4133 - val_acc: 0.0232\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4151 - acc: 0.0227 - val_loss: 0.4132 - val_acc: 0.0236\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4150 - acc: 0.0229 - val_loss: 0.4131 - val_acc: 0.0227\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4150 - acc: 0.0213 - val_loss: 0.4130 - val_acc: 0.0218\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4149 - acc: 0.0214 - val_loss: 0.4129 - val_acc: 0.0215\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4148 - acc: 0.0208 - val_loss: 0.4129 - val_acc: 0.0216\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4148 - acc: 0.0220 - val_loss: 0.4128 - val_acc: 0.0218\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4147 - acc: 0.0199 - val_loss: 0.4127 - val_acc: 0.0198\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.1539 - acc: 0.5138 - val_loss: 0.6832 - val_acc: 0.3699\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7255 - acc: 0.3088 - val_loss: 0.7409 - val_acc: 0.2894\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6708 - acc: 0.3308 - val_loss: 0.6164 - val_acc: 0.3963\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5996 - acc: 0.4434 - val_loss: 0.5860 - val_acc: 0.4814\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5691 - acc: 0.4764 - val_loss: 0.5397 - val_acc: 0.4653\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5170 - acc: 0.4525 - val_loss: 0.4929 - val_acc: 0.4438\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4736 - acc: 0.4592 - val_loss: 0.4422 - val_acc: 0.4941\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4324 - acc: 0.5164 - val_loss: 0.4277 - val_acc: 0.5164\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4283 - acc: 0.5120 - val_loss: 0.4285 - val_acc: 0.5023\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4256 - acc: 0.5036 - val_loss: 0.4232 - val_acc: 0.5091\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4228 - acc: 0.5124 - val_loss: 0.4225 - val_acc: 0.5091\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4229 - acc: 0.5093 - val_loss: 0.4267 - val_acc: 0.5111\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4258 - acc: 0.5080 - val_loss: 0.4237 - val_acc: 0.4932\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4220 - acc: 0.4894 - val_loss: 0.4205 - val_acc: 0.4966\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4205 - acc: 0.5030 - val_loss: 0.4203 - val_acc: 0.5040\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4219 - acc: 0.4849 - val_loss: 0.4226 - val_acc: 0.4779\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4215 - acc: 0.4909 - val_loss: 0.4202 - val_acc: 0.5014\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4199 - acc: 0.5009 - val_loss: 0.4200 - val_acc: 0.4977\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4197 - acc: 0.4943 - val_loss: 0.4196 - val_acc: 0.4891\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4190 - acc: 0.4919 - val_loss: 0.4189 - val_acc: 0.4918\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4187 - acc: 0.4915 - val_loss: 0.4187 - val_acc: 0.4903\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4184 - acc: 0.4894 - val_loss: 0.4184 - val_acc: 0.4884\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4182 - acc: 0.4896 - val_loss: 0.4182 - val_acc: 0.4879\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4180 - acc: 0.4859 - val_loss: 0.4180 - val_acc: 0.4850\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4177 - acc: 0.4855 - val_loss: 0.4178 - val_acc: 0.4850\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4176 - acc: 0.4848 - val_loss: 0.4176 - val_acc: 0.4833\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4239 - acc: 0.4951 - val_loss: 0.4293 - val_acc: 0.4957\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4227 - acc: 0.4746 - val_loss: 0.4189 - val_acc: 0.4560\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4177 - acc: 0.4753 - val_loss: 0.4181 - val_acc: 0.4892\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4173 - acc: 0.4809 - val_loss: 0.4166 - val_acc: 0.4707\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4163 - acc: 0.4728 - val_loss: 0.4167 - val_acc: 0.4743\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4161 - acc: 0.4768 - val_loss: 0.4163 - val_acc: 0.4742\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4159 - acc: 0.4717 - val_loss: 0.4161 - val_acc: 0.4730\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4158 - acc: 0.4761 - val_loss: 0.4160 - val_acc: 0.4721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4157 - acc: 0.4682 - val_loss: 0.4160 - val_acc: 0.4702\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4155 - acc: 0.4733 - val_loss: 0.4158 - val_acc: 0.4696\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4154 - acc: 0.4675 - val_loss: 0.4157 - val_acc: 0.4693\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4153 - acc: 0.4704 - val_loss: 0.4156 - val_acc: 0.4671\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4152 - acc: 0.4673 - val_loss: 0.4156 - val_acc: 0.4671\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4151 - acc: 0.4670 - val_loss: 0.4155 - val_acc: 0.4648\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4150 - acc: 0.4651 - val_loss: 0.4154 - val_acc: 0.4647\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4149 - acc: 0.4666 - val_loss: 0.4153 - val_acc: 0.4654\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4149 - acc: 0.4627 - val_loss: 0.4153 - val_acc: 0.4620\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4148 - acc: 0.4646 - val_loss: 0.4152 - val_acc: 0.4621\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4147 - acc: 0.4620 - val_loss: 0.4151 - val_acc: 0.4614\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4146 - acc: 0.4622 - val_loss: 0.4151 - val_acc: 0.4596\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4145 - acc: 0.4590 - val_loss: 0.4150 - val_acc: 0.4608\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4145 - acc: 0.4626 - val_loss: 0.4150 - val_acc: 0.4575\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4145 - acc: 0.4549 - val_loss: 0.4150 - val_acc: 0.4610\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4145 - acc: 0.4627 - val_loss: 0.4151 - val_acc: 0.4509\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.1560 - acc: 0.5118 - val_loss: 0.6711 - val_acc: 0.3646\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7281 - acc: 0.3064 - val_loss: 0.7262 - val_acc: 0.2928\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6605 - acc: 0.3391 - val_loss: 0.6013 - val_acc: 0.4108\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5776 - acc: 0.4659 - val_loss: 0.5471 - val_acc: 0.5073\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5231 - acc: 0.4969 - val_loss: 0.4921 - val_acc: 0.4718\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4704 - acc: 0.4646 - val_loss: 0.4492 - val_acc: 0.4566\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4455 - acc: 0.4593 - val_loss: 0.4339 - val_acc: 0.4812\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4285 - acc: 0.5014 - val_loss: 0.4225 - val_acc: 0.5231\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4258 - acc: 0.5173 - val_loss: 0.4248 - val_acc: 0.5114\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4244 - acc: 0.5036 - val_loss: 0.4219 - val_acc: 0.4946\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4220 - acc: 0.5016 - val_loss: 0.4202 - val_acc: 0.5110\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4215 - acc: 0.5108 - val_loss: 0.4198 - val_acc: 0.5066\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4210 - acc: 0.5019 - val_loss: 0.4195 - val_acc: 0.5062\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4217 - acc: 0.5085 - val_loss: 0.4205 - val_acc: 0.5046\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4207 - acc: 0.4983 - val_loss: 0.4188 - val_acc: 0.4952\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4197 - acc: 0.5002 - val_loss: 0.4184 - val_acc: 0.5018\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4203 - acc: 0.4923 - val_loss: 0.4258 - val_acc: 0.4586\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4245 - acc: 0.4744 - val_loss: 0.4190 - val_acc: 0.5068\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4207 - acc: 0.5079 - val_loss: 0.4186 - val_acc: 0.4977\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4197 - acc: 0.4856 - val_loss: 0.4181 - val_acc: 0.4839\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4191 - acc: 0.4944 - val_loss: 0.4177 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4187 - acc: 0.4962 - val_loss: 0.4173 - val_acc: 0.4881\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4185 - acc: 0.4864 - val_loss: 0.4171 - val_acc: 0.4896\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4251 - acc: 0.4651 - val_loss: 0.4303 - val_acc: 0.4571\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4236 - acc: 0.4924 - val_loss: 0.4193 - val_acc: 0.5093\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4196 - acc: 0.4964 - val_loss: 0.4186 - val_acc: 0.4791\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4190 - acc: 0.4835 - val_loss: 0.4170 - val_acc: 0.4916\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4195 - acc: 0.4991 - val_loss: 0.4179 - val_acc: 0.4949\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4185 - acc: 0.4826 - val_loss: 0.4166 - val_acc: 0.4786\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4176 - acc: 0.4859 - val_loss: 0.4163 - val_acc: 0.4894\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4175 - acc: 0.4847 - val_loss: 0.4161 - val_acc: 0.4819\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4172 - acc: 0.4839 - val_loss: 0.4159 - val_acc: 0.4835\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4171 - acc: 0.4817 - val_loss: 0.4158 - val_acc: 0.4798\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4169 - acc: 0.4820 - val_loss: 0.4156 - val_acc: 0.4817\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4168 - acc: 0.4794 - val_loss: 0.4155 - val_acc: 0.4772\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4167 - acc: 0.4796 - val_loss: 0.4153 - val_acc: 0.4786\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4165 - acc: 0.4782 - val_loss: 0.4152 - val_acc: 0.4767\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4164 - acc: 0.4771 - val_loss: 0.4151 - val_acc: 0.4760\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4163 - acc: 0.4758 - val_loss: 0.4150 - val_acc: 0.4754\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4162 - acc: 0.4753 - val_loss: 0.4149 - val_acc: 0.4747\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4161 - acc: 0.4742 - val_loss: 0.4148 - val_acc: 0.4726\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4160 - acc: 0.4728 - val_loss: 0.4147 - val_acc: 0.4711\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4159 - acc: 0.4720 - val_loss: 0.4146 - val_acc: 0.4724\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4158 - acc: 0.4708 - val_loss: 0.4145 - val_acc: 0.4672\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4157 - acc: 0.4702 - val_loss: 0.4144 - val_acc: 0.4702\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4157 - acc: 0.4683 - val_loss: 0.4144 - val_acc: 0.4667\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4156 - acc: 0.4668 - val_loss: 0.4143 - val_acc: 0.4689\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4155 - acc: 0.4687 - val_loss: 0.4142 - val_acc: 0.4657\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4154 - acc: 0.4659 - val_loss: 0.4142 - val_acc: 0.4654\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4154 - acc: 0.4673 - val_loss: 0.4141 - val_acc: 0.4635\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 1s 3us/step - loss: 1.0063 - acc: 0.2747 - val_loss: 0.7958 - val_acc: 0.1487\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7855 - acc: 0.1478 - val_loss: 0.6813 - val_acc: 0.1616\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6547 - acc: 0.1818 - val_loss: 0.6356 - val_acc: 0.1965\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6079 - acc: 0.1832 - val_loss: 0.5656 - val_acc: 0.1611\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5452 - acc: 0.1437 - val_loss: 0.5231 - val_acc: 0.1312\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5210 - acc: 0.1274 - val_loss: 0.5038 - val_acc: 0.1287\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4942 - acc: 0.1220 - val_loss: 0.4612 - val_acc: 0.1070\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4479 - acc: 0.0840 - val_loss: 0.4312 - val_acc: 0.0642\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4305 - acc: 0.0397 - val_loss: 0.4332 - val_acc: 0.0143\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4321 - acc: 0.0160 - val_loss: 0.4268 - val_acc: 0.0248\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4261 - acc: 0.0318 - val_loss: 0.4221 - val_acc: 0.0405\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4258 - acc: 0.0352 - val_loss: 0.4238 - val_acc: 0.0275\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4243 - acc: 0.0290 - val_loss: 0.4221 - val_acc: 0.0335\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4234 - acc: 0.0281 - val_loss: 0.4208 - val_acc: 0.0285\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4224 - acc: 0.0325 - val_loss: 0.4200 - val_acc: 0.0390\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4221 - acc: 0.0381 - val_loss: 0.4197 - val_acc: 0.0348\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4216 - acc: 0.0315 - val_loss: 0.4189 - val_acc: 0.0313\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4212 - acc: 0.0305 - val_loss: 0.4186 - val_acc: 0.0310\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4261 - acc: 0.0471 - val_loss: 0.4247 - val_acc: 0.0591\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4266 - acc: 0.0539 - val_loss: 0.4211 - val_acc: 0.0392\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4219 - acc: 0.0308 - val_loss: 0.4196 - val_acc: 0.0266\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4212 - acc: 0.0252 - val_loss: 0.4185 - val_acc: 0.0280\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4206 - acc: 0.0319 - val_loss: 0.4181 - val_acc: 0.0369\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4203 - acc: 0.0347 - val_loss: 0.4176 - val_acc: 0.0326\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4200 - acc: 0.0305 - val_loss: 0.4174 - val_acc: 0.0310\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4198 - acc: 0.0304 - val_loss: 0.4172 - val_acc: 0.0312\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4196 - acc: 0.0300 - val_loss: 0.4171 - val_acc: 0.0297\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4194 - acc: 0.0292 - val_loss: 0.4168 - val_acc: 0.0301\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4192 - acc: 0.0289 - val_loss: 0.4166 - val_acc: 0.0311\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4191 - acc: 0.0302 - val_loss: 0.4165 - val_acc: 0.0309\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4189 - acc: 0.0302 - val_loss: 0.4163 - val_acc: 0.0311\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4187 - acc: 0.0289 - val_loss: 0.4162 - val_acc: 0.0283\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4186 - acc: 0.0271 - val_loss: 0.4160 - val_acc: 0.0284\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4185 - acc: 0.0285 - val_loss: 0.4159 - val_acc: 0.0290\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4184 - acc: 0.0277 - val_loss: 0.4158 - val_acc: 0.0279\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4183 - acc: 0.0271 - val_loss: 0.4156 - val_acc: 0.0278\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4182 - acc: 0.0265 - val_loss: 0.4155 - val_acc: 0.0268\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4181 - acc: 0.0270 - val_loss: 0.4154 - val_acc: 0.0272\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4180 - acc: 0.0253 - val_loss: 0.4153 - val_acc: 0.0261\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4179 - acc: 0.0261 - val_loss: 0.4152 - val_acc: 0.0266\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4178 - acc: 0.0256 - val_loss: 0.4152 - val_acc: 0.0254\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4177 - acc: 0.0250 - val_loss: 0.4151 - val_acc: 0.0253\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4177 - acc: 0.0251 - val_loss: 0.4150 - val_acc: 0.0251\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4176 - acc: 0.0238 - val_loss: 0.4150 - val_acc: 0.0239\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4176 - acc: 0.0232 - val_loss: 0.4149 - val_acc: 0.0241\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4176 - acc: 0.0239 - val_loss: 0.4149 - val_acc: 0.0251\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4175 - acc: 0.0231 - val_loss: 0.4149 - val_acc: 0.0222\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4175 - acc: 0.0223 - val_loss: 0.4149 - val_acc: 0.0216\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4175 - acc: 0.0231 - val_loss: 0.4148 - val_acc: 0.0234\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4174 - acc: 0.0217 - val_loss: 0.4148 - val_acc: 0.0219\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.2534 - acc: 0.3327 - val_loss: 0.6720 - val_acc: 0.1799\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7131 - acc: 0.1532 - val_loss: 0.7520 - val_acc: 0.1382\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6918 - acc: 0.1395 - val_loss: 0.6164 - val_acc: 0.1446\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5837 - acc: 0.1518 - val_loss: 0.5595 - val_acc: 0.1583\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5474 - acc: 0.1552 - val_loss: 0.5231 - val_acc: 0.1453\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4869 - acc: 0.1217 - val_loss: 0.4475 - val_acc: 0.0881\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4296 - acc: 0.0613 - val_loss: 0.4218 - val_acc: 0.0301\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4221 - acc: 0.0175 - val_loss: 0.4273 - val_acc: 0.0093\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4241 - acc: 0.0109 - val_loss: 0.4242 - val_acc: 0.0154\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4205 - acc: 0.0211 - val_loss: 0.4215 - val_acc: 0.0285\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4193 - acc: 0.0319 - val_loss: 0.4213 - val_acc: 0.0343\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4192 - acc: 0.0335 - val_loss: 0.4211 - val_acc: 0.0322\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4190 - acc: 0.0309 - val_loss: 0.4211 - val_acc: 0.0302\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4189 - acc: 0.0295 - val_loss: 0.4210 - val_acc: 0.0294\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4188 - acc: 0.0298 - val_loss: 0.4209 - val_acc: 0.0303\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4187 - acc: 0.0303 - val_loss: 0.4208 - val_acc: 0.0305\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4186 - acc: 0.0307 - val_loss: 0.4207 - val_acc: 0.0309\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4185 - acc: 0.0308 - val_loss: 0.4206 - val_acc: 0.0308\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4184 - acc: 0.0303 - val_loss: 0.4206 - val_acc: 0.0301\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4183 - acc: 0.0299 - val_loss: 0.4205 - val_acc: 0.0302\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4183 - acc: 0.0301 - val_loss: 0.4204 - val_acc: 0.0302\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4182 - acc: 0.0300 - val_loss: 0.4204 - val_acc: 0.0299\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4182 - acc: 0.0300 - val_loss: 0.4203 - val_acc: 0.0302\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4181 - acc: 0.0300 - val_loss: 0.4203 - val_acc: 0.0301\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4180 - acc: 0.0296 - val_loss: 0.4201 - val_acc: 0.0297\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4179 - acc: 0.0291 - val_loss: 0.4201 - val_acc: 0.0294\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4179 - acc: 0.0300 - val_loss: 0.4200 - val_acc: 0.0304\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4178 - acc: 0.0304 - val_loss: 0.4200 - val_acc: 0.0304\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4178 - acc: 0.0293 - val_loss: 0.4199 - val_acc: 0.0295\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4177 - acc: 0.0301 - val_loss: 0.4198 - val_acc: 0.0310\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4176 - acc: 0.0305 - val_loss: 0.4198 - val_acc: 0.0299\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4176 - acc: 0.0277 - val_loss: 0.4198 - val_acc: 0.0256\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4175 - acc: 0.0257 - val_loss: 0.4197 - val_acc: 0.0265\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4174 - acc: 0.0272 - val_loss: 0.4196 - val_acc: 0.0281\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4173 - acc: 0.0282 - val_loss: 0.4195 - val_acc: 0.0282\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4173 - acc: 0.0278 - val_loss: 0.4195 - val_acc: 0.0276\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4172 - acc: 0.0270 - val_loss: 0.4195 - val_acc: 0.0271\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4172 - acc: 0.0271 - val_loss: 0.4194 - val_acc: 0.0276\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4171 - acc: 0.0272 - val_loss: 0.4193 - val_acc: 0.0272\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4171 - acc: 0.0271 - val_loss: 0.4193 - val_acc: 0.0272\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4170 - acc: 0.0266 - val_loss: 0.4192 - val_acc: 0.0265\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4170 - acc: 0.0266 - val_loss: 0.4193 - val_acc: 0.0264\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4171 - acc: 0.0262 - val_loss: 0.4191 - val_acc: 0.0269\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4169 - acc: 0.0268 - val_loss: 0.4192 - val_acc: 0.0264\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4168 - acc: 0.0259 - val_loss: 0.4191 - val_acc: 0.0259\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4168 - acc: 0.0258 - val_loss: 0.4191 - val_acc: 0.0260\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4167 - acc: 0.0259 - val_loss: 0.4190 - val_acc: 0.0260\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4167 - acc: 0.0256 - val_loss: 0.4190 - val_acc: 0.0254\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4167 - acc: 0.0251 - val_loss: 0.4190 - val_acc: 0.0258\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4167 - acc: 0.0259 - val_loss: 0.4190 - val_acc: 0.0261\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.0692 - acc: 0.2931 - val_loss: 0.7698 - val_acc: 0.1565\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8031 - acc: 0.1488 - val_loss: 0.7341 - val_acc: 0.1552\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6833 - acc: 0.1734 - val_loss: 0.6535 - val_acc: 0.1918\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6340 - acc: 0.1885 - val_loss: 0.5864 - val_acc: 0.1710\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5712 - acc: 0.1556 - val_loss: 0.5489 - val_acc: 0.1389\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5271 - acc: 0.1327 - val_loss: 0.4937 - val_acc: 0.1219\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4594 - acc: 0.0955 - val_loss: 0.4336 - val_acc: 0.0440\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4290 - acc: 0.0247 - val_loss: 0.4305 - val_acc: 0.0179\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4292 - acc: 0.0202 - val_loss: 0.4240 - val_acc: 0.0240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4230 - acc: 0.0296 - val_loss: 0.4224 - val_acc: 0.0377\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4280 - acc: 0.0537 - val_loss: 0.4419 - val_acc: 0.0706\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4327 - acc: 0.0627 - val_loss: 0.4289 - val_acc: 0.0359\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4264 - acc: 0.0258 - val_loss: 0.4231 - val_acc: 0.0259\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4240 - acc: 0.0288 - val_loss: 0.4214 - val_acc: 0.0292\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4211 - acc: 0.0347 - val_loss: 0.4215 - val_acc: 0.0399\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4212 - acc: 0.0414 - val_loss: 0.4220 - val_acc: 0.0433\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4214 - acc: 0.0425 - val_loss: 0.4207 - val_acc: 0.0370\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4205 - acc: 0.0333 - val_loss: 0.4204 - val_acc: 0.0301\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4202 - acc: 0.0298 - val_loss: 0.4201 - val_acc: 0.0313\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4201 - acc: 0.0296 - val_loss: 0.4199 - val_acc: 0.0299\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4197 - acc: 0.0319 - val_loss: 0.4197 - val_acc: 0.0333\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4196 - acc: 0.0331 - val_loss: 0.4195 - val_acc: 0.0322\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4194 - acc: 0.0318 - val_loss: 0.4194 - val_acc: 0.0320\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4193 - acc: 0.0324 - val_loss: 0.4192 - val_acc: 0.0315\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4192 - acc: 0.0315 - val_loss: 0.4191 - val_acc: 0.0313\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4191 - acc: 0.0321 - val_loss: 0.4191 - val_acc: 0.0316\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4191 - acc: 0.0315 - val_loss: 0.4191 - val_acc: 0.0333\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4190 - acc: 0.0334 - val_loss: 0.4189 - val_acc: 0.0321\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4190 - acc: 0.0316 - val_loss: 0.4188 - val_acc: 0.0301\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4189 - acc: 0.0293 - val_loss: 0.4187 - val_acc: 0.0289\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4188 - acc: 0.0294 - val_loss: 0.4186 - val_acc: 0.0300\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4187 - acc: 0.0299 - val_loss: 0.4185 - val_acc: 0.0287\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4187 - acc: 0.0291 - val_loss: 0.4185 - val_acc: 0.0297\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4186 - acc: 0.0303 - val_loss: 0.4184 - val_acc: 0.0291\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4186 - acc: 0.0279 - val_loss: 0.4184 - val_acc: 0.0286\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4185 - acc: 0.0293 - val_loss: 0.4183 - val_acc: 0.0294\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4185 - acc: 0.0290 - val_loss: 0.4183 - val_acc: 0.0281\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4185 - acc: 0.0289 - val_loss: 0.4183 - val_acc: 0.0285\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4185 - acc: 0.0278 - val_loss: 0.4182 - val_acc: 0.0283\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4184 - acc: 0.0290 - val_loss: 0.4182 - val_acc: 0.0280\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4184 - acc: 0.0281 - val_loss: 0.4182 - val_acc: 0.0286\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4184 - acc: 0.0277 - val_loss: 0.4182 - val_acc: 0.0270\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4184 - acc: 0.0277 - val_loss: 0.4182 - val_acc: 0.0293\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4183 - acc: 0.0289 - val_loss: 0.4181 - val_acc: 0.0266\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4184 - acc: 0.0271 - val_loss: 0.4181 - val_acc: 0.0282\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4183 - acc: 0.0277 - val_loss: 0.4181 - val_acc: 0.0264\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4183 - acc: 0.0273 - val_loss: 0.4181 - val_acc: 0.0280\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4183 - acc: 0.0267 - val_loss: 0.4181 - val_acc: 0.0270\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4183 - acc: 0.0277 - val_loss: 0.4180 - val_acc: 0.0261\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4184 - acc: 0.0257 - val_loss: 0.4182 - val_acc: 0.0284\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.2750 - acc: 0.3260 - val_loss: 0.7144 - val_acc: 0.1809\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7697 - acc: 0.1550 - val_loss: 0.7938 - val_acc: 0.1439\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7525 - acc: 0.1471 - val_loss: 0.6742 - val_acc: 0.1582\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6525 - acc: 0.1660 - val_loss: 0.6221 - val_acc: 0.1775\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6152 - acc: 0.1747 - val_loss: 0.5929 - val_acc: 0.1720\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5719 - acc: 0.1593 - val_loss: 0.5260 - val_acc: 0.1431\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5049 - acc: 0.1259 - val_loss: 0.4711 - val_acc: 0.1082\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4595 - acc: 0.0949 - val_loss: 0.4420 - val_acc: 0.0824\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4369 - acc: 0.0711 - val_loss: 0.4237 - val_acc: 0.0516\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4270 - acc: 0.0325 - val_loss: 0.4259 - val_acc: 0.0183\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4273 - acc: 0.0196 - val_loss: 0.4236 - val_acc: 0.0232\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4252 - acc: 0.0285 - val_loss: 0.4211 - val_acc: 0.0337\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4240 - acc: 0.0379 - val_loss: 0.4214 - val_acc: 0.0405\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4241 - acc: 0.0405 - val_loss: 0.4210 - val_acc: 0.0387\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4237 - acc: 0.0371 - val_loss: 0.4208 - val_acc: 0.0338\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4236 - acc: 0.0331 - val_loss: 0.4207 - val_acc: 0.0321\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4235 - acc: 0.0327 - val_loss: 0.4205 - val_acc: 0.0327\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4235 - acc: 0.0329 - val_loss: 0.4207 - val_acc: 0.0301\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4235 - acc: 0.0297 - val_loss: 0.4205 - val_acc: 0.0291\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4233 - acc: 0.0308 - val_loss: 0.4201 - val_acc: 0.0321\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4232 - acc: 0.0329 - val_loss: 0.4201 - val_acc: 0.0323\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4230 - acc: 0.0337 - val_loss: 0.4199 - val_acc: 0.0344\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4229 - acc: 0.0353 - val_loss: 0.4199 - val_acc: 0.0347\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4228 - acc: 0.0340 - val_loss: 0.4198 - val_acc: 0.0321\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4228 - acc: 0.0317 - val_loss: 0.4197 - val_acc: 0.0309\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4227 - acc: 0.0317 - val_loss: 0.4196 - val_acc: 0.0320\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4226 - acc: 0.0324 - val_loss: 0.4196 - val_acc: 0.0317\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4225 - acc: 0.0321 - val_loss: 0.4195 - val_acc: 0.0316\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4225 - acc: 0.0322 - val_loss: 0.4194 - val_acc: 0.0321\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4224 - acc: 0.0326 - val_loss: 0.4194 - val_acc: 0.0323\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4224 - acc: 0.0320 - val_loss: 0.4193 - val_acc: 0.0319\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4224 - acc: 0.0330 - val_loss: 0.4193 - val_acc: 0.0323\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4223 - acc: 0.0319 - val_loss: 0.4193 - val_acc: 0.0305\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4223 - acc: 0.0303 - val_loss: 0.4192 - val_acc: 0.0297\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4222 - acc: 0.0307 - val_loss: 0.4192 - val_acc: 0.0309\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4221 - acc: 0.0318 - val_loss: 0.4191 - val_acc: 0.0317\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4221 - acc: 0.0314 - val_loss: 0.4191 - val_acc: 0.0303\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4220 - acc: 0.0307 - val_loss: 0.4191 - val_acc: 0.0297\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4220 - acc: 0.0288 - val_loss: 0.4190 - val_acc: 0.0283\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4220 - acc: 0.0294 - val_loss: 0.4190 - val_acc: 0.0298\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4219 - acc: 0.0305 - val_loss: 0.4189 - val_acc: 0.0300\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4219 - acc: 0.0295 - val_loss: 0.4189 - val_acc: 0.0288\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4218 - acc: 0.0300 - val_loss: 0.4188 - val_acc: 0.0296\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4218 - acc: 0.0298 - val_loss: 0.4188 - val_acc: 0.0289\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4218 - acc: 0.0293 - val_loss: 0.4188 - val_acc: 0.0291\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4218 - acc: 0.0297 - val_loss: 0.4188 - val_acc: 0.0289\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4217 - acc: 0.0289 - val_loss: 0.4187 - val_acc: 0.0287\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4217 - acc: 0.0297 - val_loss: 0.4187 - val_acc: 0.0290\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4217 - acc: 0.0287 - val_loss: 0.4187 - val_acc: 0.0287\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4217 - acc: 0.0292 - val_loss: 0.4187 - val_acc: 0.0280\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 1s 3us/step - loss: 1.6813 - acc: 0.5411 - val_loss: 0.8101 - val_acc: 0.5212\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7600 - acc: 0.4493 - val_loss: 0.7446 - val_acc: 0.3822\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7595 - acc: 0.3612 - val_loss: 0.7634 - val_acc: 0.3482\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7603 - acc: 0.3546 - val_loss: 0.7444 - val_acc: 0.3676\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7400 - acc: 0.3822 - val_loss: 0.7273 - val_acc: 0.4003\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7245 - acc: 0.4134 - val_loss: 0.7132 - val_acc: 0.4272\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7080 - acc: 0.4353 - val_loss: 0.6984 - val_acc: 0.4418\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6926 - acc: 0.4437 - val_loss: 0.6812 - val_acc: 0.4443\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6731 - acc: 0.4465 - val_loss: 0.6578 - val_acc: 0.4477\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6500 - acc: 0.4491 - val_loss: 0.6386 - val_acc: 0.4491\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6298 - acc: 0.4527 - val_loss: 0.6138 - val_acc: 0.4592\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6070 - acc: 0.4618 - val_loss: 0.5938 - val_acc: 0.4653\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5868 - acc: 0.4681 - val_loss: 0.5746 - val_acc: 0.4729\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5586 - acc: 0.4845 - val_loss: 0.5359 - val_acc: 0.4993\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5204 - acc: 0.5079 - val_loss: 0.5001 - val_acc: 0.5171\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4844 - acc: 0.5222 - val_loss: 0.4693 - val_acc: 0.5177\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4659 - acc: 0.5127 - val_loss: 0.4641 - val_acc: 0.5079\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4648 - acc: 0.5062 - val_loss: 0.4652 - val_acc: 0.5050\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4650 - acc: 0.5054 - val_loss: 0.4641 - val_acc: 0.5059\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4637 - acc: 0.5068 - val_loss: 0.4631 - val_acc: 0.5076\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4631 - acc: 0.5079 - val_loss: 0.4628 - val_acc: 0.5077\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4628 - acc: 0.5078 - val_loss: 0.4624 - val_acc: 0.5085\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4626 - acc: 0.5087 - val_loss: 0.4623 - val_acc: 0.5088\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4624 - acc: 0.5087 - val_loss: 0.4620 - val_acc: 0.5085\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4622 - acc: 0.5082 - val_loss: 0.4618 - val_acc: 0.5080\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4620 - acc: 0.5077 - val_loss: 0.4616 - val_acc: 0.5075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4618 - acc: 0.5076 - val_loss: 0.4615 - val_acc: 0.5076\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4616 - acc: 0.5076 - val_loss: 0.4613 - val_acc: 0.5076\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4615 - acc: 0.5076 - val_loss: 0.4611 - val_acc: 0.5075\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4613 - acc: 0.5075 - val_loss: 0.4610 - val_acc: 0.5075\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4612 - acc: 0.5074 - val_loss: 0.4608 - val_acc: 0.5074\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4611 - acc: 0.5074 - val_loss: 0.4607 - val_acc: 0.5075\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4610 - acc: 0.5074 - val_loss: 0.4606 - val_acc: 0.5072\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4608 - acc: 0.5072 - val_loss: 0.4604 - val_acc: 0.5066\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4607 - acc: 0.5066 - val_loss: 0.4603 - val_acc: 0.5061\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4605 - acc: 0.5063 - val_loss: 0.4602 - val_acc: 0.5059\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4604 - acc: 0.5062 - val_loss: 0.4601 - val_acc: 0.5058\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4603 - acc: 0.5061 - val_loss: 0.4601 - val_acc: 0.5054\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4603 - acc: 0.5050 - val_loss: 0.4599 - val_acc: 0.5047\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4601 - acc: 0.5046 - val_loss: 0.4597 - val_acc: 0.5043\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4599 - acc: 0.5047 - val_loss: 0.4595 - val_acc: 0.5048\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4598 - acc: 0.5049 - val_loss: 0.4594 - val_acc: 0.5045\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4596 - acc: 0.5044 - val_loss: 0.4593 - val_acc: 0.5040\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4595 - acc: 0.5039 - val_loss: 0.4592 - val_acc: 0.5036\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4594 - acc: 0.5037 - val_loss: 0.4591 - val_acc: 0.5034\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4593 - acc: 0.5033 - val_loss: 0.4590 - val_acc: 0.5029\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4592 - acc: 0.5030 - val_loss: 0.4589 - val_acc: 0.5030\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4591 - acc: 0.5028 - val_loss: 0.4588 - val_acc: 0.5024\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4591 - acc: 0.5023 - val_loss: 0.4588 - val_acc: 0.5021\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4590 - acc: 0.5022 - val_loss: 0.4587 - val_acc: 0.5019\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.6860 - acc: 0.3710 - val_loss: 0.8258 - val_acc: 0.2324\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7786 - acc: 0.2045 - val_loss: 0.7476 - val_acc: 0.1806\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7567 - acc: 0.1733 - val_loss: 0.7557 - val_acc: 0.1661\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7630 - acc: 0.1646 - val_loss: 0.7576 - val_acc: 0.1625\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7611 - acc: 0.1633 - val_loss: 0.7501 - val_acc: 0.1630\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7506 - acc: 0.1644 - val_loss: 0.7402 - val_acc: 0.1652\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7401 - acc: 0.1665 - val_loss: 0.7311 - val_acc: 0.1670\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7305 - acc: 0.1683 - val_loss: 0.7225 - val_acc: 0.1683\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7223 - acc: 0.1692 - val_loss: 0.7151 - val_acc: 0.1683\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7140 - acc: 0.1684 - val_loss: 0.7080 - val_acc: 0.1675\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7069 - acc: 0.1674 - val_loss: 0.7005 - val_acc: 0.1661\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7008 - acc: 0.1660 - val_loss: 0.6948 - val_acc: 0.1643\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6940 - acc: 0.1640 - val_loss: 0.6880 - val_acc: 0.1621\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6873 - acc: 0.1616 - val_loss: 0.6816 - val_acc: 0.1597\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6829 - acc: 0.1593 - val_loss: 0.6796 - val_acc: 0.1582\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6818 - acc: 0.1580 - val_loss: 0.6760 - val_acc: 0.1565\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6755 - acc: 0.1561 - val_loss: 0.6666 - val_acc: 0.1544\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6623 - acc: 0.1526 - val_loss: 0.6465 - val_acc: 0.1498\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6388 - acc: 0.1455 - val_loss: 0.6243 - val_acc: 0.1405\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6184 - acc: 0.1359 - val_loss: 0.6039 - val_acc: 0.1291\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5936 - acc: 0.1231 - val_loss: 0.5773 - val_acc: 0.1151\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5711 - acc: 0.1097 - val_loss: 0.5549 - val_acc: 0.1011\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5458 - acc: 0.0938 - val_loss: 0.5312 - val_acc: 0.0859\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5250 - acc: 0.0789 - val_loss: 0.5121 - val_acc: 0.0712\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5051 - acc: 0.0627 - val_loss: 0.4956 - val_acc: 0.0557\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4938 - acc: 0.0503 - val_loss: 0.4857 - val_acc: 0.0419\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4851 - acc: 0.0373 - val_loss: 0.4805 - val_acc: 0.0331\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4816 - acc: 0.0314 - val_loss: 0.4784 - val_acc: 0.0292\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 0.0283 - val_loss: 0.4775 - val_acc: 0.0274\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4791 - acc: 0.0272 - val_loss: 0.4762 - val_acc: 0.0266\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4778 - acc: 0.0252 - val_loss: 0.4748 - val_acc: 0.0241\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4766 - acc: 0.0258 - val_loss: 0.4741 - val_acc: 0.0267\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4755 - acc: 0.0259 - val_loss: 0.4731 - val_acc: 0.0269\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4751 - acc: 0.0275 - val_loss: 0.4725 - val_acc: 0.0271\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4741 - acc: 0.0267 - val_loss: 0.4720 - val_acc: 0.0274\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4743 - acc: 0.0288 - val_loss: 0.4720 - val_acc: 0.0286\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4733 - acc: 0.0264 - val_loss: 0.4708 - val_acc: 0.0230\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4717 - acc: 0.0222 - val_loss: 0.4691 - val_acc: 0.0214\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4706 - acc: 0.0214 - val_loss: 0.4683 - val_acc: 0.0210\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4698 - acc: 0.0211 - val_loss: 0.4675 - val_acc: 0.0207\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4691 - acc: 0.0211 - val_loss: 0.4669 - val_acc: 0.0212\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4686 - acc: 0.0212 - val_loss: 0.4662 - val_acc: 0.0203\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4679 - acc: 0.0202 - val_loss: 0.4656 - val_acc: 0.0199\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4675 - acc: 0.0199 - val_loss: 0.4650 - val_acc: 0.0176\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4671 - acc: 0.0167 - val_loss: 0.4643 - val_acc: 0.0156\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4664 - acc: 0.0172 - val_loss: 0.4639 - val_acc: 0.0177\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4662 - acc: 0.0190 - val_loss: 0.4636 - val_acc: 0.0192\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4657 - acc: 0.0191 - val_loss: 0.4632 - val_acc: 0.0179\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4654 - acc: 0.0180 - val_loss: 0.4628 - val_acc: 0.0166\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4649 - acc: 0.0165 - val_loss: 0.4623 - val_acc: 0.0152\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.1012 - acc: 0.4916 - val_loss: 0.7657 - val_acc: 0.3359\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8080 - acc: 0.3031 - val_loss: 0.7546 - val_acc: 0.3252\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7092 - acc: 0.3983 - val_loss: 0.6874 - val_acc: 0.4751\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6747 - acc: 0.4959 - val_loss: 0.6466 - val_acc: 0.4881\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6207 - acc: 0.4654 - val_loss: 0.5919 - val_acc: 0.4503\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5583 - acc: 0.4711 - val_loss: 0.5280 - val_acc: 0.4964\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5038 - acc: 0.5161 - val_loss: 0.4744 - val_acc: 0.5204\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4704 - acc: 0.5090 - val_loss: 0.4690 - val_acc: 0.5047\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4707 - acc: 0.5039 - val_loss: 0.4663 - val_acc: 0.5058\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4648 - acc: 0.5068 - val_loss: 0.4637 - val_acc: 0.5105\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4637 - acc: 0.5108 - val_loss: 0.4630 - val_acc: 0.5117\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4628 - acc: 0.5093 - val_loss: 0.4620 - val_acc: 0.5090\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4621 - acc: 0.5076 - val_loss: 0.4615 - val_acc: 0.5082\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4617 - acc: 0.5071 - val_loss: 0.4610 - val_acc: 0.5084\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4613 - acc: 0.5076 - val_loss: 0.4607 - val_acc: 0.5088\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4610 - acc: 0.5075 - val_loss: 0.4604 - val_acc: 0.5083\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4606 - acc: 0.5070 - val_loss: 0.4600 - val_acc: 0.5073\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4603 - acc: 0.5062 - val_loss: 0.4598 - val_acc: 0.5068\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4601 - acc: 0.5058 - val_loss: 0.4595 - val_acc: 0.5065\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4598 - acc: 0.5053 - val_loss: 0.4592 - val_acc: 0.5061\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4595 - acc: 0.5051 - val_loss: 0.4590 - val_acc: 0.5055\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4593 - acc: 0.5043 - val_loss: 0.4587 - val_acc: 0.5046\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4591 - acc: 0.5035 - val_loss: 0.4585 - val_acc: 0.5041\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4590 - acc: 0.5032 - val_loss: 0.4583 - val_acc: 0.5030\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4588 - acc: 0.5020 - val_loss: 0.4582 - val_acc: 0.5028\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4586 - acc: 0.5017 - val_loss: 0.4580 - val_acc: 0.5019\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4585 - acc: 0.5008 - val_loss: 0.4578 - val_acc: 0.5014\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4583 - acc: 0.4998 - val_loss: 0.4577 - val_acc: 0.5006\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.4994 - val_loss: 0.4575 - val_acc: 0.5000\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4581 - acc: 0.4988 - val_loss: 0.4574 - val_acc: 0.4983\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4580 - acc: 0.4974 - val_loss: 0.4573 - val_acc: 0.4984\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4579 - acc: 0.4961 - val_loss: 0.4572 - val_acc: 0.4975\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4578 - acc: 0.4968 - val_loss: 0.4571 - val_acc: 0.4954\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4577 - acc: 0.4943 - val_loss: 0.4570 - val_acc: 0.4961\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4577 - acc: 0.4944 - val_loss: 0.4569 - val_acc: 0.4931\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4575 - acc: 0.4937 - val_loss: 0.4568 - val_acc: 0.4935\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4574 - acc: 0.4924 - val_loss: 0.4567 - val_acc: 0.4915\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4574 - acc: 0.4917 - val_loss: 0.4566 - val_acc: 0.4921\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4573 - acc: 0.4904 - val_loss: 0.4565 - val_acc: 0.4909\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4573 - acc: 0.4902 - val_loss: 0.4565 - val_acc: 0.4893\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4572 - acc: 0.4888 - val_loss: 0.4564 - val_acc: 0.4894\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4572 - acc: 0.4880 - val_loss: 0.4564 - val_acc: 0.4900\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4572 - acc: 0.4878 - val_loss: 0.4563 - val_acc: 0.4881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4572 - acc: 0.4874 - val_loss: 0.4563 - val_acc: 0.4881\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4571 - acc: 0.4854 - val_loss: 0.4563 - val_acc: 0.4860\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4571 - acc: 0.4859 - val_loss: 0.4563 - val_acc: 0.4872\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4571 - acc: 0.4856 - val_loss: 0.4562 - val_acc: 0.4863\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4571 - acc: 0.4847 - val_loss: 0.4562 - val_acc: 0.4860\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4571 - acc: 0.4848 - val_loss: 0.4562 - val_acc: 0.4855\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4571 - acc: 0.4845 - val_loss: 0.4562 - val_acc: 0.4858\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.8054 - acc: 0.5452 - val_loss: 0.9207 - val_acc: 0.5683\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8093 - acc: 0.5312 - val_loss: 0.7428 - val_acc: 0.4814\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7239 - acc: 0.4520 - val_loss: 0.7169 - val_acc: 0.4226\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7093 - acc: 0.4105 - val_loss: 0.7101 - val_acc: 0.3986\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7024 - acc: 0.3968 - val_loss: 0.6978 - val_acc: 0.3956\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6882 - acc: 0.3992 - val_loss: 0.6808 - val_acc: 0.4025\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6724 - acc: 0.4093 - val_loss: 0.6687 - val_acc: 0.4155\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6602 - acc: 0.4217 - val_loss: 0.6542 - val_acc: 0.4266\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6492 - acc: 0.4327 - val_loss: 0.6478 - val_acc: 0.4363\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6417 - acc: 0.4405 - val_loss: 0.6348 - val_acc: 0.4420\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6209 - acc: 0.4431 - val_loss: 0.6109 - val_acc: 0.4436\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6041 - acc: 0.4446 - val_loss: 0.6010 - val_acc: 0.4471\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5896 - acc: 0.4491 - val_loss: 0.5794 - val_acc: 0.4508\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5682 - acc: 0.4542 - val_loss: 0.5562 - val_acc: 0.4558\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5484 - acc: 0.4589 - val_loss: 0.5390 - val_acc: 0.4630\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5299 - acc: 0.4664 - val_loss: 0.5154 - val_acc: 0.4727\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5053 - acc: 0.4761 - val_loss: 0.4925 - val_acc: 0.4831\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4862 - val_loss: 0.4794 - val_acc: 0.4926\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4748 - acc: 0.4954 - val_loss: 0.4698 - val_acc: 0.5001\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4660 - acc: 0.5028 - val_loss: 0.4624 - val_acc: 0.5065\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4607 - acc: 0.5064 - val_loss: 0.4596 - val_acc: 0.5070\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4592 - acc: 0.5063 - val_loss: 0.4588 - val_acc: 0.5065\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4587 - acc: 0.5060 - val_loss: 0.4586 - val_acc: 0.5061\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4587 - acc: 0.5056 - val_loss: 0.4586 - val_acc: 0.5057\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4586 - acc: 0.5053 - val_loss: 0.4586 - val_acc: 0.5055\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4586 - acc: 0.5051 - val_loss: 0.4585 - val_acc: 0.5053\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4586 - acc: 0.5050 - val_loss: 0.4585 - val_acc: 0.5052\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4585 - acc: 0.5050 - val_loss: 0.4585 - val_acc: 0.5053\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4585 - acc: 0.5050 - val_loss: 0.4585 - val_acc: 0.5054\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4585 - acc: 0.5050 - val_loss: 0.4584 - val_acc: 0.5052\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4584 - acc: 0.5048 - val_loss: 0.4584 - val_acc: 0.5051\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4584 - acc: 0.5048 - val_loss: 0.4584 - val_acc: 0.5051\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4584 - acc: 0.5048 - val_loss: 0.4584 - val_acc: 0.5051\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4584 - acc: 0.5048 - val_loss: 0.4583 - val_acc: 0.5050\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4583 - acc: 0.5046 - val_loss: 0.4583 - val_acc: 0.5048\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4583 - acc: 0.5045 - val_loss: 0.4583 - val_acc: 0.5047\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4583 - acc: 0.5045 - val_loss: 0.4583 - val_acc: 0.5046\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4583 - acc: 0.5045 - val_loss: 0.4582 - val_acc: 0.5047\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5043 - val_loss: 0.4582 - val_acc: 0.5044\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5042 - val_loss: 0.4582 - val_acc: 0.5044\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5042 - val_loss: 0.4582 - val_acc: 0.5044\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5043 - val_loss: 0.4582 - val_acc: 0.5044\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5041 - val_loss: 0.4581 - val_acc: 0.5041\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4581 - acc: 0.5038 - val_loss: 0.4581 - val_acc: 0.5040\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4581 - acc: 0.5038 - val_loss: 0.4581 - val_acc: 0.5040\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4581 - acc: 0.5039 - val_loss: 0.4581 - val_acc: 0.5041\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4581 - acc: 0.5039 - val_loss: 0.4580 - val_acc: 0.5040\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4581 - acc: 0.5036 - val_loss: 0.4580 - val_acc: 0.5039\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4580 - acc: 0.5036 - val_loss: 0.4580 - val_acc: 0.5037\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4580 - acc: 0.5034 - val_loss: 0.4580 - val_acc: 0.5037\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.2055 - acc: 0.3003 - val_loss: 0.7843 - val_acc: 0.1581\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8406 - acc: 0.1416 - val_loss: 0.8331 - val_acc: 0.1378\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7595 - acc: 0.1471 - val_loss: 0.7142 - val_acc: 0.1633\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7073 - acc: 0.1724 - val_loss: 0.7054 - val_acc: 0.1763\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6788 - acc: 0.1653 - val_loss: 0.6420 - val_acc: 0.1455\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6076 - acc: 0.1289 - val_loss: 0.5771 - val_acc: 0.1092\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5438 - acc: 0.0936 - val_loss: 0.4967 - val_acc: 0.0658\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4743 - acc: 0.0327 - val_loss: 0.4665 - val_acc: 0.0045\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4655 - acc: 0.0020 - val_loss: 0.4677 - val_acc: 0.0014\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4651 - acc: 0.0020 - val_loss: 0.4631 - val_acc: 0.0033\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4605 - acc: 0.0054 - val_loss: 0.4609 - val_acc: 0.0084\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4595 - acc: 0.0108 - val_loss: 0.4608 - val_acc: 0.0125\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4595 - acc: 0.0124 - val_loss: 0.4605 - val_acc: 0.0109\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4592 - acc: 0.0101 - val_loss: 0.4604 - val_acc: 0.0089\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4590 - acc: 0.0085 - val_loss: 0.4603 - val_acc: 0.0082\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4589 - acc: 0.0080 - val_loss: 0.4602 - val_acc: 0.0079\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4588 - acc: 0.0079 - val_loss: 0.4601 - val_acc: 0.0080\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4587 - acc: 0.0080 - val_loss: 0.4600 - val_acc: 0.0080\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4587 - acc: 0.0081 - val_loss: 0.4599 - val_acc: 0.0078\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4587 - acc: 0.0073 - val_loss: 0.4599 - val_acc: 0.0072\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4585 - acc: 0.0076 - val_loss: 0.4599 - val_acc: 0.0076\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4584 - acc: 0.0071 - val_loss: 0.4597 - val_acc: 0.0065\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4583 - acc: 0.0067 - val_loss: 0.4597 - val_acc: 0.0067\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4583 - acc: 0.0069 - val_loss: 0.4596 - val_acc: 0.0066\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.0067 - val_loss: 0.4596 - val_acc: 0.0063\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4581 - acc: 0.0063 - val_loss: 0.4595 - val_acc: 0.0061\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4581 - acc: 0.0064 - val_loss: 0.4595 - val_acc: 0.0062\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4580 - acc: 0.0062 - val_loss: 0.4594 - val_acc: 0.0055\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4580 - acc: 0.0057 - val_loss: 0.4594 - val_acc: 0.0053\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4579 - acc: 0.0055 - val_loss: 0.4594 - val_acc: 0.0053\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4579 - acc: 0.0059 - val_loss: 0.4593 - val_acc: 0.0055\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4579 - acc: 0.0053 - val_loss: 0.4593 - val_acc: 0.0048\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4578 - acc: 0.0053 - val_loss: 0.4593 - val_acc: 0.0053\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4578 - acc: 0.0051 - val_loss: 0.4592 - val_acc: 0.0045\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4578 - acc: 0.0048 - val_loss: 0.4592 - val_acc: 0.0048\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4577 - acc: 0.0051 - val_loss: 0.4592 - val_acc: 0.0046\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4577 - acc: 0.0047 - val_loss: 0.4591 - val_acc: 0.0042\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4576 - acc: 0.0044 - val_loss: 0.4591 - val_acc: 0.0042\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4576 - acc: 0.0043 - val_loss: 0.4591 - val_acc: 0.0041\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4576 - acc: 0.0042 - val_loss: 0.4591 - val_acc: 0.0041\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4576 - acc: 0.0042 - val_loss: 0.4591 - val_acc: 0.0038\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4576 - acc: 0.0038 - val_loss: 0.4591 - val_acc: 0.0039\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4575 - acc: 0.0038 - val_loss: 0.4590 - val_acc: 0.0035\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4575 - acc: 0.0036 - val_loss: 0.4590 - val_acc: 0.0037\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4575 - acc: 0.0039 - val_loss: 0.4590 - val_acc: 0.0035\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4575 - acc: 0.0034 - val_loss: 0.4590 - val_acc: 0.0033\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4574 - acc: 0.0033 - val_loss: 0.4590 - val_acc: 0.0034\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4574 - acc: 0.0034 - val_loss: 0.4590 - val_acc: 0.0032\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4574 - acc: 0.0030 - val_loss: 0.4589 - val_acc: 0.0028\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4574 - acc: 0.0031 - val_loss: 0.4590 - val_acc: 0.0031\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.0697 - acc: 0.4572 - val_loss: 0.8633 - val_acc: 0.2986\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8566 - acc: 0.2988 - val_loss: 0.7506 - val_acc: 0.3512\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7053 - acc: 0.4371 - val_loss: 0.6693 - val_acc: 0.5215\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6394 - acc: 0.5243 - val_loss: 0.5861 - val_acc: 0.5085\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5511 - acc: 0.4923 - val_loss: 0.5163 - val_acc: 0.4760\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4881 - acc: 0.5000 - val_loss: 0.4633 - val_acc: 0.5125\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4652 - acc: 0.5057 - val_loss: 0.4652 - val_acc: 0.5019\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4653 - acc: 0.5037 - val_loss: 0.4636 - val_acc: 0.5047\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4620 - acc: 0.5068 - val_loss: 0.4612 - val_acc: 0.5081\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4615 - acc: 0.5104 - val_loss: 0.4615 - val_acc: 0.5103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4616 - acc: 0.5110 - val_loss: 0.4607 - val_acc: 0.5087\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4609 - acc: 0.5086 - val_loss: 0.4606 - val_acc: 0.5071\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4608 - acc: 0.5072 - val_loss: 0.4604 - val_acc: 0.5065\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4607 - acc: 0.5073 - val_loss: 0.4602 - val_acc: 0.5068\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4605 - acc: 0.5073 - val_loss: 0.4601 - val_acc: 0.5065\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4604 - acc: 0.5069 - val_loss: 0.4599 - val_acc: 0.5061\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4602 - acc: 0.5065 - val_loss: 0.4598 - val_acc: 0.5055\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4601 - acc: 0.5061 - val_loss: 0.4597 - val_acc: 0.5053\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4600 - acc: 0.5058 - val_loss: 0.4595 - val_acc: 0.5049\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4599 - acc: 0.5052 - val_loss: 0.4594 - val_acc: 0.5043\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4598 - acc: 0.5050 - val_loss: 0.4593 - val_acc: 0.5042\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4597 - acc: 0.5044 - val_loss: 0.4593 - val_acc: 0.5033\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4596 - acc: 0.5043 - val_loss: 0.4592 - val_acc: 0.5030\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4595 - acc: 0.5037 - val_loss: 0.4591 - val_acc: 0.5021\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4595 - acc: 0.5033 - val_loss: 0.4590 - val_acc: 0.5022\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4594 - acc: 0.5030 - val_loss: 0.4589 - val_acc: 0.5019\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4593 - acc: 0.5023 - val_loss: 0.4589 - val_acc: 0.5012\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4594 - acc: 0.5027 - val_loss: 0.4588 - val_acc: 0.5006\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4593 - acc: 0.5008 - val_loss: 0.4588 - val_acc: 0.5005\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4593 - acc: 0.5015 - val_loss: 0.4588 - val_acc: 0.4985\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4593 - acc: 0.5002 - val_loss: 0.4587 - val_acc: 0.5002\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4591 - acc: 0.5007 - val_loss: 0.4587 - val_acc: 0.4977\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4591 - acc: 0.4993 - val_loss: 0.4586 - val_acc: 0.4992\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4590 - acc: 0.4992 - val_loss: 0.4585 - val_acc: 0.4979\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4590 - acc: 0.4993 - val_loss: 0.4585 - val_acc: 0.4976\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4590 - acc: 0.4987 - val_loss: 0.4584 - val_acc: 0.4973\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4589 - acc: 0.4978 - val_loss: 0.4584 - val_acc: 0.4973\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4589 - acc: 0.4977 - val_loss: 0.4584 - val_acc: 0.4971\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4590 - acc: 0.4977 - val_loss: 0.4584 - val_acc: 0.4950\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4588 - acc: 0.4968 - val_loss: 0.4584 - val_acc: 0.4966\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4588 - acc: 0.4967 - val_loss: 0.4584 - val_acc: 0.4945\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4588 - acc: 0.4963 - val_loss: 0.4583 - val_acc: 0.4953\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4588 - acc: 0.4964 - val_loss: 0.4583 - val_acc: 0.4946\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4588 - acc: 0.4947 - val_loss: 0.4582 - val_acc: 0.4947\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4588 - acc: 0.4958 - val_loss: 0.4582 - val_acc: 0.4938\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4587 - acc: 0.4944 - val_loss: 0.4582 - val_acc: 0.4941\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4587 - acc: 0.4950 - val_loss: 0.4582 - val_acc: 0.4931\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4587 - acc: 0.4945 - val_loss: 0.4582 - val_acc: 0.4922\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4587 - acc: 0.4928 - val_loss: 0.4582 - val_acc: 0.4936\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4587 - acc: 0.4947 - val_loss: 0.4583 - val_acc: 0.4900\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.2598 - acc: 0.3082 - val_loss: 0.7848 - val_acc: 0.1631\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8423 - acc: 0.1466 - val_loss: 0.8697 - val_acc: 0.1392\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8075 - acc: 0.1473 - val_loss: 0.7538 - val_acc: 0.1597\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7320 - acc: 0.1716 - val_loss: 0.7358 - val_acc: 0.1806\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7212 - acc: 0.1794 - val_loss: 0.7171 - val_acc: 0.1715\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7023 - acc: 0.1650 - val_loss: 0.7066 - val_acc: 0.1573\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6936 - acc: 0.1555 - val_loss: 0.6865 - val_acc: 0.1514\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6536 - acc: 0.1470 - val_loss: 0.6337 - val_acc: 0.1390\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5983 - acc: 0.1275 - val_loss: 0.5807 - val_acc: 0.1132\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5523 - acc: 0.1011 - val_loss: 0.5191 - val_acc: 0.0819\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 0.0668 - val_loss: 0.4780 - val_acc: 0.0438\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4706 - acc: 0.0271 - val_loss: 0.4687 - val_acc: 0.0138\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4690 - acc: 0.0127 - val_loss: 0.4692 - val_acc: 0.0122\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4668 - acc: 0.0145 - val_loss: 0.4658 - val_acc: 0.0163\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4647 - acc: 0.0187 - val_loss: 0.4652 - val_acc: 0.0218\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4642 - acc: 0.0237 - val_loss: 0.4649 - val_acc: 0.0233\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4656 - acc: 0.0185 - val_loss: 0.4758 - val_acc: 0.0044\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4703 - acc: 0.0041 - val_loss: 0.4672 - val_acc: 0.0071\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4651 - acc: 0.0104 - val_loss: 0.4619 - val_acc: 0.0123\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4612 - acc: 0.0141 - val_loss: 0.4622 - val_acc: 0.0159\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4607 - acc: 0.0167 - val_loss: 0.4616 - val_acc: 0.0168\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4603 - acc: 0.0156 - val_loss: 0.4610 - val_acc: 0.0135\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4599 - acc: 0.0136 - val_loss: 0.4608 - val_acc: 0.0131\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4598 - acc: 0.0131 - val_loss: 0.4607 - val_acc: 0.0110\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4597 - acc: 0.0106 - val_loss: 0.4604 - val_acc: 0.0100\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4594 - acc: 0.0112 - val_loss: 0.4603 - val_acc: 0.0112\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4592 - acc: 0.0115 - val_loss: 0.4602 - val_acc: 0.0112\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4591 - acc: 0.0116 - val_loss: 0.4601 - val_acc: 0.0113\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4590 - acc: 0.0114 - val_loss: 0.4600 - val_acc: 0.0106\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4589 - acc: 0.0108 - val_loss: 0.4599 - val_acc: 0.0102\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4588 - acc: 0.0106 - val_loss: 0.4598 - val_acc: 0.0099\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4587 - acc: 0.0104 - val_loss: 0.4597 - val_acc: 0.0095\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4587 - acc: 0.0101 - val_loss: 0.4597 - val_acc: 0.0094\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4586 - acc: 0.0099 - val_loss: 0.4596 - val_acc: 0.0092\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4586 - acc: 0.0097 - val_loss: 0.4596 - val_acc: 0.0087\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4585 - acc: 0.0093 - val_loss: 0.4595 - val_acc: 0.0087\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4584 - acc: 0.0089 - val_loss: 0.4595 - val_acc: 0.0085\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4584 - acc: 0.0088 - val_loss: 0.4594 - val_acc: 0.0083\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4583 - acc: 0.0085 - val_loss: 0.4594 - val_acc: 0.0082\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4583 - acc: 0.0085 - val_loss: 0.4594 - val_acc: 0.0078\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4583 - acc: 0.0082 - val_loss: 0.4593 - val_acc: 0.0077\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.0081 - val_loss: 0.4593 - val_acc: 0.0074\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.0078 - val_loss: 0.4593 - val_acc: 0.0073\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.0077 - val_loss: 0.4593 - val_acc: 0.0069\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.0074 - val_loss: 0.4593 - val_acc: 0.0073\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4581 - acc: 0.0075 - val_loss: 0.4592 - val_acc: 0.0065\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4581 - acc: 0.0070 - val_loss: 0.4592 - val_acc: 0.0070\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4581 - acc: 0.0071 - val_loss: 0.4592 - val_acc: 0.0065\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4581 - acc: 0.0067 - val_loss: 0.4592 - val_acc: 0.0063\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4581 - acc: 0.0066 - val_loss: 0.4592 - val_acc: 0.0061\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.4494 - acc: 0.3487 - val_loss: 0.7676 - val_acc: 0.1935\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7715 - acc: 0.1645 - val_loss: 0.8083 - val_acc: 0.1446\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8062 - acc: 0.1442 - val_loss: 0.7802 - val_acc: 0.1454\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7488 - acc: 0.1512 - val_loss: 0.7118 - val_acc: 0.1553\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6933 - acc: 0.1579 - val_loss: 0.6700 - val_acc: 0.1562\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6542 - acc: 0.1525 - val_loss: 0.6260 - val_acc: 0.1413\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5994 - acc: 0.1292 - val_loss: 0.5610 - val_acc: 0.1115\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5263 - acc: 0.0906 - val_loss: 0.4859 - val_acc: 0.0610\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4718 - acc: 0.0367 - val_loss: 0.4604 - val_acc: 0.0141\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4621 - acc: 0.0089 - val_loss: 0.4611 - val_acc: 0.0056\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4633 - acc: 0.0055 - val_loss: 0.4605 - val_acc: 0.0059\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4618 - acc: 0.0073 - val_loss: 0.4591 - val_acc: 0.0092\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4609 - acc: 0.0109 - val_loss: 0.4589 - val_acc: 0.0122\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4608 - acc: 0.0132 - val_loss: 0.4588 - val_acc: 0.0132\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4607 - acc: 0.0131 - val_loss: 0.4587 - val_acc: 0.0124\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4606 - acc: 0.0124 - val_loss: 0.4586 - val_acc: 0.0116\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4605 - acc: 0.0110 - val_loss: 0.4586 - val_acc: 0.0103\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4605 - acc: 0.0106 - val_loss: 0.4585 - val_acc: 0.0106\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4605 - acc: 0.0112 - val_loss: 0.4585 - val_acc: 0.0108\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4604 - acc: 0.0106 - val_loss: 0.4585 - val_acc: 0.0102\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4603 - acc: 0.0107 - val_loss: 0.4584 - val_acc: 0.0104\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4603 - acc: 0.0104 - val_loss: 0.4584 - val_acc: 0.0100\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4602 - acc: 0.0101 - val_loss: 0.4583 - val_acc: 0.0099\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4602 - acc: 0.0102 - val_loss: 0.4583 - val_acc: 0.0099\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4601 - acc: 0.0099 - val_loss: 0.4582 - val_acc: 0.0096\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4601 - acc: 0.0099 - val_loss: 0.4582 - val_acc: 0.0096\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4601 - acc: 0.0095 - val_loss: 0.4582 - val_acc: 0.0091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4600 - acc: 0.0093 - val_loss: 0.4581 - val_acc: 0.0093\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4600 - acc: 0.0094 - val_loss: 0.4581 - val_acc: 0.0091\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4600 - acc: 0.0093 - val_loss: 0.4581 - val_acc: 0.0089\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4600 - acc: 0.0087 - val_loss: 0.4581 - val_acc: 0.0088\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4600 - acc: 0.0088 - val_loss: 0.4580 - val_acc: 0.0085\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4599 - acc: 0.0084 - val_loss: 0.4580 - val_acc: 0.0083\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4599 - acc: 0.0083 - val_loss: 0.4580 - val_acc: 0.0084\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4599 - acc: 0.0084 - val_loss: 0.4580 - val_acc: 0.0085\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4598 - acc: 0.0080 - val_loss: 0.4580 - val_acc: 0.0078\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4598 - acc: 0.0081 - val_loss: 0.4580 - val_acc: 0.0081\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4598 - acc: 0.0077 - val_loss: 0.4580 - val_acc: 0.0077\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4598 - acc: 0.0077 - val_loss: 0.4579 - val_acc: 0.0078\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4598 - acc: 0.0074 - val_loss: 0.4579 - val_acc: 0.0074\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4598 - acc: 0.0074 - val_loss: 0.4579 - val_acc: 0.0073\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4598 - acc: 0.0075 - val_loss: 0.4579 - val_acc: 0.0075\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4597 - acc: 0.0075 - val_loss: 0.4579 - val_acc: 0.0073\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4597 - acc: 0.0073 - val_loss: 0.4579 - val_acc: 0.0071\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4597 - acc: 0.0068 - val_loss: 0.4579 - val_acc: 0.0067\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4597 - acc: 0.0069 - val_loss: 0.4579 - val_acc: 0.0069\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4597 - acc: 0.0070 - val_loss: 0.4579 - val_acc: 0.0069\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4597 - acc: 0.0068 - val_loss: 0.4579 - val_acc: 0.0064\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4597 - acc: 0.0062 - val_loss: 0.4579 - val_acc: 0.0065\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4597 - acc: 0.0070 - val_loss: 0.4579 - val_acc: 0.0071\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.0458 - acc: 0.2609 - val_loss: 0.8873 - val_acc: 0.1427\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8604 - acc: 0.1448 - val_loss: 0.7559 - val_acc: 0.1607\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7518 - acc: 0.1799 - val_loss: 0.7428 - val_acc: 0.1885\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7300 - acc: 0.1763 - val_loss: 0.7086 - val_acc: 0.1585\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7007 - acc: 0.1512 - val_loss: 0.6730 - val_acc: 0.1454\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6563 - acc: 0.1444 - val_loss: 0.6179 - val_acc: 0.1359\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5911 - acc: 0.1209 - val_loss: 0.5452 - val_acc: 0.0978\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5088 - acc: 0.0662 - val_loss: 0.4753 - val_acc: 0.0223\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4771 - acc: 0.0124 - val_loss: 0.4810 - val_acc: 0.0079\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4750 - acc: 0.0087 - val_loss: 0.4674 - val_acc: 0.0144\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4667 - acc: 0.0215 - val_loss: 0.4651 - val_acc: 0.0226\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4664 - acc: 0.0151 - val_loss: 0.4633 - val_acc: 0.0142\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4645 - acc: 0.0143 - val_loss: 0.4620 - val_acc: 0.0136\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4631 - acc: 0.0141 - val_loss: 0.4613 - val_acc: 0.0171\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4625 - acc: 0.0168 - val_loss: 0.4609 - val_acc: 0.0151\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4621 - acc: 0.0137 - val_loss: 0.4606 - val_acc: 0.0139\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4619 - acc: 0.0135 - val_loss: 0.4604 - val_acc: 0.0134\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4617 - acc: 0.0130 - val_loss: 0.4602 - val_acc: 0.0127\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4615 - acc: 0.0125 - val_loss: 0.4600 - val_acc: 0.0128\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4614 - acc: 0.0125 - val_loss: 0.4598 - val_acc: 0.0129\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4613 - acc: 0.0117 - val_loss: 0.4598 - val_acc: 0.0117\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4612 - acc: 0.0112 - val_loss: 0.4596 - val_acc: 0.0113\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4611 - acc: 0.0109 - val_loss: 0.4596 - val_acc: 0.0109\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4610 - acc: 0.0107 - val_loss: 0.4595 - val_acc: 0.0107\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4610 - acc: 0.0105 - val_loss: 0.4594 - val_acc: 0.0108\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4609 - acc: 0.0106 - val_loss: 0.4594 - val_acc: 0.0103\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4609 - acc: 0.0097 - val_loss: 0.4593 - val_acc: 0.0101\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4609 - acc: 0.0098 - val_loss: 0.4593 - val_acc: 0.0097\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4608 - acc: 0.0099 - val_loss: 0.4592 - val_acc: 0.0102\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4608 - acc: 0.0097 - val_loss: 0.4592 - val_acc: 0.0094\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4608 - acc: 0.0086 - val_loss: 0.4592 - val_acc: 0.0087\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4608 - acc: 0.0090 - val_loss: 0.4593 - val_acc: 0.0085\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4608 - acc: 0.0088 - val_loss: 0.4592 - val_acc: 0.0099\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4608 - acc: 0.0091 - val_loss: 0.4591 - val_acc: 0.0086\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4607 - acc: 0.0083 - val_loss: 0.4591 - val_acc: 0.0087\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4608 - acc: 0.0088 - val_loss: 0.4591 - val_acc: 0.0093\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4607 - acc: 0.0085 - val_loss: 0.4591 - val_acc: 0.0083\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4607 - acc: 0.0082 - val_loss: 0.4591 - val_acc: 0.0084\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4607 - acc: 0.0081 - val_loss: 0.4591 - val_acc: 0.0080\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4607 - acc: 0.0081 - val_loss: 0.4591 - val_acc: 0.0089\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4607 - acc: 0.0078 - val_loss: 0.4591 - val_acc: 0.0079\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4607 - acc: 0.0082 - val_loss: 0.4591 - val_acc: 0.0077\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4607 - acc: 0.0078 - val_loss: 0.4591 - val_acc: 0.0084\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4607 - acc: 0.0080 - val_loss: 0.4591 - val_acc: 0.0074\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4607 - acc: 0.0076 - val_loss: 0.4591 - val_acc: 0.0070\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4607 - acc: 0.0075 - val_loss: 0.4590 - val_acc: 0.0076\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4607 - acc: 0.0076 - val_loss: 0.4590 - val_acc: 0.0083\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4608 - acc: 0.0074 - val_loss: 0.4590 - val_acc: 0.0080\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4607 - acc: 0.0073 - val_loss: 0.4592 - val_acc: 0.0066\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4607 - acc: 0.0076 - val_loss: 0.4590 - val_acc: 0.0074\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.1328 - acc: 0.4715 - val_loss: 0.8601 - val_acc: 0.3180\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8772 - acc: 0.3006 - val_loss: 0.8088 - val_acc: 0.3327\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7359 - acc: 0.4071 - val_loss: 0.6991 - val_acc: 0.4954\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6656 - acc: 0.5216 - val_loss: 0.6250 - val_acc: 0.5179\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5794 - acc: 0.5097 - val_loss: 0.5178 - val_acc: 0.5149\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4809 - acc: 0.5211 - val_loss: 0.4606 - val_acc: 0.5118\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4632 - acc: 0.5048 - val_loss: 0.4671 - val_acc: 0.5022\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4651 - acc: 0.5030 - val_loss: 0.4620 - val_acc: 0.5055\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4597 - acc: 0.5080 - val_loss: 0.4597 - val_acc: 0.5115\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4593 - acc: 0.5130 - val_loss: 0.4599 - val_acc: 0.5138\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4590 - acc: 0.5118 - val_loss: 0.4595 - val_acc: 0.5103\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4589 - acc: 0.5095 - val_loss: 0.4595 - val_acc: 0.5093\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4588 - acc: 0.5096 - val_loss: 0.4594 - val_acc: 0.5101\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4587 - acc: 0.5101 - val_loss: 0.4593 - val_acc: 0.5106\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4587 - acc: 0.5105 - val_loss: 0.4593 - val_acc: 0.5106\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4586 - acc: 0.5101 - val_loss: 0.4593 - val_acc: 0.5100\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4586 - acc: 0.5097 - val_loss: 0.4592 - val_acc: 0.5096\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4585 - acc: 0.5096 - val_loss: 0.4592 - val_acc: 0.5097\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4585 - acc: 0.5096 - val_loss: 0.4592 - val_acc: 0.5100\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4585 - acc: 0.5099 - val_loss: 0.4592 - val_acc: 0.5099\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4585 - acc: 0.5094 - val_loss: 0.4591 - val_acc: 0.5090\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4585 - acc: 0.5086 - val_loss: 0.4591 - val_acc: 0.5086\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4584 - acc: 0.5085 - val_loss: 0.4591 - val_acc: 0.5087\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4584 - acc: 0.5088 - val_loss: 0.4591 - val_acc: 0.5089\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4584 - acc: 0.5084 - val_loss: 0.4590 - val_acc: 0.5083\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4583 - acc: 0.5080 - val_loss: 0.4590 - val_acc: 0.5081\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4583 - acc: 0.5082 - val_loss: 0.4590 - val_acc: 0.5085\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4583 - acc: 0.5081 - val_loss: 0.4590 - val_acc: 0.5080\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4583 - acc: 0.5078 - val_loss: 0.4590 - val_acc: 0.5079\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4583 - acc: 0.5079 - val_loss: 0.4590 - val_acc: 0.5081\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4583 - acc: 0.5078 - val_loss: 0.4590 - val_acc: 0.5079\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4583 - acc: 0.5075 - val_loss: 0.4590 - val_acc: 0.5075\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4583 - acc: 0.5072 - val_loss: 0.4590 - val_acc: 0.5073\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5073 - val_loss: 0.4589 - val_acc: 0.5075\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5071 - val_loss: 0.4589 - val_acc: 0.5071\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5068 - val_loss: 0.4589 - val_acc: 0.5073\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5071 - val_loss: 0.4589 - val_acc: 0.5069\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5067 - val_loss: 0.4589 - val_acc: 0.5069\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5067 - val_loss: 0.4589 - val_acc: 0.5068\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5066 - val_loss: 0.4589 - val_acc: 0.5067\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5065 - val_loss: 0.4589 - val_acc: 0.5068\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5065 - val_loss: 0.4590 - val_acc: 0.5061\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5058 - val_loss: 0.4590 - val_acc: 0.5063\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5061 - val_loss: 0.4590 - val_acc: 0.5060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5060 - val_loss: 0.4589 - val_acc: 0.5064\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4581 - acc: 0.5060 - val_loss: 0.4589 - val_acc: 0.5060\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4581 - acc: 0.5061 - val_loss: 0.4589 - val_acc: 0.5063\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5056 - val_loss: 0.4589 - val_acc: 0.5061\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5058 - val_loss: 0.4589 - val_acc: 0.5063\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4582 - acc: 0.5058 - val_loss: 0.4589 - val_acc: 0.5055\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.0699 - acc: 0.2407 - val_loss: 0.9478 - val_acc: 0.1284\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8855 - acc: 0.1327 - val_loss: 0.7817 - val_acc: 0.1512\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7741 - acc: 0.1599 - val_loss: 0.7312 - val_acc: 0.1472\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6689 - acc: 0.1139 - val_loss: 0.5774 - val_acc: 0.0699\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5183 - acc: 0.0283 - val_loss: 0.4898 - val_acc: 2.0000e-05\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4963 - acc: 0.0000e+00 - val_loss: 0.4993 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4960 - acc: 0.0000e+00 - val_loss: 0.4880 - val_acc: 5.0000e-06\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4882 - acc: 3.3000e-04 - val_loss: 0.4857 - val_acc: 0.0014\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4881 - acc: 0.0016 - val_loss: 0.4859 - val_acc: 0.0014\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4877 - acc: 8.0000e-04 - val_loss: 0.4852 - val_acc: 5.0000e-04\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4873 - acc: 3.5000e-04 - val_loss: 0.4852 - val_acc: 1.7500e-04\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4873 - acc: 1.2500e-04 - val_loss: 0.4851 - val_acc: 1.9500e-04\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4872 - acc: 2.1500e-04 - val_loss: 0.4850 - val_acc: 2.4000e-04\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4871 - acc: 2.3000e-04 - val_loss: 0.4849 - val_acc: 2.4000e-04\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4870 - acc: 1.6500e-04 - val_loss: 0.4849 - val_acc: 1.3000e-04\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4870 - acc: 1.1500e-04 - val_loss: 0.4848 - val_acc: 1.2000e-04\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4869 - acc: 9.0000e-05 - val_loss: 0.4847 - val_acc: 1.1000e-04\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4869 - acc: 7.5000e-05 - val_loss: 0.4848 - val_acc: 6.0000e-05\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4868 - acc: 5.5000e-05 - val_loss: 0.4846 - val_acc: 6.5000e-05\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4868 - acc: 6.0000e-05 - val_loss: 0.4847 - val_acc: 2.0000e-05\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4868 - acc: 4.5000e-05 - val_loss: 0.4845 - val_acc: 2.0000e-05\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4867 - acc: 3.5000e-05 - val_loss: 0.4845 - val_acc: 2.0000e-05\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4867 - acc: 3.0000e-05 - val_loss: 0.4845 - val_acc: 1.5000e-05\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4867 - acc: 3.0000e-05 - val_loss: 0.4844 - val_acc: 1.5000e-05\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 1.5000e-05 - val_loss: 0.4844 - val_acc: 1.0000e-05\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 2.0000e-05 - val_loss: 0.4844 - val_acc: 5.0000e-06\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.0000e+00 - val_loss: 0.4843 - val_acc: 5.0000e-06\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.0000e+00 - val_loss: 0.4843 - val_acc: 5.0000e-06\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4865 - acc: 0.0000e+00 - val_loss: 0.4843 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4865 - acc: 0.0000e+00 - val_loss: 0.4843 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4865 - acc: 0.0000e+00 - val_loss: 0.4843 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4865 - acc: 0.0000e+00 - val_loss: 0.4843 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4865 - acc: 0.0000e+00 - val_loss: 0.4843 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4865 - acc: 0.0000e+00 - val_loss: 0.4842 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4865 - acc: 0.0000e+00 - val_loss: 0.4842 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4865 - acc: 0.0000e+00 - val_loss: 0.4842 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4864 - acc: 0.0000e+00 - val_loss: 0.4842 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4864 - acc: 0.0000e+00 - val_loss: 0.4843 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4864 - acc: 0.0000e+00 - val_loss: 0.4841 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4864 - acc: 0.0000e+00 - val_loss: 0.4841 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4864 - acc: 0.0000e+00 - val_loss: 0.4841 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4864 - acc: 0.0000e+00 - val_loss: 0.4842 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4864 - acc: 0.0000e+00 - val_loss: 0.4843 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4865 - acc: 0.0000e+00 - val_loss: 0.4841 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4864 - acc: 0.0000e+00 - val_loss: 0.4843 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4864 - acc: 0.0000e+00 - val_loss: 0.4841 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4864 - acc: 0.0000e+00 - val_loss: 0.4841 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4864 - acc: 0.0000e+00 - val_loss: 0.4841 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4864 - acc: 0.0000e+00 - val_loss: 0.4841 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4865 - acc: 0.0000e+00 - val_loss: 0.4841 - val_acc: 0.0000e+00\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.0848 - acc: 0.4451 - val_loss: 0.9622 - val_acc: 0.2981\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9181 - acc: 0.3223 - val_loss: 0.8339 - val_acc: 0.4012\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8412 - acc: 0.4571 - val_loss: 0.8373 - val_acc: 0.4750\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8110 - acc: 0.4446 - val_loss: 0.7951 - val_acc: 0.4047\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7872 - acc: 0.4085 - val_loss: 0.7682 - val_acc: 0.4360\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7539 - acc: 0.4632 - val_loss: 0.7362 - val_acc: 0.4702\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7125 - acc: 0.4762 - val_loss: 0.6763 - val_acc: 0.5072\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6222 - acc: 0.5206 - val_loss: 0.5571 - val_acc: 0.5169\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5670 - acc: 0.5162 - val_loss: 0.5504 - val_acc: 0.5141\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5406 - acc: 0.5131 - val_loss: 0.5275 - val_acc: 0.5100\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5233 - acc: 0.5095 - val_loss: 0.5159 - val_acc: 0.5048\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5116 - acc: 0.5049 - val_loss: 0.5227 - val_acc: 0.5059\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5091 - acc: 0.5064 - val_loss: 0.5060 - val_acc: 0.5045\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.5057 - val_loss: 0.4985 - val_acc: 0.5040\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.5037 - val_loss: 0.4948 - val_acc: 0.5024\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4929 - acc: 0.5032 - val_loss: 0.4933 - val_acc: 0.5025\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4914 - acc: 0.5028 - val_loss: 0.4920 - val_acc: 0.5022\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4908 - acc: 0.5029 - val_loss: 0.4998 - val_acc: 0.5043\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4963 - acc: 0.5052 - val_loss: 0.4967 - val_acc: 0.5032\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4921 - acc: 0.5032 - val_loss: 0.4919 - val_acc: 0.5019\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4898 - acc: 0.5015 - val_loss: 0.4904 - val_acc: 0.5008\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4888 - acc: 0.5015 - val_loss: 0.4896 - val_acc: 0.5012\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4881 - acc: 0.5016 - val_loss: 0.4891 - val_acc: 0.5011\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4877 - acc: 0.5015 - val_loss: 0.4887 - val_acc: 0.5008\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4874 - acc: 0.5011 - val_loss: 0.4883 - val_acc: 0.5006\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4871 - acc: 0.5009 - val_loss: 0.4881 - val_acc: 0.5005\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4869 - acc: 0.5008 - val_loss: 0.4879 - val_acc: 0.5005\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4867 - acc: 0.5008 - val_loss: 0.4877 - val_acc: 0.5003\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4865 - acc: 0.5007 - val_loss: 0.4875 - val_acc: 0.5002\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4864 - acc: 0.5006 - val_loss: 0.4874 - val_acc: 0.5002\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4864 - acc: 0.5005 - val_loss: 0.4874 - val_acc: 0.5002\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4863 - acc: 0.5005 - val_loss: 0.4873 - val_acc: 0.5000\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4862 - acc: 0.5004 - val_loss: 0.4871 - val_acc: 0.5000\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4860 - acc: 0.5004 - val_loss: 0.4870 - val_acc: 0.4999\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4860 - acc: 0.5004 - val_loss: 0.4869 - val_acc: 0.4999\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4859 - acc: 0.5004 - val_loss: 0.4869 - val_acc: 0.4999\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4859 - acc: 0.5004 - val_loss: 0.4868 - val_acc: 0.4998\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 0.5004 - val_loss: 0.4868 - val_acc: 0.4998\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 0.5003 - val_loss: 0.4867 - val_acc: 0.4998\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 0.5003 - val_loss: 0.4867 - val_acc: 0.4998\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 0.5003 - val_loss: 0.4867 - val_acc: 0.4998\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 0.5003 - val_loss: 0.4866 - val_acc: 0.4997\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 0.5003 - val_loss: 0.4866 - val_acc: 0.4997\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 0.5003 - val_loss: 0.4866 - val_acc: 0.4997\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4857 - acc: 0.5002 - val_loss: 0.4867 - val_acc: 0.4997\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4857 - acc: 0.5002 - val_loss: 0.4865 - val_acc: 0.4997\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4856 - acc: 0.5002 - val_loss: 0.4865 - val_acc: 0.4997\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4857 - acc: 0.5002 - val_loss: 0.4866 - val_acc: 0.4997\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4856 - acc: 0.5002 - val_loss: 0.4865 - val_acc: 0.4997\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4857 - acc: 0.5002 - val_loss: 0.4866 - val_acc: 0.4996\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.8179 - acc: 0.4866 - val_loss: 0.9106 - val_acc: 0.3832\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9786 - acc: 0.3214 - val_loss: 1.0295 - val_acc: 0.2901\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9852 - acc: 0.3106 - val_loss: 0.9221 - val_acc: 0.3500\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9099 - acc: 0.3856 - val_loss: 0.9041 - val_acc: 0.4180\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9081 - acc: 0.4246 - val_loss: 0.8992 - val_acc: 0.4203\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8954 - acc: 0.4081 - val_loss: 0.8864 - val_acc: 0.3921\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8836 - acc: 0.3870 - val_loss: 0.8766 - val_acc: 0.3857\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8702 - acc: 0.3924 - val_loss: 0.8607 - val_acc: 0.4009\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8547 - acc: 0.4088 - val_loss: 0.8472 - val_acc: 0.4139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8432 - acc: 0.4139 - val_loss: 0.8356 - val_acc: 0.4104\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8283 - acc: 0.4106 - val_loss: 0.8161 - val_acc: 0.4131\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8122 - acc: 0.4182 - val_loss: 0.7985 - val_acc: 0.4260\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7939 - acc: 0.4296 - val_loss: 0.7783 - val_acc: 0.4343\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7756 - acc: 0.4331 - val_loss: 0.7611 - val_acc: 0.4426\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7506 - acc: 0.4615 - val_loss: 0.7298 - val_acc: 0.4777\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7209 - acc: 0.4866 - val_loss: 0.7078 - val_acc: 0.4955\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7024 - acc: 0.4947 - val_loss: 0.6924 - val_acc: 0.4942\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6902 - acc: 0.4928 - val_loss: 0.6826 - val_acc: 0.4918\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6858 - acc: 0.4898 - val_loss: 0.6856 - val_acc: 0.4875\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6815 - acc: 0.4894 - val_loss: 0.6716 - val_acc: 0.4890\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6673 - acc: 0.4914 - val_loss: 0.6560 - val_acc: 0.4927\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6461 - acc: 0.4979 - val_loss: 0.6273 - val_acc: 0.5016\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6342 - acc: 0.5000 - val_loss: 0.6305 - val_acc: 0.5002\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6342 - acc: 0.4997 - val_loss: 0.6350 - val_acc: 0.4972\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6337 - acc: 0.4987 - val_loss: 0.6280 - val_acc: 0.5005\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6184 - acc: 0.5025 - val_loss: 0.6132 - val_acc: 0.5040\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6060 - acc: 0.5049 - val_loss: 0.6090 - val_acc: 0.5045\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6067 - acc: 0.5044 - val_loss: 0.6082 - val_acc: 0.5052\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6058 - acc: 0.5048 - val_loss: 0.6069 - val_acc: 0.5043\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6013 - acc: 0.5057 - val_loss: 0.6016 - val_acc: 0.5057\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6065 - acc: 0.5037 - val_loss: 0.6101 - val_acc: 0.5033\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6107 - acc: 0.5034 - val_loss: 0.6170 - val_acc: 0.5002\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6143 - acc: 0.5009 - val_loss: 0.6159 - val_acc: 0.5005\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6096 - acc: 0.5015 - val_loss: 0.6024 - val_acc: 0.5049\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5965 - acc: 0.5046 - val_loss: 0.5933 - val_acc: 0.5058\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5878 - acc: 0.5066 - val_loss: 0.5962 - val_acc: 0.5048\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5968 - acc: 0.5048 - val_loss: 0.5991 - val_acc: 0.5082\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5762 - acc: 0.5097 - val_loss: 0.5704 - val_acc: 0.5101\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5679 - acc: 0.5109 - val_loss: 0.5696 - val_acc: 0.5107\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5702 - acc: 0.5102 - val_loss: 0.5849 - val_acc: 0.5066\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5794 - acc: 0.5081 - val_loss: 0.5793 - val_acc: 0.5072\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5769 - acc: 0.5067 - val_loss: 0.5799 - val_acc: 0.5063\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5746 - acc: 0.5077 - val_loss: 0.5701 - val_acc: 0.5094\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5637 - acc: 0.5100 - val_loss: 0.5667 - val_acc: 0.5085\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5599 - acc: 0.5108 - val_loss: 0.5563 - val_acc: 0.5101\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5545 - acc: 0.5106 - val_loss: 0.5536 - val_acc: 0.5112\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5479 - acc: 0.5122 - val_loss: 0.5508 - val_acc: 0.5108\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5451 - acc: 0.5118 - val_loss: 0.5456 - val_acc: 0.5124\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5323 - acc: 0.5111 - val_loss: 0.5129 - val_acc: 0.5065\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5089 - acc: 0.5041 - val_loss: 0.5053 - val_acc: 0.5006\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.4083 - acc: 0.5135 - val_loss: 0.8189 - val_acc: 0.4370\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8623 - acc: 0.3568 - val_loss: 0.8864 - val_acc: 0.3200\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8483 - acc: 0.3406 - val_loss: 0.7866 - val_acc: 0.3927\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7679 - acc: 0.4322 - val_loss: 0.7496 - val_acc: 0.4748\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7344 - acc: 0.4851 - val_loss: 0.6992 - val_acc: 0.4933\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6816 - acc: 0.4815 - val_loss: 0.6627 - val_acc: 0.4722\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6593 - acc: 0.4634 - val_loss: 0.6476 - val_acc: 0.4674\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6371 - acc: 0.4784 - val_loss: 0.6178 - val_acc: 0.4961\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5975 - acc: 0.5072 - val_loss: 0.5629 - val_acc: 0.5197\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5347 - acc: 0.5143 - val_loss: 0.4990 - val_acc: 0.5099\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4946 - acc: 0.5024 - val_loss: 0.4885 - val_acc: 0.5021\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4935 - acc: 0.4990 - val_loss: 0.4903 - val_acc: 0.5017\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4926 - acc: 0.4991 - val_loss: 0.4877 - val_acc: 0.5022\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4905 - acc: 0.4997 - val_loss: 0.4868 - val_acc: 0.5032\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4903 - acc: 0.5005 - val_loss: 0.4868 - val_acc: 0.5033\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4901 - acc: 0.5003 - val_loss: 0.4865 - val_acc: 0.5029\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4899 - acc: 0.4999 - val_loss: 0.4864 - val_acc: 0.5026\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4897 - acc: 0.4998 - val_loss: 0.4863 - val_acc: 0.5025\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4896 - acc: 0.4997 - val_loss: 0.4861 - val_acc: 0.5025\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4895 - acc: 0.4997 - val_loss: 0.4861 - val_acc: 0.5024\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4894 - acc: 0.4997 - val_loss: 0.4859 - val_acc: 0.5024\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4893 - acc: 0.4996 - val_loss: 0.4859 - val_acc: 0.5023\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4892 - acc: 0.4995 - val_loss: 0.4858 - val_acc: 0.5023\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4891 - acc: 0.4995 - val_loss: 0.4857 - val_acc: 0.5022\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4890 - acc: 0.4995 - val_loss: 0.4856 - val_acc: 0.5022\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4889 - acc: 0.4994 - val_loss: 0.4856 - val_acc: 0.5022\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4888 - acc: 0.4994 - val_loss: 0.4855 - val_acc: 0.5021\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4888 - acc: 0.4993 - val_loss: 0.4854 - val_acc: 0.5021\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4887 - acc: 0.4993 - val_loss: 0.4854 - val_acc: 0.5020\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4886 - acc: 0.4993 - val_loss: 0.4853 - val_acc: 0.5020\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4886 - acc: 0.4993 - val_loss: 0.4853 - val_acc: 0.5019\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4885 - acc: 0.4992 - val_loss: 0.4852 - val_acc: 0.5019\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4884 - acc: 0.4992 - val_loss: 0.4852 - val_acc: 0.5018\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4884 - acc: 0.4991 - val_loss: 0.4851 - val_acc: 0.5018\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4883 - acc: 0.4991 - val_loss: 0.4851 - val_acc: 0.5018\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4883 - acc: 0.4990 - val_loss: 0.4850 - val_acc: 0.5018\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4882 - acc: 0.4990 - val_loss: 0.4850 - val_acc: 0.5017\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4882 - acc: 0.4989 - val_loss: 0.4850 - val_acc: 0.5017\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4882 - acc: 0.4989 - val_loss: 0.4849 - val_acc: 0.5017\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4882 - acc: 0.4989 - val_loss: 0.4849 - val_acc: 0.5017\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4881 - acc: 0.4989 - val_loss: 0.4848 - val_acc: 0.5016\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4880 - acc: 0.4989 - val_loss: 0.4848 - val_acc: 0.5016\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4880 - acc: 0.4988 - val_loss: 0.4848 - val_acc: 0.5016\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4880 - acc: 0.4988 - val_loss: 0.4848 - val_acc: 0.5016\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4880 - acc: 0.4988 - val_loss: 0.4847 - val_acc: 0.5016\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4879 - acc: 0.4988 - val_loss: 0.4848 - val_acc: 0.5015\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4879 - acc: 0.4987 - val_loss: 0.4847 - val_acc: 0.5015\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4879 - acc: 0.4988 - val_loss: 0.4847 - val_acc: 0.5015\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4878 - acc: 0.4988 - val_loss: 0.4847 - val_acc: 0.5015\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4878 - acc: 0.4987 - val_loss: 0.4847 - val_acc: 0.5015\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.6763 - acc: 0.3567 - val_loss: 0.8798 - val_acc: 0.2095\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8416 - acc: 0.1797 - val_loss: 0.8251 - val_acc: 0.1583\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8381 - acc: 0.1507 - val_loss: 0.8420 - val_acc: 0.1462\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8450 - acc: 0.1444 - val_loss: 0.8362 - val_acc: 0.1452\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8320 - acc: 0.1457 - val_loss: 0.8180 - val_acc: 0.1482\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8142 - acc: 0.1482 - val_loss: 0.8031 - val_acc: 0.1507\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7988 - acc: 0.1501 - val_loss: 0.7913 - val_acc: 0.1510\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7850 - acc: 0.1492 - val_loss: 0.7800 - val_acc: 0.1491\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7745 - acc: 0.1470 - val_loss: 0.7684 - val_acc: 0.1459\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7617 - acc: 0.1431 - val_loss: 0.7551 - val_acc: 0.1405\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7488 - acc: 0.1380 - val_loss: 0.7407 - val_acc: 0.1346\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7337 - acc: 0.1315 - val_loss: 0.7215 - val_acc: 0.1267\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7130 - acc: 0.1237 - val_loss: 0.6976 - val_acc: 0.1169\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6835 - acc: 0.1133 - val_loss: 0.6619 - val_acc: 0.1037\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6373 - acc: 0.0964 - val_loss: 0.6135 - val_acc: 0.0840\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5796 - acc: 0.0727 - val_loss: 0.5437 - val_acc: 0.0512\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5142 - acc: 0.0333 - val_loss: 0.4946 - val_acc: 0.0096\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4891 - acc: 0.0036 - val_loss: 0.4877 - val_acc: 3.7500e-04\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4870 - acc: 2.6000e-04 - val_loss: 0.4886 - val_acc: 1.2500e-04\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4875 - acc: 2.5000e-04 - val_loss: 0.4879 - val_acc: 2.4000e-04\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4864 - acc: 4.4000e-04 - val_loss: 0.4871 - val_acc: 5.0000e-04\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4860 - acc: 8.3000e-04 - val_loss: 0.4870 - val_acc: 0.0010\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4859 - acc: 0.0012 - val_loss: 0.4870 - val_acc: 0.0013\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4859 - acc: 0.0014 - val_loss: 0.4870 - val_acc: 0.0013\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 0.0013 - val_loss: 0.4870 - val_acc: 0.0011\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 0.0011 - val_loss: 0.4869 - val_acc: 9.7000e-04\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 0.0010 - val_loss: 0.4869 - val_acc: 9.0500e-04\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 9.9000e-04 - val_loss: 0.4869 - val_acc: 9.5500e-04\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 0.0010 - val_loss: 0.4869 - val_acc: 9.2000e-04\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 9.8000e-04 - val_loss: 0.4869 - val_acc: 9.0500e-04\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 9.5000e-04 - val_loss: 0.4868 - val_acc: 8.7000e-04\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4857 - acc: 9.5000e-04 - val_loss: 0.4868 - val_acc: 8.6000e-04\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4857 - acc: 9.5500e-04 - val_loss: 0.4868 - val_acc: 8.3000e-04\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4857 - acc: 9.0000e-04 - val_loss: 0.4868 - val_acc: 8.0500e-04\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4857 - acc: 8.7500e-04 - val_loss: 0.4868 - val_acc: 8.2000e-04\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4857 - acc: 8.6000e-04 - val_loss: 0.4867 - val_acc: 7.8000e-04\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4857 - acc: 8.5000e-04 - val_loss: 0.4867 - val_acc: 7.8500e-04\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4857 - acc: 8.7000e-04 - val_loss: 0.4867 - val_acc: 7.8000e-04\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4856 - acc: 8.2000e-04 - val_loss: 0.4867 - val_acc: 7.6000e-04\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4856 - acc: 8.0500e-04 - val_loss: 0.4867 - val_acc: 7.6000e-04\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4856 - acc: 7.6500e-04 - val_loss: 0.4867 - val_acc: 7.1000e-04\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4856 - acc: 7.6500e-04 - val_loss: 0.4867 - val_acc: 7.4500e-04\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4856 - acc: 7.7000e-04 - val_loss: 0.4866 - val_acc: 7.3000e-04\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4856 - acc: 7.5000e-04 - val_loss: 0.4866 - val_acc: 6.8000e-04\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4856 - acc: 7.1000e-04 - val_loss: 0.4866 - val_acc: 6.8000e-04\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4856 - acc: 7.4500e-04 - val_loss: 0.4866 - val_acc: 6.8500e-04\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4856 - acc: 7.0000e-04 - val_loss: 0.4866 - val_acc: 6.3000e-04\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4856 - acc: 6.2500e-04 - val_loss: 0.4865 - val_acc: 5.7000e-04\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4855 - acc: 6.4500e-04 - val_loss: 0.4865 - val_acc: 6.3500e-04\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4855 - acc: 6.6000e-04 - val_loss: 0.4865 - val_acc: 6.2000e-04\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.1935 - acc: 0.2722 - val_loss: 0.9457 - val_acc: 0.1388\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9563 - acc: 0.1329 - val_loss: 0.8806 - val_acc: 0.1400\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8338 - acc: 0.1583 - val_loss: 0.8214 - val_acc: 0.1760\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8113 - acc: 0.1741 - val_loss: 0.7888 - val_acc: 0.1604\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7689 - acc: 0.1471 - val_loss: 0.7537 - val_acc: 0.1331\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7323 - acc: 0.1274 - val_loss: 0.7173 - val_acc: 0.1238\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6934 - acc: 0.1196 - val_loss: 0.6571 - val_acc: 0.1096\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6097 - acc: 0.0893 - val_loss: 0.5520 - val_acc: 0.0596\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5135 - acc: 0.0310 - val_loss: 0.4913 - val_acc: 0.0079\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4908 - acc: 0.0029 - val_loss: 0.4960 - val_acc: 6.8000e-04\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4928 - acc: 7.2000e-04 - val_loss: 0.4923 - val_acc: 0.0015\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4888 - acc: 0.0029 - val_loss: 0.4898 - val_acc: 0.0045\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4881 - acc: 0.0052 - val_loss: 0.4897 - val_acc: 0.0053\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4878 - acc: 0.0047 - val_loss: 0.4893 - val_acc: 0.0040\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4874 - acc: 0.0034 - val_loss: 0.4890 - val_acc: 0.0029\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4872 - acc: 0.0027 - val_loss: 0.4888 - val_acc: 0.0026\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4870 - acc: 0.0027 - val_loss: 0.4886 - val_acc: 0.0026\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4868 - acc: 0.0026 - val_loss: 0.4884 - val_acc: 0.0024\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.0024 - val_loss: 0.4882 - val_acc: 0.0021\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4865 - acc: 0.0021 - val_loss: 0.4881 - val_acc: 0.0020\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4863 - acc: 0.0019 - val_loss: 0.4880 - val_acc: 0.0019\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4862 - acc: 0.0018 - val_loss: 0.4879 - val_acc: 0.0017\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0016 - val_loss: 0.4878 - val_acc: 0.0016\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4860 - acc: 0.0014 - val_loss: 0.4877 - val_acc: 0.0014\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4859 - acc: 0.0013 - val_loss: 0.4876 - val_acc: 0.0014\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 0.0013 - val_loss: 0.4875 - val_acc: 0.0011\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 9.1500e-04 - val_loss: 0.4875 - val_acc: 0.0010\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4857 - acc: 8.0500e-04 - val_loss: 0.4874 - val_acc: 8.3500e-04\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4857 - acc: 8.8500e-04 - val_loss: 0.4873 - val_acc: 7.9000e-04\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4856 - acc: 6.6000e-04 - val_loss: 0.4874 - val_acc: 8.5500e-04\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4856 - acc: 6.6000e-04 - val_loss: 0.4873 - val_acc: 6.9500e-04\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4855 - acc: 5.8500e-04 - val_loss: 0.4873 - val_acc: 6.8000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 5.4000e-04 - val_loss: 0.4872 - val_acc: 5.7500e-04\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 4.6500e-04 - val_loss: 0.4871 - val_acc: 5.4500e-04\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 4.2500e-04 - val_loss: 0.4871 - val_acc: 4.1500e-04\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4853 - acc: 2.3500e-04 - val_loss: 0.4871 - val_acc: 4.2500e-04\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4853 - acc: 3.2500e-04 - val_loss: 0.4870 - val_acc: 3.6500e-04\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4853 - acc: 2.2500e-04 - val_loss: 0.4871 - val_acc: 4.0000e-04\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4853 - acc: 2.6000e-04 - val_loss: 0.4870 - val_acc: 2.9000e-04\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4852 - acc: 2.0000e-04 - val_loss: 0.4870 - val_acc: 3.2500e-04\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4852 - acc: 1.7500e-04 - val_loss: 0.4870 - val_acc: 2.7000e-04\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4852 - acc: 1.4000e-04 - val_loss: 0.4870 - val_acc: 2.4000e-04\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4852 - acc: 1.4500e-04 - val_loss: 0.4870 - val_acc: 2.7000e-04\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4852 - acc: 1.2000e-04 - val_loss: 0.4869 - val_acc: 2.0500e-04\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4851 - acc: 1.1500e-04 - val_loss: 0.4870 - val_acc: 2.4000e-04\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4851 - acc: 1.1500e-04 - val_loss: 0.4869 - val_acc: 1.8000e-04\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4851 - acc: 9.5000e-05 - val_loss: 0.4869 - val_acc: 8.5000e-05\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4852 - acc: 9.5000e-05 - val_loss: 0.4869 - val_acc: 1.0500e-04\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4851 - acc: 8.5000e-05 - val_loss: 0.4869 - val_acc: 8.0000e-05\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4851 - acc: 6.5000e-05 - val_loss: 0.4869 - val_acc: 6.5000e-05\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.3503 - acc: 0.3136 - val_loss: 0.8307 - val_acc: 0.1552\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8836 - acc: 0.1333 - val_loss: 0.8971 - val_acc: 0.1208\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8387 - acc: 0.1282 - val_loss: 0.7816 - val_acc: 0.1392\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7541 - acc: 0.1438 - val_loss: 0.7231 - val_acc: 0.1405\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6845 - acc: 0.1260 - val_loss: 0.6332 - val_acc: 0.1032\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6041 - acc: 0.0862 - val_loss: 0.5660 - val_acc: 0.0643\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5410 - acc: 0.0495 - val_loss: 0.5127 - val_acc: 0.0313\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0182 - val_loss: 0.4888 - val_acc: 0.0062\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4872 - acc: 0.0027 - val_loss: 0.4849 - val_acc: 5.3500e-04\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4862 - acc: 3.4500e-04 - val_loss: 0.4854 - val_acc: 1.3000e-04\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4865 - acc: 1.9000e-04 - val_loss: 0.4852 - val_acc: 1.6000e-04\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 3.4000e-04 - val_loss: 0.4849 - val_acc: 4.5500e-04\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4859 - acc: 6.0500e-04 - val_loss: 0.4848 - val_acc: 7.8500e-04\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4859 - acc: 8.0500e-04 - val_loss: 0.4848 - val_acc: 8.9000e-04\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4859 - acc: 8.0000e-04 - val_loss: 0.4848 - val_acc: 8.2500e-04\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4859 - acc: 7.2000e-04 - val_loss: 0.4848 - val_acc: 7.3500e-04\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4859 - acc: 6.9500e-04 - val_loss: 0.4848 - val_acc: 6.7500e-04\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4859 - acc: 6.8000e-04 - val_loss: 0.4848 - val_acc: 7.2000e-04\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4859 - acc: 6.9000e-04 - val_loss: 0.4848 - val_acc: 7.2000e-04\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4859 - acc: 6.7000e-04 - val_loss: 0.4848 - val_acc: 6.6500e-04\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4859 - acc: 6.7500e-04 - val_loss: 0.4848 - val_acc: 7.2000e-04\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4859 - acc: 6.8000e-04 - val_loss: 0.4848 - val_acc: 6.6500e-04\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4859 - acc: 6.4500e-04 - val_loss: 0.4848 - val_acc: 6.6500e-04\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 6.5500e-04 - val_loss: 0.4848 - val_acc: 6.6500e-04\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 6.5000e-04 - val_loss: 0.4848 - val_acc: 6.5500e-04\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4859 - acc: 6.4000e-04 - val_loss: 0.4848 - val_acc: 6.8500e-04\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 6.6500e-04 - val_loss: 0.4848 - val_acc: 6.6500e-04\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 6.3500e-04 - val_loss: 0.4848 - val_acc: 6.2000e-04\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 6.3500e-04 - val_loss: 0.4848 - val_acc: 6.4000e-04\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 6.2000e-04 - val_loss: 0.4848 - val_acc: 6.1500e-04\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 6.1500e-04 - val_loss: 0.4848 - val_acc: 6.4000e-04\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4859 - acc: 6.3500e-04 - val_loss: 0.4848 - val_acc: 6.0500e-04\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 5.8500e-04 - val_loss: 0.4848 - val_acc: 5.7000e-04\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 6.1500e-04 - val_loss: 0.4848 - val_acc: 6.4000e-04\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 6.0000e-04 - val_loss: 0.4848 - val_acc: 5.4500e-04\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 5.6000e-04 - val_loss: 0.4848 - val_acc: 5.8000e-04\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 5.9500e-04 - val_loss: 0.4848 - val_acc: 5.5000e-04\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 5.7500e-04 - val_loss: 0.4848 - val_acc: 5.6500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 5.8000e-04 - val_loss: 0.4848 - val_acc: 5.4500e-04\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 5.4500e-04 - val_loss: 0.4848 - val_acc: 5.0500e-04\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 5.4500e-04 - val_loss: 0.4848 - val_acc: 5.3500e-04\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4859 - acc: 5.9500e-04 - val_loss: 0.4848 - val_acc: 5.7000e-04\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 5.5500e-04 - val_loss: 0.4848 - val_acc: 4.8500e-04\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 5.5000e-04 - val_loss: 0.4848 - val_acc: 5.4500e-04\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 5.6000e-04 - val_loss: 0.4848 - val_acc: 4.8500e-04\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 5.3500e-04 - val_loss: 0.4848 - val_acc: 4.8500e-04\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 5.3500e-04 - val_loss: 0.4848 - val_acc: 4.8000e-04\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 5.2500e-04 - val_loss: 0.4848 - val_acc: 4.8000e-04\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 5.2500e-04 - val_loss: 0.4848 - val_acc: 4.7500e-04\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4858 - acc: 5.2500e-04 - val_loss: 0.4848 - val_acc: 4.7500e-04\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.3629 - acc: 0.4920 - val_loss: 0.8599 - val_acc: 0.3775\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9266 - acc: 0.3230 - val_loss: 0.9627 - val_acc: 0.2995\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9047 - acc: 0.3245 - val_loss: 0.8395 - val_acc: 0.3684\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8037 - acc: 0.4114 - val_loss: 0.7779 - val_acc: 0.4603\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7546 - acc: 0.4819 - val_loss: 0.7349 - val_acc: 0.4980\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7039 - acc: 0.4996 - val_loss: 0.6635 - val_acc: 0.5042\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6255 - acc: 0.5063 - val_loss: 0.5805 - val_acc: 0.5130\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5427 - acc: 0.5151 - val_loss: 0.5103 - val_acc: 0.5162\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4980 - acc: 0.5082 - val_loss: 0.4878 - val_acc: 0.5047\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4874 - acc: 0.5002 - val_loss: 0.4848 - val_acc: 0.5022\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4872 - acc: 0.4990 - val_loss: 0.4851 - val_acc: 0.5019\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4873 - acc: 0.4988 - val_loss: 0.4849 - val_acc: 0.5020\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4869 - acc: 0.4990 - val_loss: 0.4847 - val_acc: 0.5023\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4993 - val_loss: 0.4848 - val_acc: 0.5025\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4867 - acc: 0.4995 - val_loss: 0.4848 - val_acc: 0.5025\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4867 - acc: 0.4996 - val_loss: 0.4848 - val_acc: 0.5025\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4995 - val_loss: 0.4848 - val_acc: 0.5025\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4994 - val_loss: 0.4847 - val_acc: 0.5025\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4993 - val_loss: 0.4847 - val_acc: 0.5024\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4993 - val_loss: 0.4847 - val_acc: 0.5024\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4993 - val_loss: 0.4847 - val_acc: 0.5024\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4993 - val_loss: 0.4848 - val_acc: 0.5025\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4994 - val_loss: 0.4848 - val_acc: 0.5024\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4993 - val_loss: 0.4847 - val_acc: 0.5024\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4993 - val_loss: 0.4847 - val_acc: 0.5024\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4993 - val_loss: 0.4847 - val_acc: 0.5023\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4992 - val_loss: 0.4847 - val_acc: 0.5023\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4993 - val_loss: 0.4847 - val_acc: 0.5024\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4993 - val_loss: 0.4847 - val_acc: 0.5023\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4992 - val_loss: 0.4847 - val_acc: 0.5023\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4993 - val_loss: 0.4847 - val_acc: 0.5023\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4992 - val_loss: 0.4847 - val_acc: 0.5023\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4992 - val_loss: 0.4847 - val_acc: 0.5023\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4992 - val_loss: 0.4847 - val_acc: 0.5023\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4993 - val_loss: 0.4847 - val_acc: 0.5023\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4993 - val_loss: 0.4847 - val_acc: 0.5023\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4992 - val_loss: 0.4847 - val_acc: 0.5023\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4992 - val_loss: 0.4847 - val_acc: 0.5022\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4992 - val_loss: 0.4847 - val_acc: 0.5023\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4992 - val_loss: 0.4847 - val_acc: 0.5022\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4991 - val_loss: 0.4847 - val_acc: 0.5023\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4992 - val_loss: 0.4847 - val_acc: 0.5022\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4991 - val_loss: 0.4847 - val_acc: 0.5023\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4992 - val_loss: 0.4847 - val_acc: 0.5023\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4991 - val_loss: 0.4847 - val_acc: 0.5022\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4991 - val_loss: 0.4847 - val_acc: 0.5022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4991 - val_loss: 0.4847 - val_acc: 0.5023\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4991 - val_loss: 0.4847 - val_acc: 0.5021\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4991 - val_loss: 0.4847 - val_acc: 0.5022\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4866 - acc: 0.4991 - val_loss: 0.4847 - val_acc: 0.5022\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.1161 - acc: 0.4248 - val_loss: 1.0299 - val_acc: 0.2870\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9280 - acc: 0.3342 - val_loss: 0.8044 - val_acc: 0.4418\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7696 - acc: 0.5110 - val_loss: 0.6951 - val_acc: 0.5413\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5946 - acc: 0.5319 - val_loss: 0.5091 - val_acc: 0.5157\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4913 - acc: 0.5071 - val_loss: 0.4889 - val_acc: 0.4998\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4924 - acc: 0.5004 - val_loss: 0.4945 - val_acc: 0.4997\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4906 - acc: 0.5004 - val_loss: 0.4876 - val_acc: 0.4999\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4860 - acc: 0.5010 - val_loss: 0.4862 - val_acc: 0.5010\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4857 - acc: 0.5023 - val_loss: 0.4865 - val_acc: 0.5017\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4856 - acc: 0.5021 - val_loss: 0.4861 - val_acc: 0.5009\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5015 - val_loss: 0.4861 - val_acc: 0.5006\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5013 - val_loss: 0.4861 - val_acc: 0.5005\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5013 - val_loss: 0.4861 - val_acc: 0.5006\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5014 - val_loss: 0.4861 - val_acc: 0.5007\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5014 - val_loss: 0.4861 - val_acc: 0.5007\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5014 - val_loss: 0.4861 - val_acc: 0.5006\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5013 - val_loss: 0.4861 - val_acc: 0.5006\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5014 - val_loss: 0.4861 - val_acc: 0.5005\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5013 - val_loss: 0.4861 - val_acc: 0.5006\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5014 - val_loss: 0.4862 - val_acc: 0.5004\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4855 - acc: 0.5012 - val_loss: 0.4861 - val_acc: 0.5006\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5013 - val_loss: 0.4861 - val_acc: 0.5004\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5013 - val_loss: 0.4861 - val_acc: 0.5005\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5012 - val_loss: 0.4862 - val_acc: 0.5006\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5013 - val_loss: 0.4861 - val_acc: 0.5003\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5012 - val_loss: 0.4862 - val_acc: 0.5006\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5012 - val_loss: 0.4861 - val_acc: 0.5003\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5012 - val_loss: 0.4861 - val_acc: 0.5006\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5012 - val_loss: 0.4861 - val_acc: 0.5005\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5012 - val_loss: 0.4861 - val_acc: 0.5003\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5011 - val_loss: 0.4861 - val_acc: 0.5005\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4853 - acc: 0.5012 - val_loss: 0.4861 - val_acc: 0.5005\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4853 - acc: 0.5013 - val_loss: 0.4860 - val_acc: 0.5004\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5011 - val_loss: 0.4861 - val_acc: 0.5004\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5011 - val_loss: 0.4861 - val_acc: 0.5005\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5012 - val_loss: 0.4861 - val_acc: 0.5002\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5011 - val_loss: 0.4861 - val_acc: 0.5003\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5011 - val_loss: 0.4860 - val_acc: 0.5005\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5011 - val_loss: 0.4861 - val_acc: 0.5005\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4853 - acc: 0.5012 - val_loss: 0.4861 - val_acc: 0.5002\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4853 - acc: 0.5010 - val_loss: 0.4862 - val_acc: 0.5006\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4855 - acc: 0.5012 - val_loss: 0.4862 - val_acc: 0.5002\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4855 - acc: 0.5012 - val_loss: 0.4861 - val_acc: 0.5005\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5011 - val_loss: 0.4861 - val_acc: 0.5004\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4853 - acc: 0.5011 - val_loss: 0.4861 - val_acc: 0.5002\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5012 - val_loss: 0.4860 - val_acc: 0.5004\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4854 - acc: 0.5011 - val_loss: 0.4860 - val_acc: 0.5002\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4853 - acc: 0.5010 - val_loss: 0.4860 - val_acc: 0.5003\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4853 - acc: 0.5011 - val_loss: 0.4860 - val_acc: 0.5004\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4853 - acc: 0.5011 - val_loss: 0.4861 - val_acc: 0.5005\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.3964 - acc: 0.3069 - val_loss: 0.8544 - val_acc: 0.1581\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9128 - acc: 0.1398 - val_loss: 0.9476 - val_acc: 0.1311\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9087 - acc: 0.1355 - val_loss: 0.8510 - val_acc: 0.1455\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8293 - acc: 0.1545 - val_loss: 0.8125 - val_acc: 0.1638\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8054 - acc: 0.1645 - val_loss: 0.7805 - val_acc: 0.1582\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7580 - acc: 0.1482 - val_loss: 0.7252 - val_acc: 0.1346\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6928 - acc: 0.1228 - val_loss: 0.6418 - val_acc: 0.1044\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5993 - acc: 0.0878 - val_loss: 0.5536 - val_acc: 0.0644\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5221 - acc: 0.0429 - val_loss: 0.4927 - val_acc: 0.0170\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4889 - acc: 0.0077 - val_loss: 0.4845 - val_acc: 0.0022\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4882 - acc: 0.0014 - val_loss: 0.4861 - val_acc: 0.0013\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4879 - acc: 0.0014 - val_loss: 0.4845 - val_acc: 0.0020\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4864 - acc: 0.0028 - val_loss: 0.4839 - val_acc: 0.0041\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4863 - acc: 0.0048 - val_loss: 0.4841 - val_acc: 0.0050\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4863 - acc: 0.0049 - val_loss: 0.4840 - val_acc: 0.0044\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4863 - acc: 0.0041 - val_loss: 0.4839 - val_acc: 0.0037\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4862 - acc: 0.0036 - val_loss: 0.4839 - val_acc: 0.0035\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4862 - acc: 0.0035 - val_loss: 0.4839 - val_acc: 0.0035\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4862 - acc: 0.0036 - val_loss: 0.4839 - val_acc: 0.0038\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4862 - acc: 0.0038 - val_loss: 0.4839 - val_acc: 0.0035\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4862 - acc: 0.0034 - val_loss: 0.4839 - val_acc: 0.0033\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4862 - acc: 0.0035 - val_loss: 0.4838 - val_acc: 0.0035\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4862 - acc: 0.0035 - val_loss: 0.4839 - val_acc: 0.0033\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4862 - acc: 0.0032 - val_loss: 0.4838 - val_acc: 0.0032\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0034 - val_loss: 0.4838 - val_acc: 0.0033\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0033 - val_loss: 0.4838 - val_acc: 0.0032\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0033 - val_loss: 0.4838 - val_acc: 0.0031\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0032 - val_loss: 0.4838 - val_acc: 0.0030\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0030 - val_loss: 0.4838 - val_acc: 0.0031\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0032 - val_loss: 0.4838 - val_acc: 0.0031\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0030 - val_loss: 0.4838 - val_acc: 0.0028\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0029 - val_loss: 0.4838 - val_acc: 0.0030\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0030 - val_loss: 0.4838 - val_acc: 0.0029\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0028 - val_loss: 0.4838 - val_acc: 0.0028\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0030 - val_loss: 0.4838 - val_acc: 0.0028\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0026 - val_loss: 0.4838 - val_acc: 0.0027\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0029 - val_loss: 0.4838 - val_acc: 0.0029\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0027 - val_loss: 0.4838 - val_acc: 0.0027\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0028 - val_loss: 0.4837 - val_acc: 0.0028\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0026 - val_loss: 0.4837 - val_acc: 0.0027\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0026 - val_loss: 0.4837 - val_acc: 0.0027\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4860 - acc: 0.0027 - val_loss: 0.4838 - val_acc: 0.0027\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0025 - val_loss: 0.4837 - val_acc: 0.0027\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0026 - val_loss: 0.4838 - val_acc: 0.0025\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0026 - val_loss: 0.4838 - val_acc: 0.0025\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0024 - val_loss: 0.4837 - val_acc: 0.0027\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0027 - val_loss: 0.4838 - val_acc: 0.0024\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0022 - val_loss: 0.4837 - val_acc: 0.0025\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0025 - val_loss: 0.4838 - val_acc: 0.0023\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4861 - acc: 0.0023 - val_loss: 0.4837 - val_acc: 0.0027\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 1s 3us/step - loss: 1.1771 - acc: 0.2319 - val_loss: 1.0539 - val_acc: 0.1205\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0094 - acc: 0.1267 - val_loss: 0.8963 - val_acc: 0.1420\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8934 - acc: 0.1602 - val_loss: 0.8812 - val_acc: 0.1644\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8479 - acc: 0.1450 - val_loss: 0.8052 - val_acc: 0.1192\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7847 - acc: 0.1077 - val_loss: 0.7589 - val_acc: 0.0989\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7298 - acc: 0.0926 - val_loss: 0.6931 - val_acc: 0.0830\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6569 - acc: 0.0682 - val_loss: 0.6038 - val_acc: 0.0481\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5607 - acc: 0.0280 - val_loss: 0.5180 - val_acc: 0.0076\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5129 - acc: 0.0026 - val_loss: 0.5150 - val_acc: 4.7000e-04\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5146 - acc: 3.2500e-04 - val_loss: 0.5121 - val_acc: 2.6000e-04\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5083 - acc: 5.8500e-04 - val_loss: 0.5060 - val_acc: 0.0011\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5057 - acc: 0.0013 - val_loss: 0.5052 - val_acc: 0.0015\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5049 - acc: 0.0013 - val_loss: 0.5042 - val_acc: 9.5500e-04\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5038 - acc: 5.9500e-04 - val_loss: 0.5034 - val_acc: 5.4000e-04\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5032 - acc: 3.9500e-04 - val_loss: 0.5030 - val_acc: 2.9000e-04\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5028 - acc: 2.8000e-04 - val_loss: 0.5025 - val_acc: 3.2000e-04\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5023 - acc: 2.7000e-04 - val_loss: 0.5021 - val_acc: 1.7000e-04\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5019 - acc: 1.8000e-04 - val_loss: 0.5017 - val_acc: 1.5500e-04\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5017 - acc: 1.0000e-04 - val_loss: 0.5014 - val_acc: 8.5000e-05\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5014 - acc: 8.0000e-05 - val_loss: 0.5012 - val_acc: 7.5000e-05\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5011 - acc: 5.5000e-05 - val_loss: 0.5009 - val_acc: 6.5000e-05\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5009 - acc: 4.0000e-05 - val_loss: 0.5008 - val_acc: 4.0000e-05\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5008 - acc: 2.0000e-05 - val_loss: 0.5006 - val_acc: 3.5000e-05\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5006 - acc: 2.0000e-05 - val_loss: 0.5004 - val_acc: 1.0000e-05\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5005 - acc: 1.0000e-05 - val_loss: 0.5003 - val_acc: 5.0000e-06\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5004 - acc: 0.0000e+00 - val_loss: 0.5002 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5003 - acc: 0.0000e+00 - val_loss: 0.5001 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5002 - acc: 0.0000e+00 - val_loss: 0.5000 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5001 - acc: 0.0000e+00 - val_loss: 0.5000 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4998 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4998 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4999 - acc: 0.0000e+00 - val_loss: 0.4997 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4998 - acc: 0.0000e+00 - val_loss: 0.4996 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4997 - acc: 0.0000e+00 - val_loss: 0.4997 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4998 - acc: 0.0000e+00 - val_loss: 0.4995 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4996 - acc: 0.0000e+00 - val_loss: 0.4994 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4997 - acc: 0.0000e+00 - val_loss: 0.4995 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4994 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4994 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4993 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4996 - acc: 0.0000e+00 - val_loss: 0.4995 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4997 - acc: 0.0000e+00 - val_loss: 0.4992 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4996 - acc: 0.0000e+00 - val_loss: 0.4997 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4996 - acc: 0.0000e+00 - val_loss: 0.4992 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4993 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4994 - acc: 0.0000e+00 - val_loss: 0.4992 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4994 - acc: 0.0000e+00 - val_loss: 0.4992 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4994 - acc: 0.0000e+00 - val_loss: 0.4991 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4994 - acc: 0.0000e+00 - val_loss: 0.4992 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4993 - acc: 0.0000e+00 - val_loss: 0.4991 - val_acc: 0.0000e+00\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.4431 - acc: 0.2956 - val_loss: 0.9160 - val_acc: 0.1404\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9776 - acc: 0.1219 - val_loss: 1.0158 - val_acc: 0.1156\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9679 - acc: 0.1185 - val_loss: 0.9065 - val_acc: 0.1281\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8780 - acc: 0.1348 - val_loss: 0.8573 - val_acc: 0.1416\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8465 - acc: 0.1409 - val_loss: 0.8324 - val_acc: 0.1361\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8048 - acc: 0.1247 - val_loss: 0.7738 - val_acc: 0.1105\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7342 - acc: 0.0966 - val_loss: 0.6909 - val_acc: 0.0803\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6312 - acc: 0.0597 - val_loss: 0.5681 - val_acc: 0.0289\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5393 - acc: 0.0106 - val_loss: 0.5113 - val_acc: 9.0500e-04\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5043 - acc: 3.2000e-04 - val_loss: 0.5008 - val_acc: 2.5000e-05\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5015 - acc: 1.0000e-05 - val_loss: 0.4994 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5013 - acc: 0.0000e+00 - val_loss: 0.4995 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5008 - acc: 0.0000e+00 - val_loss: 0.4990 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5004 - acc: 0.0000e+00 - val_loss: 0.4988 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5003 - acc: 0.0000e+00 - val_loss: 0.4988 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5002 - acc: 0.0000e+00 - val_loss: 0.4988 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5002 - acc: 0.0000e+00 - val_loss: 0.4988 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5002 - acc: 0.0000e+00 - val_loss: 0.4988 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5002 - acc: 0.0000e+00 - val_loss: 0.4987 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5001 - acc: 0.0000e+00 - val_loss: 0.4987 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5001 - acc: 0.0000e+00 - val_loss: 0.4987 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5001 - acc: 0.0000e+00 - val_loss: 0.4987 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5001 - acc: 0.0000e+00 - val_loss: 0.4987 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5001 - acc: 0.0000e+00 - val_loss: 0.4986 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5001 - acc: 0.0000e+00 - val_loss: 0.4986 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5001 - acc: 0.0000e+00 - val_loss: 0.4986 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4986 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4986 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4986 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4986 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4986 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4985 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4986 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4985 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4985 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4985 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4985 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4985 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4985 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4985 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4985 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4985 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4985 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4985 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4985 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4985 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4985 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4985 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4985 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.0000e+00 - val_loss: 0.4985 - val_acc: 0.0000e+00\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 1s 3us/step - loss: 1.3838 - acc: 0.2912 - val_loss: 0.9036 - val_acc: 0.1368\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9631 - acc: 0.1195 - val_loss: 0.9668 - val_acc: 0.1103\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9125 - acc: 0.1156 - val_loss: 0.8495 - val_acc: 0.1242\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8379 - acc: 0.1311 - val_loss: 0.8185 - val_acc: 0.1336\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7945 - acc: 0.1241 - val_loss: 0.7476 - val_acc: 0.1057\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7051 - acc: 0.0868 - val_loss: 0.6332 - val_acc: 0.0599\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5729 - acc: 0.0339 - val_loss: 0.5204 - val_acc: 0.0047\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5078 - acc: 9.3000e-04 - val_loss: 0.5003 - val_acc: 2.0000e-05\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5035 - acc: 0.0000e+00 - val_loss: 0.5041 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5034 - acc: 0.0000e+00 - val_loss: 0.5019 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5009 - acc: 0.0000e+00 - val_loss: 0.4999 - val_acc: 2.0000e-05\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5001 - acc: 1.5000e-05 - val_loss: 0.4997 - val_acc: 2.5000e-05\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5001 - acc: 2.0000e-05 - val_loss: 0.4996 - val_acc: 2.5000e-05\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 1.5000e-05 - val_loss: 0.4996 - val_acc: 2.0000e-05\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4999 - acc: 5.0000e-06 - val_loss: 0.4995 - val_acc: 2.0000e-05\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4999 - acc: 5.0000e-06 - val_loss: 0.4995 - val_acc: 2.0000e-05\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4998 - acc: 0.0000e+00 - val_loss: 0.4995 - val_acc: 1.5000e-05\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4998 - acc: 0.0000e+00 - val_loss: 0.4994 - val_acc: 1.5000e-05\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4998 - acc: 0.0000e+00 - val_loss: 0.4994 - val_acc: 1.5000e-05\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4998 - acc: 0.0000e+00 - val_loss: 0.4994 - val_acc: 1.5000e-05\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4997 - acc: 0.0000e+00 - val_loss: 0.4993 - val_acc: 5.0000e-06\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4997 - acc: 0.0000e+00 - val_loss: 0.4993 - val_acc: 5.0000e-06\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4997 - acc: 0.0000e+00 - val_loss: 0.4993 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4996 - acc: 0.0000e+00 - val_loss: 0.4993 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4996 - acc: 0.0000e+00 - val_loss: 0.4992 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4996 - acc: 0.0000e+00 - val_loss: 0.4992 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4996 - acc: 0.0000e+00 - val_loss: 0.4992 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4992 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4991 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4991 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4991 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4994 - acc: 0.0000e+00 - val_loss: 0.4991 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4994 - acc: 0.0000e+00 - val_loss: 0.4991 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4991 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4994 - acc: 0.0000e+00 - val_loss: 0.4990 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4994 - acc: 0.0000e+00 - val_loss: 0.4990 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4994 - acc: 0.0000e+00 - val_loss: 0.4990 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4994 - acc: 0.0000e+00 - val_loss: 0.4991 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4993 - acc: 0.0000e+00 - val_loss: 0.4990 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4993 - acc: 0.0000e+00 - val_loss: 0.4990 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4993 - acc: 0.0000e+00 - val_loss: 0.4989 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4993 - acc: 0.0000e+00 - val_loss: 0.4989 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4993 - acc: 0.0000e+00 - val_loss: 0.4989 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4993 - acc: 0.0000e+00 - val_loss: 0.4989 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4992 - acc: 0.0000e+00 - val_loss: 0.4989 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4993 - acc: 0.0000e+00 - val_loss: 0.4989 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4992 - acc: 0.0000e+00 - val_loss: 0.4989 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4992 - acc: 0.0000e+00 - val_loss: 0.4989 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4992 - acc: 0.0000e+00 - val_loss: 0.4988 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4992 - acc: 0.0000e+00 - val_loss: 0.4989 - val_acc: 0.0000e+00\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.3088 - acc: 0.4613 - val_loss: 0.9931 - val_acc: 0.3300\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0427 - acc: 0.3053 - val_loss: 0.9816 - val_acc: 0.3269\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9037 - acc: 0.3917 - val_loss: 0.8658 - val_acc: 0.4644\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8516 - acc: 0.4885 - val_loss: 0.8186 - val_acc: 0.4986\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7675 - acc: 0.4978 - val_loss: 0.7144 - val_acc: 0.4947\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6704 - acc: 0.5025 - val_loss: 0.6096 - val_acc: 0.5058\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5609 - acc: 0.5042 - val_loss: 0.5210 - val_acc: 0.5014\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5078 - acc: 0.5006 - val_loss: 0.5037 - val_acc: 0.5002\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5035 - acc: 0.5001 - val_loss: 0.5042 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5036 - acc: 0.5000 - val_loss: 0.5025 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5018 - acc: 0.5000 - val_loss: 0.5011 - val_acc: 0.5001\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5009 - acc: 0.5000 - val_loss: 0.5008 - val_acc: 0.5001\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5008 - acc: 0.5001 - val_loss: 0.5007 - val_acc: 0.5001\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5006 - acc: 0.5000 - val_loss: 0.5005 - val_acc: 0.5001\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5004 - acc: 0.5000 - val_loss: 0.5003 - val_acc: 0.5001\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5003 - acc: 0.5000 - val_loss: 0.5002 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5001 - acc: 0.5000 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5000 - acc: 0.5000 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4999 - acc: 0.5000 - val_loss: 0.4998 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4998 - acc: 0.5000 - val_loss: 0.4997 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4997 - acc: 0.5000 - val_loss: 0.4997 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4997 - acc: 0.5000 - val_loss: 0.4996 - val_acc: 0.5000\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4996 - acc: 0.5000 - val_loss: 0.4995 - val_acc: 0.5000\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.5000 - val_loss: 0.4995 - val_acc: 0.5000\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.5000 - val_loss: 0.4994 - val_acc: 0.5000\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4994 - acc: 0.5000 - val_loss: 0.4994 - val_acc: 0.5000\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4994 - acc: 0.5000 - val_loss: 0.4993 - val_acc: 0.5000\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4994 - acc: 0.5000 - val_loss: 0.4993 - val_acc: 0.5000\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4993 - acc: 0.5000 - val_loss: 0.4993 - val_acc: 0.5000\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4993 - acc: 0.5000 - val_loss: 0.4992 - val_acc: 0.5000\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4993 - acc: 0.5000 - val_loss: 0.4992 - val_acc: 0.5000\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4992 - acc: 0.5000 - val_loss: 0.4992 - val_acc: 0.5000\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4992 - acc: 0.5000 - val_loss: 0.4991 - val_acc: 0.5000\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4992 - acc: 0.5000 - val_loss: 0.4991 - val_acc: 0.5000\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4992 - acc: 0.5000 - val_loss: 0.4991 - val_acc: 0.5000\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4992 - acc: 0.5000 - val_loss: 0.4991 - val_acc: 0.5000\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4991 - val_acc: 0.5000\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4992 - acc: 0.5000 - val_loss: 0.4991 - val_acc: 0.5000\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4990 - val_acc: 0.5000\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4990 - val_acc: 0.5000\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4990 - val_acc: 0.5000\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4990 - val_acc: 0.5000\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4990 - val_acc: 0.5000\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4991 - val_acc: 0.5000\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4990 - val_acc: 0.5000\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4990 - val_acc: 0.5000\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4990 - val_acc: 0.5000\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4990 - val_acc: 0.5000\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4990 - val_acc: 0.5000\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4990 - val_acc: 0.5000\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.6960 - acc: 0.5005 - val_loss: 0.9233 - val_acc: 0.4608\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9308 - acc: 0.4117 - val_loss: 0.9502 - val_acc: 0.3646\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9762 - acc: 0.3514 - val_loss: 0.9860 - val_acc: 0.3388\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9892 - acc: 0.3414 - val_loss: 0.9764 - val_acc: 0.3434\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9703 - acc: 0.3525 - val_loss: 0.9509 - val_acc: 0.3601\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9441 - acc: 0.3716 - val_loss: 0.9261 - val_acc: 0.3802\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9234 - acc: 0.3911 - val_loss: 0.9094 - val_acc: 0.3989\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9101 - acc: 0.4079 - val_loss: 0.8976 - val_acc: 0.4144\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8991 - acc: 0.4213 - val_loss: 0.8870 - val_acc: 0.4257\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8889 - acc: 0.4316 - val_loss: 0.8761 - val_acc: 0.4339\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8793 - acc: 0.4384 - val_loss: 0.8682 - val_acc: 0.4394\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8705 - acc: 0.4434 - val_loss: 0.8549 - val_acc: 0.4449\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8593 - acc: 0.4480 - val_loss: 0.8465 - val_acc: 0.4483\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8467 - acc: 0.4522 - val_loss: 0.8317 - val_acc: 0.4534\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8306 - acc: 0.4569 - val_loss: 0.8192 - val_acc: 0.4576\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8157 - acc: 0.4612 - val_loss: 0.7999 - val_acc: 0.4642\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7925 - acc: 0.4687 - val_loss: 0.7743 - val_acc: 0.4726\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7622 - acc: 0.4781 - val_loss: 0.7431 - val_acc: 0.4824\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7354 - acc: 0.4834 - val_loss: 0.7257 - val_acc: 0.4830\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7180 - acc: 0.4855 - val_loss: 0.6986 - val_acc: 0.4897\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6827 - acc: 0.4952 - val_loss: 0.6569 - val_acc: 0.4998\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6364 - acc: 0.5045 - val_loss: 0.6095 - val_acc: 0.5060\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5906 - acc: 0.5072 - val_loss: 0.5617 - val_acc: 0.5046\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5427 - acc: 0.5048 - val_loss: 0.5237 - val_acc: 0.5020\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5144 - acc: 0.5025 - val_loss: 0.5071 - val_acc: 0.4999\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5026 - acc: 0.5015 - val_loss: 0.5017 - val_acc: 0.4993\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.5011 - val_loss: 0.5009 - val_acc: 0.4991\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5010 - val_loss: 0.5009 - val_acc: 0.4991\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4989 - acc: 0.5010 - val_loss: 0.5009 - val_acc: 0.4991\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4989 - acc: 0.5009 - val_loss: 0.5009 - val_acc: 0.4991\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4989 - acc: 0.5009 - val_loss: 0.5008 - val_acc: 0.4991\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4989 - acc: 0.5009 - val_loss: 0.5008 - val_acc: 0.4991\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4989 - acc: 0.5009 - val_loss: 0.5008 - val_acc: 0.4991\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4988 - acc: 0.5009 - val_loss: 0.5007 - val_acc: 0.4991\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4988 - acc: 0.5009 - val_loss: 0.5007 - val_acc: 0.4991\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4988 - acc: 0.5009 - val_loss: 0.5007 - val_acc: 0.4991\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4988 - acc: 0.5010 - val_loss: 0.5007 - val_acc: 0.4991\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4988 - acc: 0.5009 - val_loss: 0.5007 - val_acc: 0.4991\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4988 - acc: 0.5009 - val_loss: 0.5007 - val_acc: 0.4991\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4988 - acc: 0.5009 - val_loss: 0.5006 - val_acc: 0.4991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4988 - acc: 0.5009 - val_loss: 0.5006 - val_acc: 0.4991\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4987 - acc: 0.5009 - val_loss: 0.5006 - val_acc: 0.4991\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4987 - acc: 0.5009 - val_loss: 0.5006 - val_acc: 0.4991\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4987 - acc: 0.5009 - val_loss: 0.5006 - val_acc: 0.4991\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4987 - acc: 0.5009 - val_loss: 0.5006 - val_acc: 0.4991\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4987 - acc: 0.5009 - val_loss: 0.5006 - val_acc: 0.4991\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4987 - acc: 0.5009 - val_loss: 0.5006 - val_acc: 0.4991\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4987 - acc: 0.5009 - val_loss: 0.5005 - val_acc: 0.4991\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4987 - acc: 0.5009 - val_loss: 0.5005 - val_acc: 0.4991\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4986 - acc: 0.5009 - val_loss: 0.5005 - val_acc: 0.4991\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.1070 - acc: 0.4099 - val_loss: 1.0436 - val_acc: 0.3183\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9582 - acc: 0.3956 - val_loss: 0.9152 - val_acc: 0.4841\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8680 - acc: 0.4892 - val_loss: 0.7572 - val_acc: 0.4917\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6508 - acc: 0.5000 - val_loss: 0.5240 - val_acc: 0.5029\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5121 - acc: 0.5004 - val_loss: 0.5152 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5168 - acc: 0.5000 - val_loss: 0.5095 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5027 - acc: 0.5000 - val_loss: 0.5001 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5011 - acc: 0.5002 - val_loss: 0.5007 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5004 - acc: 0.5001 - val_loss: 0.4992 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4996 - acc: 0.5000 - val_loss: 0.4993 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4996 - acc: 0.5000 - val_loss: 0.4991 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4994 - acc: 0.5000 - val_loss: 0.4990 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4994 - acc: 0.5000 - val_loss: 0.4990 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4993 - acc: 0.5000 - val_loss: 0.4989 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4993 - acc: 0.5000 - val_loss: 0.4989 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4992 - acc: 0.5000 - val_loss: 0.4989 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4992 - acc: 0.5000 - val_loss: 0.4989 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4992 - acc: 0.5000 - val_loss: 0.4988 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4988 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4988 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4988 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4988 - val_acc: 0.5000\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4988 - val_acc: 0.5000\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4989 - val_acc: 0.5000\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4988 - val_acc: 0.5000\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4989 - val_acc: 0.5000\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4988 - val_acc: 0.5000\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4988 - val_acc: 0.5000\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4988 - val_acc: 0.5000\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4988 - val_acc: 0.5000\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4992 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 0.5000 - val_loss: 0.4987 - val_acc: 0.5000\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 1s 3us/step - loss: 1.5350 - acc: 0.2987 - val_loss: 0.9242 - val_acc: 0.1498\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9818 - acc: 0.1340 - val_loss: 1.0335 - val_acc: 0.1191\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0286 - acc: 0.1213 - val_loss: 0.9890 - val_acc: 0.1203\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9490 - acc: 0.1265 - val_loss: 0.9025 - val_acc: 0.1282\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8843 - acc: 0.1343 - val_loss: 0.8645 - val_acc: 0.1350\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8526 - acc: 0.1375 - val_loss: 0.8337 - val_acc: 0.1317\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8162 - acc: 0.1289 - val_loss: 0.7904 - val_acc: 0.1179\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7747 - acc: 0.1133 - val_loss: 0.7480 - val_acc: 0.1017\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7318 - acc: 0.0968 - val_loss: 0.6992 - val_acc: 0.0844\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6617 - acc: 0.0734 - val_loss: 0.6088 - val_acc: 0.0548\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5738 - acc: 0.0362 - val_loss: 0.5376 - val_acc: 0.0125\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5226 - acc: 0.0043 - val_loss: 0.5065 - val_acc: 3.6500e-04\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5031 - acc: 9.5000e-05 - val_loss: 0.4990 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4999 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4998 - acc: 0.0000e+00 - val_loss: 0.4983 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4998 - acc: 0.0000e+00 - val_loss: 0.4981 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4996 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4979 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4979 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4979 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4979 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4979 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4979 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4979 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4979 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4979 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4979 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4979 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4979 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4979 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4994 - acc: 0.0000e+00 - val_loss: 0.4979 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0000e+00 - val_loss: 0.4979 - val_acc: 0.0000e+00\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 1s 3us/step - loss: 1.2131 - acc: 0.2466 - val_loss: 1.0395 - val_acc: 0.1178\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0059 - acc: 0.1183 - val_loss: 0.8979 - val_acc: 0.1339\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8864 - acc: 0.1540 - val_loss: 0.8934 - val_acc: 0.1669\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8635 - acc: 0.1526 - val_loss: 0.8369 - val_acc: 0.1322\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8067 - acc: 0.1191 - val_loss: 0.7608 - val_acc: 0.1063\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6901 - acc: 0.0858 - val_loss: 0.5926 - val_acc: 0.0471\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5358 - acc: 0.0182 - val_loss: 0.5009 - val_acc: 0.0019\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5060 - acc: 5.5500e-04 - val_loss: 0.5090 - val_acc: 8.5000e-05\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5078 - acc: 1.0500e-04 - val_loss: 0.5019 - val_acc: 1.0500e-04\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5008 - acc: 4.0500e-04 - val_loss: 0.4989 - val_acc: 6.9500e-04\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4996 - acc: 0.0010 - val_loss: 0.4992 - val_acc: 0.0012\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4996 - acc: 0.0011 - val_loss: 0.4987 - val_acc: 7.4500e-04\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4992 - acc: 5.6500e-04 - val_loss: 0.4984 - val_acc: 4.3500e-04\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 4.0500e-04 - val_loss: 0.4983 - val_acc: 3.4000e-04\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4990 - acc: 3.8500e-04 - val_loss: 0.4982 - val_acc: 3.3000e-04\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4989 - acc: 3.6000e-04 - val_loss: 0.4981 - val_acc: 3.2500e-04\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4988 - acc: 3.5000e-04 - val_loss: 0.4981 - val_acc: 2.8000e-04\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4988 - acc: 3.1000e-04 - val_loss: 0.4981 - val_acc: 1.8000e-04\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4987 - acc: 2.2500e-04 - val_loss: 0.4980 - val_acc: 1.7500e-04\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4987 - acc: 2.1500e-04 - val_loss: 0.4980 - val_acc: 1.4000e-04\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4987 - acc: 1.8000e-04 - val_loss: 0.4979 - val_acc: 1.3000e-04\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4986 - acc: 1.7000e-04 - val_loss: 0.4979 - val_acc: 1.1500e-04\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 1.5500e-04 - val_loss: 0.4979 - val_acc: 1.0000e-04\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 1.5000e-04 - val_loss: 0.4978 - val_acc: 1.0500e-04\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 1.4500e-04 - val_loss: 0.4978 - val_acc: 9.0000e-05\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 1.3000e-04 - val_loss: 0.4978 - val_acc: 9.0000e-05\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 1.1500e-04 - val_loss: 0.4978 - val_acc: 5.0000e-05\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 9.0000e-05 - val_loss: 0.4978 - val_acc: 9.0000e-05\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 1.1000e-04 - val_loss: 0.4978 - val_acc: 4.0000e-05\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 7.0000e-05 - val_loss: 0.4978 - val_acc: 6.0000e-05\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 7.5000e-05 - val_loss: 0.4978 - val_acc: 4.0000e-05\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 6.5000e-05 - val_loss: 0.4977 - val_acc: 4.0000e-05\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 6.5000e-05 - val_loss: 0.4977 - val_acc: 4.0000e-05\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 4.0000e-05 - val_loss: 0.4977 - val_acc: 4.0000e-05\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 4.0000e-05 - val_loss: 0.4977 - val_acc: 3.5000e-05\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 4.0000e-05 - val_loss: 0.4977 - val_acc: 4.0000e-05\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 3.5000e-05 - val_loss: 0.4977 - val_acc: 4.0000e-05\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 4.0000e-05 - val_loss: 0.4977 - val_acc: 3.5000e-05\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 3.5000e-05 - val_loss: 0.4978 - val_acc: 2.0000e-05\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 2.0000e-05 - val_loss: 0.4979 - val_acc: 4.0000e-05\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 3.0000e-05 - val_loss: 0.4978 - val_acc: 2.0000e-05\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 4.0000e-05 - val_loss: 0.4977 - val_acc: 2.0000e-05\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 2.5000e-05 - val_loss: 0.4979 - val_acc: 4.0000e-05\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 3.5000e-05 - val_loss: 0.4977 - val_acc: 2.5000e-05\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 2.0000e-05 - val_loss: 0.4977 - val_acc: 1.5000e-05\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4983 - acc: 2.0000e-05 - val_loss: 0.4977 - val_acc: 2.0000e-05\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 1.5000e-05 - val_loss: 0.4979 - val_acc: 4.0000e-05\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4986 - acc: 2.5000e-05 - val_loss: 0.4979 - val_acc: 1.0000e-05\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 2.5000e-05 - val_loss: 0.4978 - val_acc: 1.0000e-05\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 2.0000e-05 - val_loss: 0.4977 - val_acc: 2.0000e-05\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.4654 - acc: 0.2927 - val_loss: 0.9329 - val_acc: 0.1417\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9899 - acc: 0.1270 - val_loss: 1.0342 - val_acc: 0.1164\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9938 - acc: 0.1227 - val_loss: 0.9414 - val_acc: 0.1287\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9089 - acc: 0.1404 - val_loss: 0.8942 - val_acc: 0.1498\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8873 - acc: 0.1557 - val_loss: 0.8775 - val_acc: 0.1536\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8621 - acc: 0.1487 - val_loss: 0.8400 - val_acc: 0.1372\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8210 - acc: 0.1300 - val_loss: 0.7963 - val_acc: 0.1195\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7706 - acc: 0.1125 - val_loss: 0.7296 - val_acc: 0.1010\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7031 - acc: 0.0926 - val_loss: 0.6697 - val_acc: 0.0795\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6420 - acc: 0.0700 - val_loss: 0.5978 - val_acc: 0.0531\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5641 - acc: 0.0326 - val_loss: 0.5294 - val_acc: 0.0126\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5115 - acc: 0.0078 - val_loss: 0.5023 - val_acc: 0.0039\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5020 - acc: 0.0026 - val_loss: 0.4997 - val_acc: 9.8000e-04\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5008 - acc: 6.7500e-04 - val_loss: 0.5002 - val_acc: 4.8500e-04\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5001 - acc: 7.4500e-04 - val_loss: 0.4994 - val_acc: 8.6500e-04\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.0010 - val_loss: 0.4987 - val_acc: 9.8000e-04\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.0011 - val_loss: 0.4986 - val_acc: 0.0011\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4989 - acc: 0.0013 - val_loss: 0.4985 - val_acc: 0.0012\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4989 - acc: 0.0012 - val_loss: 0.4984 - val_acc: 0.0011\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4987 - acc: 0.0011 - val_loss: 0.4983 - val_acc: 9.6000e-04\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4987 - acc: 9.9500e-04 - val_loss: 0.4982 - val_acc: 8.4000e-04\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4986 - acc: 8.9000e-04 - val_loss: 0.4982 - val_acc: 7.3000e-04\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 8.2000e-04 - val_loss: 0.4981 - val_acc: 7.1000e-04\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 7.8500e-04 - val_loss: 0.4981 - val_acc: 6.3000e-04\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 7.2500e-04 - val_loss: 0.4980 - val_acc: 6.0000e-04\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4983 - acc: 7.1500e-04 - val_loss: 0.4980 - val_acc: 6.0000e-04\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4983 - acc: 6.7000e-04 - val_loss: 0.4979 - val_acc: 4.9500e-04\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4982 - acc: 5.6500e-04 - val_loss: 0.4979 - val_acc: 4.8500e-04\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4982 - acc: 5.5500e-04 - val_loss: 0.4979 - val_acc: 3.9000e-04\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4982 - acc: 4.7000e-04 - val_loss: 0.4978 - val_acc: 3.9000e-04\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4981 - acc: 4.8500e-04 - val_loss: 0.4978 - val_acc: 3.7000e-04\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4981 - acc: 4.2000e-04 - val_loss: 0.4978 - val_acc: 3.3500e-04\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4980 - acc: 4.2000e-04 - val_loss: 0.4977 - val_acc: 3.2000e-04\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4980 - acc: 4.0000e-04 - val_loss: 0.4977 - val_acc: 2.8000e-04\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4980 - acc: 3.4000e-04 - val_loss: 0.4977 - val_acc: 2.8000e-04\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4980 - acc: 3.4500e-04 - val_loss: 0.4977 - val_acc: 2.6500e-04\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4979 - acc: 3.1500e-04 - val_loss: 0.4977 - val_acc: 2.3500e-04\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4979 - acc: 2.9000e-04 - val_loss: 0.4976 - val_acc: 2.2000e-04\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4979 - acc: 2.7000e-04 - val_loss: 0.4976 - val_acc: 2.1000e-04\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4979 - acc: 2.4000e-04 - val_loss: 0.4976 - val_acc: 2.0500e-04\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4979 - acc: 2.4500e-04 - val_loss: 0.4976 - val_acc: 1.9500e-04\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4979 - acc: 1.9500e-04 - val_loss: 0.4976 - val_acc: 1.9000e-04\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4979 - acc: 2.0500e-04 - val_loss: 0.4976 - val_acc: 1.6000e-04\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4978 - acc: 1.6000e-04 - val_loss: 0.4976 - val_acc: 1.6000e-04\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4978 - acc: 1.5500e-04 - val_loss: 0.4976 - val_acc: 1.5500e-04\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4978 - acc: 1.4000e-04 - val_loss: 0.4976 - val_acc: 1.2500e-04\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4978 - acc: 1.2500e-04 - val_loss: 0.4975 - val_acc: 1.2500e-04\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4978 - acc: 1.3000e-04 - val_loss: 0.4975 - val_acc: 1.2500e-04\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4978 - acc: 1.1500e-04 - val_loss: 0.4975 - val_acc: 1.1500e-04\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4978 - acc: 1.2500e-04 - val_loss: 0.4975 - val_acc: 1.2000e-04\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.3276 - acc: 0.2768 - val_loss: 0.9632 - val_acc: 0.1319\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0175 - acc: 0.1208 - val_loss: 0.9785 - val_acc: 0.1188\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9203 - acc: 0.1316 - val_loss: 0.8716 - val_acc: 0.1471\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8652 - acc: 0.1491 - val_loss: 0.8201 - val_acc: 0.1396\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7756 - acc: 0.1197 - val_loss: 0.7062 - val_acc: 0.0935\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6389 - acc: 0.0671 - val_loss: 0.5533 - val_acc: 0.0328\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5222 - acc: 0.0117 - val_loss: 0.5001 - val_acc: 3.6500e-04\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4974 - acc: 9.0000e-05 - val_loss: 0.5017 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5001 - acc: 0.0000e+00 - val_loss: 0.5016 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4982 - acc: 0.0000e+00 - val_loss: 0.4984 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4965 - acc: 7.0000e-05 - val_loss: 0.4976 - val_acc: 5.0000e-05\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4965 - acc: 1.0500e-04 - val_loss: 0.4976 - val_acc: 8.5000e-05\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4965 - acc: 1.1000e-04 - val_loss: 0.4976 - val_acc: 7.5000e-05\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4964 - acc: 9.0000e-05 - val_loss: 0.4976 - val_acc: 5.0000e-05\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4963 - acc: 7.0000e-05 - val_loss: 0.4976 - val_acc: 3.5000e-05\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4963 - acc: 8.0000e-05 - val_loss: 0.4976 - val_acc: 5.0000e-05\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4963 - acc: 8.5000e-05 - val_loss: 0.4976 - val_acc: 5.5000e-05\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4963 - acc: 8.5000e-05 - val_loss: 0.4975 - val_acc: 7.0000e-05\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4963 - acc: 1.0000e-04 - val_loss: 0.4976 - val_acc: 5.5000e-05\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4963 - acc: 9.0000e-05 - val_loss: 0.4976 - val_acc: 7.5000e-05\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4963 - acc: 1.2000e-04 - val_loss: 0.4975 - val_acc: 7.5000e-05\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4963 - acc: 1.0500e-04 - val_loss: 0.4975 - val_acc: 7.5000e-05\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4963 - acc: 1.3000e-04 - val_loss: 0.4975 - val_acc: 7.5000e-05\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4962 - acc: 1.2500e-04 - val_loss: 0.4975 - val_acc: 1.0500e-04\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4962 - acc: 1.4500e-04 - val_loss: 0.4975 - val_acc: 8.0000e-05\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4962 - acc: 1.3500e-04 - val_loss: 0.4975 - val_acc: 1.0000e-04\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4962 - acc: 1.4500e-04 - val_loss: 0.4975 - val_acc: 9.5000e-05\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4962 - acc: 1.5000e-04 - val_loss: 0.4975 - val_acc: 1.0500e-04\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4962 - acc: 1.4500e-04 - val_loss: 0.4975 - val_acc: 1.1000e-04\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4962 - acc: 1.7000e-04 - val_loss: 0.4975 - val_acc: 1.0500e-04\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4962 - acc: 1.4500e-04 - val_loss: 0.4975 - val_acc: 1.1000e-04\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4963 - acc: 1.6000e-04 - val_loss: 0.4975 - val_acc: 1.1000e-04\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4962 - acc: 1.7500e-04 - val_loss: 0.4975 - val_acc: 1.0500e-04\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4962 - acc: 1.5000e-04 - val_loss: 0.4975 - val_acc: 1.4000e-04\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4962 - acc: 1.9500e-04 - val_loss: 0.4977 - val_acc: 9.5000e-05\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4963 - acc: 1.5000e-04 - val_loss: 0.4976 - val_acc: 1.6500e-04\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4963 - acc: 1.7000e-04 - val_loss: 0.4975 - val_acc: 1.1000e-04\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4962 - acc: 1.7500e-04 - val_loss: 0.4975 - val_acc: 1.1000e-04\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4961 - acc: 1.7500e-04 - val_loss: 0.4974 - val_acc: 1.4000e-04\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4961 - acc: 1.7500e-04 - val_loss: 0.4974 - val_acc: 1.1500e-04\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4961 - acc: 1.6500e-04 - val_loss: 0.4975 - val_acc: 1.4000e-04\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4962 - acc: 1.8500e-04 - val_loss: 0.4975 - val_acc: 1.1000e-04\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4961 - acc: 1.8000e-04 - val_loss: 0.4975 - val_acc: 1.6500e-04\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4962 - acc: 1.9500e-04 - val_loss: 0.4975 - val_acc: 1.0500e-04\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4961 - acc: 1.9500e-04 - val_loss: 0.4974 - val_acc: 1.4500e-04\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4961 - acc: 1.7500e-04 - val_loss: 0.4974 - val_acc: 1.4500e-04\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4962 - acc: 1.8500e-04 - val_loss: 0.4975 - val_acc: 1.1000e-04\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4961 - acc: 1.6500e-04 - val_loss: 0.4974 - val_acc: 1.4500e-04\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4962 - acc: 1.6500e-04 - val_loss: 0.4974 - val_acc: 1.4000e-04\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4961 - acc: 1.9000e-04 - val_loss: 0.4974 - val_acc: 1.2000e-04\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.6986 - acc: 0.4803 - val_loss: 0.9776 - val_acc: 0.4511\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9795 - acc: 0.4050 - val_loss: 1.0049 - val_acc: 0.3628\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0169 - acc: 0.3525 - val_loss: 1.0053 - val_acc: 0.3558\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9853 - acc: 0.3686 - val_loss: 0.9536 - val_acc: 0.3909\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9376 - acc: 0.4071 - val_loss: 0.9140 - val_acc: 0.4281\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9054 - acc: 0.4392 - val_loss: 0.8889 - val_acc: 0.4511\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8782 - acc: 0.4560 - val_loss: 0.8555 - val_acc: 0.4632\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8431 - acc: 0.4641 - val_loss: 0.8206 - val_acc: 0.4685\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8014 - acc: 0.4702 - val_loss: 0.7736 - val_acc: 0.4762\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7507 - acc: 0.4782 - val_loss: 0.7149 - val_acc: 0.4852\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6784 - acc: 0.4876 - val_loss: 0.6305 - val_acc: 0.4921\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5901 - acc: 0.4947 - val_loss: 0.5510 - val_acc: 0.4981\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5322 - acc: 0.4996 - val_loss: 0.5139 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5065 - acc: 0.4999 - val_loss: 0.5006 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4989 - acc: 0.5000 - val_loss: 0.4975 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4974 - acc: 0.5000 - val_loss: 0.4974 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4974 - acc: 0.5000 - val_loss: 0.4974 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4974 - acc: 0.5000 - val_loss: 0.4973 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 0.5000 - val_loss: 0.4973 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 0.5000 - val_loss: 0.4972 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 0.5000 - val_loss: 0.4972 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 0.5000 - val_loss: 0.4972 - val_acc: 0.5000\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.5000 - val_loss: 0.4972 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.5000 - val_loss: 0.4972 - val_acc: 0.5000\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.5000 - val_loss: 0.4972 - val_acc: 0.5000\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.5000 - val_loss: 0.4972 - val_acc: 0.5000\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.5000 - val_loss: 0.4972 - val_acc: 0.5000\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.5000 - val_loss: 0.4972 - val_acc: 0.5000\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.5000 - val_loss: 0.4972 - val_acc: 0.5000\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.5000 - val_loss: 0.4972 - val_acc: 0.5000\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.5000 - val_loss: 0.4972 - val_acc: 0.5000\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.5000 - val_loss: 0.4971 - val_acc: 0.5000\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.5000 - val_loss: 0.4971 - val_acc: 0.5000\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.5000 - val_loss: 0.4971 - val_acc: 0.5000\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.5000 - val_loss: 0.4971 - val_acc: 0.5000\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.5000 - val_loss: 0.4971 - val_acc: 0.5000\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.5000 - val_loss: 0.4971 - val_acc: 0.5000\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.5000 - val_loss: 0.4971 - val_acc: 0.5000\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.5000 - val_loss: 0.4971 - val_acc: 0.5000\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.5000 - val_loss: 0.4971 - val_acc: 0.5000\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.5000 - val_loss: 0.4971 - val_acc: 0.5000\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.5000 - val_loss: 0.4971 - val_acc: 0.5000\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.5000 - val_loss: 0.4971 - val_acc: 0.5000\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.5000 - val_loss: 0.4971 - val_acc: 0.5000\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.5000 - val_loss: 0.4971 - val_acc: 0.5000\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.5000 - val_loss: 0.4971 - val_acc: 0.5000\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.5000 - val_loss: 0.4971 - val_acc: 0.5000\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.5000 - val_loss: 0.4971 - val_acc: 0.5000\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.5000 - val_loss: 0.4971 - val_acc: 0.5000\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.5000 - val_loss: 0.4971 - val_acc: 0.5000\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.4850 - acc: 0.2733 - val_loss: 0.9951 - val_acc: 0.1205\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0590 - acc: 0.1060 - val_loss: 1.0856 - val_acc: 0.0986\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0352 - acc: 0.1019 - val_loss: 0.9670 - val_acc: 0.1082\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9395 - acc: 0.1150 - val_loss: 0.9141 - val_acc: 0.1202\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9025 - acc: 0.1188 - val_loss: 0.8746 - val_acc: 0.1120\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8509 - acc: 0.1015 - val_loss: 0.8173 - val_acc: 0.0887\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7924 - acc: 0.0789 - val_loss: 0.7535 - val_acc: 0.0679\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7274 - acc: 0.0597 - val_loss: 0.6802 - val_acc: 0.0490\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6352 - acc: 0.0350 - val_loss: 0.5752 - val_acc: 0.0147\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5444 - acc: 0.0060 - val_loss: 0.5138 - val_acc: 7.7000e-04\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5061 - acc: 2.0500e-04 - val_loss: 0.4996 - val_acc: 5.0000e-06\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4993 - acc: 0.0000e+00 - val_loss: 0.4994 - val_acc: 1.0000e-05\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4997 - acc: 5.0000e-06 - val_loss: 0.4993 - val_acc: 1.0000e-05\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4993 - acc: 0.0000e+00 - val_loss: 0.4985 - val_acc: 1.0000e-05\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4986 - acc: 0.0000e+00 - val_loss: 0.4981 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 0.0000e+00 - val_loss: 0.4980 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4983 - acc: 0.0000e+00 - val_loss: 0.4979 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4983 - acc: 0.0000e+00 - val_loss: 0.4978 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4982 - acc: 0.0000e+00 - val_loss: 0.4978 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4981 - acc: 0.0000e+00 - val_loss: 0.4977 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4981 - acc: 0.0000e+00 - val_loss: 0.4976 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4980 - acc: 0.0000e+00 - val_loss: 0.4976 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4979 - acc: 0.0000e+00 - val_loss: 0.4975 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4978 - acc: 0.0000e+00 - val_loss: 0.4975 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4978 - acc: 0.0000e+00 - val_loss: 0.4974 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4977 - acc: 0.0000e+00 - val_loss: 0.4974 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4977 - acc: 0.0000e+00 - val_loss: 0.4973 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4977 - acc: 0.0000e+00 - val_loss: 0.4973 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4976 - acc: 0.0000e+00 - val_loss: 0.4972 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4976 - acc: 0.0000e+00 - val_loss: 0.4972 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4975 - acc: 0.0000e+00 - val_loss: 0.4972 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4975 - acc: 0.0000e+00 - val_loss: 0.4972 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4974 - acc: 0.0000e+00 - val_loss: 0.4971 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4974 - acc: 0.0000e+00 - val_loss: 0.4971 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4974 - acc: 0.0000e+00 - val_loss: 0.4971 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4974 - acc: 0.0000e+00 - val_loss: 0.4970 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 0.0000e+00 - val_loss: 0.4970 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 0.0000e+00 - val_loss: 0.4970 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 0.0000e+00 - val_loss: 0.4970 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 0.0000e+00 - val_loss: 0.4970 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 0.0000e+00 - val_loss: 0.4969 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 0.0000e+00 - val_loss: 0.4970 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.0000e+00 - val_loss: 0.4969 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.0000e+00 - val_loss: 0.4969 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.0000e+00 - val_loss: 0.4969 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.0000e+00 - val_loss: 0.4969 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.0000e+00 - val_loss: 0.4969 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.0000e+00 - val_loss: 0.4969 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.0000e+00 - val_loss: 0.4969 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.0000e+00 - val_loss: 0.4969 - val_acc: 0.0000e+00\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.7341 - acc: 0.3170 - val_loss: 0.9947 - val_acc: 0.1547\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9775 - acc: 0.1311 - val_loss: 1.0013 - val_acc: 0.1167\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0042 - acc: 0.1102 - val_loss: 1.0225 - val_acc: 0.1086\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0043 - acc: 0.1061 - val_loss: 1.0005 - val_acc: 0.1082\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9756 - acc: 0.1075 - val_loss: 0.9662 - val_acc: 0.1106\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9447 - acc: 0.1103 - val_loss: 0.9397 - val_acc: 0.1130\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9209 - acc: 0.1118 - val_loss: 0.9162 - val_acc: 0.1130\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8982 - acc: 0.1105 - val_loss: 0.8916 - val_acc: 0.1094\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8686 - acc: 0.1050 - val_loss: 0.8542 - val_acc: 0.1015\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8336 - acc: 0.0956 - val_loss: 0.8159 - val_acc: 0.0904\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7943 - acc: 0.0841 - val_loss: 0.7751 - val_acc: 0.0776\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7478 - acc: 0.0709 - val_loss: 0.7229 - val_acc: 0.0623\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6865 - acc: 0.0537 - val_loss: 0.6524 - val_acc: 0.0422\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6177 - acc: 0.0316 - val_loss: 0.5846 - val_acc: 0.0176\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5610 - acc: 0.0103 - val_loss: 0.5412 - val_acc: 0.0036\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5272 - acc: 0.0018 - val_loss: 0.5165 - val_acc: 4.2000e-04\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5093 - acc: 1.9500e-04 - val_loss: 0.5046 - val_acc: 2.5000e-05\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5013 - acc: 0.0000e+00 - val_loss: 0.4996 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 0.0000e+00 - val_loss: 0.4981 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4978 - acc: 0.0000e+00 - val_loss: 0.4978 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4977 - acc: 0.0000e+00 - val_loss: 0.4977 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4977 - acc: 0.0000e+00 - val_loss: 0.4977 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4976 - acc: 0.0000e+00 - val_loss: 0.4976 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4976 - acc: 0.0000e+00 - val_loss: 0.4976 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4975 - acc: 0.0000e+00 - val_loss: 0.4976 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4975 - acc: 0.0000e+00 - val_loss: 0.4976 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4975 - acc: 0.0000e+00 - val_loss: 0.4976 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4975 - acc: 0.0000e+00 - val_loss: 0.4976 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4974 - acc: 0.0000e+00 - val_loss: 0.4975 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4975 - acc: 0.0000e+00 - val_loss: 0.4975 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4974 - acc: 0.0000e+00 - val_loss: 0.4975 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4974 - acc: 0.0000e+00 - val_loss: 0.4975 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 0.0000e+00 - val_loss: 0.4975 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 0.0000e+00 - val_loss: 0.4974 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 0.0000e+00 - val_loss: 0.4974 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 0.0000e+00 - val_loss: 0.4974 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 0.0000e+00 - val_loss: 0.4974 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.0000e+00 - val_loss: 0.4974 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.0000e+00 - val_loss: 0.4974 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.0000e+00 - val_loss: 0.4973 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.0000e+00 - val_loss: 0.4973 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.0000e+00 - val_loss: 0.4973 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.0000e+00 - val_loss: 0.4973 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.0000e+00 - val_loss: 0.4973 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.0000e+00 - val_loss: 0.4973 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.0000e+00 - val_loss: 0.4973 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.0000e+00 - val_loss: 0.4973 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.0000e+00 - val_loss: 0.4972 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.0000e+00 - val_loss: 0.4972 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.0000e+00 - val_loss: 0.4972 - val_acc: 0.0000e+00\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.3612 - acc: 0.4342 - val_loss: 1.1420 - val_acc: 0.3162\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1508 - acc: 0.3122 - val_loss: 1.0642 - val_acc: 0.3498\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0113 - acc: 0.4041 - val_loss: 0.9988 - val_acc: 0.4517\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9963 - acc: 0.4566 - val_loss: 0.9811 - val_acc: 0.4505\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9621 - acc: 0.4373 - val_loss: 0.9425 - val_acc: 0.4244\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9203 - acc: 0.4318 - val_loss: 0.8930 - val_acc: 0.4484\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8719 - acc: 0.4613 - val_loss: 0.8343 - val_acc: 0.4787\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7677 - acc: 0.4859 - val_loss: 0.6685 - val_acc: 0.4907\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5948 - acc: 0.4949 - val_loss: 0.5254 - val_acc: 0.4988\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5089 - acc: 0.5001 - val_loss: 0.5013 - val_acc: 0.4997\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5026 - acc: 0.5005 - val_loss: 0.5044 - val_acc: 0.4998\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5034 - acc: 0.5005 - val_loss: 0.5021 - val_acc: 0.4997\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5006 - acc: 0.5004 - val_loss: 0.4998 - val_acc: 0.4997\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4993 - acc: 0.5003 - val_loss: 0.4994 - val_acc: 0.4997\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 0.5003 - val_loss: 0.4992 - val_acc: 0.4997\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4989 - acc: 0.5003 - val_loss: 0.4990 - val_acc: 0.4997\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4986 - acc: 0.5003 - val_loss: 0.4989 - val_acc: 0.4997\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 0.5003 - val_loss: 0.4987 - val_acc: 0.4997\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4983 - acc: 0.5003 - val_loss: 0.4986 - val_acc: 0.4997\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4982 - acc: 0.5003 - val_loss: 0.4985 - val_acc: 0.4997\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4981 - acc: 0.5003 - val_loss: 0.4984 - val_acc: 0.4997\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4980 - acc: 0.5003 - val_loss: 0.4983 - val_acc: 0.4997\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4978 - acc: 0.5003 - val_loss: 0.4982 - val_acc: 0.4997\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4978 - acc: 0.5003 - val_loss: 0.4981 - val_acc: 0.4997\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4976 - acc: 0.5003 - val_loss: 0.4980 - val_acc: 0.4997\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4976 - acc: 0.5003 - val_loss: 0.4980 - val_acc: 0.4997\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4975 - acc: 0.5003 - val_loss: 0.4979 - val_acc: 0.4997\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4974 - acc: 0.5003 - val_loss: 0.4978 - val_acc: 0.4997\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4974 - acc: 0.5003 - val_loss: 0.4978 - val_acc: 0.4997\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 0.5003 - val_loss: 0.4977 - val_acc: 0.4997\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 0.5003 - val_loss: 0.4977 - val_acc: 0.4997\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.5003 - val_loss: 0.4977 - val_acc: 0.4997\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.5003 - val_loss: 0.4976 - val_acc: 0.4997\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.5003 - val_loss: 0.4976 - val_acc: 0.4997\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.5003 - val_loss: 0.4976 - val_acc: 0.4997\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.5003 - val_loss: 0.4976 - val_acc: 0.4997\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4970 - acc: 0.5003 - val_loss: 0.4975 - val_acc: 0.4997\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 0.5003 - val_loss: 0.4976 - val_acc: 0.4997\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4970 - acc: 0.5003 - val_loss: 0.4975 - val_acc: 0.4997\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4970 - acc: 0.5003 - val_loss: 0.4975 - val_acc: 0.4997\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4969 - acc: 0.5003 - val_loss: 0.4975 - val_acc: 0.4997\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4969 - acc: 0.5003 - val_loss: 0.4975 - val_acc: 0.4997\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4969 - acc: 0.5003 - val_loss: 0.4975 - val_acc: 0.4997\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4969 - acc: 0.5003 - val_loss: 0.4975 - val_acc: 0.4997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4970 - acc: 0.5003 - val_loss: 0.4974 - val_acc: 0.4997\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4969 - acc: 0.5003 - val_loss: 0.4975 - val_acc: 0.4997\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4968 - acc: 0.5003 - val_loss: 0.4976 - val_acc: 0.4997\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4970 - acc: 0.5003 - val_loss: 0.4974 - val_acc: 0.4997\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4969 - acc: 0.5003 - val_loss: 0.4974 - val_acc: 0.4997\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4969 - acc: 0.5003 - val_loss: 0.4975 - val_acc: 0.4997\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.1947 - acc: 0.2039 - val_loss: 1.1145 - val_acc: 0.1084\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0118 - acc: 0.1195 - val_loss: 0.9372 - val_acc: 0.1411\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9149 - acc: 0.1342 - val_loss: 0.8577 - val_acc: 0.1069\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8061 - acc: 0.0856 - val_loss: 0.6954 - val_acc: 0.0580\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6028 - acc: 0.0261 - val_loss: 0.5119 - val_acc: 0.0023\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5099 - acc: 0.0011 - val_loss: 0.5093 - val_acc: 0.0042\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5126 - acc: 0.0031 - val_loss: 0.5051 - val_acc: 2.6000e-04\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5039 - acc: 3.9000e-04 - val_loss: 0.4979 - val_acc: 5.0000e-05\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5005 - acc: 4.5000e-05 - val_loss: 0.4982 - val_acc: 1.0000e-05\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5004 - acc: 2.5000e-05 - val_loss: 0.4974 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4997 - acc: 2.0000e-05 - val_loss: 0.4968 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 2.0000e-05 - val_loss: 0.4965 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4993 - acc: 1.0000e-05 - val_loss: 0.4965 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 1.0000e-05 - val_loss: 0.4963 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4989 - acc: 5.0000e-06 - val_loss: 0.4962 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4988 - acc: 5.0000e-06 - val_loss: 0.4960 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4988 - acc: 0.0000e+00 - val_loss: 0.4962 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4988 - acc: 0.0000e+00 - val_loss: 0.4959 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4987 - acc: 0.0000e+00 - val_loss: 0.4958 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4986 - acc: 0.0000e+00 - val_loss: 0.4958 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4986 - acc: 0.0000e+00 - val_loss: 0.4958 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 0.0000e+00 - val_loss: 0.4958 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 0.0000e+00 - val_loss: 0.4957 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 0.0000e+00 - val_loss: 0.4957 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 0.0000e+00 - val_loss: 0.4957 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 0.0000e+00 - val_loss: 0.4956 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 0.0000e+00 - val_loss: 0.4957 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 0.0000e+00 - val_loss: 0.4956 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 0.0000e+00 - val_loss: 0.4956 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 0.0000e+00 - val_loss: 0.4957 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4986 - acc: 0.0000e+00 - val_loss: 0.4955 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 0.0000e+00 - val_loss: 0.4956 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4986 - acc: 0.0000e+00 - val_loss: 0.4957 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4986 - acc: 0.0000e+00 - val_loss: 0.4956 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 0.0000e+00 - val_loss: 0.4956 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 0.0000e+00 - val_loss: 0.4956 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 0.0000e+00 - val_loss: 0.4955 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 0.0000e+00 - val_loss: 0.4956 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 0.0000e+00 - val_loss: 0.4955 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 0.0000e+00 - val_loss: 0.4955 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 0.0000e+00 - val_loss: 0.4955 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 0.0000e+00 - val_loss: 0.4958 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 0.0000e+00 - val_loss: 0.4955 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 0.0000e+00 - val_loss: 0.4956 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 0.0000e+00 - val_loss: 0.4958 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 0.0000e+00 - val_loss: 0.4955 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 0.0000e+00 - val_loss: 0.4955 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 0.0000e+00 - val_loss: 0.4956 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 0.0000e+00 - val_loss: 0.4955 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 0.0000e+00 - val_loss: 0.4955 - val_acc: 0.0000e+00\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 2us/step - loss: 2.1798 - acc: 0.3936 - val_loss: 1.1834 - val_acc: 0.2462\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0932 - acc: 0.2059 - val_loss: 1.0525 - val_acc: 0.1757\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0518 - acc: 0.1637 - val_loss: 1.0634 - val_acc: 0.1560\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0589 - acc: 0.1539 - val_loss: 1.0617 - val_acc: 0.1533\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0495 - acc: 0.1531 - val_loss: 1.0467 - val_acc: 0.1554\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0345 - acc: 0.1565 - val_loss: 1.0323 - val_acc: 0.1585\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0231 - acc: 0.1577 - val_loss: 1.0179 - val_acc: 0.1570\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0101 - acc: 0.1549 - val_loss: 1.0059 - val_acc: 0.1548\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0012 - acc: 0.1538 - val_loss: 0.9982 - val_acc: 0.1543\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9914 - acc: 0.1517 - val_loss: 0.9861 - val_acc: 0.1489\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9769 - acc: 0.1457 - val_loss: 0.9694 - val_acc: 0.1410\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9554 - acc: 0.1352 - val_loss: 0.9454 - val_acc: 0.1301\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9250 - acc: 0.1221 - val_loss: 0.9062 - val_acc: 0.1146\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8858 - acc: 0.1082 - val_loss: 0.8676 - val_acc: 0.1037\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8446 - acc: 0.0982 - val_loss: 0.8181 - val_acc: 0.0912\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7938 - acc: 0.0850 - val_loss: 0.7709 - val_acc: 0.0778\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7451 - acc: 0.0712 - val_loss: 0.7264 - val_acc: 0.0630\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6906 - acc: 0.0547 - val_loss: 0.6488 - val_acc: 0.0413\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6048 - acc: 0.0301 - val_loss: 0.5723 - val_acc: 0.0190\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5434 - acc: 0.0118 - val_loss: 0.5215 - val_acc: 0.0055\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5099 - acc: 0.0028 - val_loss: 0.5039 - val_acc: 0.0013\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5010 - acc: 6.7500e-04 - val_loss: 0.5016 - val_acc: 5.3500e-04\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5006 - acc: 4.3000e-04 - val_loss: 0.5017 - val_acc: 5.3000e-04\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5005 - acc: 4.1500e-04 - val_loss: 0.5014 - val_acc: 4.3000e-04\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5001 - acc: 2.9500e-04 - val_loss: 0.5009 - val_acc: 3.8500e-04\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4996 - acc: 2.8000e-04 - val_loss: 0.5006 - val_acc: 3.6000e-04\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 2.4000e-04 - val_loss: 0.5004 - val_acc: 3.3000e-04\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4993 - acc: 2.4000e-04 - val_loss: 0.5002 - val_acc: 3.0500e-04\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4991 - acc: 2.1000e-04 - val_loss: 0.5001 - val_acc: 2.6500e-04\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4989 - acc: 1.8500e-04 - val_loss: 0.4999 - val_acc: 2.2500e-04\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4987 - acc: 1.7000e-04 - val_loss: 0.4997 - val_acc: 1.7500e-04\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4986 - acc: 1.2500e-04 - val_loss: 0.4996 - val_acc: 1.6000e-04\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 1.1500e-04 - val_loss: 0.4995 - val_acc: 1.3000e-04\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 1.1000e-04 - val_loss: 0.4993 - val_acc: 1.2000e-04\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4983 - acc: 9.0000e-05 - val_loss: 0.4992 - val_acc: 1.1500e-04\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4981 - acc: 8.5000e-05 - val_loss: 0.4991 - val_acc: 1.0500e-04\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4981 - acc: 7.0000e-05 - val_loss: 0.4990 - val_acc: 9.0000e-05\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4979 - acc: 7.0000e-05 - val_loss: 0.4989 - val_acc: 7.5000e-05\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4979 - acc: 6.0000e-05 - val_loss: 0.4988 - val_acc: 7.0000e-05\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4978 - acc: 6.0000e-05 - val_loss: 0.4987 - val_acc: 7.0000e-05\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4977 - acc: 5.5000e-05 - val_loss: 0.4986 - val_acc: 7.0000e-05\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4976 - acc: 4.5000e-05 - val_loss: 0.4986 - val_acc: 6.0000e-05\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4975 - acc: 4.0000e-05 - val_loss: 0.4985 - val_acc: 6.0000e-05\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4975 - acc: 3.0000e-05 - val_loss: 0.4984 - val_acc: 6.0000e-05\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4974 - acc: 2.5000e-05 - val_loss: 0.4983 - val_acc: 5.0000e-05\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 2.0000e-05 - val_loss: 0.4982 - val_acc: 4.5000e-05\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 2.0000e-05 - val_loss: 0.4982 - val_acc: 3.0000e-05\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 2.0000e-05 - val_loss: 0.4981 - val_acc: 3.0000e-05\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 2.0000e-05 - val_loss: 0.4981 - val_acc: 3.0000e-05\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4971 - acc: 1.5000e-05 - val_loss: 0.4980 - val_acc: 3.0000e-05\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.4720 - acc: 0.4604 - val_loss: 1.0459 - val_acc: 0.3676\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1086 - acc: 0.3316 - val_loss: 1.1112 - val_acc: 0.3253\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0235 - acc: 0.3699 - val_loss: 0.9530 - val_acc: 0.4244\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9263 - acc: 0.4576 - val_loss: 0.9001 - val_acc: 0.4778\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8585 - acc: 0.4832 - val_loss: 0.8039 - val_acc: 0.4845\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7606 - acc: 0.4864 - val_loss: 0.7135 - val_acc: 0.4883\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6519 - acc: 0.4944 - val_loss: 0.5865 - val_acc: 0.4973\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5509 - acc: 0.4994 - val_loss: 0.5195 - val_acc: 0.4995\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5059 - acc: 0.5004 - val_loss: 0.4992 - val_acc: 0.4996\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4972 - acc: 0.5004 - val_loss: 0.4980 - val_acc: 0.4996\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4979 - acc: 0.5004 - val_loss: 0.4983 - val_acc: 0.4996\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4975 - acc: 0.5004 - val_loss: 0.4975 - val_acc: 0.4996\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4968 - acc: 0.5004 - val_loss: 0.4972 - val_acc: 0.4996\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4967 - acc: 0.5004 - val_loss: 0.4972 - val_acc: 0.4996\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4967 - acc: 0.5004 - val_loss: 0.4972 - val_acc: 0.4996\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4972 - val_acc: 0.4996\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4972 - val_acc: 0.4996\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4970 - val_acc: 0.4996\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4965 - acc: 0.5004 - val_loss: 0.4970 - val_acc: 0.4996\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4965 - acc: 0.5004 - val_loss: 0.4970 - val_acc: 0.4996\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4966 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4965 - acc: 0.5004 - val_loss: 0.4970 - val_acc: 0.4996\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4965 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4965 - acc: 0.5004 - val_loss: 0.4970 - val_acc: 0.4996\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4965 - acc: 0.5004 - val_loss: 0.4971 - val_acc: 0.4996\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4965 - acc: 0.5004 - val_loss: 0.4970 - val_acc: 0.4996\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4965 - acc: 0.5004 - val_loss: 0.4970 - val_acc: 0.4996\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4965 - acc: 0.5004 - val_loss: 0.4970 - val_acc: 0.4996\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4965 - acc: 0.5004 - val_loss: 0.4970 - val_acc: 0.4996\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4965 - acc: 0.5004 - val_loss: 0.4970 - val_acc: 0.4996\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 1s 3us/step - loss: 1.4157 - acc: 0.4437 - val_loss: 1.1179 - val_acc: 0.3311\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1539 - acc: 0.3146 - val_loss: 1.0919 - val_acc: 0.3360\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0137 - acc: 0.3936 - val_loss: 0.9741 - val_acc: 0.4478\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9593 - acc: 0.4675 - val_loss: 0.9289 - val_acc: 0.4737\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8891 - acc: 0.4773 - val_loss: 0.8391 - val_acc: 0.4741\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7917 - acc: 0.4826 - val_loss: 0.7182 - val_acc: 0.4917\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6361 - acc: 0.4971 - val_loss: 0.5625 - val_acc: 0.4980\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5227 - acc: 0.5014 - val_loss: 0.5044 - val_acc: 0.4986\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4987 - acc: 0.5014 - val_loss: 0.5015 - val_acc: 0.4990\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4995 - acc: 0.5017 - val_loss: 0.5019 - val_acc: 0.4986\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4974 - acc: 0.5014 - val_loss: 0.4988 - val_acc: 0.4986\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4956 - acc: 0.5014 - val_loss: 0.4983 - val_acc: 0.4986\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4955 - acc: 0.5014 - val_loss: 0.4983 - val_acc: 0.4986\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4955 - acc: 0.5014 - val_loss: 0.4982 - val_acc: 0.4986\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4954 - acc: 0.5014 - val_loss: 0.4982 - val_acc: 0.4986\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4954 - acc: 0.5014 - val_loss: 0.4981 - val_acc: 0.4986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4954 - acc: 0.5014 - val_loss: 0.4981 - val_acc: 0.4986\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.5014 - val_loss: 0.4981 - val_acc: 0.4986\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.5014 - val_loss: 0.4980 - val_acc: 0.4986\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.5014 - val_loss: 0.4981 - val_acc: 0.4986\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.5014 - val_loss: 0.4980 - val_acc: 0.4986\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.5014 - val_loss: 0.4980 - val_acc: 0.4986\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.5014 - val_loss: 0.4980 - val_acc: 0.4986\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.5014 - val_loss: 0.4979 - val_acc: 0.4986\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.5014 - val_loss: 0.4982 - val_acc: 0.4986\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.5014 - val_loss: 0.4979 - val_acc: 0.4986\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.5014 - val_loss: 0.4980 - val_acc: 0.4986\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.5014 - val_loss: 0.4979 - val_acc: 0.4986\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.5014 - val_loss: 0.4979 - val_acc: 0.4986\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.5014 - val_loss: 0.4979 - val_acc: 0.4986\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.5014 - val_loss: 0.4979 - val_acc: 0.4986\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.5014 - val_loss: 0.4979 - val_acc: 0.4986\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4951 - acc: 0.5014 - val_loss: 0.4979 - val_acc: 0.4986\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.5014 - val_loss: 0.4980 - val_acc: 0.4986\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.5014 - val_loss: 0.4978 - val_acc: 0.4986\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4951 - acc: 0.5014 - val_loss: 0.4979 - val_acc: 0.4986\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4951 - acc: 0.5014 - val_loss: 0.4978 - val_acc: 0.4986\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.5014 - val_loss: 0.4979 - val_acc: 0.4986\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4951 - acc: 0.5014 - val_loss: 0.4979 - val_acc: 0.4986\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4951 - acc: 0.5014 - val_loss: 0.4978 - val_acc: 0.4986\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.5014 - val_loss: 0.4980 - val_acc: 0.4986\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4951 - acc: 0.5014 - val_loss: 0.4978 - val_acc: 0.4986\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.5014 - val_loss: 0.4979 - val_acc: 0.4986\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.5014 - val_loss: 0.4981 - val_acc: 0.4986\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.5014 - val_loss: 0.4979 - val_acc: 0.4986\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4951 - acc: 0.5014 - val_loss: 0.4979 - val_acc: 0.4986\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4951 - acc: 0.5014 - val_loss: 0.4978 - val_acc: 0.4986\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4951 - acc: 0.5014 - val_loss: 0.4978 - val_acc: 0.4986\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4951 - acc: 0.5014 - val_loss: 0.4981 - val_acc: 0.4986\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4951 - acc: 0.5014 - val_loss: 0.4978 - val_acc: 0.4986\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.2978 - acc: 0.2352 - val_loss: 1.1024 - val_acc: 0.1055\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0788 - acc: 0.1025 - val_loss: 0.9687 - val_acc: 0.1087\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9171 - acc: 0.1205 - val_loss: 0.8814 - val_acc: 0.1275\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8097 - acc: 0.1070 - val_loss: 0.7051 - val_acc: 0.0699\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6305 - acc: 0.0397 - val_loss: 0.5499 - val_acc: 0.0089\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5191 - acc: 0.0018 - val_loss: 0.4992 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4969 - acc: 0.0000e+00 - val_loss: 0.4991 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4989 - acc: 0.0000e+00 - val_loss: 0.4997 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 0.0000e+00 - val_loss: 0.4971 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4958 - acc: 0.0000e+00 - val_loss: 0.4964 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4956 - acc: 0.0000e+00 - val_loss: 0.4965 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4956 - acc: 0.0000e+00 - val_loss: 0.4964 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4955 - acc: 0.0000e+00 - val_loss: 0.4963 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4955 - acc: 0.0000e+00 - val_loss: 0.4963 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4954 - acc: 0.0000e+00 - val_loss: 0.4963 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4954 - acc: 0.0000e+00 - val_loss: 0.4963 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4954 - acc: 0.0000e+00 - val_loss: 0.4963 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4954 - acc: 0.0000e+00 - val_loss: 0.4963 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4954 - acc: 0.0000e+00 - val_loss: 0.4962 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.0000e+00 - val_loss: 0.4962 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.0000e+00 - val_loss: 0.4962 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.0000e+00 - val_loss: 0.4962 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.0000e+00 - val_loss: 0.4962 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.0000e+00 - val_loss: 0.4962 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.0000e+00 - val_loss: 0.4962 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.0000e+00 - val_loss: 0.4961 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.0000e+00 - val_loss: 0.4961 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.0000e+00 - val_loss: 0.4962 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.0000e+00 - val_loss: 0.4961 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.0000e+00 - val_loss: 0.4961 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.0000e+00 - val_loss: 0.4961 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.0000e+00 - val_loss: 0.4961 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.0000e+00 - val_loss: 0.4961 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.0000e+00 - val_loss: 0.4962 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.0000e+00 - val_loss: 0.4961 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.0000e+00 - val_loss: 0.4961 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.0000e+00 - val_loss: 0.4961 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.0000e+00 - val_loss: 0.4962 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 5.0000e-06 - val_loss: 0.4961 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4954 - acc: 0.0000e+00 - val_loss: 0.4964 - val_acc: 5.0000e-06\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4954 - acc: 0.0000e+00 - val_loss: 0.4961 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.0000e+00 - val_loss: 0.4961 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 5.0000e-06 - val_loss: 0.4964 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 5.0000e-06 - val_loss: 0.4961 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.0000e+00 - val_loss: 0.4961 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 0.0000e+00 - val_loss: 0.4962 - val_acc: 5.0000e-06\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.0000e+00 - val_loss: 0.4961 - val_acc: 5.0000e-06\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.0000e+00 - val_loss: 0.4961 - val_acc: 5.0000e-06\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4952 - acc: 5.0000e-06 - val_loss: 0.4962 - val_acc: 5.0000e-06\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4953 - acc: 0.0000e+00 - val_loss: 0.4960 - val_acc: 0.0000e+00\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.4880 - acc: 0.2653 - val_loss: 1.0432 - val_acc: 0.1221\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1092 - acc: 0.1080 - val_loss: 1.1221 - val_acc: 0.1037\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0476 - acc: 0.1058 - val_loss: 0.9707 - val_acc: 0.1147\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9373 - acc: 0.1212 - val_loss: 0.9267 - val_acc: 0.1305\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9110 - acc: 0.1281 - val_loss: 0.8926 - val_acc: 0.1230\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8625 - acc: 0.1110 - val_loss: 0.8277 - val_acc: 0.0988\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7903 - acc: 0.0860 - val_loss: 0.7495 - val_acc: 0.0748\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7051 - acc: 0.0618 - val_loss: 0.6349 - val_acc: 0.0443\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5828 - acc: 0.0237 - val_loss: 0.5336 - val_acc: 0.0054\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5117 - acc: 0.0014 - val_loss: 0.4952 - val_acc: 4.5000e-05\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4962 - acc: 5.0000e-06 - val_loss: 0.4968 - val_acc: 1.0000e-05\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4976 - acc: 1.4500e-04 - val_loss: 0.4971 - val_acc: 1.1500e-04\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4964 - acc: 7.5000e-05 - val_loss: 0.4952 - val_acc: 5.0000e-06\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4951 - acc: 1.0000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 5.0000e-06 - val_loss: 0.4946 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4949 - acc: 5.0000e-06 - val_loss: 0.4946 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 5.0000e-06 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 5.0000e-06 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 5.0000e-06 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 5.0000e-06 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 5.0000e-06 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.0000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 5.0000e-06 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.0000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 5.0000e-06 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.0000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.0000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 5.0000e-06 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 5.0000e-06 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.0000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 5.0000e-06 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.0000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.0000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 5.0000e-06 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.0000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.0000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.0000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.0000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 5.0000e-06 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.0000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.0000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.0000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.0000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 5.0000e-06 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.5000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 5.0000e-06 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.5000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.0000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.0000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4948 - acc: 1.0000e-05 - val_loss: 0.4945 - val_acc: 0.0000e+00\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.3758 - acc: 0.2215 - val_loss: 1.2210 - val_acc: 0.0927\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1759 - acc: 0.0917 - val_loss: 1.0522 - val_acc: 0.1024\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0185 - acc: 0.1159 - val_loss: 0.9851 - val_acc: 0.1208\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9010 - acc: 0.0958 - val_loss: 0.7894 - val_acc: 0.0587\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6983 - acc: 0.0347 - val_loss: 0.5944 - val_acc: 0.0090\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5435 - acc: 0.0018 - val_loss: 0.4979 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4881 - acc: 2.5000e-05 - val_loss: 0.4791 - val_acc: 2.4000e-04\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4852 - acc: 0.0025 - val_loss: 0.4817 - val_acc: 0.0029\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4853 - acc: 0.0013 - val_loss: 0.4790 - val_acc: 1.0000e-03\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4829 - acc: 7.3500e-04 - val_loss: 0.4783 - val_acc: 6.0000e-05\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4824 - acc: 1.3500e-04 - val_loss: 0.4786 - val_acc: 5.5000e-05\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4823 - acc: 7.0000e-05 - val_loss: 0.4783 - val_acc: 4.5000e-05\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4822 - acc: 1.3000e-04 - val_loss: 0.4780 - val_acc: 6.5000e-05\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4820 - acc: 1.6500e-04 - val_loss: 0.4780 - val_acc: 9.0000e-05\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4820 - acc: 1.3500e-04 - val_loss: 0.4779 - val_acc: 3.5000e-05\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4819 - acc: 6.0000e-05 - val_loss: 0.4779 - val_acc: 3.0000e-05\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4819 - acc: 5.0000e-05 - val_loss: 0.4778 - val_acc: 2.0000e-05\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4818 - acc: 3.0000e-05 - val_loss: 0.4778 - val_acc: 2.0000e-05\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4818 - acc: 2.5000e-05 - val_loss: 0.4777 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4817 - acc: 1.5000e-05 - val_loss: 0.4778 - val_acc: 1.5000e-05\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4817 - acc: 5.0000e-06 - val_loss: 0.4778 - val_acc: 1.5000e-05\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4818 - acc: 3.5000e-05 - val_loss: 0.4777 - val_acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4817 - acc: 5.0000e-06 - val_loss: 0.4776 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4816 - acc: 0.0000e+00 - val_loss: 0.4776 - val_acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4816 - acc: 0.0000e+00 - val_loss: 0.4775 - val_acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4816 - acc: 0.0000e+00 - val_loss: 0.4776 - val_acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4816 - acc: 0.0000e+00 - val_loss: 0.4775 - val_acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4815 - acc: 0.0000e+00 - val_loss: 0.4775 - val_acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4815 - acc: 0.0000e+00 - val_loss: 0.4775 - val_acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 0.0000e+00 - val_loss: 0.4774 - val_acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 0.0000e+00 - val_loss: 0.4775 - val_acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 0.0000e+00 - val_loss: 0.4774 - val_acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4815 - acc: 0.0000e+00 - val_loss: 0.4776 - val_acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4815 - acc: 0.0000e+00 - val_loss: 0.4775 - val_acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4815 - acc: 0.0000e+00 - val_loss: 0.4774 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4815 - acc: 0.0000e+00 - val_loss: 0.4777 - val_acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 0.0000e+00 - val_loss: 0.4774 - val_acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 0.0000e+00 - val_loss: 0.4774 - val_acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 0.0000e+00 - val_loss: 0.4774 - val_acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 0.0000e+00 - val_loss: 0.4774 - val_acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4813 - acc: 0.0000e+00 - val_loss: 0.4773 - val_acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 0.0000e+00 - val_loss: 0.4773 - val_acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 0.0000e+00 - val_loss: 0.4778 - val_acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 0.0000e+00 - val_loss: 0.4774 - val_acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4813 - acc: 0.0000e+00 - val_loss: 0.4773 - val_acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4813 - acc: 0.0000e+00 - val_loss: 0.4773 - val_acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4813 - acc: 0.0000e+00 - val_loss: 0.4773 - val_acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 0.0000e+00 - val_loss: 0.4774 - val_acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 0.0000e+00 - val_loss: 0.4774 - val_acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 0.0000e+00 - val_loss: 0.4774 - val_acc: 0.0000e+00\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.5754 - acc: 0.4484 - val_loss: 1.0928 - val_acc: 0.3792\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1655 - acc: 0.3387 - val_loss: 1.1921 - val_acc: 0.3215\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1300 - acc: 0.3450 - val_loss: 1.0483 - val_acc: 0.3844\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0059 - acc: 0.4156 - val_loss: 0.9732 - val_acc: 0.4424\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9491 - acc: 0.4505 - val_loss: 0.9105 - val_acc: 0.4556\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8655 - acc: 0.4595 - val_loss: 0.8032 - val_acc: 0.4652\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7387 - acc: 0.4708 - val_loss: 0.6582 - val_acc: 0.4813\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6072 - acc: 0.4897 - val_loss: 0.5550 - val_acc: 0.4989\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5277 - acc: 0.4995 - val_loss: 0.5000 - val_acc: 0.5003\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4901 - acc: 0.4997 - val_loss: 0.4812 - val_acc: 0.5003\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.4997 - val_loss: 0.4794 - val_acc: 0.5003\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 0.4998 - val_loss: 0.4799 - val_acc: 0.5004\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.4998 - val_loss: 0.4795 - val_acc: 0.5003\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4801 - acc: 0.4998 - val_loss: 0.4791 - val_acc: 0.5003\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4799 - acc: 0.4997 - val_loss: 0.4791 - val_acc: 0.5003\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4799 - acc: 0.4997 - val_loss: 0.4791 - val_acc: 0.5003\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4799 - acc: 0.4997 - val_loss: 0.4790 - val_acc: 0.5003\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4798 - acc: 0.4997 - val_loss: 0.4790 - val_acc: 0.5003\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4798 - acc: 0.4997 - val_loss: 0.4790 - val_acc: 0.5003\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4798 - acc: 0.4997 - val_loss: 0.4790 - val_acc: 0.5003\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4798 - acc: 0.4997 - val_loss: 0.4790 - val_acc: 0.5003\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4798 - acc: 0.4997 - val_loss: 0.4790 - val_acc: 0.5003\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4798 - acc: 0.4997 - val_loss: 0.4790 - val_acc: 0.5003\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4798 - acc: 0.4997 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4788 - val_acc: 0.5003\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4796 - acc: 0.4997 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4788 - val_acc: 0.5003\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4788 - val_acc: 0.5003\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4788 - val_acc: 0.5003\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4788 - val_acc: 0.5003\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4788 - val_acc: 0.5003\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4788 - val_acc: 0.5003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4796 - acc: 0.4997 - val_loss: 0.4788 - val_acc: 0.5003\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4796 - acc: 0.4997 - val_loss: 0.4788 - val_acc: 0.5003\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4788 - val_acc: 0.5003\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4796 - acc: 0.4997 - val_loss: 0.4788 - val_acc: 0.5003\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4788 - val_acc: 0.5003\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4796 - acc: 0.4997 - val_loss: 0.4788 - val_acc: 0.5003\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.4997 - val_loss: 0.4791 - val_acc: 0.5003\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 1s 3us/step - loss: 1.4161 - acc: 0.4246 - val_loss: 1.1757 - val_acc: 0.3263\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1651 - acc: 0.3292 - val_loss: 1.0379 - val_acc: 0.3817\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9904 - acc: 0.4282 - val_loss: 0.9563 - val_acc: 0.4519\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9058 - acc: 0.4556 - val_loss: 0.8150 - val_acc: 0.4624\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7224 - acc: 0.4742 - val_loss: 0.6240 - val_acc: 0.4860\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5648 - acc: 0.4951 - val_loss: 0.5148 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4950 - acc: 0.4999 - val_loss: 0.4830 - val_acc: 0.5001\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4811 - acc: 0.5006 - val_loss: 0.4827 - val_acc: 0.5016\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4824 - acc: 0.5013 - val_loss: 0.4832 - val_acc: 0.5009\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4815 - acc: 0.5010 - val_loss: 0.4814 - val_acc: 0.5006\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 0.5003 - val_loss: 0.4808 - val_acc: 0.5002\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4802 - acc: 0.5001 - val_loss: 0.4808 - val_acc: 0.5002\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4801 - acc: 0.5001 - val_loss: 0.4807 - val_acc: 0.5002\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4800 - acc: 0.5001 - val_loss: 0.4806 - val_acc: 0.5002\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4799 - acc: 0.5001 - val_loss: 0.4805 - val_acc: 0.5002\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4799 - acc: 0.5001 - val_loss: 0.4804 - val_acc: 0.5002\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4799 - acc: 0.5001 - val_loss: 0.4805 - val_acc: 0.5001\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4798 - acc: 0.5001 - val_loss: 0.4803 - val_acc: 0.5001\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.5000 - val_loss: 0.4802 - val_acc: 0.5001\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4797 - acc: 0.5000 - val_loss: 0.4801 - val_acc: 0.5001\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4796 - acc: 0.5000 - val_loss: 0.4801 - val_acc: 0.5001\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4796 - acc: 0.5000 - val_loss: 0.4800 - val_acc: 0.5001\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4795 - acc: 0.5000 - val_loss: 0.4800 - val_acc: 0.5001\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4795 - acc: 0.4999 - val_loss: 0.4800 - val_acc: 0.5001\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4796 - acc: 0.5000 - val_loss: 0.4799 - val_acc: 0.5001\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4795 - acc: 0.5000 - val_loss: 0.4799 - val_acc: 0.5001\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4795 - acc: 0.4999 - val_loss: 0.4798 - val_acc: 0.5001\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4794 - acc: 0.4999 - val_loss: 0.4798 - val_acc: 0.5001\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4794 - acc: 0.4999 - val_loss: 0.4799 - val_acc: 0.5001\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4795 - acc: 0.4999 - val_loss: 0.4798 - val_acc: 0.5001\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4794 - acc: 0.4999 - val_loss: 0.4798 - val_acc: 0.5001\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4794 - acc: 0.4999 - val_loss: 0.4798 - val_acc: 0.5001\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4795 - acc: 0.4999 - val_loss: 0.4797 - val_acc: 0.5001\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4794 - acc: 0.4999 - val_loss: 0.4797 - val_acc: 0.5001\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4794 - acc: 0.4999 - val_loss: 0.4797 - val_acc: 0.5001\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4793 - acc: 0.4999 - val_loss: 0.4796 - val_acc: 0.5001\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4793 - acc: 0.4999 - val_loss: 0.4796 - val_acc: 0.5001\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4794 - acc: 0.4999 - val_loss: 0.4796 - val_acc: 0.5001\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4793 - acc: 0.4999 - val_loss: 0.4796 - val_acc: 0.5001\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4793 - acc: 0.4999 - val_loss: 0.4796 - val_acc: 0.5001\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4793 - acc: 0.4999 - val_loss: 0.4795 - val_acc: 0.5001\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4793 - acc: 0.4999 - val_loss: 0.4796 - val_acc: 0.5001\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4793 - acc: 0.4999 - val_loss: 0.4795 - val_acc: 0.5001\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4793 - acc: 0.4999 - val_loss: 0.4795 - val_acc: 0.5001\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4793 - acc: 0.4999 - val_loss: 0.4796 - val_acc: 0.5001\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4793 - acc: 0.4999 - val_loss: 0.4796 - val_acc: 0.5001\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4793 - acc: 0.4999 - val_loss: 0.4795 - val_acc: 0.5001\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4793 - acc: 0.4999 - val_loss: 0.4795 - val_acc: 0.5001\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4794 - acc: 0.4999 - val_loss: 0.4795 - val_acc: 0.5001\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4794 - acc: 0.4999 - val_loss: 0.4795 - val_acc: 0.5001\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.3043 - acc: 0.4127 - val_loss: 1.1937 - val_acc: 0.3165\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1306 - acc: 0.3401 - val_loss: 1.0308 - val_acc: 0.4074\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0257 - acc: 0.4336 - val_loss: 1.0290 - val_acc: 0.4412\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0003 - acc: 0.4323 - val_loss: 0.9895 - val_acc: 0.4132\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9603 - acc: 0.4167 - val_loss: 0.9361 - val_acc: 0.4336\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8897 - acc: 0.4396 - val_loss: 0.8491 - val_acc: 0.4422\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8010 - acc: 0.4473 - val_loss: 0.7579 - val_acc: 0.4491\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7253 - acc: 0.4514 - val_loss: 0.6939 - val_acc: 0.4533\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6716 - acc: 0.4584 - val_loss: 0.6561 - val_acc: 0.4603\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6519 - acc: 0.4645 - val_loss: 0.6577 - val_acc: 0.4590\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6480 - acc: 0.4661 - val_loss: 0.6399 - val_acc: 0.4669\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6357 - acc: 0.4741 - val_loss: 0.6202 - val_acc: 0.4744\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6192 - acc: 0.4775 - val_loss: 0.6058 - val_acc: 0.4851\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6052 - acc: 0.4787 - val_loss: 0.6007 - val_acc: 0.4784\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6046 - acc: 0.4781 - val_loss: 0.6025 - val_acc: 0.4747\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6014 - acc: 0.4781 - val_loss: 0.5924 - val_acc: 0.4797\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5903 - acc: 0.4792 - val_loss: 0.5844 - val_acc: 0.4822\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5804 - acc: 0.4841 - val_loss: 0.5692 - val_acc: 0.4868\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5616 - acc: 0.4899 - val_loss: 0.5499 - val_acc: 0.4954\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5369 - acc: 0.4988 - val_loss: 0.5195 - val_acc: 0.5031\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5112 - acc: 0.5024 - val_loss: 0.5005 - val_acc: 0.5044\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4956 - acc: 0.5020 - val_loss: 0.4891 - val_acc: 0.5000\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4870 - acc: 0.5000 - val_loss: 0.4841 - val_acc: 0.4998\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4835 - acc: 0.5000 - val_loss: 0.4822 - val_acc: 0.4998\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4823 - acc: 0.5000 - val_loss: 0.4817 - val_acc: 0.4998\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4819 - acc: 0.5000 - val_loss: 0.4812 - val_acc: 0.4999\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4815 - acc: 0.5001 - val_loss: 0.4810 - val_acc: 0.4999\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 0.5001 - val_loss: 0.4809 - val_acc: 0.4999\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4813 - acc: 0.5001 - val_loss: 0.4809 - val_acc: 0.4999\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4812 - acc: 0.5001 - val_loss: 0.4808 - val_acc: 0.4999\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4812 - acc: 0.5001 - val_loss: 0.4808 - val_acc: 0.4999\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4812 - acc: 0.5001 - val_loss: 0.4807 - val_acc: 0.4999\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4812 - acc: 0.5001 - val_loss: 0.4807 - val_acc: 0.4999\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4812 - acc: 0.5001 - val_loss: 0.4807 - val_acc: 0.4999\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4810 - acc: 0.5001 - val_loss: 0.4807 - val_acc: 0.4999\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4810 - acc: 0.5001 - val_loss: 0.4806 - val_acc: 0.4999\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4810 - acc: 0.5001 - val_loss: 0.4806 - val_acc: 0.4999\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4809 - acc: 0.5001 - val_loss: 0.4806 - val_acc: 0.4999\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4809 - acc: 0.5001 - val_loss: 0.4805 - val_acc: 0.4999\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4808 - acc: 0.5001 - val_loss: 0.4804 - val_acc: 0.4999\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4808 - acc: 0.5001 - val_loss: 0.4804 - val_acc: 0.4999\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4808 - acc: 0.5001 - val_loss: 0.4804 - val_acc: 0.4999\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 0.5001 - val_loss: 0.4803 - val_acc: 0.4999\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 0.5001 - val_loss: 0.4803 - val_acc: 0.4999\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 0.5001 - val_loss: 0.4802 - val_acc: 0.4999\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 0.5001 - val_loss: 0.4802 - val_acc: 0.4999\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 0.5001 - val_loss: 0.4802 - val_acc: 0.4999\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 0.5001 - val_loss: 0.4802 - val_acc: 0.4999\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.5001 - val_loss: 0.4802 - val_acc: 0.4999\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 0.5001 - val_loss: 0.4802 - val_acc: 0.4999\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 1s 3us/step - loss: 1.4133 - acc: 0.4258 - val_loss: 1.1822 - val_acc: 0.3252\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1915 - acc: 0.3202 - val_loss: 1.0781 - val_acc: 0.3656\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0027 - acc: 0.4162 - val_loss: 0.9573 - val_acc: 0.4546\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9155 - acc: 0.4550 - val_loss: 0.8495 - val_acc: 0.4633\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7992 - acc: 0.4671 - val_loss: 0.7233 - val_acc: 0.4775\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6478 - acc: 0.4832 - val_loss: 0.5657 - val_acc: 0.4981\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5308 - acc: 0.4972 - val_loss: 0.4940 - val_acc: 0.5020\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4887 - acc: 0.4980 - val_loss: 0.4787 - val_acc: 0.5024\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4840 - acc: 0.4999 - val_loss: 0.4804 - val_acc: 0.5043\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4846 - acc: 0.4996 - val_loss: 0.4793 - val_acc: 0.5032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4833 - acc: 0.4992 - val_loss: 0.4785 - val_acc: 0.5028\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4827 - acc: 0.4985 - val_loss: 0.4785 - val_acc: 0.5024\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4826 - acc: 0.4985 - val_loss: 0.4785 - val_acc: 0.5024\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4825 - acc: 0.4984 - val_loss: 0.4783 - val_acc: 0.5024\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4825 - acc: 0.4984 - val_loss: 0.4784 - val_acc: 0.5025\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4824 - acc: 0.4985 - val_loss: 0.4781 - val_acc: 0.5023\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4824 - acc: 0.4984 - val_loss: 0.4782 - val_acc: 0.5024\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4823 - acc: 0.4983 - val_loss: 0.4781 - val_acc: 0.5024\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4823 - acc: 0.4983 - val_loss: 0.4780 - val_acc: 0.5022\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4822 - acc: 0.4983 - val_loss: 0.4780 - val_acc: 0.5021\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4822 - acc: 0.4982 - val_loss: 0.4780 - val_acc: 0.5023\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4821 - acc: 0.4983 - val_loss: 0.4779 - val_acc: 0.5021\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4821 - acc: 0.4982 - val_loss: 0.4780 - val_acc: 0.5022\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4820 - acc: 0.4982 - val_loss: 0.4778 - val_acc: 0.5021\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4820 - acc: 0.4982 - val_loss: 0.4779 - val_acc: 0.5022\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4820 - acc: 0.4981 - val_loss: 0.4778 - val_acc: 0.5021\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4820 - acc: 0.4982 - val_loss: 0.4777 - val_acc: 0.5021\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4820 - acc: 0.4981 - val_loss: 0.4780 - val_acc: 0.5022\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4819 - acc: 0.4981 - val_loss: 0.4777 - val_acc: 0.5021\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4819 - acc: 0.4981 - val_loss: 0.4777 - val_acc: 0.5021\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4818 - acc: 0.4981 - val_loss: 0.4777 - val_acc: 0.5021\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4818 - acc: 0.4981 - val_loss: 0.4776 - val_acc: 0.5021\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4818 - acc: 0.4981 - val_loss: 0.4776 - val_acc: 0.5020\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4818 - acc: 0.4980 - val_loss: 0.4776 - val_acc: 0.5020\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4817 - acc: 0.4980 - val_loss: 0.4776 - val_acc: 0.5020\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4817 - acc: 0.4980 - val_loss: 0.4776 - val_acc: 0.5020\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4817 - acc: 0.4980 - val_loss: 0.4776 - val_acc: 0.5020\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4817 - acc: 0.4980 - val_loss: 0.4776 - val_acc: 0.5020\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4817 - acc: 0.4980 - val_loss: 0.4775 - val_acc: 0.5020\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4817 - acc: 0.4980 - val_loss: 0.4775 - val_acc: 0.5020\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4817 - acc: 0.4980 - val_loss: 0.4775 - val_acc: 0.5020\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4817 - acc: 0.4980 - val_loss: 0.4775 - val_acc: 0.5020\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4817 - acc: 0.4980 - val_loss: 0.4775 - val_acc: 0.5020\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4817 - acc: 0.4980 - val_loss: 0.4779 - val_acc: 0.5020\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4817 - acc: 0.4980 - val_loss: 0.4775 - val_acc: 0.5020\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4816 - acc: 0.4980 - val_loss: 0.4775 - val_acc: 0.5020\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4816 - acc: 0.4980 - val_loss: 0.4775 - val_acc: 0.5020\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4817 - acc: 0.4980 - val_loss: 0.4775 - val_acc: 0.5020\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4816 - acc: 0.4980 - val_loss: 0.4776 - val_acc: 0.5020\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4817 - acc: 0.4980 - val_loss: 0.4775 - val_acc: 0.5020\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.3314 - acc: 0.1975 - val_loss: 1.2519 - val_acc: 0.0923\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1352 - acc: 0.0945 - val_loss: 1.0005 - val_acc: 0.1113\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9825 - acc: 0.1173 - val_loss: 0.9235 - val_acc: 0.1038\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8339 - acc: 0.0733 - val_loss: 0.7337 - val_acc: 0.0423\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6247 - acc: 0.0195 - val_loss: 0.5389 - val_acc: 4.1000e-04\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5037 - acc: 1.2000e-04 - val_loss: 0.4848 - val_acc: 4.0000e-05\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4845 - acc: 0.0035 - val_loss: 0.4860 - val_acc: 0.0105\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4856 - acc: 0.0058 - val_loss: 0.4835 - val_acc: 0.0030\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4828 - acc: 0.0032 - val_loss: 0.4804 - val_acc: 0.0020\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4811 - acc: 7.9500e-04 - val_loss: 0.4803 - val_acc: 8.6500e-04\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4812 - acc: 8.3000e-04 - val_loss: 0.4803 - val_acc: 3.9500e-04\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4809 - acc: 6.5000e-04 - val_loss: 0.4801 - val_acc: 8.1500e-04\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 8.5500e-04 - val_loss: 0.4799 - val_acc: 6.6000e-04\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 7.7000e-04 - val_loss: 0.4799 - val_acc: 8.6500e-04\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 8.5500e-04 - val_loss: 0.4799 - val_acc: 4.0500e-04\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 5.0500e-04 - val_loss: 0.4799 - val_acc: 8.7500e-04\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 7.0000e-04 - val_loss: 0.4798 - val_acc: 2.8000e-04\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 5.0000e-04 - val_loss: 0.4797 - val_acc: 5.2500e-04\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 4.4000e-04 - val_loss: 0.4796 - val_acc: 4.4000e-04\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 4.2500e-04 - val_loss: 0.4796 - val_acc: 3.4000e-04\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 4.0000e-04 - val_loss: 0.4796 - val_acc: 3.1000e-04\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 4.0500e-04 - val_loss: 0.4796 - val_acc: 2.2000e-04\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 2.4500e-04 - val_loss: 0.4800 - val_acc: 7.3000e-04\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 3.2500e-04 - val_loss: 0.4795 - val_acc: 1.8000e-04\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 3.5000e-04 - val_loss: 0.4795 - val_acc: 1.7000e-04\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 2.4500e-04 - val_loss: 0.4795 - val_acc: 2.8500e-04\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 2.6500e-04 - val_loss: 0.4794 - val_acc: 1.6500e-04\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 2.7500e-04 - val_loss: 0.4795 - val_acc: 8.0000e-05\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 2.5000e-04 - val_loss: 0.4794 - val_acc: 1.4500e-04\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 2.1500e-04 - val_loss: 0.4796 - val_acc: 2.4000e-04\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 1.7000e-04 - val_loss: 0.4795 - val_acc: 2.3000e-04\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 1.5500e-04 - val_loss: 0.4794 - val_acc: 1.3500e-04\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 1.7000e-04 - val_loss: 0.4794 - val_acc: 8.5000e-05\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 1.8500e-04 - val_loss: 0.4796 - val_acc: 1.0000e-05\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 1.6000e-04 - val_loss: 0.4794 - val_acc: 5.0000e-05\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 1.5500e-04 - val_loss: 0.4794 - val_acc: 1.5500e-04\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 1.3000e-04 - val_loss: 0.4793 - val_acc: 8.5000e-05\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 1.1000e-04 - val_loss: 0.4793 - val_acc: 8.0000e-05\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 1.1500e-04 - val_loss: 0.4793 - val_acc: 3.5000e-05\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 9.5000e-05 - val_loss: 0.4793 - val_acc: 3.0000e-05\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 8.0000e-05 - val_loss: 0.4793 - val_acc: 7.0000e-05\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 9.5000e-05 - val_loss: 0.4794 - val_acc: 8.5000e-05\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 1.0500e-04 - val_loss: 0.4793 - val_acc: 3.5000e-05\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 1.0000e-04 - val_loss: 0.4795 - val_acc: 1.4500e-04\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 1.2500e-04 - val_loss: 0.4793 - val_acc: 7.5000e-05\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 9.5000e-05 - val_loss: 0.4793 - val_acc: 7.0000e-05\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 9.0000e-05 - val_loss: 0.4799 - val_acc: 2.4000e-04\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 1.0000e-04 - val_loss: 0.4794 - val_acc: 8.0000e-05\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 1.1000e-04 - val_loss: 0.4793 - val_acc: 5.5000e-05\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 1.0500e-04 - val_loss: 0.4793 - val_acc: 1.0000e-05\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.3693 - acc: 0.4110 - val_loss: 1.2454 - val_acc: 0.3127\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1345 - acc: 0.3464 - val_loss: 0.9629 - val_acc: 0.4310\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8793 - acc: 0.4566 - val_loss: 0.7871 - val_acc: 0.4660\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6803 - acc: 0.4820 - val_loss: 0.5753 - val_acc: 0.4966\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5313 - acc: 0.4992 - val_loss: 0.4947 - val_acc: 0.5001\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4852 - acc: 0.5000 - val_loss: 0.4795 - val_acc: 0.5013\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4822 - acc: 0.5007 - val_loss: 0.4815 - val_acc: 0.5013\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4829 - acc: 0.5013 - val_loss: 0.4799 - val_acc: 0.5012\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4810 - acc: 0.5003 - val_loss: 0.4789 - val_acc: 0.5005\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5001 - val_loss: 0.4790 - val_acc: 0.5003\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 0.5000 - val_loss: 0.4790 - val_acc: 0.5003\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5001 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5004\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5001 - val_loss: 0.4789 - val_acc: 0.5004\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5004\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5001 - val_loss: 0.4791 - val_acc: 0.5003\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 0.5001 - val_loss: 0.4789 - val_acc: 0.5004\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5004\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5001 - val_loss: 0.4789 - val_acc: 0.5004\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 0.5001 - val_loss: 0.4791 - val_acc: 0.5003\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4790 - val_acc: 0.5006\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5001 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5004\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5001 - val_loss: 0.4789 - val_acc: 0.5004\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5001 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5004\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5001 - val_loss: 0.4790 - val_acc: 0.5003\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5001 - val_loss: 0.4790 - val_acc: 0.5003\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5004\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5004\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4790 - val_acc: 0.5006\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5004\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 0.5001 - val_loss: 0.4793 - val_acc: 0.5002\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 0.5001 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5004\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5004\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5004\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5004\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5004\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5005\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5004\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5004\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4789 - val_acc: 0.5003\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5000 - val_loss: 0.4790 - val_acc: 0.5002\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.3935 - acc: 0.2155 - val_loss: 1.2544 - val_acc: 0.0916\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1834 - acc: 0.0909 - val_loss: 1.0223 - val_acc: 0.1001\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9918 - acc: 0.1148 - val_loss: 0.9591 - val_acc: 0.1187\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8933 - acc: 0.0954 - val_loss: 0.8127 - val_acc: 0.0657\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7417 - acc: 0.0468 - val_loss: 0.6387 - val_acc: 0.0244\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5800 - acc: 0.0102 - val_loss: 0.5221 - val_acc: 4.7500e-04\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5001 - acc: 7.0000e-05 - val_loss: 0.4809 - val_acc: 1.6500e-04\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4827 - acc: 0.0029 - val_loss: 0.4803 - val_acc: 0.0057\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4844 - acc: 0.0042 - val_loss: 0.4802 - val_acc: 0.0043\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4829 - acc: 0.0037 - val_loss: 0.4784 - val_acc: 0.0017\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4816 - acc: 0.0015 - val_loss: 0.4784 - val_acc: 0.0013\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4817 - acc: 0.0013 - val_loss: 0.4784 - val_acc: 7.4500e-04\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4816 - acc: 0.0011 - val_loss: 0.4782 - val_acc: 9.8500e-04\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4815 - acc: 0.0012 - val_loss: 0.4781 - val_acc: 0.0010\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4815 - acc: 0.0013 - val_loss: 0.4781 - val_acc: 8.1500e-04\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4815 - acc: 0.0012 - val_loss: 0.4782 - val_acc: 0.0012\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 0.0010 - val_loss: 0.4781 - val_acc: 7.9000e-04\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 8.8000e-04 - val_loss: 0.4781 - val_acc: 9.4500e-04\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 8.4500e-04 - val_loss: 0.4780 - val_acc: 7.0500e-04\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 0.0010 - val_loss: 0.4780 - val_acc: 6.6500e-04\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4813 - acc: 6.7000e-04 - val_loss: 0.4781 - val_acc: 7.9000e-04\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4813 - acc: 7.7500e-04 - val_loss: 0.4780 - val_acc: 4.3500e-04\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4813 - acc: 6.2000e-04 - val_loss: 0.4781 - val_acc: 8.9500e-04\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4813 - acc: 7.2000e-04 - val_loss: 0.4780 - val_acc: 3.1000e-04\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4813 - acc: 6.7000e-04 - val_loss: 0.4780 - val_acc: 5.3500e-04\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4813 - acc: 5.0500e-04 - val_loss: 0.4779 - val_acc: 5.5500e-04\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4812 - acc: 5.3500e-04 - val_loss: 0.4780 - val_acc: 7.2000e-04\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4813 - acc: 5.7500e-04 - val_loss: 0.4779 - val_acc: 3.8000e-04\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4813 - acc: 5.0000e-04 - val_loss: 0.4780 - val_acc: 2.6500e-04\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4813 - acc: 5.1500e-04 - val_loss: 0.4779 - val_acc: 3.6500e-04\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4812 - acc: 4.1500e-04 - val_loss: 0.4780 - val_acc: 4.5500e-04\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4813 - acc: 3.9000e-04 - val_loss: 0.4783 - val_acc: 7.7000e-04\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 4.1000e-04 - val_loss: 0.4780 - val_acc: 4.3500e-04\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4812 - acc: 4.7500e-04 - val_loss: 0.4779 - val_acc: 2.6000e-04\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4812 - acc: 3.2500e-04 - val_loss: 0.4780 - val_acc: 4.3500e-04\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4812 - acc: 4.3500e-04 - val_loss: 0.4779 - val_acc: 3.1000e-04\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4812 - acc: 3.1500e-04 - val_loss: 0.4779 - val_acc: 3.0500e-04\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4812 - acc: 3.2500e-04 - val_loss: 0.4779 - val_acc: 2.3000e-04\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4811 - acc: 3.3000e-04 - val_loss: 0.4780 - val_acc: 4.2000e-04\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4812 - acc: 3.3500e-04 - val_loss: 0.4779 - val_acc: 2.2000e-04\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4811 - acc: 3.4500e-04 - val_loss: 0.4779 - val_acc: 2.9000e-04\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4811 - acc: 3.2000e-04 - val_loss: 0.4781 - val_acc: 4.5500e-04\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4811 - acc: 3.2500e-04 - val_loss: 0.4779 - val_acc: 2.4500e-04\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4812 - acc: 3.0500e-04 - val_loss: 0.4779 - val_acc: 1.7500e-04\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4812 - acc: 3.5500e-04 - val_loss: 0.4779 - val_acc: 1.7500e-04\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4812 - acc: 2.9000e-04 - val_loss: 0.4779 - val_acc: 1.7500e-04\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4811 - acc: 2.7000e-04 - val_loss: 0.4779 - val_acc: 2.3000e-04\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4811 - acc: 3.0000e-04 - val_loss: 0.4779 - val_acc: 2.8500e-04\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4812 - acc: 3.1500e-04 - val_loss: 0.4782 - val_acc: 4.3500e-04\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4812 - acc: 2.4500e-04 - val_loss: 0.4780 - val_acc: 3.5000e-04\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.2577 - acc: 0.3946 - val_loss: 1.1768 - val_acc: 0.3302\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0455 - acc: 0.4048 - val_loss: 0.9582 - val_acc: 0.4588\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8827 - acc: 0.4640 - val_loss: 0.7582 - val_acc: 0.4774\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6505 - acc: 0.4864 - val_loss: 0.5357 - val_acc: 0.5003\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5007 - acc: 0.5015 - val_loss: 0.4879 - val_acc: 0.5011\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4903 - acc: 0.5067 - val_loss: 0.4924 - val_acc: 0.5114\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4880 - acc: 0.5055 - val_loss: 0.4824 - val_acc: 0.5041\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4814 - acc: 0.5030 - val_loss: 0.4807 - val_acc: 0.5015\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4813 - acc: 0.5009 - val_loss: 0.4810 - val_acc: 0.5019\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4811 - acc: 0.5007 - val_loss: 0.4805 - val_acc: 0.5019\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4808 - acc: 0.5016 - val_loss: 0.4806 - val_acc: 0.5015\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4808 - acc: 0.5014 - val_loss: 0.4804 - val_acc: 0.5024\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.5010 - val_loss: 0.4803 - val_acc: 0.5021\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 0.5013 - val_loss: 0.4804 - val_acc: 0.5011\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 0.5010 - val_loss: 0.4803 - val_acc: 0.5019\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 0.5010 - val_loss: 0.4802 - val_acc: 0.5016\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 0.5008 - val_loss: 0.4805 - val_acc: 0.5022\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 0.5008 - val_loss: 0.4802 - val_acc: 0.5015\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.5011 - val_loss: 0.4805 - val_acc: 0.5008\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.5008 - val_loss: 0.4802 - val_acc: 0.5013\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5006 - val_loss: 0.4802 - val_acc: 0.5015\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5006 - val_loss: 0.4801 - val_acc: 0.5011\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5006 - val_loss: 0.4801 - val_acc: 0.5011\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5005 - val_loss: 0.4801 - val_acc: 0.5010\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 0.5005 - val_loss: 0.4804 - val_acc: 0.5016\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 0.5004 - val_loss: 0.4804 - val_acc: 0.5015\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5005 - val_loss: 0.4801 - val_acc: 0.5009\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 0.5005 - val_loss: 0.4802 - val_acc: 0.5008\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5004 - val_loss: 0.4801 - val_acc: 0.5009\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 0.5004 - val_loss: 0.4801 - val_acc: 0.5009\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 0.5003 - val_loss: 0.4803 - val_acc: 0.5014\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 0.5003 - val_loss: 0.4801 - val_acc: 0.5010\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 0.5004 - val_loss: 0.4806 - val_acc: 0.5006\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 0.5004 - val_loss: 0.4801 - val_acc: 0.5008\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 0.5002 - val_loss: 0.4802 - val_acc: 0.5011\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 0.5003 - val_loss: 0.4801 - val_acc: 0.5009\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5003 - val_loss: 0.4801 - val_acc: 0.5008\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 0.5002 - val_loss: 0.4801 - val_acc: 0.5008\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 0.5003 - val_loss: 0.4801 - val_acc: 0.5009\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 0.5002 - val_loss: 0.4804 - val_acc: 0.5013\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4805 - acc: 0.5004 - val_loss: 0.4804 - val_acc: 0.5012\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5002 - val_loss: 0.4801 - val_acc: 0.5009\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 0.5003 - val_loss: 0.4803 - val_acc: 0.5007\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5002 - val_loss: 0.4802 - val_acc: 0.5007\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5003 - val_loss: 0.4803 - val_acc: 0.5007\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5003 - val_loss: 0.4801 - val_acc: 0.5008\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 0.5002 - val_loss: 0.4802 - val_acc: 0.5011\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4803 - acc: 0.5002 - val_loss: 0.4802 - val_acc: 0.5010\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5003 - val_loss: 0.4803 - val_acc: 0.5012\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4804 - acc: 0.5003 - val_loss: 0.4804 - val_acc: 0.5012\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.3586 - acc: 0.2109 - val_loss: 1.2711 - val_acc: 0.0964\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1617 - acc: 0.0982 - val_loss: 1.0249 - val_acc: 0.1111\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9824 - acc: 0.1201 - val_loss: 0.9076 - val_acc: 0.1087\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7969 - acc: 0.0746 - val_loss: 0.6773 - val_acc: 0.0354\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5938 - acc: 0.0135 - val_loss: 0.5193 - val_acc: 2.5000e-05\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4958 - acc: 5.0000e-05 - val_loss: 0.4792 - val_acc: 3.1500e-04\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4831 - acc: 0.0021 - val_loss: 0.4840 - val_acc: 0.0058\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4851 - acc: 0.0047 - val_loss: 0.4808 - val_acc: 0.0021\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4816 - acc: 0.0016 - val_loss: 0.4791 - val_acc: 9.1500e-04\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4809 - acc: 4.0500e-04 - val_loss: 0.4794 - val_acc: 4.0500e-04\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4810 - acc: 5.4500e-04 - val_loss: 0.4792 - val_acc: 3.8000e-04\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4808 - acc: 4.4500e-04 - val_loss: 0.4792 - val_acc: 0.0012\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4808 - acc: 9.9500e-04 - val_loss: 0.4790 - val_acc: 8.7500e-04\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 0.0010 - val_loss: 0.4790 - val_acc: 0.0010\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 9.5500e-04 - val_loss: 0.4790 - val_acc: 7.3000e-04\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4808 - acc: 9.3500e-04 - val_loss: 0.4791 - val_acc: 0.0012\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 8.7500e-04 - val_loss: 0.4790 - val_acc: 0.0010\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4808 - acc: 1.0000e-03 - val_loss: 0.4790 - val_acc: 9.1000e-04\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 0.0012 - val_loss: 0.4789 - val_acc: 9.9500e-04\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 9.7000e-04 - val_loss: 0.4791 - val_acc: 0.0015\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 0.0010 - val_loss: 0.4790 - val_acc: 0.0013\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 0.0013 - val_loss: 0.4790 - val_acc: 8.7500e-04\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 0.0011 - val_loss: 0.4790 - val_acc: 0.0012\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.0012 - val_loss: 0.4789 - val_acc: 0.0011\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 0.0014 - val_loss: 0.4789 - val_acc: 0.0012\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 0.0012 - val_loss: 0.4789 - val_acc: 0.0013\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.0013 - val_loss: 0.4789 - val_acc: 0.0014\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.0013 - val_loss: 0.4789 - val_acc: 0.0012\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.0014 - val_loss: 0.4789 - val_acc: 0.0014\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.0014 - val_loss: 0.4789 - val_acc: 0.0013\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 0.0014 - val_loss: 0.4789 - val_acc: 0.0014\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.0014 - val_loss: 0.4789 - val_acc: 0.0016\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.0015 - val_loss: 0.4789 - val_acc: 0.0013\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.0013 - val_loss: 0.4789 - val_acc: 0.0015\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 0.0016 - val_loss: 0.4789 - val_acc: 0.0013\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 0.0018 - val_loss: 0.4791 - val_acc: 0.0020\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4810 - acc: 0.0016 - val_loss: 0.4794 - val_acc: 0.0026\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4808 - acc: 0.0017 - val_loss: 0.4791 - val_acc: 0.0021\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.0016 - val_loss: 0.4789 - val_acc: 0.0016\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.0017 - val_loss: 0.4789 - val_acc: 0.0014\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.0017 - val_loss: 0.4789 - val_acc: 0.0018\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.0017 - val_loss: 0.4789 - val_acc: 0.0018\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.0017 - val_loss: 0.4789 - val_acc: 0.0017\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.0016 - val_loss: 0.4791 - val_acc: 0.0021\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4807 - acc: 0.0019 - val_loss: 0.4789 - val_acc: 0.0019\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.0017 - val_loss: 0.4789 - val_acc: 0.0018\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.0017 - val_loss: 0.4789 - val_acc: 0.0019\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.0017 - val_loss: 0.4790 - val_acc: 0.0021\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.0018 - val_loss: 0.4789 - val_acc: 0.0017\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4806 - acc: 0.0017 - val_loss: 0.4789 - val_acc: 0.0019\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.6736 - acc: 0.2519 - val_loss: 1.1532 - val_acc: 0.0889\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2205 - acc: 0.0775 - val_loss: 1.2751 - val_acc: 0.0705\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2275 - acc: 0.0719 - val_loss: 1.1661 - val_acc: 0.0735\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1128 - acc: 0.0784 - val_loss: 1.0723 - val_acc: 0.0829\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0461 - acc: 0.0856 - val_loss: 1.0233 - val_acc: 0.0861\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9956 - acc: 0.0817 - val_loss: 0.9567 - val_acc: 0.0726\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8958 - acc: 0.0631 - val_loss: 0.8031 - val_acc: 0.0460\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7213 - acc: 0.0289 - val_loss: 0.6402 - val_acc: 0.0072\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5900 - acc: 0.0020 - val_loss: 0.5387 - val_acc: 1.5000e-05\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5118 - acc: 5.0000e-06 - val_loss: 0.4830 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4703 - acc: 2.4500e-04 - val_loss: 0.4559 - val_acc: 0.0015\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4535 - acc: 0.0025 - val_loss: 0.4473 - val_acc: 0.0046\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0070 - val_loss: 0.4460 - val_acc: 0.0114\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4496 - acc: 0.0100 - val_loss: 0.4460 - val_acc: 0.0098\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4495 - acc: 0.0100 - val_loss: 0.4457 - val_acc: 0.0116\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4492 - acc: 0.0082 - val_loss: 0.4455 - val_acc: 0.0083\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4489 - acc: 0.0080 - val_loss: 0.4454 - val_acc: 0.0083\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4487 - acc: 0.0062 - val_loss: 0.4453 - val_acc: 0.0068\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4486 - acc: 0.0062 - val_loss: 0.4452 - val_acc: 0.0066\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4484 - acc: 0.0055 - val_loss: 0.4450 - val_acc: 0.0059\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4483 - acc: 0.0055 - val_loss: 0.4449 - val_acc: 0.0062\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4482 - acc: 0.0052 - val_loss: 0.4448 - val_acc: 0.0058\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4480 - acc: 0.0049 - val_loss: 0.4446 - val_acc: 0.0055\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4479 - acc: 0.0046 - val_loss: 0.4446 - val_acc: 0.0044\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4478 - acc: 0.0040 - val_loss: 0.4444 - val_acc: 0.0046\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4477 - acc: 0.0037 - val_loss: 0.4443 - val_acc: 0.0039\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4476 - acc: 0.0037 - val_loss: 0.4443 - val_acc: 0.0037\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4475 - acc: 0.0031 - val_loss: 0.4442 - val_acc: 0.0041\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4474 - acc: 0.0031 - val_loss: 0.4441 - val_acc: 0.0031\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4473 - acc: 0.0027 - val_loss: 0.4440 - val_acc: 0.0035\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4473 - acc: 0.0028 - val_loss: 0.4440 - val_acc: 0.0022\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4472 - acc: 0.0023 - val_loss: 0.4438 - val_acc: 0.0027\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4472 - acc: 0.0017 - val_loss: 0.4438 - val_acc: 0.0031\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4471 - acc: 0.0022 - val_loss: 0.4438 - val_acc: 0.0017\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4470 - acc: 0.0018 - val_loss: 0.4437 - val_acc: 0.0021\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4470 - acc: 0.0014 - val_loss: 0.4437 - val_acc: 0.0018\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4469 - acc: 0.0014 - val_loss: 0.4437 - val_acc: 0.0012\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4469 - acc: 0.0011 - val_loss: 0.4436 - val_acc: 0.0016\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4469 - acc: 0.0011 - val_loss: 0.4436 - val_acc: 0.0011\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4468 - acc: 9.8500e-04 - val_loss: 0.4436 - val_acc: 9.7000e-04\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4468 - acc: 8.9500e-04 - val_loss: 0.4436 - val_acc: 0.0014\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4468 - acc: 7.4500e-04 - val_loss: 0.4435 - val_acc: 6.4000e-04\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4468 - acc: 7.5000e-04 - val_loss: 0.4435 - val_acc: 8.6000e-04\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4468 - acc: 5.3500e-04 - val_loss: 0.4435 - val_acc: 6.0000e-04\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4468 - acc: 8.0000e-04 - val_loss: 0.4436 - val_acc: 2.5000e-04\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4468 - acc: 4.1000e-04 - val_loss: 0.4435 - val_acc: 8.3500e-04\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4467 - acc: 4.2000e-04 - val_loss: 0.4435 - val_acc: 4.1500e-04\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4467 - acc: 3.5000e-04 - val_loss: 0.4435 - val_acc: 6.7500e-04\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4468 - acc: 4.8500e-04 - val_loss: 0.4435 - val_acc: 2.3500e-04\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4467 - acc: 4.1500e-04 - val_loss: 0.4435 - val_acc: 3.5500e-04\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.5736 - acc: 0.2186 - val_loss: 1.2551 - val_acc: 0.0799\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3217 - acc: 0.0731 - val_loss: 1.2751 - val_acc: 0.0730\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1725 - acc: 0.0768 - val_loss: 1.0743 - val_acc: 0.0854\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0438 - acc: 0.0909 - val_loss: 1.0039 - val_acc: 0.0943\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9524 - acc: 0.0823 - val_loss: 0.8775 - val_acc: 0.0642\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8185 - acc: 0.0466 - val_loss: 0.7483 - val_acc: 0.0298\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6799 - acc: 0.0170 - val_loss: 0.6019 - val_acc: 0.0043\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5597 - acc: 8.6000e-04 - val_loss: 0.5145 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4888 - acc: 1.0000e-05 - val_loss: 0.4691 - val_acc: 2.0500e-04\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4569 - acc: 0.0035 - val_loss: 0.4528 - val_acc: 0.0117\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4483 - acc: 0.0128 - val_loss: 0.4513 - val_acc: 0.0128\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4477 - acc: 0.0147 - val_loss: 0.4516 - val_acc: 0.0173\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4476 - acc: 0.0162 - val_loss: 0.4512 - val_acc: 0.0154\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4471 - acc: 0.0140 - val_loss: 0.4506 - val_acc: 0.0135\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4469 - acc: 0.0107 - val_loss: 0.4502 - val_acc: 0.0103\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4466 - acc: 0.0120 - val_loss: 0.4500 - val_acc: 0.0107\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4463 - acc: 0.0098 - val_loss: 0.4498 - val_acc: 0.0102\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4461 - acc: 0.0102 - val_loss: 0.4497 - val_acc: 0.0113\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4459 - acc: 0.0104 - val_loss: 0.4495 - val_acc: 0.0097\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4457 - acc: 0.0100 - val_loss: 0.4493 - val_acc: 0.0097\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4455 - acc: 0.0089 - val_loss: 0.4492 - val_acc: 0.0096\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4453 - acc: 0.0091 - val_loss: 0.4490 - val_acc: 0.0101\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4452 - acc: 0.0088 - val_loss: 0.4489 - val_acc: 0.0082\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4450 - acc: 0.0080 - val_loss: 0.4488 - val_acc: 0.0093\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4448 - acc: 0.0080 - val_loss: 0.4486 - val_acc: 0.0073\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4447 - acc: 0.0070 - val_loss: 0.4485 - val_acc: 0.0079\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4446 - acc: 0.0073 - val_loss: 0.4484 - val_acc: 0.0060\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4444 - acc: 0.0064 - val_loss: 0.4483 - val_acc: 0.0070\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4443 - acc: 0.0058 - val_loss: 0.4482 - val_acc: 0.0061\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4442 - acc: 0.0060 - val_loss: 0.4481 - val_acc: 0.0053\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4441 - acc: 0.0052 - val_loss: 0.4480 - val_acc: 0.0050\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4440 - acc: 0.0042 - val_loss: 0.4479 - val_acc: 0.0060\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4439 - acc: 0.0052 - val_loss: 0.4479 - val_acc: 0.0036\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4438 - acc: 0.0039 - val_loss: 0.4478 - val_acc: 0.0042\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4437 - acc: 0.0037 - val_loss: 0.4477 - val_acc: 0.0032\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4436 - acc: 0.0032 - val_loss: 0.4477 - val_acc: 0.0040\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4435 - acc: 0.0032 - val_loss: 0.4476 - val_acc: 0.0030\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4435 - acc: 0.0026 - val_loss: 0.4476 - val_acc: 0.0030\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4434 - acc: 0.0026 - val_loss: 0.4475 - val_acc: 0.0026\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4434 - acc: 0.0021 - val_loss: 0.4475 - val_acc: 0.0025\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4434 - acc: 0.0022 - val_loss: 0.4476 - val_acc: 0.0014\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4433 - acc: 0.0021 - val_loss: 0.4474 - val_acc: 0.0020\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4433 - acc: 0.0014 - val_loss: 0.4474 - val_acc: 0.0017\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4432 - acc: 0.0017 - val_loss: 0.4474 - val_acc: 0.0012\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4432 - acc: 0.0012 - val_loss: 0.4474 - val_acc: 0.0013\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4432 - acc: 0.0013 - val_loss: 0.4474 - val_acc: 0.0012\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4432 - acc: 8.7500e-04 - val_loss: 0.4474 - val_acc: 0.0015\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4432 - acc: 0.0011 - val_loss: 0.4475 - val_acc: 5.1500e-04\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4432 - acc: 9.9000e-04 - val_loss: 0.4474 - val_acc: 9.0000e-04\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4432 - acc: 5.5000e-04 - val_loss: 0.4474 - val_acc: 0.0012\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.8698 - acc: 0.2752 - val_loss: 1.1431 - val_acc: 0.1104\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1775 - acc: 0.0934 - val_loss: 1.2185 - val_acc: 0.0837\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2299 - acc: 0.0813 - val_loss: 1.2161 - val_acc: 0.0811\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1956 - acc: 0.0822 - val_loss: 1.1603 - val_acc: 0.0851\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1436 - acc: 0.0876 - val_loss: 1.1177 - val_acc: 0.0915\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1125 - acc: 0.0939 - val_loss: 1.0999 - val_acc: 0.0984\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0966 - acc: 0.0986 - val_loss: 1.0894 - val_acc: 0.1012\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0877 - acc: 0.0997 - val_loss: 1.0800 - val_acc: 0.1003\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0768 - acc: 0.0977 - val_loss: 1.0686 - val_acc: 0.0968\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0654 - acc: 0.0938 - val_loss: 1.0592 - val_acc: 0.0922\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0539 - acc: 0.0901 - val_loss: 1.0456 - val_acc: 0.0891\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0376 - acc: 0.0873 - val_loss: 1.0277 - val_acc: 0.0860\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0208 - acc: 0.0841 - val_loss: 1.0061 - val_acc: 0.0822\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9978 - acc: 0.0799 - val_loss: 0.9778 - val_acc: 0.0780\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9667 - acc: 0.0744 - val_loss: 0.9396 - val_acc: 0.0710\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9147 - acc: 0.0671 - val_loss: 0.8743 - val_acc: 0.0611\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8387 - acc: 0.0530 - val_loss: 0.7926 - val_acc: 0.0430\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7509 - acc: 0.0331 - val_loss: 0.6917 - val_acc: 0.0214\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6444 - acc: 0.0111 - val_loss: 0.5931 - val_acc: 0.0025\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5604 - acc: 0.0010 - val_loss: 0.5262 - val_acc: 3.0000e-05\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5034 - acc: 5.0000e-06 - val_loss: 0.4819 - val_acc: 2.5000e-05\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4688 - acc: 4.3000e-04 - val_loss: 0.4593 - val_acc: 0.0013\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4530 - acc: 0.0025 - val_loss: 0.4511 - val_acc: 0.0053\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4480 - acc: 0.0078 - val_loss: 0.4496 - val_acc: 0.0098\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4473 - acc: 0.0106 - val_loss: 0.4496 - val_acc: 0.0108\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4473 - acc: 0.0108 - val_loss: 0.4496 - val_acc: 0.0114\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4472 - acc: 0.0110 - val_loss: 0.4494 - val_acc: 0.0100\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4471 - acc: 0.0102 - val_loss: 0.4493 - val_acc: 0.0101\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4470 - acc: 0.0094 - val_loss: 0.4491 - val_acc: 0.0090\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4469 - acc: 0.0091 - val_loss: 0.4490 - val_acc: 0.0091\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4468 - acc: 0.0086 - val_loss: 0.4490 - val_acc: 0.0084\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4467 - acc: 0.0082 - val_loss: 0.4489 - val_acc: 0.0075\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4466 - acc: 0.0081 - val_loss: 0.4488 - val_acc: 0.0082\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4465 - acc: 0.0084 - val_loss: 0.4487 - val_acc: 0.0072\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4465 - acc: 0.0071 - val_loss: 0.4487 - val_acc: 0.0084\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4464 - acc: 0.0078 - val_loss: 0.4486 - val_acc: 0.0072\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4463 - acc: 0.0074 - val_loss: 0.4485 - val_acc: 0.0064\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4462 - acc: 0.0064 - val_loss: 0.4485 - val_acc: 0.0078\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4462 - acc: 0.0072 - val_loss: 0.4484 - val_acc: 0.0056\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4461 - acc: 0.0061 - val_loss: 0.4483 - val_acc: 0.0067\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4460 - acc: 0.0061 - val_loss: 0.4483 - val_acc: 0.0063\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4460 - acc: 0.0064 - val_loss: 0.4482 - val_acc: 0.0054\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4459 - acc: 0.0054 - val_loss: 0.4481 - val_acc: 0.0061\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4459 - acc: 0.0058 - val_loss: 0.4481 - val_acc: 0.0045\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4458 - acc: 0.0054 - val_loss: 0.4480 - val_acc: 0.0051\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4458 - acc: 0.0049 - val_loss: 0.4480 - val_acc: 0.0047\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4457 - acc: 0.0051 - val_loss: 0.4479 - val_acc: 0.0044\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4457 - acc: 0.0046 - val_loss: 0.4479 - val_acc: 0.0046\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4456 - acc: 0.0045 - val_loss: 0.4479 - val_acc: 0.0038\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4456 - acc: 0.0044 - val_loss: 0.4478 - val_acc: 0.0039\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.3707 - acc: 0.3824 - val_loss: 1.2885 - val_acc: 0.3235\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1095 - acc: 0.3836 - val_loss: 0.9836 - val_acc: 0.4284\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8791 - acc: 0.4327 - val_loss: 0.7178 - val_acc: 0.4636\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6160 - acc: 0.4853 - val_loss: 0.5247 - val_acc: 0.5014\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4868 - acc: 0.5002 - val_loss: 0.4542 - val_acc: 0.5107\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4536 - acc: 0.5048 - val_loss: 0.4497 - val_acc: 0.4931\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4570 - acc: 0.4804 - val_loss: 0.4513 - val_acc: 0.4826\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4544 - acc: 0.4975 - val_loss: 0.4479 - val_acc: 0.5118\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4520 - acc: 0.5053 - val_loss: 0.4482 - val_acc: 0.5139\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4514 - acc: 0.5073 - val_loss: 0.4472 - val_acc: 0.5069\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4508 - acc: 0.5069 - val_loss: 0.4467 - val_acc: 0.5078\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4506 - acc: 0.5056 - val_loss: 0.4466 - val_acc: 0.5097\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4503 - acc: 0.5049 - val_loss: 0.4464 - val_acc: 0.5084\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4501 - acc: 0.5042 - val_loss: 0.4463 - val_acc: 0.5077\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4500 - acc: 0.5032 - val_loss: 0.4462 - val_acc: 0.5068\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4499 - acc: 0.5028 - val_loss: 0.4461 - val_acc: 0.5039\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4498 - acc: 0.5018 - val_loss: 0.4459 - val_acc: 0.5031\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4496 - acc: 0.4996 - val_loss: 0.4459 - val_acc: 0.5034\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4494 - acc: 0.4980 - val_loss: 0.4456 - val_acc: 0.5010\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4493 - acc: 0.4973 - val_loss: 0.4456 - val_acc: 0.5006\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4492 - acc: 0.4960 - val_loss: 0.4457 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4492 - acc: 0.4945 - val_loss: 0.4454 - val_acc: 0.4966\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4490 - acc: 0.4930 - val_loss: 0.4453 - val_acc: 0.4960\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4490 - acc: 0.4924 - val_loss: 0.4452 - val_acc: 0.4946\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4489 - acc: 0.4906 - val_loss: 0.4452 - val_acc: 0.4932\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4488 - acc: 0.4892 - val_loss: 0.4451 - val_acc: 0.4919\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4487 - acc: 0.4880 - val_loss: 0.4451 - val_acc: 0.4913\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4486 - acc: 0.4874 - val_loss: 0.4451 - val_acc: 0.4907\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4486 - acc: 0.4855 - val_loss: 0.4452 - val_acc: 0.4893\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4486 - acc: 0.4844 - val_loss: 0.4452 - val_acc: 0.4887\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4486 - acc: 0.4835 - val_loss: 0.4450 - val_acc: 0.4867\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4485 - acc: 0.4823 - val_loss: 0.4452 - val_acc: 0.4868\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4484 - acc: 0.4822 - val_loss: 0.4450 - val_acc: 0.4858\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4484 - acc: 0.4812 - val_loss: 0.4449 - val_acc: 0.4836\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4484 - acc: 0.4802 - val_loss: 0.4449 - val_acc: 0.4835\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4483 - acc: 0.4787 - val_loss: 0.4453 - val_acc: 0.4826\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4484 - acc: 0.4776 - val_loss: 0.4450 - val_acc: 0.4820\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4483 - acc: 0.4778 - val_loss: 0.4448 - val_acc: 0.4811\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4483 - acc: 0.4772 - val_loss: 0.4448 - val_acc: 0.4799\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4483 - acc: 0.4770 - val_loss: 0.4449 - val_acc: 0.4800\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4482 - acc: 0.4752 - val_loss: 0.4450 - val_acc: 0.4783\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4482 - acc: 0.4749 - val_loss: 0.4448 - val_acc: 0.4784\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4482 - acc: 0.4759 - val_loss: 0.4448 - val_acc: 0.4777\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4482 - acc: 0.4736 - val_loss: 0.4448 - val_acc: 0.4759\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4482 - acc: 0.4740 - val_loss: 0.4448 - val_acc: 0.4778\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4482 - acc: 0.4747 - val_loss: 0.4448 - val_acc: 0.4766\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4482 - acc: 0.4733 - val_loss: 0.4448 - val_acc: 0.4754\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4482 - acc: 0.4723 - val_loss: 0.4448 - val_acc: 0.4743\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4483 - acc: 0.4732 - val_loss: 0.4448 - val_acc: 0.4759\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4481 - acc: 0.4734 - val_loss: 0.4448 - val_acc: 0.4760\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 1s 3us/step - loss: 1.5406 - acc: 0.4101 - val_loss: 1.2922 - val_acc: 0.3302\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3094 - acc: 0.3214 - val_loss: 1.2030 - val_acc: 0.3519\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1110 - acc: 0.3932 - val_loss: 1.0422 - val_acc: 0.4256\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0131 - acc: 0.4257 - val_loss: 0.9573 - val_acc: 0.4307\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8853 - acc: 0.4383 - val_loss: 0.7911 - val_acc: 0.4525\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7165 - acc: 0.4662 - val_loss: 0.6274 - val_acc: 0.4850\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5773 - acc: 0.4948 - val_loss: 0.5250 - val_acc: 0.5001\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4964 - acc: 0.4999 - val_loss: 0.4692 - val_acc: 0.5001\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4577 - acc: 0.5009 - val_loss: 0.4497 - val_acc: 0.5045\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4475 - acc: 0.5043 - val_loss: 0.4482 - val_acc: 0.4999\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4476 - acc: 0.4929 - val_loss: 0.4489 - val_acc: 0.4894\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4476 - acc: 0.4904 - val_loss: 0.4483 - val_acc: 0.4958\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4470 - acc: 0.4985 - val_loss: 0.4478 - val_acc: 0.5014\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4468 - acc: 0.5019 - val_loss: 0.4477 - val_acc: 0.5039\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4467 - acc: 0.5028 - val_loss: 0.4476 - val_acc: 0.5025\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4467 - acc: 0.5018 - val_loss: 0.4476 - val_acc: 0.5020\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4466 - acc: 0.5004 - val_loss: 0.4475 - val_acc: 0.5005\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4465 - acc: 0.4996 - val_loss: 0.4474 - val_acc: 0.4990\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4465 - acc: 0.4977 - val_loss: 0.4474 - val_acc: 0.4987\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4464 - acc: 0.4974 - val_loss: 0.4473 - val_acc: 0.4976\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4464 - acc: 0.4967 - val_loss: 0.4473 - val_acc: 0.4970\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4463 - acc: 0.4960 - val_loss: 0.4473 - val_acc: 0.4965\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4463 - acc: 0.4949 - val_loss: 0.4472 - val_acc: 0.4957\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4462 - acc: 0.4944 - val_loss: 0.4472 - val_acc: 0.4950\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4462 - acc: 0.4939 - val_loss: 0.4471 - val_acc: 0.4940\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4461 - acc: 0.4925 - val_loss: 0.4471 - val_acc: 0.4930\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4461 - acc: 0.4912 - val_loss: 0.4471 - val_acc: 0.4923\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4461 - acc: 0.4909 - val_loss: 0.4471 - val_acc: 0.4912\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4460 - acc: 0.4901 - val_loss: 0.4470 - val_acc: 0.4908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4460 - acc: 0.4892 - val_loss: 0.4470 - val_acc: 0.4898\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4460 - acc: 0.4889 - val_loss: 0.4470 - val_acc: 0.4893\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4461 - acc: 0.4885 - val_loss: 0.4471 - val_acc: 0.4894\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4459 - acc: 0.4867 - val_loss: 0.4469 - val_acc: 0.4867\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4459 - acc: 0.4859 - val_loss: 0.4469 - val_acc: 0.4871\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4458 - acc: 0.4856 - val_loss: 0.4469 - val_acc: 0.4861\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4458 - acc: 0.4851 - val_loss: 0.4468 - val_acc: 0.4858\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4459 - acc: 0.4853 - val_loss: 0.4469 - val_acc: 0.4860\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4458 - acc: 0.4844 - val_loss: 0.4468 - val_acc: 0.4847\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4458 - acc: 0.4832 - val_loss: 0.4468 - val_acc: 0.4840\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4458 - acc: 0.4826 - val_loss: 0.4469 - val_acc: 0.4827\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4458 - acc: 0.4823 - val_loss: 0.4469 - val_acc: 0.4838\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4458 - acc: 0.4823 - val_loss: 0.4469 - val_acc: 0.4835\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4458 - acc: 0.4822 - val_loss: 0.4468 - val_acc: 0.4819\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4457 - acc: 0.4811 - val_loss: 0.4468 - val_acc: 0.4810\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4457 - acc: 0.4797 - val_loss: 0.4468 - val_acc: 0.4808\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4457 - acc: 0.4800 - val_loss: 0.4468 - val_acc: 0.4812\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4457 - acc: 0.4802 - val_loss: 0.4468 - val_acc: 0.4799\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4457 - acc: 0.4797 - val_loss: 0.4467 - val_acc: 0.4799\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4457 - acc: 0.4786 - val_loss: 0.4468 - val_acc: 0.4799\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4457 - acc: 0.4788 - val_loss: 0.4467 - val_acc: 0.4795\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.4749 - acc: 0.4154 - val_loss: 1.2532 - val_acc: 0.3308\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2371 - acc: 0.3327 - val_loss: 1.1092 - val_acc: 0.3828\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0411 - acc: 0.4164 - val_loss: 1.0053 - val_acc: 0.4290\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9542 - acc: 0.4327 - val_loss: 0.8652 - val_acc: 0.4450\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7939 - acc: 0.4567 - val_loss: 0.7150 - val_acc: 0.4720\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6282 - acc: 0.4837 - val_loss: 0.5477 - val_acc: 0.4990\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5081 - acc: 0.4988 - val_loss: 0.4682 - val_acc: 0.5014\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4590 - acc: 0.5014 - val_loss: 0.4488 - val_acc: 0.5116\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4521 - acc: 0.5139 - val_loss: 0.4500 - val_acc: 0.5125\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4531 - acc: 0.5121 - val_loss: 0.4495 - val_acc: 0.5170\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4514 - acc: 0.5111 - val_loss: 0.4479 - val_acc: 0.5103\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4505 - acc: 0.5085 - val_loss: 0.4478 - val_acc: 0.5102\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4504 - acc: 0.5070 - val_loss: 0.4477 - val_acc: 0.5082\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4503 - acc: 0.5068 - val_loss: 0.4475 - val_acc: 0.5087\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4501 - acc: 0.5069 - val_loss: 0.4473 - val_acc: 0.5089\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4500 - acc: 0.5068 - val_loss: 0.4473 - val_acc: 0.5096\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4499 - acc: 0.5066 - val_loss: 0.4471 - val_acc: 0.5088\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4498 - acc: 0.5066 - val_loss: 0.4470 - val_acc: 0.5078\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.5057 - val_loss: 0.4470 - val_acc: 0.5082\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4496 - acc: 0.5057 - val_loss: 0.4469 - val_acc: 0.5076\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4495 - acc: 0.5056 - val_loss: 0.4468 - val_acc: 0.5075\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4494 - acc: 0.5056 - val_loss: 0.4467 - val_acc: 0.5071\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4494 - acc: 0.5042 - val_loss: 0.4468 - val_acc: 0.5073\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4494 - acc: 0.5041 - val_loss: 0.4466 - val_acc: 0.5050\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4492 - acc: 0.5030 - val_loss: 0.4465 - val_acc: 0.5043\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4492 - acc: 0.5017 - val_loss: 0.4466 - val_acc: 0.5036\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4491 - acc: 0.5005 - val_loss: 0.4465 - val_acc: 0.5014\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4492 - acc: 0.4994 - val_loss: 0.4465 - val_acc: 0.5003\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4491 - acc: 0.4985 - val_loss: 0.4468 - val_acc: 0.5011\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4492 - acc: 0.4975 - val_loss: 0.4464 - val_acc: 0.4984\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4490 - acc: 0.4954 - val_loss: 0.4463 - val_acc: 0.4962\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4490 - acc: 0.4947 - val_loss: 0.4463 - val_acc: 0.4967\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4490 - acc: 0.4942 - val_loss: 0.4463 - val_acc: 0.4957\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4490 - acc: 0.4933 - val_loss: 0.4463 - val_acc: 0.4944\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4489 - acc: 0.4924 - val_loss: 0.4463 - val_acc: 0.4940\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4489 - acc: 0.4916 - val_loss: 0.4463 - val_acc: 0.4928\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4489 - acc: 0.4901 - val_loss: 0.4463 - val_acc: 0.4918\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4489 - acc: 0.4900 - val_loss: 0.4464 - val_acc: 0.4930\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4490 - acc: 0.4912 - val_loss: 0.4464 - val_acc: 0.4918\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4490 - acc: 0.4895 - val_loss: 0.4462 - val_acc: 0.4900\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4489 - acc: 0.4881 - val_loss: 0.4464 - val_acc: 0.4906\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4489 - acc: 0.4873 - val_loss: 0.4464 - val_acc: 0.4903\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4490 - acc: 0.4879 - val_loss: 0.4463 - val_acc: 0.4902\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4489 - acc: 0.4884 - val_loss: 0.4462 - val_acc: 0.4900\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4489 - acc: 0.4876 - val_loss: 0.4462 - val_acc: 0.4886\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4488 - acc: 0.4862 - val_loss: 0.4464 - val_acc: 0.4869\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4490 - acc: 0.4861 - val_loss: 0.4462 - val_acc: 0.4883\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4489 - acc: 0.4866 - val_loss: 0.4462 - val_acc: 0.4886\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4489 - acc: 0.4861 - val_loss: 0.4463 - val_acc: 0.4882\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4489 - acc: 0.4858 - val_loss: 0.4462 - val_acc: 0.4876\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.4678 - acc: 0.4174 - val_loss: 1.2477 - val_acc: 0.3385\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2357 - acc: 0.3364 - val_loss: 1.1208 - val_acc: 0.3799\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0484 - acc: 0.4152 - val_loss: 1.0044 - val_acc: 0.4316\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9478 - acc: 0.4354 - val_loss: 0.8679 - val_acc: 0.4453\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7710 - acc: 0.4604 - val_loss: 0.6477 - val_acc: 0.4802\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5734 - acc: 0.4932 - val_loss: 0.5042 - val_acc: 0.5005\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4772 - acc: 0.5004 - val_loss: 0.4557 - val_acc: 0.5027\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4533 - acc: 0.5100 - val_loss: 0.4509 - val_acc: 0.5171\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4543 - acc: 0.5132 - val_loss: 0.4514 - val_acc: 0.5144\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4533 - acc: 0.5148 - val_loss: 0.4498 - val_acc: 0.5115\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4519 - acc: 0.5105 - val_loss: 0.4493 - val_acc: 0.5106\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4516 - acc: 0.5091 - val_loss: 0.4494 - val_acc: 0.5086\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4515 - acc: 0.5085 - val_loss: 0.4492 - val_acc: 0.5094\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4514 - acc: 0.5087 - val_loss: 0.4490 - val_acc: 0.5094\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4513 - acc: 0.5093 - val_loss: 0.4489 - val_acc: 0.5094\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4512 - acc: 0.5090 - val_loss: 0.4488 - val_acc: 0.5095\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4511 - acc: 0.5086 - val_loss: 0.4488 - val_acc: 0.5091\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4510 - acc: 0.5088 - val_loss: 0.4487 - val_acc: 0.5085\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4509 - acc: 0.5081 - val_loss: 0.4486 - val_acc: 0.5093\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4508 - acc: 0.5083 - val_loss: 0.4485 - val_acc: 0.5085\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4508 - acc: 0.5083 - val_loss: 0.4485 - val_acc: 0.5081\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4507 - acc: 0.5077 - val_loss: 0.4484 - val_acc: 0.5091\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4507 - acc: 0.5077 - val_loss: 0.4484 - val_acc: 0.5075\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4506 - acc: 0.5082 - val_loss: 0.4483 - val_acc: 0.5072\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4506 - acc: 0.5071 - val_loss: 0.4483 - val_acc: 0.5093\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4506 - acc: 0.5074 - val_loss: 0.4482 - val_acc: 0.5071\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4504 - acc: 0.5075 - val_loss: 0.4481 - val_acc: 0.5074\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4504 - acc: 0.5067 - val_loss: 0.4481 - val_acc: 0.5083\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4504 - acc: 0.5070 - val_loss: 0.4481 - val_acc: 0.5062\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4503 - acc: 0.5066 - val_loss: 0.4480 - val_acc: 0.5069\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4503 - acc: 0.5061 - val_loss: 0.4479 - val_acc: 0.5064\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4503 - acc: 0.5055 - val_loss: 0.4479 - val_acc: 0.5052\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4502 - acc: 0.5051 - val_loss: 0.4479 - val_acc: 0.5052\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4502 - acc: 0.5045 - val_loss: 0.4478 - val_acc: 0.5050\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4502 - acc: 0.5043 - val_loss: 0.4479 - val_acc: 0.5039\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4501 - acc: 0.5033 - val_loss: 0.4478 - val_acc: 0.5035\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4501 - acc: 0.5028 - val_loss: 0.4479 - val_acc: 0.5025\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4501 - acc: 0.5023 - val_loss: 0.4477 - val_acc: 0.5023\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4501 - acc: 0.5013 - val_loss: 0.4477 - val_acc: 0.5023\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4500 - acc: 0.5011 - val_loss: 0.4477 - val_acc: 0.5018\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4500 - acc: 0.5011 - val_loss: 0.4477 - val_acc: 0.5009\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4500 - acc: 0.5004 - val_loss: 0.4477 - val_acc: 0.5002\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4500 - acc: 0.4995 - val_loss: 0.4476 - val_acc: 0.5001\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4500 - acc: 0.4986 - val_loss: 0.4478 - val_acc: 0.5005\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4500 - acc: 0.4985 - val_loss: 0.4477 - val_acc: 0.4983\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4500 - acc: 0.4987 - val_loss: 0.4477 - val_acc: 0.4983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4500 - acc: 0.4975 - val_loss: 0.4476 - val_acc: 0.4985\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4500 - acc: 0.4971 - val_loss: 0.4479 - val_acc: 0.5000\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4500 - acc: 0.4975 - val_loss: 0.4476 - val_acc: 0.4976\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4499 - acc: 0.4966 - val_loss: 0.4476 - val_acc: 0.4964\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.4267 - acc: 0.1847 - val_loss: 1.3311 - val_acc: 0.0779\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1948 - acc: 0.0769 - val_loss: 1.0260 - val_acc: 0.0887\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9913 - acc: 0.0940 - val_loss: 0.9070 - val_acc: 0.0803\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7976 - acc: 0.0489 - val_loss: 0.6500 - val_acc: 0.0150\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5718 - acc: 0.0034 - val_loss: 0.4977 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4677 - acc: 0.0010 - val_loss: 0.4525 - val_acc: 0.0076\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4473 - acc: 0.0169 - val_loss: 0.4562 - val_acc: 0.0190\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4495 - acc: 0.0209 - val_loss: 0.4557 - val_acc: 0.0231\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4471 - acc: 0.0180 - val_loss: 0.4522 - val_acc: 0.0128\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4458 - acc: 0.0123 - val_loss: 0.4515 - val_acc: 0.0106\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4458 - acc: 0.0097 - val_loss: 0.4515 - val_acc: 0.0111\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4457 - acc: 0.0108 - val_loss: 0.4515 - val_acc: 0.0092\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4457 - acc: 0.0111 - val_loss: 0.4515 - val_acc: 0.0111\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4456 - acc: 0.0118 - val_loss: 0.4516 - val_acc: 0.0126\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4456 - acc: 0.0108 - val_loss: 0.4515 - val_acc: 0.0126\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4456 - acc: 0.0109 - val_loss: 0.4514 - val_acc: 0.0111\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4455 - acc: 0.0110 - val_loss: 0.4514 - val_acc: 0.0101\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4455 - acc: 0.0108 - val_loss: 0.4514 - val_acc: 0.0107\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4455 - acc: 0.0101 - val_loss: 0.4514 - val_acc: 0.0108\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4454 - acc: 0.0109 - val_loss: 0.4514 - val_acc: 0.0087\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4454 - acc: 0.0100 - val_loss: 0.4513 - val_acc: 0.0109\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4454 - acc: 0.0098 - val_loss: 0.4514 - val_acc: 0.0115\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4454 - acc: 0.0101 - val_loss: 0.4513 - val_acc: 0.0089\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4454 - acc: 0.0097 - val_loss: 0.4513 - val_acc: 0.0090\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4454 - acc: 0.0093 - val_loss: 0.4513 - val_acc: 0.0104\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4454 - acc: 0.0096 - val_loss: 0.4513 - val_acc: 0.0083\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4455 - acc: 0.0095 - val_loss: 0.4513 - val_acc: 0.0073\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4453 - acc: 0.0097 - val_loss: 0.4512 - val_acc: 0.0090\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4454 - acc: 0.0092 - val_loss: 0.4513 - val_acc: 0.0080\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4453 - acc: 0.0087 - val_loss: 0.4512 - val_acc: 0.0084\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4453 - acc: 0.0091 - val_loss: 0.4514 - val_acc: 0.0065\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4453 - acc: 0.0089 - val_loss: 0.4513 - val_acc: 0.0080\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4453 - acc: 0.0088 - val_loss: 0.4512 - val_acc: 0.0078\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4453 - acc: 0.0084 - val_loss: 0.4512 - val_acc: 0.0095\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4453 - acc: 0.0082 - val_loss: 0.4512 - val_acc: 0.0092\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4453 - acc: 0.0088 - val_loss: 0.4512 - val_acc: 0.0081\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4452 - acc: 0.0081 - val_loss: 0.4512 - val_acc: 0.0086\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4453 - acc: 0.0088 - val_loss: 0.4513 - val_acc: 0.0071\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4453 - acc: 0.0081 - val_loss: 0.4512 - val_acc: 0.0067\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4452 - acc: 0.0079 - val_loss: 0.4513 - val_acc: 0.0094\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4453 - acc: 0.0080 - val_loss: 0.4513 - val_acc: 0.0097\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4453 - acc: 0.0075 - val_loss: 0.4514 - val_acc: 0.0105\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4454 - acc: 0.0081 - val_loss: 0.4512 - val_acc: 0.0082\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4453 - acc: 0.0081 - val_loss: 0.4512 - val_acc: 0.0079\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4453 - acc: 0.0085 - val_loss: 0.4512 - val_acc: 0.0074\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4452 - acc: 0.0074 - val_loss: 0.4512 - val_acc: 0.0064\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4452 - acc: 0.0074 - val_loss: 0.4513 - val_acc: 0.0092\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4453 - acc: 0.0077 - val_loss: 0.4516 - val_acc: 0.0118\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4454 - acc: 0.0079 - val_loss: 0.4512 - val_acc: 0.0060\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4453 - acc: 0.0074 - val_loss: 0.4515 - val_acc: 0.0052\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.4108 - acc: 0.3778 - val_loss: 1.3454 - val_acc: 0.3185\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1803 - acc: 0.3828 - val_loss: 1.0980 - val_acc: 0.4232\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0439 - acc: 0.4298 - val_loss: 0.9396 - val_acc: 0.4422\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8431 - acc: 0.4570 - val_loss: 0.7000 - val_acc: 0.4730\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6020 - acc: 0.4885 - val_loss: 0.5109 - val_acc: 0.5037\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4753 - acc: 0.5036 - val_loss: 0.4541 - val_acc: 0.5090\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4574 - acc: 0.5200 - val_loss: 0.4590 - val_acc: 0.5187\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4593 - acc: 0.5188 - val_loss: 0.4548 - val_acc: 0.5211\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4541 - acc: 0.5137 - val_loss: 0.4519 - val_acc: 0.5145\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4530 - acc: 0.5128 - val_loss: 0.4524 - val_acc: 0.5082\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4527 - acc: 0.5113 - val_loss: 0.4515 - val_acc: 0.5105\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4521 - acc: 0.5117 - val_loss: 0.4511 - val_acc: 0.5137\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4519 - acc: 0.5122 - val_loss: 0.4509 - val_acc: 0.5132\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4517 - acc: 0.5117 - val_loss: 0.4508 - val_acc: 0.5128\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4515 - acc: 0.5117 - val_loss: 0.4507 - val_acc: 0.5103\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4514 - acc: 0.5109 - val_loss: 0.4506 - val_acc: 0.5097\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4512 - acc: 0.5109 - val_loss: 0.4504 - val_acc: 0.5122\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4511 - acc: 0.5107 - val_loss: 0.4503 - val_acc: 0.5097\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4511 - acc: 0.5104 - val_loss: 0.4502 - val_acc: 0.5094\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4510 - acc: 0.5099 - val_loss: 0.4501 - val_acc: 0.5102\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4509 - acc: 0.5091 - val_loss: 0.4503 - val_acc: 0.5121\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4510 - acc: 0.5097 - val_loss: 0.4500 - val_acc: 0.5092\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4509 - acc: 0.5096 - val_loss: 0.4501 - val_acc: 0.5075\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4508 - acc: 0.5092 - val_loss: 0.4499 - val_acc: 0.5079\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4507 - acc: 0.5091 - val_loss: 0.4499 - val_acc: 0.5081\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4507 - acc: 0.5087 - val_loss: 0.4498 - val_acc: 0.5078\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4506 - acc: 0.5085 - val_loss: 0.4498 - val_acc: 0.5081\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4506 - acc: 0.5082 - val_loss: 0.4498 - val_acc: 0.5081\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4506 - acc: 0.5085 - val_loss: 0.4497 - val_acc: 0.5078\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4506 - acc: 0.5082 - val_loss: 0.4497 - val_acc: 0.5074\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4506 - acc: 0.5076 - val_loss: 0.4497 - val_acc: 0.5087\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4506 - acc: 0.5079 - val_loss: 0.4497 - val_acc: 0.5083\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4506 - acc: 0.5078 - val_loss: 0.4497 - val_acc: 0.5074\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4507 - acc: 0.5077 - val_loss: 0.4497 - val_acc: 0.5070\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4507 - acc: 0.5078 - val_loss: 0.4496 - val_acc: 0.5075\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4505 - acc: 0.5069 - val_loss: 0.4496 - val_acc: 0.5070\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4504 - acc: 0.5067 - val_loss: 0.4497 - val_acc: 0.5081\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4506 - acc: 0.5073 - val_loss: 0.4497 - val_acc: 0.5085\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4505 - acc: 0.5074 - val_loss: 0.4496 - val_acc: 0.5072\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4505 - acc: 0.5069 - val_loss: 0.4497 - val_acc: 0.5080\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4505 - acc: 0.5071 - val_loss: 0.4496 - val_acc: 0.5063\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4505 - acc: 0.5066 - val_loss: 0.4496 - val_acc: 0.5060\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4504 - acc: 0.5065 - val_loss: 0.4496 - val_acc: 0.5057\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4504 - acc: 0.5065 - val_loss: 0.4497 - val_acc: 0.5052\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4505 - acc: 0.5063 - val_loss: 0.4496 - val_acc: 0.5055\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4505 - acc: 0.5062 - val_loss: 0.4496 - val_acc: 0.5054\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4504 - acc: 0.5063 - val_loss: 0.4497 - val_acc: 0.5069\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4505 - acc: 0.5061 - val_loss: 0.4496 - val_acc: 0.5055\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4504 - acc: 0.5059 - val_loss: 0.4496 - val_acc: 0.5053\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4505 - acc: 0.5059 - val_loss: 0.4496 - val_acc: 0.5052\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.2854 - acc: 0.1595 - val_loss: 1.1773 - val_acc: 0.0801\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0247 - acc: 0.0887 - val_loss: 0.9154 - val_acc: 0.0953\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7624 - acc: 0.0499 - val_loss: 0.5924 - val_acc: 0.0108\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5186 - acc: 0.0058 - val_loss: 0.4640 - val_acc: 0.0233\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4565 - acc: 0.0204 - val_loss: 0.4582 - val_acc: 0.0207\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4594 - acc: 0.0324 - val_loss: 0.4579 - val_acc: 0.0273\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4570 - acc: 0.0153 - val_loss: 0.4547 - val_acc: 0.0343\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4537 - acc: 0.0187 - val_loss: 0.4531 - val_acc: 0.0077\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4519 - acc: 0.0143 - val_loss: 0.4520 - val_acc: 0.0097\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4508 - acc: 0.0131 - val_loss: 0.4511 - val_acc: 0.0180\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4504 - acc: 0.0148 - val_loss: 0.4510 - val_acc: 0.0160\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4504 - acc: 0.0160 - val_loss: 0.4514 - val_acc: 0.0117\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4502 - acc: 0.0152 - val_loss: 0.4510 - val_acc: 0.0134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4501 - acc: 0.0132 - val_loss: 0.4509 - val_acc: 0.0146\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4501 - acc: 0.0134 - val_loss: 0.4508 - val_acc: 0.0148\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4500 - acc: 0.0129 - val_loss: 0.4509 - val_acc: 0.0166\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4500 - acc: 0.0127 - val_loss: 0.4508 - val_acc: 0.0128\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4500 - acc: 0.0137 - val_loss: 0.4512 - val_acc: 0.0097\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4499 - acc: 0.0126 - val_loss: 0.4509 - val_acc: 0.0104\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4499 - acc: 0.0121 - val_loss: 0.4508 - val_acc: 0.0109\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4498 - acc: 0.0121 - val_loss: 0.4508 - val_acc: 0.0112\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4499 - acc: 0.0116 - val_loss: 0.4508 - val_acc: 0.0139\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0109 - val_loss: 0.4508 - val_acc: 0.0142\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4498 - acc: 0.0112 - val_loss: 0.4507 - val_acc: 0.0113\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4498 - acc: 0.0118 - val_loss: 0.4509 - val_acc: 0.0096\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0109 - val_loss: 0.4507 - val_acc: 0.0116\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0114 - val_loss: 0.4508 - val_acc: 0.0098\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0108 - val_loss: 0.4508 - val_acc: 0.0101\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0104 - val_loss: 0.4507 - val_acc: 0.0109\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0103 - val_loss: 0.4508 - val_acc: 0.0097\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0105 - val_loss: 0.4507 - val_acc: 0.0113\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0101 - val_loss: 0.4508 - val_acc: 0.0122\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0101 - val_loss: 0.4508 - val_acc: 0.0104\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4496 - acc: 0.0098 - val_loss: 0.4510 - val_acc: 0.0138\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4500 - acc: 0.0106 - val_loss: 0.4511 - val_acc: 0.0151\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0098 - val_loss: 0.4508 - val_acc: 0.0098\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0099 - val_loss: 0.4508 - val_acc: 0.0095\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0099 - val_loss: 0.4508 - val_acc: 0.0108\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0104 - val_loss: 0.4513 - val_acc: 0.0069\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4498 - acc: 0.0095 - val_loss: 0.4509 - val_acc: 0.0086\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4498 - acc: 0.0092 - val_loss: 0.4508 - val_acc: 0.0101\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0097 - val_loss: 0.4508 - val_acc: 0.0121\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4499 - acc: 0.0096 - val_loss: 0.4510 - val_acc: 0.0133\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4498 - acc: 0.0104 - val_loss: 0.4508 - val_acc: 0.0109\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0100 - val_loss: 0.4509 - val_acc: 0.0087\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0095 - val_loss: 0.4510 - val_acc: 0.0078\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0097 - val_loss: 0.4508 - val_acc: 0.0097\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0093 - val_loss: 0.4509 - val_acc: 0.0084\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4497 - acc: 0.0095 - val_loss: 0.4510 - val_acc: 0.0079\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4499 - acc: 0.0089 - val_loss: 0.4509 - val_acc: 0.0086\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 2.0118 - acc: 0.4018 - val_loss: 1.3828 - val_acc: 0.3309\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.4672 - acc: 0.3073 - val_loss: 1.4954 - val_acc: 0.2987\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.4211 - acc: 0.3168 - val_loss: 1.3491 - val_acc: 0.3396\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3308 - acc: 0.3522 - val_loss: 1.3365 - val_acc: 0.3591\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3331 - acc: 0.3617 - val_loss: 1.3299 - val_acc: 0.3597\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3122 - acc: 0.3580 - val_loss: 1.3048 - val_acc: 0.3524\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2948 - acc: 0.3531 - val_loss: 1.2918 - val_acc: 0.3536\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2781 - acc: 0.3572 - val_loss: 1.2717 - val_acc: 0.3589\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2548 - acc: 0.3617 - val_loss: 1.2508 - val_acc: 0.3637\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2325 - acc: 0.3654 - val_loss: 1.2218 - val_acc: 0.3647\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1994 - acc: 0.3685 - val_loss: 1.1888 - val_acc: 0.3709\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1622 - acc: 0.3750 - val_loss: 1.1395 - val_acc: 0.3782\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1037 - acc: 0.3837 - val_loss: 1.0747 - val_acc: 0.3863\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0373 - acc: 0.3901 - val_loss: 1.0085 - val_acc: 0.3913\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9715 - acc: 0.3948 - val_loss: 0.9378 - val_acc: 0.3975\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8933 - acc: 0.4020 - val_loss: 0.8550 - val_acc: 0.4056\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8117 - acc: 0.4109 - val_loss: 0.7718 - val_acc: 0.4183\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7309 - acc: 0.4292 - val_loss: 0.6954 - val_acc: 0.4416\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6758 - acc: 0.4454 - val_loss: 0.6534 - val_acc: 0.4559\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6469 - acc: 0.4593 - val_loss: 0.6399 - val_acc: 0.4559\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6319 - acc: 0.4711 - val_loss: 0.6199 - val_acc: 0.4734\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6219 - acc: 0.4663 - val_loss: 0.6082 - val_acc: 0.4795\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6166 - acc: 0.4891 - val_loss: 0.6420 - val_acc: 0.4625\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6219 - acc: 0.4775 - val_loss: 0.6004 - val_acc: 0.5027\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5995 - acc: 0.4794 - val_loss: 0.5935 - val_acc: 0.4770\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5922 - acc: 0.4788 - val_loss: 0.6035 - val_acc: 0.4664\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6044 - acc: 0.4858 - val_loss: 0.6355 - val_acc: 0.5258\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5990 - acc: 0.4942 - val_loss: 0.5903 - val_acc: 0.4728\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5787 - acc: 0.4880 - val_loss: 0.5710 - val_acc: 0.4910\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5831 - acc: 0.4730 - val_loss: 0.5695 - val_acc: 0.4884\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5729 - acc: 0.4895 - val_loss: 0.5653 - val_acc: 0.4788\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5737 - acc: 0.4937 - val_loss: 0.5858 - val_acc: 0.5153\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5659 - acc: 0.4921 - val_loss: 0.5563 - val_acc: 0.4854\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5588 - acc: 0.4844 - val_loss: 0.5534 - val_acc: 0.4830\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5552 - acc: 0.4928 - val_loss: 0.5466 - val_acc: 0.4918\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5498 - acc: 0.4822 - val_loss: 0.5423 - val_acc: 0.4859\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5454 - acc: 0.4897 - val_loss: 0.5381 - val_acc: 0.4880\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5420 - acc: 0.4860 - val_loss: 0.5369 - val_acc: 0.4936\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5381 - acc: 0.4822 - val_loss: 0.5420 - val_acc: 0.4701\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5452 - acc: 0.4967 - val_loss: 0.5237 - val_acc: 0.4945\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5332 - acc: 0.4790 - val_loss: 0.5246 - val_acc: 0.5063\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5246 - acc: 0.4963 - val_loss: 0.5142 - val_acc: 0.4864\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5151 - acc: 0.4963 - val_loss: 0.5048 - val_acc: 0.4989\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5071 - acc: 0.4927 - val_loss: 0.4999 - val_acc: 0.5071\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5037 - acc: 0.4977 - val_loss: 0.4968 - val_acc: 0.4888\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4997 - acc: 0.4974 - val_loss: 0.4948 - val_acc: 0.4884\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4999 - acc: 0.4917 - val_loss: 0.4932 - val_acc: 0.4992\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4973 - acc: 0.4905 - val_loss: 0.4898 - val_acc: 0.5041\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4928 - acc: 0.4920 - val_loss: 0.4857 - val_acc: 0.4984\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4879 - acc: 0.4960 - val_loss: 0.4806 - val_acc: 0.4935\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 1s 3us/step - loss: 1.6042 - acc: 0.4001 - val_loss: 1.3377 - val_acc: 0.3334\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3451 - acc: 0.3256 - val_loss: 1.2126 - val_acc: 0.3655\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1002 - acc: 0.3946 - val_loss: 1.0128 - val_acc: 0.4068\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9380 - acc: 0.4078 - val_loss: 0.8304 - val_acc: 0.4263\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7387 - acc: 0.4505 - val_loss: 0.6430 - val_acc: 0.4812\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5822 - acc: 0.4928 - val_loss: 0.5154 - val_acc: 0.5004\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4785 - acc: 0.5030 - val_loss: 0.4395 - val_acc: 0.5105\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4252 - acc: 0.5129 - val_loss: 0.4101 - val_acc: 0.5242\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4107 - acc: 0.5095 - val_loss: 0.4081 - val_acc: 0.4710\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4109 - acc: 0.4674 - val_loss: 0.4085 - val_acc: 0.4698\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4109 - acc: 0.4611 - val_loss: 0.4079 - val_acc: 0.4583\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4097 - acc: 0.4748 - val_loss: 0.4154 - val_acc: 0.5080\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4184 - acc: 0.4846 - val_loss: 0.4175 - val_acc: 0.4615\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4154 - acc: 0.4939 - val_loss: 0.4214 - val_acc: 0.5169\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4162 - acc: 0.4748 - val_loss: 0.4099 - val_acc: 0.4635\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4116 - acc: 0.4910 - val_loss: 0.4169 - val_acc: 0.5068\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4303 - acc: 0.4632 - val_loss: 0.4127 - val_acc: 0.4816\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4150 - acc: 0.5088 - val_loss: 0.4304 - val_acc: 0.5020\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4208 - acc: 0.5111 - val_loss: 0.4151 - val_acc: 0.5349\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4110 - acc: 0.5127 - val_loss: 0.4071 - val_acc: 0.4883\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4074 - acc: 0.4829 - val_loss: 0.4098 - val_acc: 0.4663\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4077 - acc: 0.4786 - val_loss: 0.4059 - val_acc: 0.4973\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4094 - acc: 0.4727 - val_loss: 0.4083 - val_acc: 0.4631\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4064 - acc: 0.4837 - val_loss: 0.4020 - val_acc: 0.4781\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4044 - acc: 0.4670 - val_loss: 0.4017 - val_acc: 0.4740\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4035 - acc: 0.4662 - val_loss: 0.4014 - val_acc: 0.4577\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4029 - acc: 0.4608 - val_loss: 0.4008 - val_acc: 0.4616\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4026 - acc: 0.4566 - val_loss: 0.4005 - val_acc: 0.4584\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4023 - acc: 0.4561 - val_loss: 0.4003 - val_acc: 0.4551\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4020 - acc: 0.4562 - val_loss: 0.4001 - val_acc: 0.4527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4018 - acc: 0.4535 - val_loss: 0.3998 - val_acc: 0.4553\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4015 - acc: 0.4518 - val_loss: 0.3996 - val_acc: 0.4544\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4013 - acc: 0.4519 - val_loss: 0.3995 - val_acc: 0.4466\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4010 - acc: 0.4495 - val_loss: 0.3992 - val_acc: 0.4502\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4007 - acc: 0.4469 - val_loss: 0.3990 - val_acc: 0.4492\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4005 - acc: 0.4466 - val_loss: 0.3988 - val_acc: 0.4506\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4002 - acc: 0.4458 - val_loss: 0.3986 - val_acc: 0.4436\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4000 - acc: 0.4455 - val_loss: 0.3984 - val_acc: 0.4439\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3999 - acc: 0.4421 - val_loss: 0.3982 - val_acc: 0.4434\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3996 - acc: 0.4400 - val_loss: 0.3981 - val_acc: 0.4434\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3994 - acc: 0.4379 - val_loss: 0.3979 - val_acc: 0.4404\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3993 - acc: 0.4386 - val_loss: 0.3978 - val_acc: 0.4352\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3990 - acc: 0.4379 - val_loss: 0.3976 - val_acc: 0.4381\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3988 - acc: 0.4348 - val_loss: 0.3974 - val_acc: 0.4364\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3986 - acc: 0.4347 - val_loss: 0.3973 - val_acc: 0.4327\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3984 - acc: 0.4315 - val_loss: 0.3972 - val_acc: 0.4340\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3983 - acc: 0.4317 - val_loss: 0.3972 - val_acc: 0.4285\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3982 - acc: 0.4313 - val_loss: 0.3971 - val_acc: 0.4274\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3981 - acc: 0.4294 - val_loss: 0.3970 - val_acc: 0.4268\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3980 - acc: 0.4273 - val_loss: 0.3968 - val_acc: 0.4299\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.4473 - acc: 0.1631 - val_loss: 1.3548 - val_acc: 0.0638\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2018 - acc: 0.0669 - val_loss: 1.0815 - val_acc: 0.0852\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9833 - acc: 0.0832 - val_loss: 0.7831 - val_acc: 0.0359\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6374 - acc: 0.0080 - val_loss: 0.5081 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4500 - acc: 0.0144 - val_loss: 0.4107 - val_acc: 0.0487\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4071 - acc: 0.0391 - val_loss: 0.4140 - val_acc: 0.0649\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4123 - acc: 0.0433 - val_loss: 0.4069 - val_acc: 0.0504\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4076 - acc: 0.0585 - val_loss: 0.4079 - val_acc: 0.0153\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4046 - acc: 0.0347 - val_loss: 0.4027 - val_acc: 0.0342\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4017 - acc: 0.0282 - val_loss: 0.4027 - val_acc: 0.0401\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4011 - acc: 0.0341 - val_loss: 0.4018 - val_acc: 0.0374\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4005 - acc: 0.0367 - val_loss: 0.4016 - val_acc: 0.0283\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4001 - acc: 0.0347 - val_loss: 0.4010 - val_acc: 0.0320\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3997 - acc: 0.0333 - val_loss: 0.4021 - val_acc: 0.0464\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3996 - acc: 0.0342 - val_loss: 0.4005 - val_acc: 0.0332\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3990 - acc: 0.0341 - val_loss: 0.4002 - val_acc: 0.0296\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3987 - acc: 0.0303 - val_loss: 0.4000 - val_acc: 0.0323\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3984 - acc: 0.0297 - val_loss: 0.3997 - val_acc: 0.0309\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3982 - acc: 0.0290 - val_loss: 0.3999 - val_acc: 0.0360\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3979 - acc: 0.0291 - val_loss: 0.3993 - val_acc: 0.0284\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3976 - acc: 0.0282 - val_loss: 0.3992 - val_acc: 0.0305\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3974 - acc: 0.0268 - val_loss: 0.3991 - val_acc: 0.0300\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3972 - acc: 0.0261 - val_loss: 0.3988 - val_acc: 0.0215\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3971 - acc: 0.0251 - val_loss: 0.3987 - val_acc: 0.0196\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3971 - acc: 0.0243 - val_loss: 0.3988 - val_acc: 0.0161\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3969 - acc: 0.0235 - val_loss: 0.3989 - val_acc: 0.0128\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3969 - acc: 0.0207 - val_loss: 0.3985 - val_acc: 0.0176\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3966 - acc: 0.0211 - val_loss: 0.3984 - val_acc: 0.0183\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3965 - acc: 0.0210 - val_loss: 0.3984 - val_acc: 0.0197\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3965 - acc: 0.0198 - val_loss: 0.3983 - val_acc: 0.0158\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3964 - acc: 0.0188 - val_loss: 0.3983 - val_acc: 0.0188\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3964 - acc: 0.0185 - val_loss: 0.3984 - val_acc: 0.0129\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3965 - acc: 0.0176 - val_loss: 0.3985 - val_acc: 0.0105\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3966 - acc: 0.0167 - val_loss: 0.3983 - val_acc: 0.0158\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3964 - acc: 0.0176 - val_loss: 0.3986 - val_acc: 0.0221\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3965 - acc: 0.0159 - val_loss: 0.3988 - val_acc: 0.0234\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3965 - acc: 0.0171 - val_loss: 0.3984 - val_acc: 0.0177\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3963 - acc: 0.0162 - val_loss: 0.3984 - val_acc: 0.0107\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3964 - acc: 0.0158 - val_loss: 0.3983 - val_acc: 0.0151\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3963 - acc: 0.0156 - val_loss: 0.3983 - val_acc: 0.0146\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3963 - acc: 0.0151 - val_loss: 0.3983 - val_acc: 0.0137\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3963 - acc: 0.0150 - val_loss: 0.3984 - val_acc: 0.0162\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3963 - acc: 0.0158 - val_loss: 0.3985 - val_acc: 0.0077\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3965 - acc: 0.0133 - val_loss: 0.3984 - val_acc: 0.0090\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3964 - acc: 0.0152 - val_loss: 0.3984 - val_acc: 0.0169\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3964 - acc: 0.0154 - val_loss: 0.3990 - val_acc: 0.0231\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3965 - acc: 0.0165 - val_loss: 0.3987 - val_acc: 0.0208\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3963 - acc: 0.0145 - val_loss: 0.3983 - val_acc: 0.0156\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3963 - acc: 0.0158 - val_loss: 0.3983 - val_acc: 0.0166\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3963 - acc: 0.0134 - val_loss: 0.3983 - val_acc: 0.0140\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.7975 - acc: 0.2319 - val_loss: 1.2422 - val_acc: 0.0735\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3268 - acc: 0.0651 - val_loss: 1.3508 - val_acc: 0.0623\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2722 - acc: 0.0620 - val_loss: 1.1756 - val_acc: 0.0658\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1289 - acc: 0.0700 - val_loss: 1.0957 - val_acc: 0.0773\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0910 - acc: 0.0803 - val_loss: 1.0764 - val_acc: 0.0824\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0593 - acc: 0.0781 - val_loss: 1.0356 - val_acc: 0.0723\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0043 - acc: 0.0650 - val_loss: 0.9669 - val_acc: 0.0574\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9276 - acc: 0.0496 - val_loss: 0.8764 - val_acc: 0.0414\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8217 - acc: 0.0337 - val_loss: 0.7594 - val_acc: 0.0229\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7095 - acc: 0.0170 - val_loss: 0.6455 - val_acc: 0.0083\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5943 - acc: 0.0046 - val_loss: 0.5413 - val_acc: 0.0025\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5072 - acc: 0.0036 - val_loss: 0.4720 - val_acc: 0.0062\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4522 - acc: 0.0125 - val_loss: 0.4333 - val_acc: 0.0236\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4249 - acc: 0.0308 - val_loss: 0.4175 - val_acc: 0.0343\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4154 - acc: 0.0355 - val_loss: 0.4139 - val_acc: 0.0369\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4135 - acc: 0.0458 - val_loss: 0.4129 - val_acc: 0.0457\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4130 - acc: 0.0450 - val_loss: 0.4125 - val_acc: 0.0463\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4125 - acc: 0.0415 - val_loss: 0.4119 - val_acc: 0.0426\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4131 - acc: 0.0332 - val_loss: 0.4121 - val_acc: 0.0322\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4115 - acc: 0.0428 - val_loss: 0.4108 - val_acc: 0.0379\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4106 - acc: 0.0362 - val_loss: 0.4102 - val_acc: 0.0400\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4100 - acc: 0.0384 - val_loss: 0.4095 - val_acc: 0.0391\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4095 - acc: 0.0426 - val_loss: 0.4091 - val_acc: 0.0362\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4160 - acc: 0.0195 - val_loss: 0.4091 - val_acc: 0.0290\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4109 - acc: 0.0496 - val_loss: 0.4081 - val_acc: 0.0317\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4088 - acc: 0.0279 - val_loss: 0.4074 - val_acc: 0.0422\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4074 - acc: 0.0416 - val_loss: 0.4069 - val_acc: 0.0312\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4067 - acc: 0.0327 - val_loss: 0.4066 - val_acc: 0.0291\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4064 - acc: 0.0339 - val_loss: 0.4062 - val_acc: 0.0451\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4057 - acc: 0.0366 - val_loss: 0.4052 - val_acc: 0.0307\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4053 - acc: 0.0382 - val_loss: 0.4045 - val_acc: 0.0371\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4049 - acc: 0.0327 - val_loss: 0.4041 - val_acc: 0.0371\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4044 - acc: 0.0394 - val_loss: 0.4037 - val_acc: 0.0369\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4040 - acc: 0.0363 - val_loss: 0.4033 - val_acc: 0.0353\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4036 - acc: 0.0343 - val_loss: 0.4029 - val_acc: 0.0326\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4033 - acc: 0.0335 - val_loss: 0.4025 - val_acc: 0.0355\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4030 - acc: 0.0347 - val_loss: 0.4022 - val_acc: 0.0321\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4027 - acc: 0.0334 - val_loss: 0.4019 - val_acc: 0.0351\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4025 - acc: 0.0323 - val_loss: 0.4016 - val_acc: 0.0357\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4022 - acc: 0.0333 - val_loss: 0.4015 - val_acc: 0.0270\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4020 - acc: 0.0325 - val_loss: 0.4010 - val_acc: 0.0318\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4027 - acc: 0.0369 - val_loss: 0.4113 - val_acc: 0.0753\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4061 - acc: 0.0388 - val_loss: 0.4033 - val_acc: 0.0199\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4028 - acc: 0.0396 - val_loss: 0.4007 - val_acc: 0.0302\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4018 - acc: 0.0264 - val_loss: 0.4006 - val_acc: 0.0334\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4012 - acc: 0.0289 - val_loss: 0.4003 - val_acc: 0.0273\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4010 - acc: 0.0283 - val_loss: 0.4001 - val_acc: 0.0264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4008 - acc: 0.0275 - val_loss: 0.3999 - val_acc: 0.0307\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4007 - acc: 0.0282 - val_loss: 0.3997 - val_acc: 0.0276\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4005 - acc: 0.0276 - val_loss: 0.3996 - val_acc: 0.0273\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.4540 - acc: 0.3711 - val_loss: 1.3587 - val_acc: 0.3205\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2071 - acc: 0.3682 - val_loss: 1.0709 - val_acc: 0.4027\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0124 - acc: 0.4052 - val_loss: 0.8869 - val_acc: 0.4257\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7881 - acc: 0.4506 - val_loss: 0.6422 - val_acc: 0.4767\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5507 - acc: 0.4978 - val_loss: 0.4662 - val_acc: 0.5156\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4306 - acc: 0.5173 - val_loss: 0.4154 - val_acc: 0.5292\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4145 - acc: 0.4631 - val_loss: 0.4206 - val_acc: 0.4232\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4127 - acc: 0.4339 - val_loss: 0.4147 - val_acc: 0.4572\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4086 - acc: 0.4822 - val_loss: 0.4119 - val_acc: 0.5006\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4068 - acc: 0.5198 - val_loss: 0.4108 - val_acc: 0.5234\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4061 - acc: 0.5097 - val_loss: 0.4100 - val_acc: 0.4901\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4053 - acc: 0.4824 - val_loss: 0.4102 - val_acc: 0.4833\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4047 - acc: 0.4730 - val_loss: 0.4086 - val_acc: 0.4684\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4038 - acc: 0.4747 - val_loss: 0.4079 - val_acc: 0.4680\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4028 - acc: 0.4708 - val_loss: 0.4069 - val_acc: 0.4708\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4020 - acc: 0.4675 - val_loss: 0.4062 - val_acc: 0.4669\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4014 - acc: 0.4618 - val_loss: 0.4057 - val_acc: 0.4624\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4008 - acc: 0.4574 - val_loss: 0.4052 - val_acc: 0.4514\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4003 - acc: 0.4552 - val_loss: 0.4047 - val_acc: 0.4478\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3997 - acc: 0.4508 - val_loss: 0.4044 - val_acc: 0.4422\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3994 - acc: 0.4455 - val_loss: 0.4038 - val_acc: 0.4445\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3989 - acc: 0.4440 - val_loss: 0.4034 - val_acc: 0.4429\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3986 - acc: 0.4420 - val_loss: 0.4032 - val_acc: 0.4422\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3984 - acc: 0.4405 - val_loss: 0.4029 - val_acc: 0.4385\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3982 - acc: 0.4353 - val_loss: 0.4029 - val_acc: 0.4385\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3980 - acc: 0.4346 - val_loss: 0.4026 - val_acc: 0.4342\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3978 - acc: 0.4342 - val_loss: 0.4025 - val_acc: 0.4298\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3977 - acc: 0.4312 - val_loss: 0.4024 - val_acc: 0.4278\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3977 - acc: 0.4297 - val_loss: 0.4027 - val_acc: 0.4222\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3976 - acc: 0.4271 - val_loss: 0.4023 - val_acc: 0.4282\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3975 - acc: 0.4263 - val_loss: 0.4023 - val_acc: 0.4295\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3976 - acc: 0.4269 - val_loss: 0.4023 - val_acc: 0.4304\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3975 - acc: 0.4269 - val_loss: 0.4022 - val_acc: 0.4259\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3974 - acc: 0.4246 - val_loss: 0.4022 - val_acc: 0.4258\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3974 - acc: 0.4241 - val_loss: 0.4022 - val_acc: 0.4262\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3975 - acc: 0.4241 - val_loss: 0.4023 - val_acc: 0.4284\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3975 - acc: 0.4243 - val_loss: 0.4021 - val_acc: 0.4231\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3974 - acc: 0.4224 - val_loss: 0.4022 - val_acc: 0.4202\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3974 - acc: 0.4229 - val_loss: 0.4021 - val_acc: 0.4216\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3974 - acc: 0.4229 - val_loss: 0.4023 - val_acc: 0.4183\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3974 - acc: 0.4229 - val_loss: 0.4023 - val_acc: 0.4174\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3975 - acc: 0.4215 - val_loss: 0.4026 - val_acc: 0.4144\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3977 - acc: 0.4220 - val_loss: 0.4021 - val_acc: 0.4226\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3975 - acc: 0.4236 - val_loss: 0.4022 - val_acc: 0.4261\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3974 - acc: 0.4227 - val_loss: 0.4021 - val_acc: 0.4233\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3973 - acc: 0.4227 - val_loss: 0.4022 - val_acc: 0.4186\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3974 - acc: 0.4219 - val_loss: 0.4021 - val_acc: 0.4266\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3973 - acc: 0.4233 - val_loss: 0.4021 - val_acc: 0.4243\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3973 - acc: 0.4226 - val_loss: 0.4021 - val_acc: 0.4206\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3974 - acc: 0.4229 - val_loss: 0.4020 - val_acc: 0.4244\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.4805 - acc: 0.1694 - val_loss: 1.4093 - val_acc: 0.0642\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2618 - acc: 0.0731 - val_loss: 1.1391 - val_acc: 0.0921\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0784 - acc: 0.0926 - val_loss: 0.9455 - val_acc: 0.0614\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8106 - acc: 0.0329 - val_loss: 0.6320 - val_acc: 0.0054\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5438 - acc: 0.0012 - val_loss: 0.4603 - val_acc: 0.0014\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4292 - acc: 0.0077 - val_loss: 0.4073 - val_acc: 0.0346\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4088 - acc: 0.0368 - val_loss: 0.4161 - val_acc: 0.0206\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4152 - acc: 0.0638 - val_loss: 0.4077 - val_acc: 0.0512\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4090 - acc: 0.0327 - val_loss: 0.4076 - val_acc: 0.0604\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4105 - acc: 0.0553 - val_loss: 0.4211 - val_acc: 0.0073\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4107 - acc: 0.0349 - val_loss: 0.4059 - val_acc: 0.0500\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4050 - acc: 0.0255 - val_loss: 0.4039 - val_acc: 0.0372\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4038 - acc: 0.0374 - val_loss: 0.4044 - val_acc: 0.0250\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4031 - acc: 0.0353 - val_loss: 0.4031 - val_acc: 0.0365\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4026 - acc: 0.0337 - val_loss: 0.4029 - val_acc: 0.0373\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4023 - acc: 0.0348 - val_loss: 0.4028 - val_acc: 0.0335\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4021 - acc: 0.0344 - val_loss: 0.4026 - val_acc: 0.0321\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4019 - acc: 0.0341 - val_loss: 0.4024 - val_acc: 0.0310\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4018 - acc: 0.0324 - val_loss: 0.4022 - val_acc: 0.0344\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4015 - acc: 0.0329 - val_loss: 0.4020 - val_acc: 0.0330\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4014 - acc: 0.0320 - val_loss: 0.4019 - val_acc: 0.0349\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4013 - acc: 0.0321 - val_loss: 0.4017 - val_acc: 0.0324\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4011 - acc: 0.0313 - val_loss: 0.4016 - val_acc: 0.0329\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4010 - acc: 0.0317 - val_loss: 0.4015 - val_acc: 0.0283\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4008 - acc: 0.0295 - val_loss: 0.4013 - val_acc: 0.0312\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4007 - acc: 0.0301 - val_loss: 0.4012 - val_acc: 0.0285\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4006 - acc: 0.0292 - val_loss: 0.4011 - val_acc: 0.0284\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4005 - acc: 0.0285 - val_loss: 0.4010 - val_acc: 0.0317\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4005 - acc: 0.0270 - val_loss: 0.4010 - val_acc: 0.0323\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4004 - acc: 0.0279 - val_loss: 0.4010 - val_acc: 0.0245\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4004 - acc: 0.0277 - val_loss: 0.4011 - val_acc: 0.0224\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4004 - acc: 0.0262 - val_loss: 0.4008 - val_acc: 0.0249\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4002 - acc: 0.0265 - val_loss: 0.4007 - val_acc: 0.0245\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4001 - acc: 0.0258 - val_loss: 0.4006 - val_acc: 0.0261\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4001 - acc: 0.0254 - val_loss: 0.4007 - val_acc: 0.0232\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4000 - acc: 0.0244 - val_loss: 0.4006 - val_acc: 0.0230\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4001 - acc: 0.0250 - val_loss: 0.4007 - val_acc: 0.0210\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4002 - acc: 0.0229 - val_loss: 0.4009 - val_acc: 0.0177\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4000 - acc: 0.0226 - val_loss: 0.4005 - val_acc: 0.0231\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3999 - acc: 0.0227 - val_loss: 0.4005 - val_acc: 0.0254\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4000 - acc: 0.0238 - val_loss: 0.4005 - val_acc: 0.0230\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3999 - acc: 0.0210 - val_loss: 0.4004 - val_acc: 0.0227\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4000 - acc: 0.0217 - val_loss: 0.4004 - val_acc: 0.0249\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3999 - acc: 0.0223 - val_loss: 0.4004 - val_acc: 0.0239\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3999 - acc: 0.0213 - val_loss: 0.4005 - val_acc: 0.0277\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4001 - acc: 0.0214 - val_loss: 0.4004 - val_acc: 0.0240\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4001 - acc: 0.0205 - val_loss: 0.4004 - val_acc: 0.0221\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4000 - acc: 0.0213 - val_loss: 0.4004 - val_acc: 0.0254\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4000 - acc: 0.0215 - val_loss: 0.4004 - val_acc: 0.0213\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4000 - acc: 0.0224 - val_loss: 0.4009 - val_acc: 0.0139\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.4419 - acc: 0.1651 - val_loss: 1.3751 - val_acc: 0.0711\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2248 - acc: 0.0779 - val_loss: 1.1246 - val_acc: 0.0984\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1025 - acc: 0.0990 - val_loss: 1.0420 - val_acc: 0.0802\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0165 - acc: 0.0669 - val_loss: 0.9518 - val_acc: 0.0551\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8548 - acc: 0.0419 - val_loss: 0.7416 - val_acc: 0.0240\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6571 - acc: 0.0155 - val_loss: 0.5533 - val_acc: 0.0136\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4985 - acc: 0.0239 - val_loss: 0.4522 - val_acc: 0.0479\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4367 - acc: 0.0526 - val_loss: 0.4375 - val_acc: 0.0458\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4525 - acc: 0.0961 - val_loss: 0.4443 - val_acc: 0.0497\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4636 - acc: 0.0426 - val_loss: 0.4852 - val_acc: 0.1389\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4446 - acc: 0.0488 - val_loss: 0.4272 - val_acc: 0.0273\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4248 - acc: 0.0576 - val_loss: 0.4349 - val_acc: 0.0133\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4265 - acc: 0.0281 - val_loss: 0.4264 - val_acc: 0.0729\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4179 - acc: 0.0422 - val_loss: 0.4179 - val_acc: 0.0252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4125 - acc: 0.0477 - val_loss: 0.4129 - val_acc: 0.0395\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4101 - acc: 0.0370 - val_loss: 0.4190 - val_acc: 0.0736\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4212 - acc: 0.0562 - val_loss: 0.4248 - val_acc: 0.0156\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4124 - acc: 0.0478 - val_loss: 0.4102 - val_acc: 0.0401\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4087 - acc: 0.0299 - val_loss: 0.4103 - val_acc: 0.0460\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4070 - acc: 0.0399 - val_loss: 0.4093 - val_acc: 0.0297\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4061 - acc: 0.0377 - val_loss: 0.4081 - val_acc: 0.0371\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4054 - acc: 0.0342 - val_loss: 0.4077 - val_acc: 0.0405\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4049 - acc: 0.0368 - val_loss: 0.4071 - val_acc: 0.0344\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4044 - acc: 0.0351 - val_loss: 0.4067 - val_acc: 0.0375\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4041 - acc: 0.0344 - val_loss: 0.4064 - val_acc: 0.0361\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4038 - acc: 0.0352 - val_loss: 0.4061 - val_acc: 0.0321\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4036 - acc: 0.0335 - val_loss: 0.4058 - val_acc: 0.0346\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4034 - acc: 0.0342 - val_loss: 0.4056 - val_acc: 0.0342\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4032 - acc: 0.0318 - val_loss: 0.4054 - val_acc: 0.0358\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4030 - acc: 0.0317 - val_loss: 0.4052 - val_acc: 0.0303\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4029 - acc: 0.0313 - val_loss: 0.4051 - val_acc: 0.0340\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4028 - acc: 0.0313 - val_loss: 0.4049 - val_acc: 0.0306\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4027 - acc: 0.0297 - val_loss: 0.4048 - val_acc: 0.0280\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4025 - acc: 0.0276 - val_loss: 0.4047 - val_acc: 0.0335\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4025 - acc: 0.0286 - val_loss: 0.4045 - val_acc: 0.0299\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4023 - acc: 0.0285 - val_loss: 0.4044 - val_acc: 0.0286\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4023 - acc: 0.0264 - val_loss: 0.4044 - val_acc: 0.0269\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4023 - acc: 0.0273 - val_loss: 0.4045 - val_acc: 0.0241\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4022 - acc: 0.0266 - val_loss: 0.4042 - val_acc: 0.0274\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4021 - acc: 0.0259 - val_loss: 0.4042 - val_acc: 0.0290\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4021 - acc: 0.0261 - val_loss: 0.4042 - val_acc: 0.0287\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4021 - acc: 0.0244 - val_loss: 0.4041 - val_acc: 0.0268\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4020 - acc: 0.0252 - val_loss: 0.4041 - val_acc: 0.0277\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4020 - acc: 0.0248 - val_loss: 0.4041 - val_acc: 0.0254\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4020 - acc: 0.0245 - val_loss: 0.4041 - val_acc: 0.0255\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4020 - acc: 0.0241 - val_loss: 0.4040 - val_acc: 0.0247\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4020 - acc: 0.0235 - val_loss: 0.4040 - val_acc: 0.0238\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4020 - acc: 0.0229 - val_loss: 0.4040 - val_acc: 0.0256\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4020 - acc: 0.0231 - val_loss: 0.4040 - val_acc: 0.0274\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4021 - acc: 0.0243 - val_loss: 0.4040 - val_acc: 0.0248\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.3970 - acc: 0.1534 - val_loss: 1.3113 - val_acc: 0.0694\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1551 - acc: 0.0758 - val_loss: 1.0740 - val_acc: 0.0925\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9833 - acc: 0.0752 - val_loss: 0.8470 - val_acc: 0.0393\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7163 - acc: 0.0190 - val_loss: 0.5632 - val_acc: 0.0076\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4884 - acc: 0.0139 - val_loss: 0.4299 - val_acc: 0.0074\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4180 - acc: 0.0435 - val_loss: 0.4139 - val_acc: 0.0589\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4247 - acc: 0.0652 - val_loss: 0.4288 - val_acc: 0.0298\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4199 - acc: 0.0499 - val_loss: 0.4116 - val_acc: 0.0629\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4115 - acc: 0.0431 - val_loss: 0.4088 - val_acc: 0.0325\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4111 - acc: 0.0320 - val_loss: 0.4086 - val_acc: 0.0419\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4096 - acc: 0.0354 - val_loss: 0.4074 - val_acc: 0.0392\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4088 - acc: 0.0372 - val_loss: 0.4069 - val_acc: 0.0421\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4084 - acc: 0.0383 - val_loss: 0.4065 - val_acc: 0.0419\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4080 - acc: 0.0366 - val_loss: 0.4065 - val_acc: 0.0453\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4078 - acc: 0.0371 - val_loss: 0.4058 - val_acc: 0.0348\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4074 - acc: 0.0380 - val_loss: 0.4057 - val_acc: 0.0316\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4070 - acc: 0.0352 - val_loss: 0.4052 - val_acc: 0.0337\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4068 - acc: 0.0358 - val_loss: 0.4049 - val_acc: 0.0346\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4066 - acc: 0.0344 - val_loss: 0.4048 - val_acc: 0.0390\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4063 - acc: 0.0339 - val_loss: 0.4048 - val_acc: 0.0414\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4061 - acc: 0.0338 - val_loss: 0.4044 - val_acc: 0.0377\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4060 - acc: 0.0333 - val_loss: 0.4043 - val_acc: 0.0373\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4061 - acc: 0.0334 - val_loss: 0.4041 - val_acc: 0.0321\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4058 - acc: 0.0322 - val_loss: 0.4040 - val_acc: 0.0316\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4055 - acc: 0.0328 - val_loss: 0.4039 - val_acc: 0.0296\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4055 - acc: 0.0318 - val_loss: 0.4039 - val_acc: 0.0295\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4053 - acc: 0.0309 - val_loss: 0.4038 - val_acc: 0.0319\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4052 - acc: 0.0296 - val_loss: 0.4037 - val_acc: 0.0299\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4052 - acc: 0.0282 - val_loss: 0.4037 - val_acc: 0.0315\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4051 - acc: 0.0283 - val_loss: 0.4037 - val_acc: 0.0260\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4052 - acc: 0.0276 - val_loss: 0.4037 - val_acc: 0.0250\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4050 - acc: 0.0275 - val_loss: 0.4035 - val_acc: 0.0278\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4050 - acc: 0.0277 - val_loss: 0.4037 - val_acc: 0.0233\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4050 - acc: 0.0268 - val_loss: 0.4035 - val_acc: 0.0256\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4049 - acc: 0.0258 - val_loss: 0.4035 - val_acc: 0.0258\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4049 - acc: 0.0257 - val_loss: 0.4035 - val_acc: 0.0269\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4049 - acc: 0.0248 - val_loss: 0.4035 - val_acc: 0.0250\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4049 - acc: 0.0248 - val_loss: 0.4035 - val_acc: 0.0271\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4049 - acc: 0.0255 - val_loss: 0.4035 - val_acc: 0.0256\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4049 - acc: 0.0249 - val_loss: 0.4035 - val_acc: 0.0257\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4049 - acc: 0.0252 - val_loss: 0.4035 - val_acc: 0.0277\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4050 - acc: 0.0242 - val_loss: 0.4040 - val_acc: 0.0341\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4049 - acc: 0.0251 - val_loss: 0.4035 - val_acc: 0.0266\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4049 - acc: 0.0247 - val_loss: 0.4035 - val_acc: 0.0228\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4049 - acc: 0.0239 - val_loss: 0.4036 - val_acc: 0.0211\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4049 - acc: 0.0243 - val_loss: 0.4036 - val_acc: 0.0211\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4049 - acc: 0.0240 - val_loss: 0.4035 - val_acc: 0.0228\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4049 - acc: 0.0247 - val_loss: 0.4035 - val_acc: 0.0237\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4049 - acc: 0.0238 - val_loss: 0.4035 - val_acc: 0.0259\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4049 - acc: 0.0249 - val_loss: 0.4035 - val_acc: 0.0241\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.5497 - acc: 0.4047 - val_loss: 1.3068 - val_acc: 0.3446\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2902 - acc: 0.3419 - val_loss: 1.1756 - val_acc: 0.3805\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0751 - acc: 0.4074 - val_loss: 1.0163 - val_acc: 0.4131\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9637 - acc: 0.4177 - val_loss: 0.8825 - val_acc: 0.4304\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8134 - acc: 0.4466 - val_loss: 0.7237 - val_acc: 0.4649\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6328 - acc: 0.4816 - val_loss: 0.5489 - val_acc: 0.4948\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5020 - acc: 0.5016 - val_loss: 0.4537 - val_acc: 0.5106\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4326 - acc: 0.5176 - val_loss: 0.4158 - val_acc: 0.5262\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4141 - acc: 0.5316 - val_loss: 0.4131 - val_acc: 0.5137\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4144 - acc: 0.4882 - val_loss: 0.4137 - val_acc: 0.4752\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4155 - acc: 0.4892 - val_loss: 0.4119 - val_acc: 0.5331\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4139 - acc: 0.5410 - val_loss: 0.4116 - val_acc: 0.5289\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4123 - acc: 0.5306 - val_loss: 0.4114 - val_acc: 0.5386\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4122 - acc: 0.5283 - val_loss: 0.4106 - val_acc: 0.5350\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4114 - acc: 0.5345 - val_loss: 0.4106 - val_acc: 0.5289\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4109 - acc: 0.5298 - val_loss: 0.4099 - val_acc: 0.5219\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4109 - acc: 0.5143 - val_loss: 0.4143 - val_acc: 0.5200\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4124 - acc: 0.4984 - val_loss: 0.4108 - val_acc: 0.4896\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4107 - acc: 0.5045 - val_loss: 0.4092 - val_acc: 0.5063\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4102 - acc: 0.4996 - val_loss: 0.4091 - val_acc: 0.5086\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4097 - acc: 0.5070 - val_loss: 0.4090 - val_acc: 0.5067\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4093 - acc: 0.4979 - val_loss: 0.4087 - val_acc: 0.4920\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4092 - acc: 0.4913 - val_loss: 0.4083 - val_acc: 0.4970\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4089 - acc: 0.4981 - val_loss: 0.4081 - val_acc: 0.4947\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4087 - acc: 0.4900 - val_loss: 0.4079 - val_acc: 0.4926\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4084 - acc: 0.4889 - val_loss: 0.4078 - val_acc: 0.4862\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4082 - acc: 0.4871 - val_loss: 0.4075 - val_acc: 0.4867\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4080 - acc: 0.4862 - val_loss: 0.4074 - val_acc: 0.4844\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4079 - acc: 0.4834 - val_loss: 0.4072 - val_acc: 0.4857\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4076 - acc: 0.4824 - val_loss: 0.4070 - val_acc: 0.4785\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4075 - acc: 0.4781 - val_loss: 0.4069 - val_acc: 0.4769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4073 - acc: 0.4772 - val_loss: 0.4067 - val_acc: 0.4778\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4072 - acc: 0.4779 - val_loss: 0.4066 - val_acc: 0.4746\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4071 - acc: 0.4746 - val_loss: 0.4065 - val_acc: 0.4750\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4070 - acc: 0.4738 - val_loss: 0.4064 - val_acc: 0.4721\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4068 - acc: 0.4718 - val_loss: 0.4063 - val_acc: 0.4701\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4067 - acc: 0.4699 - val_loss: 0.4063 - val_acc: 0.4722\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4067 - acc: 0.4694 - val_loss: 0.4063 - val_acc: 0.4647\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4067 - acc: 0.4682 - val_loss: 0.4064 - val_acc: 0.4605\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4072 - acc: 0.4677 - val_loss: 0.4067 - val_acc: 0.4534\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4070 - acc: 0.4608 - val_loss: 0.4063 - val_acc: 0.4708\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4067 - acc: 0.4635 - val_loss: 0.4063 - val_acc: 0.4739\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4065 - acc: 0.4671 - val_loss: 0.4064 - val_acc: 0.4597\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4064 - acc: 0.4663 - val_loss: 0.4060 - val_acc: 0.4594\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4063 - acc: 0.4630 - val_loss: 0.4059 - val_acc: 0.4578\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4063 - acc: 0.4602 - val_loss: 0.4058 - val_acc: 0.4603\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4062 - acc: 0.4608 - val_loss: 0.4058 - val_acc: 0.4628\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4062 - acc: 0.4606 - val_loss: 0.4058 - val_acc: 0.4634\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4061 - acc: 0.4592 - val_loss: 0.4057 - val_acc: 0.4614\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4061 - acc: 0.4591 - val_loss: 0.4057 - val_acc: 0.4583\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.6424 - acc: 0.2288 - val_loss: 1.2554 - val_acc: 0.0762\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3260 - acc: 0.0693 - val_loss: 1.2939 - val_acc: 0.0656\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1982 - acc: 0.0675 - val_loss: 1.0968 - val_acc: 0.0712\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0527 - acc: 0.0759 - val_loss: 1.0035 - val_acc: 0.0767\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9408 - acc: 0.0672 - val_loss: 0.8662 - val_acc: 0.0495\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7837 - acc: 0.0346 - val_loss: 0.6881 - val_acc: 0.0161\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6205 - acc: 0.0066 - val_loss: 0.5479 - val_acc: 1.3000e-04\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5032 - acc: 1.1500e-04 - val_loss: 0.4566 - val_acc: 7.5000e-04\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4361 - acc: 0.0066 - val_loss: 0.4152 - val_acc: 0.0210\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4125 - acc: 0.0323 - val_loss: 0.4071 - val_acc: 0.0393\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4106 - acc: 0.0411 - val_loss: 0.4082 - val_acc: 0.0450\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4110 - acc: 0.0418 - val_loss: 0.4075 - val_acc: 0.0430\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4100 - acc: 0.0402 - val_loss: 0.4069 - val_acc: 0.0377\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4096 - acc: 0.0361 - val_loss: 0.4069 - val_acc: 0.0369\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4096 - acc: 0.0364 - val_loss: 0.4069 - val_acc: 0.0352\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4096 - acc: 0.0346 - val_loss: 0.4067 - val_acc: 0.0362\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4095 - acc: 0.0367 - val_loss: 0.4067 - val_acc: 0.0350\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4094 - acc: 0.0362 - val_loss: 0.4067 - val_acc: 0.0387\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4094 - acc: 0.0364 - val_loss: 0.4066 - val_acc: 0.0330\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4093 - acc: 0.0354 - val_loss: 0.4066 - val_acc: 0.0386\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4094 - acc: 0.0351 - val_loss: 0.4066 - val_acc: 0.0381\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4093 - acc: 0.0358 - val_loss: 0.4065 - val_acc: 0.0338\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4092 - acc: 0.0360 - val_loss: 0.4064 - val_acc: 0.0353\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4092 - acc: 0.0346 - val_loss: 0.4064 - val_acc: 0.0359\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4093 - acc: 0.0330 - val_loss: 0.4065 - val_acc: 0.0382\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4093 - acc: 0.0358 - val_loss: 0.4064 - val_acc: 0.0316\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4091 - acc: 0.0353 - val_loss: 0.4063 - val_acc: 0.0354\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4091 - acc: 0.0337 - val_loss: 0.4063 - val_acc: 0.0346\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4091 - acc: 0.0344 - val_loss: 0.4063 - val_acc: 0.0325\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4091 - acc: 0.0344 - val_loss: 0.4062 - val_acc: 0.0333\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4091 - acc: 0.0336 - val_loss: 0.4062 - val_acc: 0.0322\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4090 - acc: 0.0337 - val_loss: 0.4063 - val_acc: 0.0357\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4090 - acc: 0.0328 - val_loss: 0.4063 - val_acc: 0.0355\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4090 - acc: 0.0342 - val_loss: 0.4062 - val_acc: 0.0314\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4090 - acc: 0.0331 - val_loss: 0.4063 - val_acc: 0.0365\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4091 - acc: 0.0351 - val_loss: 0.4064 - val_acc: 0.0389\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4090 - acc: 0.0344 - val_loss: 0.4062 - val_acc: 0.0316\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4090 - acc: 0.0306 - val_loss: 0.4064 - val_acc: 0.0363\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4090 - acc: 0.0325 - val_loss: 0.4062 - val_acc: 0.0285\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4090 - acc: 0.0320 - val_loss: 0.4062 - val_acc: 0.0329\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4090 - acc: 0.0320 - val_loss: 0.4063 - val_acc: 0.0356\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4091 - acc: 0.0306 - val_loss: 0.4064 - val_acc: 0.0359\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4090 - acc: 0.0311 - val_loss: 0.4062 - val_acc: 0.0295\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4090 - acc: 0.0325 - val_loss: 0.4061 - val_acc: 0.0304\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4090 - acc: 0.0294 - val_loss: 0.4069 - val_acc: 0.0416\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4096 - acc: 0.0323 - val_loss: 0.4061 - val_acc: 0.0316\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4092 - acc: 0.0342 - val_loss: 0.4063 - val_acc: 0.0264\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4091 - acc: 0.0314 - val_loss: 0.4062 - val_acc: 0.0291\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4090 - acc: 0.0316 - val_loss: 0.4061 - val_acc: 0.0289\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4089 - acc: 0.0304 - val_loss: 0.4062 - val_acc: 0.0312\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.6217 - acc: 0.1835 - val_loss: 1.4526 - val_acc: 0.0516\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.4250 - acc: 0.0478 - val_loss: 1.2705 - val_acc: 0.0476\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1832 - acc: 0.0561 - val_loss: 1.1213 - val_acc: 0.0669\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0706 - acc: 0.0640 - val_loss: 0.9750 - val_acc: 0.0475\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8879 - acc: 0.0309 - val_loss: 0.7691 - val_acc: 0.0139\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6826 - acc: 0.0061 - val_loss: 0.5866 - val_acc: 4.5000e-04\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5296 - acc: 5.0000e-04 - val_loss: 0.4660 - val_acc: 0.0020\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4285 - acc: 0.0062 - val_loss: 0.3912 - val_acc: 0.0177\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3712 - acc: 0.0375 - val_loss: 0.3550 - val_acc: 0.0554\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3490 - acc: 0.0572 - val_loss: 0.3460 - val_acc: 0.0678\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3569 - acc: 0.0385 - val_loss: 0.3452 - val_acc: 0.0645\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3475 - acc: 0.0816 - val_loss: 0.3495 - val_acc: 0.0414\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3465 - acc: 0.0573 - val_loss: 0.3488 - val_acc: 0.0961\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3446 - acc: 0.0714 - val_loss: 0.3443 - val_acc: 0.0540\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3425 - acc: 0.0688 - val_loss: 0.3427 - val_acc: 0.0736\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3420 - acc: 0.0627 - val_loss: 0.3422 - val_acc: 0.0749\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3415 - acc: 0.0774 - val_loss: 0.3415 - val_acc: 0.0647\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3447 - acc: 0.0460 - val_loss: 0.3413 - val_acc: 0.0547\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3404 - acc: 0.0635 - val_loss: 0.3412 - val_acc: 0.0494\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3394 - acc: 0.0609 - val_loss: 0.3396 - val_acc: 0.0671\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3382 - acc: 0.0607 - val_loss: 0.3386 - val_acc: 0.0649\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3375 - acc: 0.0657 - val_loss: 0.3381 - val_acc: 0.0625\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3367 - acc: 0.0638 - val_loss: 0.3375 - val_acc: 0.0698\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3361 - acc: 0.0655 - val_loss: 0.3370 - val_acc: 0.0587\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3356 - acc: 0.0645 - val_loss: 0.3363 - val_acc: 0.0646\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3350 - acc: 0.0619 - val_loss: 0.3359 - val_acc: 0.0680\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3345 - acc: 0.0637 - val_loss: 0.3357 - val_acc: 0.0557\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3341 - acc: 0.0633 - val_loss: 0.3350 - val_acc: 0.0630\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3336 - acc: 0.0612 - val_loss: 0.3347 - val_acc: 0.0677\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3332 - acc: 0.0616 - val_loss: 0.3343 - val_acc: 0.0640\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3328 - acc: 0.0627 - val_loss: 0.3340 - val_acc: 0.0571\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3325 - acc: 0.0617 - val_loss: 0.3337 - val_acc: 0.0589\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3321 - acc: 0.0596 - val_loss: 0.3334 - val_acc: 0.0606\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3318 - acc: 0.0610 - val_loss: 0.3332 - val_acc: 0.0562\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3316 - acc: 0.0577 - val_loss: 0.3330 - val_acc: 0.0594\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3314 - acc: 0.0588 - val_loss: 0.3328 - val_acc: 0.0574\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3312 - acc: 0.0593 - val_loss: 0.3327 - val_acc: 0.0516\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3311 - acc: 0.0552 - val_loss: 0.3326 - val_acc: 0.0614\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3309 - acc: 0.0555 - val_loss: 0.3325 - val_acc: 0.0601\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3308 - acc: 0.0549 - val_loss: 0.3324 - val_acc: 0.0603\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3307 - acc: 0.0534 - val_loss: 0.3323 - val_acc: 0.0575\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3307 - acc: 0.0555 - val_loss: 0.3322 - val_acc: 0.0494\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3305 - acc: 0.0545 - val_loss: 0.3321 - val_acc: 0.0519\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3304 - acc: 0.0529 - val_loss: 0.3322 - val_acc: 0.0482\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3303 - acc: 0.0503 - val_loss: 0.3321 - val_acc: 0.0553\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3304 - acc: 0.0522 - val_loss: 0.3322 - val_acc: 0.0594\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3303 - acc: 0.0512 - val_loss: 0.3321 - val_acc: 0.0537\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3303 - acc: 0.0495 - val_loss: 0.3320 - val_acc: 0.0515\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3303 - acc: 0.0512 - val_loss: 0.3320 - val_acc: 0.0501\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3302 - acc: 0.0503 - val_loss: 0.3320 - val_acc: 0.0467\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 1s 3us/step - loss: 1.4908 - acc: 0.3517 - val_loss: 1.3353 - val_acc: 0.3480\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1604 - acc: 0.3701 - val_loss: 1.0137 - val_acc: 0.3643\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8205 - acc: 0.4211 - val_loss: 0.6116 - val_acc: 0.4909\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5053 - acc: 0.5014 - val_loss: 0.4034 - val_acc: 0.5235\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3704 - acc: 0.5080 - val_loss: 0.3496 - val_acc: 0.4179\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3669 - acc: 0.3602 - val_loss: 0.3550 - val_acc: 0.4153\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3560 - acc: 0.4177 - val_loss: 0.3508 - val_acc: 0.3817\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3491 - acc: 0.4130 - val_loss: 0.3454 - val_acc: 0.4257\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3481 - acc: 0.4315 - val_loss: 0.3555 - val_acc: 0.3890\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3518 - acc: 0.4286 - val_loss: 0.3445 - val_acc: 0.4477\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3451 - acc: 0.4293 - val_loss: 0.3442 - val_acc: 0.4069\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3453 - acc: 0.4166 - val_loss: 0.3415 - val_acc: 0.4177\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3437 - acc: 0.4226 - val_loss: 0.3399 - val_acc: 0.4300\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3415 - acc: 0.4200 - val_loss: 0.3388 - val_acc: 0.4273\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3404 - acc: 0.4138 - val_loss: 0.3376 - val_acc: 0.4215\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3393 - acc: 0.4098 - val_loss: 0.3363 - val_acc: 0.4056\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3382 - acc: 0.4109 - val_loss: 0.3353 - val_acc: 0.4089\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3372 - acc: 0.4107 - val_loss: 0.3345 - val_acc: 0.4038\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3366 - acc: 0.4049 - val_loss: 0.3343 - val_acc: 0.3944\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3360 - acc: 0.4057 - val_loss: 0.3337 - val_acc: 0.3915\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3354 - acc: 0.4012 - val_loss: 0.3326 - val_acc: 0.4025\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3350 - acc: 0.4004 - val_loss: 0.3324 - val_acc: 0.3937\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3348 - acc: 0.3993 - val_loss: 0.3321 - val_acc: 0.3913\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3344 - acc: 0.3989 - val_loss: 0.3317 - val_acc: 0.3928\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3342 - acc: 0.3956 - val_loss: 0.3314 - val_acc: 0.3968\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3340 - acc: 0.3953 - val_loss: 0.3313 - val_acc: 0.3925\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3339 - acc: 0.3945 - val_loss: 0.3312 - val_acc: 0.3898\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3339 - acc: 0.3942 - val_loss: 0.3312 - val_acc: 0.3869\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3338 - acc: 0.3925 - val_loss: 0.3314 - val_acc: 0.3822\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3338 - acc: 0.3914 - val_loss: 0.3311 - val_acc: 0.3837\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3338 - acc: 0.3916 - val_loss: 0.3314 - val_acc: 0.3799\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3338 - acc: 0.3915 - val_loss: 0.3312 - val_acc: 0.3797\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3337 - acc: 0.3898 - val_loss: 0.3309 - val_acc: 0.3869\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3337 - acc: 0.3907 - val_loss: 0.3308 - val_acc: 0.3890\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3336 - acc: 0.3914 - val_loss: 0.3310 - val_acc: 0.3817\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3338 - acc: 0.3889 - val_loss: 0.3308 - val_acc: 0.3856\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3338 - acc: 0.3907 - val_loss: 0.3311 - val_acc: 0.4018\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3339 - acc: 0.3920 - val_loss: 0.3308 - val_acc: 0.3869\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3338 - acc: 0.3914 - val_loss: 0.3315 - val_acc: 0.3742\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3339 - acc: 0.3877 - val_loss: 0.3310 - val_acc: 0.3795\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3337 - acc: 0.3895 - val_loss: 0.3307 - val_acc: 0.3922\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3336 - acc: 0.3912 - val_loss: 0.3307 - val_acc: 0.3922\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3336 - acc: 0.3896 - val_loss: 0.3306 - val_acc: 0.3917\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3336 - acc: 0.3913 - val_loss: 0.3307 - val_acc: 0.3950\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3336 - acc: 0.3905 - val_loss: 0.3306 - val_acc: 0.3891\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3336 - acc: 0.3902 - val_loss: 0.3307 - val_acc: 0.3866\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3336 - acc: 0.3903 - val_loss: 0.3307 - val_acc: 0.3972\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3337 - acc: 0.3933 - val_loss: 0.3308 - val_acc: 0.3830\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3338 - acc: 0.3878 - val_loss: 0.3309 - val_acc: 0.3809\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3337 - acc: 0.3914 - val_loss: 0.3308 - val_acc: 0.4007\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.8486 - acc: 0.3931 - val_loss: 1.2762 - val_acc: 0.3626\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3356 - acc: 0.3462 - val_loss: 1.4123 - val_acc: 0.3265\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3889 - acc: 0.3314 - val_loss: 1.3599 - val_acc: 0.3381\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2948 - acc: 0.3549 - val_loss: 1.2446 - val_acc: 0.3676\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1934 - acc: 0.3776 - val_loss: 1.1664 - val_acc: 0.3801\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1398 - acc: 0.3809 - val_loss: 1.1259 - val_acc: 0.3767\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1049 - acc: 0.3797 - val_loss: 1.0799 - val_acc: 0.3802\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0514 - acc: 0.3871 - val_loss: 1.0170 - val_acc: 0.3910\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9722 - acc: 0.4001 - val_loss: 0.9050 - val_acc: 0.4047\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8405 - acc: 0.4227 - val_loss: 0.7565 - val_acc: 0.4432\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6950 - acc: 0.4654 - val_loss: 0.6198 - val_acc: 0.4821\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5692 - acc: 0.4939 - val_loss: 0.5150 - val_acc: 0.4970\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4791 - acc: 0.5040 - val_loss: 0.4428 - val_acc: 0.5083\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4178 - acc: 0.5208 - val_loss: 0.3966 - val_acc: 0.5278\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3804 - acc: 0.5372 - val_loss: 0.3712 - val_acc: 0.5389\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3610 - acc: 0.5396 - val_loss: 0.3603 - val_acc: 0.4936\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3543 - acc: 0.4739 - val_loss: 0.3611 - val_acc: 0.4144\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3580 - acc: 0.4066 - val_loss: 0.3567 - val_acc: 0.4442\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3602 - acc: 0.4529 - val_loss: 0.3834 - val_acc: 0.3491\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3812 - acc: 0.3555 - val_loss: 0.3552 - val_acc: 0.4461\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4051 - acc: 0.5061 - val_loss: 0.3594 - val_acc: 0.4529\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3810 - acc: 0.3512 - val_loss: 0.3813 - val_acc: 0.3437\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3716 - acc: 0.4389 - val_loss: 0.4403 - val_acc: 0.5192\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4050 - acc: 0.4879 - val_loss: 0.3546 - val_acc: 0.3944\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3550 - acc: 0.3632 - val_loss: 0.3562 - val_acc: 0.3789\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3529 - acc: 0.4150 - val_loss: 0.3718 - val_acc: 0.4494\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3555 - acc: 0.4236 - val_loss: 0.3546 - val_acc: 0.3900\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3480 - acc: 0.3958 - val_loss: 0.3539 - val_acc: 0.4017\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3478 - acc: 0.3931 - val_loss: 0.3539 - val_acc: 0.3864\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3469 - acc: 0.4108 - val_loss: 0.3525 - val_acc: 0.4239\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3476 - acc: 0.4033 - val_loss: 0.3586 - val_acc: 0.3740\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3470 - acc: 0.4048 - val_loss: 0.3515 - val_acc: 0.4367\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3456 - acc: 0.4318 - val_loss: 0.3517 - val_acc: 0.3989\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3448 - acc: 0.4077 - val_loss: 0.3490 - val_acc: 0.4223\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3431 - acc: 0.4221 - val_loss: 0.3485 - val_acc: 0.4106\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3425 - acc: 0.4155 - val_loss: 0.3485 - val_acc: 0.4263\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3461 - acc: 0.4381 - val_loss: 0.3477 - val_acc: 0.4043\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3433 - acc: 0.3901 - val_loss: 0.3474 - val_acc: 0.3993\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3416 - acc: 0.4144 - val_loss: 0.3466 - val_acc: 0.4073\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3408 - acc: 0.4050 - val_loss: 0.3461 - val_acc: 0.4064\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3403 - acc: 0.4132 - val_loss: 0.3462 - val_acc: 0.3975\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3401 - acc: 0.4020 - val_loss: 0.3451 - val_acc: 0.4113\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3391 - acc: 0.4136 - val_loss: 0.3446 - val_acc: 0.4053\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3387 - acc: 0.4083 - val_loss: 0.3441 - val_acc: 0.4072\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3382 - acc: 0.4108 - val_loss: 0.3436 - val_acc: 0.4040\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3378 - acc: 0.4044 - val_loss: 0.3432 - val_acc: 0.4042\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3373 - acc: 0.4072 - val_loss: 0.3428 - val_acc: 0.4029\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3369 - acc: 0.4051 - val_loss: 0.3423 - val_acc: 0.4017\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3366 - acc: 0.4056 - val_loss: 0.3419 - val_acc: 0.4019\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3362 - acc: 0.4051 - val_loss: 0.3416 - val_acc: 0.4006\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.4767 - acc: 0.1412 - val_loss: 1.3918 - val_acc: 0.0522\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2171 - acc: 0.0574 - val_loss: 1.1026 - val_acc: 0.0763\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0015 - acc: 0.0627 - val_loss: 0.8249 - val_acc: 0.0273\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6721 - acc: 0.0081 - val_loss: 0.5196 - val_acc: 9.0000e-05\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4531 - acc: 0.0059 - val_loss: 0.3858 - val_acc: 0.0462\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3837 - acc: 0.0778 - val_loss: 0.4158 - val_acc: 0.0040\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3777 - acc: 0.0707 - val_loss: 0.3637 - val_acc: 0.1210\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3664 - acc: 0.0472 - val_loss: 0.3512 - val_acc: 0.0988\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3581 - acc: 0.1032 - val_loss: 0.3502 - val_acc: 0.0456\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3505 - acc: 0.0675 - val_loss: 0.3755 - val_acc: 0.1430\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3765 - acc: 0.1297 - val_loss: 0.3506 - val_acc: 0.0607\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3506 - acc: 0.0675 - val_loss: 0.3583 - val_acc: 0.0361\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3553 - acc: 0.0591 - val_loss: 0.3507 - val_acc: 0.1029\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3489 - acc: 0.0484 - val_loss: 0.3433 - val_acc: 0.0682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3485 - acc: 0.0716 - val_loss: 0.3583 - val_acc: 0.0164\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3489 - acc: 0.0573 - val_loss: 0.3439 - val_acc: 0.0892\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3422 - acc: 0.0577 - val_loss: 0.3395 - val_acc: 0.0665\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3403 - acc: 0.0667 - val_loss: 0.3391 - val_acc: 0.0562\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3393 - acc: 0.0646 - val_loss: 0.3381 - val_acc: 0.0616\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3385 - acc: 0.0608 - val_loss: 0.3375 - val_acc: 0.0672\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3379 - acc: 0.0631 - val_loss: 0.3369 - val_acc: 0.0597\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3374 - acc: 0.0633 - val_loss: 0.3364 - val_acc: 0.0632\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3369 - acc: 0.0606 - val_loss: 0.3361 - val_acc: 0.0660\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3365 - acc: 0.0615 - val_loss: 0.3357 - val_acc: 0.0641\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3361 - acc: 0.0611 - val_loss: 0.3354 - val_acc: 0.0584\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3358 - acc: 0.0613 - val_loss: 0.3352 - val_acc: 0.0567\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3356 - acc: 0.0599 - val_loss: 0.3349 - val_acc: 0.0583\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3353 - acc: 0.0573 - val_loss: 0.3347 - val_acc: 0.0628\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3351 - acc: 0.0579 - val_loss: 0.3345 - val_acc: 0.0628\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3350 - acc: 0.0570 - val_loss: 0.3345 - val_acc: 0.0663\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3349 - acc: 0.0558 - val_loss: 0.3343 - val_acc: 0.0615\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3348 - acc: 0.0565 - val_loss: 0.3342 - val_acc: 0.0583\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3347 - acc: 0.0555 - val_loss: 0.3341 - val_acc: 0.0545\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3345 - acc: 0.0565 - val_loss: 0.3340 - val_acc: 0.0539\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3344 - acc: 0.0551 - val_loss: 0.3340 - val_acc: 0.0538\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3343 - acc: 0.0532 - val_loss: 0.3340 - val_acc: 0.0493\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3343 - acc: 0.0531 - val_loss: 0.3339 - val_acc: 0.0552\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3343 - acc: 0.0531 - val_loss: 0.3339 - val_acc: 0.0543\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3342 - acc: 0.0516 - val_loss: 0.3339 - val_acc: 0.0567\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3342 - acc: 0.0510 - val_loss: 0.3339 - val_acc: 0.0569\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3342 - acc: 0.0520 - val_loss: 0.3338 - val_acc: 0.0554\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3341 - acc: 0.0517 - val_loss: 0.3338 - val_acc: 0.0508\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3341 - acc: 0.0506 - val_loss: 0.3338 - val_acc: 0.0477\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3341 - acc: 0.0518 - val_loss: 0.3339 - val_acc: 0.0466\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3342 - acc: 0.0492 - val_loss: 0.3339 - val_acc: 0.0449\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3341 - acc: 0.0509 - val_loss: 0.3339 - val_acc: 0.0453\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3341 - acc: 0.0493 - val_loss: 0.3338 - val_acc: 0.0460\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3341 - acc: 0.0500 - val_loss: 0.3339 - val_acc: 0.0587\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3341 - acc: 0.0510 - val_loss: 0.3338 - val_acc: 0.0541\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3341 - acc: 0.0504 - val_loss: 0.3338 - val_acc: 0.0539\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.5340 - acc: 0.1744 - val_loss: 1.4281 - val_acc: 0.0529\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3244 - acc: 0.0539 - val_loss: 1.1702 - val_acc: 0.0634\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1272 - acc: 0.0735 - val_loss: 1.0379 - val_acc: 0.0671\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8974 - acc: 0.0404 - val_loss: 0.7158 - val_acc: 0.0106\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6049 - acc: 0.0027 - val_loss: 0.4940 - val_acc: 2.2500e-04\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4322 - acc: 0.0205 - val_loss: 0.3789 - val_acc: 0.0489\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3598 - acc: 0.0558 - val_loss: 0.3569 - val_acc: 0.0792\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3559 - acc: 0.0717 - val_loss: 0.3755 - val_acc: 0.0417\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3625 - acc: 0.0815 - val_loss: 0.3650 - val_acc: 0.1105\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3562 - acc: 0.0802 - val_loss: 0.3565 - val_acc: 0.0598\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3522 - acc: 0.0823 - val_loss: 0.3563 - val_acc: 0.0546\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3509 - acc: 0.0641 - val_loss: 0.3542 - val_acc: 0.0824\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3520 - acc: 0.0593 - val_loss: 0.3550 - val_acc: 0.0492\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3539 - acc: 0.0879 - val_loss: 0.3526 - val_acc: 0.0591\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3528 - acc: 0.0563 - val_loss: 0.3598 - val_acc: 0.1064\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3506 - acc: 0.0647 - val_loss: 0.3515 - val_acc: 0.0573\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3551 - acc: 0.0969 - val_loss: 0.3523 - val_acc: 0.0876\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3506 - acc: 0.0616 - val_loss: 0.3567 - val_acc: 0.1032\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3469 - acc: 0.0710 - val_loss: 0.3495 - val_acc: 0.0675\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3454 - acc: 0.0695 - val_loss: 0.3503 - val_acc: 0.0514\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3455 - acc: 0.0709 - val_loss: 0.3485 - val_acc: 0.0598\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3444 - acc: 0.0580 - val_loss: 0.3485 - val_acc: 0.0532\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3512 - acc: 0.0813 - val_loss: 0.3675 - val_acc: 0.0221\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3495 - acc: 0.0526 - val_loss: 0.3601 - val_acc: 0.0221\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3496 - acc: 0.0641 - val_loss: 0.3489 - val_acc: 0.0808\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3439 - acc: 0.0533 - val_loss: 0.3475 - val_acc: 0.0830\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3425 - acc: 0.0682 - val_loss: 0.3460 - val_acc: 0.0559\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3417 - acc: 0.0753 - val_loss: 0.3456 - val_acc: 0.0780\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3408 - acc: 0.0631 - val_loss: 0.3448 - val_acc: 0.0737\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3403 - acc: 0.0635 - val_loss: 0.3439 - val_acc: 0.0625\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3394 - acc: 0.0650 - val_loss: 0.3438 - val_acc: 0.0559\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3388 - acc: 0.0614 - val_loss: 0.3432 - val_acc: 0.0662\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3384 - acc: 0.0632 - val_loss: 0.3429 - val_acc: 0.0650\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3380 - acc: 0.0617 - val_loss: 0.3426 - val_acc: 0.0669\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3377 - acc: 0.0622 - val_loss: 0.3423 - val_acc: 0.0592\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3374 - acc: 0.0620 - val_loss: 0.3421 - val_acc: 0.0569\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3371 - acc: 0.0609 - val_loss: 0.3418 - val_acc: 0.0619\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3369 - acc: 0.0596 - val_loss: 0.3417 - val_acc: 0.0554\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3367 - acc: 0.0606 - val_loss: 0.3416 - val_acc: 0.0546\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3366 - acc: 0.0589 - val_loss: 0.3415 - val_acc: 0.0527\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3364 - acc: 0.0588 - val_loss: 0.3412 - val_acc: 0.0567\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3362 - acc: 0.0582 - val_loss: 0.3413 - val_acc: 0.0522\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3361 - acc: 0.0584 - val_loss: 0.3410 - val_acc: 0.0567\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3361 - acc: 0.0556 - val_loss: 0.3410 - val_acc: 0.0581\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3360 - acc: 0.0566 - val_loss: 0.3410 - val_acc: 0.0587\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3359 - acc: 0.0558 - val_loss: 0.3409 - val_acc: 0.0561\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3358 - acc: 0.0551 - val_loss: 0.3409 - val_acc: 0.0549\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3358 - acc: 0.0554 - val_loss: 0.3412 - val_acc: 0.0466\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3359 - acc: 0.0545 - val_loss: 0.3410 - val_acc: 0.0470\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3359 - acc: 0.0528 - val_loss: 0.3414 - val_acc: 0.0416\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.6391 - acc: 0.3913 - val_loss: 1.3468 - val_acc: 0.3474\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3473 - acc: 0.3462 - val_loss: 1.2372 - val_acc: 0.3719\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1401 - acc: 0.3874 - val_loss: 1.0556 - val_acc: 0.3839\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9669 - acc: 0.3925 - val_loss: 0.8276 - val_acc: 0.4154\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7128 - acc: 0.4601 - val_loss: 0.5946 - val_acc: 0.4955\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5237 - acc: 0.5000 - val_loss: 0.4489 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4069 - acc: 0.5185 - val_loss: 0.3694 - val_acc: 0.5280\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3564 - acc: 0.4791 - val_loss: 0.3499 - val_acc: 0.4290\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3502 - acc: 0.4125 - val_loss: 0.3519 - val_acc: 0.4118\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3518 - acc: 0.3987 - val_loss: 0.3524 - val_acc: 0.3868\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3507 - acc: 0.4297 - val_loss: 0.3484 - val_acc: 0.4267\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3497 - acc: 0.4164 - val_loss: 0.3479 - val_acc: 0.4354\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3566 - acc: 0.4133 - val_loss: 0.3523 - val_acc: 0.4749\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3527 - acc: 0.4574 - val_loss: 0.3531 - val_acc: 0.4115\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3488 - acc: 0.4407 - val_loss: 0.3463 - val_acc: 0.4328\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3466 - acc: 0.4182 - val_loss: 0.3461 - val_acc: 0.4297\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3471 - acc: 0.4169 - val_loss: 0.3480 - val_acc: 0.3975\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3479 - acc: 0.4358 - val_loss: 0.3453 - val_acc: 0.4290\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3451 - acc: 0.4155 - val_loss: 0.3452 - val_acc: 0.4051\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3449 - acc: 0.4138 - val_loss: 0.3448 - val_acc: 0.4300\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3444 - acc: 0.4189 - val_loss: 0.3440 - val_acc: 0.4209\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3439 - acc: 0.4200 - val_loss: 0.3436 - val_acc: 0.4174\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3434 - acc: 0.4212 - val_loss: 0.3433 - val_acc: 0.4119\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3430 - acc: 0.4175 - val_loss: 0.3430 - val_acc: 0.4095\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3428 - acc: 0.4162 - val_loss: 0.3427 - val_acc: 0.4093\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3424 - acc: 0.4141 - val_loss: 0.3423 - val_acc: 0.4146\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3421 - acc: 0.4141 - val_loss: 0.3421 - val_acc: 0.4102\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3420 - acc: 0.4137 - val_loss: 0.3418 - val_acc: 0.4089\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3418 - acc: 0.4133 - val_loss: 0.3417 - val_acc: 0.4144\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3416 - acc: 0.4121 - val_loss: 0.3414 - val_acc: 0.4072\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3414 - acc: 0.4110 - val_loss: 0.3412 - val_acc: 0.4086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3416 - acc: 0.4060 - val_loss: 0.3412 - val_acc: 0.4175\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3412 - acc: 0.4130 - val_loss: 0.3409 - val_acc: 0.4062\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3409 - acc: 0.4100 - val_loss: 0.3409 - val_acc: 0.3991\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3408 - acc: 0.4077 - val_loss: 0.3406 - val_acc: 0.4030\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3406 - acc: 0.4077 - val_loss: 0.3404 - val_acc: 0.4055\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3405 - acc: 0.4069 - val_loss: 0.3403 - val_acc: 0.4074\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3404 - acc: 0.4060 - val_loss: 0.3403 - val_acc: 0.4015\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3404 - acc: 0.4061 - val_loss: 0.3402 - val_acc: 0.4015\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3403 - acc: 0.4051 - val_loss: 0.3401 - val_acc: 0.4035\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3403 - acc: 0.4052 - val_loss: 0.3401 - val_acc: 0.3992\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3402 - acc: 0.4038 - val_loss: 0.3400 - val_acc: 0.4031\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3402 - acc: 0.4053 - val_loss: 0.3400 - val_acc: 0.4008\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3402 - acc: 0.4039 - val_loss: 0.3401 - val_acc: 0.3959\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3402 - acc: 0.4026 - val_loss: 0.3400 - val_acc: 0.3970\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3401 - acc: 0.4029 - val_loss: 0.3399 - val_acc: 0.4019\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3401 - acc: 0.4030 - val_loss: 0.3400 - val_acc: 0.3964\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3401 - acc: 0.4023 - val_loss: 0.3399 - val_acc: 0.3988\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3401 - acc: 0.4029 - val_loss: 0.3400 - val_acc: 0.3952\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3401 - acc: 0.4008 - val_loss: 0.3399 - val_acc: 0.4015\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.7473 - acc: 0.3928 - val_loss: 1.2971 - val_acc: 0.3629\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3623 - acc: 0.3457 - val_loss: 1.3623 - val_acc: 0.3440\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2868 - acc: 0.3626 - val_loss: 1.1899 - val_acc: 0.3844\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1371 - acc: 0.3894 - val_loss: 1.0796 - val_acc: 0.3884\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0352 - acc: 0.3902 - val_loss: 0.9608 - val_acc: 0.3961\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8915 - acc: 0.4108 - val_loss: 0.8016 - val_acc: 0.4327\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7348 - acc: 0.4552 - val_loss: 0.6544 - val_acc: 0.4788\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6010 - acc: 0.4921 - val_loss: 0.5406 - val_acc: 0.4985\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4984 - acc: 0.5013 - val_loss: 0.4533 - val_acc: 0.5022\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4217 - acc: 0.5129 - val_loss: 0.3938 - val_acc: 0.5238\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3741 - acc: 0.5368 - val_loss: 0.3634 - val_acc: 0.5257\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3566 - acc: 0.5026 - val_loss: 0.3578 - val_acc: 0.4634\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3521 - acc: 0.4364 - val_loss: 0.3605 - val_acc: 0.3816\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3537 - acc: 0.3904 - val_loss: 0.3561 - val_acc: 0.4182\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3497 - acc: 0.4173 - val_loss: 0.3553 - val_acc: 0.4147\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3528 - acc: 0.4119 - val_loss: 0.3541 - val_acc: 0.4432\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3503 - acc: 0.4659 - val_loss: 0.3538 - val_acc: 0.4511\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3489 - acc: 0.4339 - val_loss: 0.3532 - val_acc: 0.4379\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3480 - acc: 0.4475 - val_loss: 0.3531 - val_acc: 0.4255\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3474 - acc: 0.4227 - val_loss: 0.3525 - val_acc: 0.4288\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3467 - acc: 0.4348 - val_loss: 0.3525 - val_acc: 0.4213\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3463 - acc: 0.4271 - val_loss: 0.3517 - val_acc: 0.4344\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3458 - acc: 0.4329 - val_loss: 0.3517 - val_acc: 0.4201\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3456 - acc: 0.4280 - val_loss: 0.3511 - val_acc: 0.4354\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3451 - acc: 0.4325 - val_loss: 0.3507 - val_acc: 0.4210\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3447 - acc: 0.4231 - val_loss: 0.3503 - val_acc: 0.4276\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3442 - acc: 0.4266 - val_loss: 0.3498 - val_acc: 0.4242\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3438 - acc: 0.4271 - val_loss: 0.3495 - val_acc: 0.4238\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3435 - acc: 0.4263 - val_loss: 0.3491 - val_acc: 0.4224\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3461 - acc: 0.4063 - val_loss: 0.3486 - val_acc: 0.4308\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3468 - acc: 0.4227 - val_loss: 0.3569 - val_acc: 0.3930\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3460 - acc: 0.4414 - val_loss: 0.3485 - val_acc: 0.4433\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3432 - acc: 0.4220 - val_loss: 0.3475 - val_acc: 0.4304\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3418 - acc: 0.4301 - val_loss: 0.3472 - val_acc: 0.4118\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3413 - acc: 0.4170 - val_loss: 0.3471 - val_acc: 0.4209\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3411 - acc: 0.4137 - val_loss: 0.3476 - val_acc: 0.4005\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3409 - acc: 0.4171 - val_loss: 0.3466 - val_acc: 0.4280\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3404 - acc: 0.4184 - val_loss: 0.3459 - val_acc: 0.4144\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3402 - acc: 0.4233 - val_loss: 0.3463 - val_acc: 0.4243\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3399 - acc: 0.4146 - val_loss: 0.3457 - val_acc: 0.4088\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3396 - acc: 0.4142 - val_loss: 0.3454 - val_acc: 0.4112\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3394 - acc: 0.4155 - val_loss: 0.3452 - val_acc: 0.4113\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3392 - acc: 0.4135 - val_loss: 0.3451 - val_acc: 0.4157\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3390 - acc: 0.4155 - val_loss: 0.3449 - val_acc: 0.4091\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3389 - acc: 0.4141 - val_loss: 0.3448 - val_acc: 0.4115\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3388 - acc: 0.4094 - val_loss: 0.3446 - val_acc: 0.4132\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3387 - acc: 0.4146 - val_loss: 0.3445 - val_acc: 0.4082\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3385 - acc: 0.4111 - val_loss: 0.3444 - val_acc: 0.4073\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3385 - acc: 0.4135 - val_loss: 0.3443 - val_acc: 0.4093\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3385 - acc: 0.4082 - val_loss: 0.3444 - val_acc: 0.4168\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.8054 - acc: 0.2088 - val_loss: 1.3541 - val_acc: 0.0632\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.4620 - acc: 0.0568 - val_loss: 1.5199 - val_acc: 0.0528\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.4725 - acc: 0.0526 - val_loss: 1.3823 - val_acc: 0.0530\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3111 - acc: 0.0555 - val_loss: 1.2390 - val_acc: 0.0597\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2037 - acc: 0.0631 - val_loss: 1.1644 - val_acc: 0.0672\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1398 - acc: 0.0686 - val_loss: 1.1040 - val_acc: 0.0665\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0572 - acc: 0.0620 - val_loss: 0.9911 - val_acc: 0.0536\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9240 - acc: 0.0442 - val_loss: 0.8461 - val_acc: 0.0307\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7784 - acc: 0.0208 - val_loss: 0.6984 - val_acc: 0.0089\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6406 - acc: 0.0032 - val_loss: 0.5769 - val_acc: 9.0000e-05\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5324 - acc: 1.0000e-05 - val_loss: 0.4832 - val_acc: 5.5000e-05\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4521 - acc: 0.0020 - val_loss: 0.4179 - val_acc: 0.0088\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3986 - acc: 0.0241 - val_loss: 0.3778 - val_acc: 0.0404\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3689 - acc: 0.0462 - val_loss: 0.3588 - val_acc: 0.0525\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3575 - acc: 0.0714 - val_loss: 0.3530 - val_acc: 0.0686\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3545 - acc: 0.0608 - val_loss: 0.3524 - val_acc: 0.0645\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3535 - acc: 0.0723 - val_loss: 0.3523 - val_acc: 0.0618\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3539 - acc: 0.0615 - val_loss: 0.3513 - val_acc: 0.0741\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3541 - acc: 0.0841 - val_loss: 0.3518 - val_acc: 0.0822\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3537 - acc: 0.0613 - val_loss: 0.3523 - val_acc: 0.0522\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3526 - acc: 0.0658 - val_loss: 0.3510 - val_acc: 0.0794\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3519 - acc: 0.0681 - val_loss: 0.3498 - val_acc: 0.0646\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3511 - acc: 0.0705 - val_loss: 0.3494 - val_acc: 0.0680\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3508 - acc: 0.0661 - val_loss: 0.3490 - val_acc: 0.0690\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3505 - acc: 0.0701 - val_loss: 0.3486 - val_acc: 0.0663\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3501 - acc: 0.0683 - val_loss: 0.3486 - val_acc: 0.0736\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3500 - acc: 0.0688 - val_loss: 0.3481 - val_acc: 0.0619\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3496 - acc: 0.0695 - val_loss: 0.3478 - val_acc: 0.0716\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3494 - acc: 0.0646 - val_loss: 0.3474 - val_acc: 0.0619\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3490 - acc: 0.0664 - val_loss: 0.3470 - val_acc: 0.0628\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3487 - acc: 0.0657 - val_loss: 0.3466 - val_acc: 0.0657\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3483 - acc: 0.0637 - val_loss: 0.3463 - val_acc: 0.0654\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3481 - acc: 0.0673 - val_loss: 0.3462 - val_acc: 0.0584\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3479 - acc: 0.0618 - val_loss: 0.3459 - val_acc: 0.0691\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3476 - acc: 0.0673 - val_loss: 0.3455 - val_acc: 0.0616\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3474 - acc: 0.0630 - val_loss: 0.3454 - val_acc: 0.0685\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3472 - acc: 0.0673 - val_loss: 0.3452 - val_acc: 0.0584\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3472 - acc: 0.0577 - val_loss: 0.3449 - val_acc: 0.0631\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3469 - acc: 0.0657 - val_loss: 0.3447 - val_acc: 0.0643\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3467 - acc: 0.0623 - val_loss: 0.3445 - val_acc: 0.0615\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3466 - acc: 0.0637 - val_loss: 0.3444 - val_acc: 0.0612\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3464 - acc: 0.0635 - val_loss: 0.3443 - val_acc: 0.0613\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3464 - acc: 0.0617 - val_loss: 0.3442 - val_acc: 0.0604\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3465 - acc: 0.0667 - val_loss: 0.3444 - val_acc: 0.0544\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3464 - acc: 0.0600 - val_loss: 0.3442 - val_acc: 0.0659\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3463 - acc: 0.0602 - val_loss: 0.3440 - val_acc: 0.0622\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3461 - acc: 0.0627 - val_loss: 0.3440 - val_acc: 0.0558\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3460 - acc: 0.0593 - val_loss: 0.3439 - val_acc: 0.0625\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3460 - acc: 0.0599 - val_loss: 0.3438 - val_acc: 0.0587\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3459 - acc: 0.0596 - val_loss: 0.3438 - val_acc: 0.0606\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 1s 3us/step - loss: 1.4225 - acc: 0.3577 - val_loss: 1.2666 - val_acc: 0.3714\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1415 - acc: 0.3757 - val_loss: 1.0000 - val_acc: 0.3907\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8149 - acc: 0.4343 - val_loss: 0.5996 - val_acc: 0.5015\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4849 - acc: 0.5134 - val_loss: 0.3881 - val_acc: 0.5270\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3694 - acc: 0.4982 - val_loss: 0.3649 - val_acc: 0.3756\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3930 - acc: 0.4137 - val_loss: 0.5362 - val_acc: 0.4772\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4852 - acc: 0.3117 - val_loss: 0.3852 - val_acc: 0.3101\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3863 - acc: 0.4132 - val_loss: 0.3913 - val_acc: 0.3643\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3727 - acc: 0.4608 - val_loss: 0.3608 - val_acc: 0.4891\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3711 - acc: 0.4986 - val_loss: 0.3634 - val_acc: 0.5310\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3630 - acc: 0.4927 - val_loss: 0.3550 - val_acc: 0.4527\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3685 - acc: 0.4758 - val_loss: 0.3573 - val_acc: 0.4468\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3711 - acc: 0.3882 - val_loss: 0.3569 - val_acc: 0.3880\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3639 - acc: 0.4464 - val_loss: 0.3574 - val_acc: 0.4030\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3619 - acc: 0.4268 - val_loss: 0.3660 - val_acc: 0.4993\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3735 - acc: 0.4330 - val_loss: 0.3603 - val_acc: 0.4216\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3604 - acc: 0.4750 - val_loss: 0.3523 - val_acc: 0.4427\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3573 - acc: 0.4392 - val_loss: 0.3525 - val_acc: 0.4701\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3632 - acc: 0.4449 - val_loss: 0.3673 - val_acc: 0.3662\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3625 - acc: 0.4341 - val_loss: 0.3531 - val_acc: 0.4641\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3556 - acc: 0.4217 - val_loss: 0.3487 - val_acc: 0.4478\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3536 - acc: 0.4418 - val_loss: 0.3489 - val_acc: 0.4257\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3528 - acc: 0.4396 - val_loss: 0.3479 - val_acc: 0.4469\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3522 - acc: 0.4311 - val_loss: 0.3469 - val_acc: 0.4328\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3520 - acc: 0.4364 - val_loss: 0.3496 - val_acc: 0.4512\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3546 - acc: 0.4176 - val_loss: 0.3464 - val_acc: 0.4280\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3521 - acc: 0.4391 - val_loss: 0.3463 - val_acc: 0.4248\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3509 - acc: 0.4302 - val_loss: 0.3458 - val_acc: 0.4327\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3506 - acc: 0.4279 - val_loss: 0.3456 - val_acc: 0.4308\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3506 - acc: 0.4233 - val_loss: 0.3459 - val_acc: 0.4404\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3502 - acc: 0.4303 - val_loss: 0.3450 - val_acc: 0.4240\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3499 - acc: 0.4256 - val_loss: 0.3447 - val_acc: 0.4220\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3496 - acc: 0.4235 - val_loss: 0.3445 - val_acc: 0.4238\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3494 - acc: 0.4233 - val_loss: 0.3443 - val_acc: 0.4270\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3492 - acc: 0.4220 - val_loss: 0.3442 - val_acc: 0.4263\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3491 - acc: 0.4218 - val_loss: 0.3440 - val_acc: 0.4208\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3490 - acc: 0.4201 - val_loss: 0.3440 - val_acc: 0.4252\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3489 - acc: 0.4197 - val_loss: 0.3438 - val_acc: 0.4207\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3488 - acc: 0.4192 - val_loss: 0.3437 - val_acc: 0.4196\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3488 - acc: 0.4191 - val_loss: 0.3437 - val_acc: 0.4215\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3487 - acc: 0.4183 - val_loss: 0.3436 - val_acc: 0.4205\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3488 - acc: 0.4175 - val_loss: 0.3438 - val_acc: 0.4256\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3489 - acc: 0.4159 - val_loss: 0.3445 - val_acc: 0.4328\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3488 - acc: 0.4167 - val_loss: 0.3436 - val_acc: 0.4219\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3486 - acc: 0.4166 - val_loss: 0.3435 - val_acc: 0.4144\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3486 - acc: 0.4161 - val_loss: 0.3434 - val_acc: 0.4155\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3485 - acc: 0.4153 - val_loss: 0.3435 - val_acc: 0.4207\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3486 - acc: 0.4158 - val_loss: 0.3435 - val_acc: 0.4212\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3485 - acc: 0.4151 - val_loss: 0.3434 - val_acc: 0.4138\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3485 - acc: 0.4151 - val_loss: 0.3434 - val_acc: 0.4183\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.5765 - acc: 0.3816 - val_loss: 1.4319 - val_acc: 0.3344\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3152 - acc: 0.3607 - val_loss: 1.1227 - val_acc: 0.3996\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0221 - acc: 0.3933 - val_loss: 0.8940 - val_acc: 0.3915\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7610 - acc: 0.4432 - val_loss: 0.6135 - val_acc: 0.4890\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5395 - acc: 0.4977 - val_loss: 0.4551 - val_acc: 0.4999\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4100 - acc: 0.5285 - val_loss: 0.3710 - val_acc: 0.5505\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3604 - acc: 0.4775 - val_loss: 0.3557 - val_acc: 0.4335\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3576 - acc: 0.4195 - val_loss: 0.3587 - val_acc: 0.3983\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3573 - acc: 0.4055 - val_loss: 0.3552 - val_acc: 0.4263\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3555 - acc: 0.4476 - val_loss: 0.3545 - val_acc: 0.4359\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3548 - acc: 0.4405 - val_loss: 0.3621 - val_acc: 0.4780\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3651 - acc: 0.4657 - val_loss: 0.3580 - val_acc: 0.3948\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3563 - acc: 0.4099 - val_loss: 0.3550 - val_acc: 0.4276\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3542 - acc: 0.4335 - val_loss: 0.3540 - val_acc: 0.4373\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3536 - acc: 0.4390 - val_loss: 0.3537 - val_acc: 0.4436\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3537 - acc: 0.4500 - val_loss: 0.3538 - val_acc: 0.4465\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3533 - acc: 0.4334 - val_loss: 0.3534 - val_acc: 0.4400\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3544 - acc: 0.4427 - val_loss: 0.3555 - val_acc: 0.4100\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3541 - acc: 0.4358 - val_loss: 0.3531 - val_acc: 0.4408\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3535 - acc: 0.4301 - val_loss: 0.3530 - val_acc: 0.4502\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3525 - acc: 0.4416 - val_loss: 0.3527 - val_acc: 0.4317\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3522 - acc: 0.4407 - val_loss: 0.3524 - val_acc: 0.4283\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3521 - acc: 0.4325 - val_loss: 0.3518 - val_acc: 0.4380\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3517 - acc: 0.4335 - val_loss: 0.3519 - val_acc: 0.4459\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3516 - acc: 0.4346 - val_loss: 0.3513 - val_acc: 0.4342\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3511 - acc: 0.4361 - val_loss: 0.3514 - val_acc: 0.4228\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3511 - acc: 0.4286 - val_loss: 0.3521 - val_acc: 0.4171\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3512 - acc: 0.4363 - val_loss: 0.3508 - val_acc: 0.4271\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3508 - acc: 0.4292 - val_loss: 0.3506 - val_acc: 0.4327\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3505 - acc: 0.4292 - val_loss: 0.3504 - val_acc: 0.4301\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3503 - acc: 0.4282 - val_loss: 0.3503 - val_acc: 0.4280\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3501 - acc: 0.4282 - val_loss: 0.3503 - val_acc: 0.4238\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3501 - acc: 0.4272 - val_loss: 0.3502 - val_acc: 0.4312\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3501 - acc: 0.4265 - val_loss: 0.3501 - val_acc: 0.4284\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3500 - acc: 0.4260 - val_loss: 0.3500 - val_acc: 0.4237\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3501 - acc: 0.4265 - val_loss: 0.3502 - val_acc: 0.4175\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3500 - acc: 0.4273 - val_loss: 0.3505 - val_acc: 0.4130\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3500 - acc: 0.4254 - val_loss: 0.3502 - val_acc: 0.4150\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3498 - acc: 0.4243 - val_loss: 0.3498 - val_acc: 0.4220\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3497 - acc: 0.4240 - val_loss: 0.3498 - val_acc: 0.4237\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3497 - acc: 0.4244 - val_loss: 0.3498 - val_acc: 0.4198\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3497 - acc: 0.4234 - val_loss: 0.3499 - val_acc: 0.4162\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3497 - acc: 0.4234 - val_loss: 0.3497 - val_acc: 0.4198\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3496 - acc: 0.4224 - val_loss: 0.3497 - val_acc: 0.4231\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3496 - acc: 0.4236 - val_loss: 0.3497 - val_acc: 0.4180\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3496 - acc: 0.4235 - val_loss: 0.3497 - val_acc: 0.4187\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3497 - acc: 0.4241 - val_loss: 0.3502 - val_acc: 0.4091\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3498 - acc: 0.4216 - val_loss: 0.3499 - val_acc: 0.4122\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3498 - acc: 0.4218 - val_loss: 0.3498 - val_acc: 0.4136\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3500 - acc: 0.4230 - val_loss: 0.3501 - val_acc: 0.4103\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.6913 - acc: 0.3745 - val_loss: 1.3965 - val_acc: 0.3385\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.4467 - acc: 0.3264 - val_loss: 1.3810 - val_acc: 0.3397\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2701 - acc: 0.3598 - val_loss: 1.1696 - val_acc: 0.3655\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1476 - acc: 0.3559 - val_loss: 1.1162 - val_acc: 0.3527\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0728 - acc: 0.3628 - val_loss: 1.0118 - val_acc: 0.3813\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9623 - acc: 0.3974 - val_loss: 0.8840 - val_acc: 0.4140\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8175 - acc: 0.4301 - val_loss: 0.7369 - val_acc: 0.4462\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6644 - acc: 0.4674 - val_loss: 0.5660 - val_acc: 0.5053\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4951 - acc: 0.5383 - val_loss: 0.4145 - val_acc: 0.5501\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3731 - acc: 0.5409 - val_loss: 0.3402 - val_acc: 0.5394\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3143 - acc: 0.5347 - val_loss: 0.3032 - val_acc: 0.4579\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2918 - acc: 0.4108 - val_loss: 0.2952 - val_acc: 0.3981\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2910 - acc: 0.3647 - val_loss: 0.2994 - val_acc: 0.3391\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2853 - acc: 0.3744 - val_loss: 0.2912 - val_acc: 0.3932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2832 - acc: 0.3919 - val_loss: 0.2918 - val_acc: 0.3554\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2825 - acc: 0.3723 - val_loss: 0.2942 - val_acc: 0.4288\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2946 - acc: 0.4185 - val_loss: 0.3124 - val_acc: 0.2907\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2944 - acc: 0.3221 - val_loss: 0.2868 - val_acc: 0.4170\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3032 - acc: 0.4565 - val_loss: 0.2895 - val_acc: 0.4201\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2827 - acc: 0.3397 - val_loss: 0.2825 - val_acc: 0.3686\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2775 - acc: 0.4046 - val_loss: 0.2853 - val_acc: 0.4105\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2751 - acc: 0.3684 - val_loss: 0.2820 - val_acc: 0.3516\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2714 - acc: 0.3869 - val_loss: 0.2819 - val_acc: 0.3479\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2756 - acc: 0.3499 - val_loss: 0.2769 - val_acc: 0.4189\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2679 - acc: 0.4086 - val_loss: 0.2731 - val_acc: 0.3970\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2665 - acc: 0.4087 - val_loss: 0.2746 - val_acc: 0.4077\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2640 - acc: 0.3861 - val_loss: 0.2729 - val_acc: 0.3837\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2641 - acc: 0.3749 - val_loss: 0.2742 - val_acc: 0.3504\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2630 - acc: 0.3595 - val_loss: 0.2684 - val_acc: 0.3868\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2596 - acc: 0.3978 - val_loss: 0.2671 - val_acc: 0.3869\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2594 - acc: 0.3848 - val_loss: 0.2709 - val_acc: 0.4287\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2648 - acc: 0.4042 - val_loss: 0.3020 - val_acc: 0.2775\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2745 - acc: 0.3463 - val_loss: 0.2789 - val_acc: 0.4506\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2602 - acc: 0.3843 - val_loss: 0.2670 - val_acc: 0.3555\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2550 - acc: 0.3967 - val_loss: 0.2619 - val_acc: 0.3896\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2533 - acc: 0.3724 - val_loss: 0.2615 - val_acc: 0.3959\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2519 - acc: 0.3899 - val_loss: 0.2614 - val_acc: 0.3718\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2509 - acc: 0.3828 - val_loss: 0.2602 - val_acc: 0.3903\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2502 - acc: 0.3818 - val_loss: 0.2598 - val_acc: 0.3823\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2497 - acc: 0.3859 - val_loss: 0.2595 - val_acc: 0.3794\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2493 - acc: 0.3820 - val_loss: 0.2591 - val_acc: 0.3858\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2488 - acc: 0.3823 - val_loss: 0.2589 - val_acc: 0.3817\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2485 - acc: 0.3828 - val_loss: 0.2588 - val_acc: 0.3814\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2483 - acc: 0.3815 - val_loss: 0.2585 - val_acc: 0.3841\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2481 - acc: 0.3853 - val_loss: 0.2587 - val_acc: 0.3743\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2480 - acc: 0.3798 - val_loss: 0.2584 - val_acc: 0.3890\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2478 - acc: 0.3814 - val_loss: 0.2583 - val_acc: 0.3793\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2477 - acc: 0.3826 - val_loss: 0.2583 - val_acc: 0.3776\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2475 - acc: 0.3820 - val_loss: 0.2582 - val_acc: 0.3844\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2474 - acc: 0.3805 - val_loss: 0.2581 - val_acc: 0.3833\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.6943 - acc: 0.3558 - val_loss: 1.5885 - val_acc: 0.3117\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.4598 - acc: 0.3343 - val_loss: 1.2500 - val_acc: 0.3627\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1869 - acc: 0.3470 - val_loss: 1.1124 - val_acc: 0.3351\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9980 - acc: 0.3616 - val_loss: 0.8551 - val_acc: 0.4059\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7439 - acc: 0.4485 - val_loss: 0.6234 - val_acc: 0.4908\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5453 - acc: 0.4985 - val_loss: 0.4596 - val_acc: 0.5039\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4040 - acc: 0.5200 - val_loss: 0.3462 - val_acc: 0.5495\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3168 - acc: 0.5257 - val_loss: 0.2916 - val_acc: 0.4553\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2867 - acc: 0.4108 - val_loss: 0.2852 - val_acc: 0.3637\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2825 - acc: 0.3781 - val_loss: 0.2888 - val_acc: 0.3365\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3007 - acc: 0.3975 - val_loss: 0.2846 - val_acc: 0.4184\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3028 - acc: 0.3222 - val_loss: 0.2809 - val_acc: 0.4151\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2815 - acc: 0.4037 - val_loss: 0.2849 - val_acc: 0.3594\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2810 - acc: 0.4050 - val_loss: 0.2773 - val_acc: 0.4183\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2776 - acc: 0.3892 - val_loss: 0.2757 - val_acc: 0.3951\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2753 - acc: 0.4004 - val_loss: 0.2748 - val_acc: 0.3853\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2764 - acc: 0.3771 - val_loss: 0.2798 - val_acc: 0.3585\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2751 - acc: 0.4056 - val_loss: 0.2721 - val_acc: 0.3957\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2809 - acc: 0.3579 - val_loss: 0.2714 - val_acc: 0.3996\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2718 - acc: 0.4102 - val_loss: 0.2707 - val_acc: 0.3963\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2718 - acc: 0.3831 - val_loss: 0.2692 - val_acc: 0.3888\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2688 - acc: 0.4119 - val_loss: 0.2674 - val_acc: 0.3797\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2674 - acc: 0.3821 - val_loss: 0.2754 - val_acc: 0.3387\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2749 - acc: 0.3735 - val_loss: 0.2697 - val_acc: 0.4380\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2672 - acc: 0.3835 - val_loss: 0.2631 - val_acc: 0.4114\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2634 - acc: 0.4024 - val_loss: 0.2627 - val_acc: 0.3668\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2612 - acc: 0.3910 - val_loss: 0.2599 - val_acc: 0.3782\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2599 - acc: 0.3826 - val_loss: 0.2588 - val_acc: 0.3952\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2586 - acc: 0.3850 - val_loss: 0.2577 - val_acc: 0.3942\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2577 - acc: 0.3895 - val_loss: 0.2567 - val_acc: 0.3854\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2568 - acc: 0.3908 - val_loss: 0.2560 - val_acc: 0.3832\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2561 - acc: 0.3881 - val_loss: 0.2552 - val_acc: 0.3842\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2556 - acc: 0.3867 - val_loss: 0.2546 - val_acc: 0.3867\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2550 - acc: 0.3845 - val_loss: 0.2541 - val_acc: 0.3903\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2546 - acc: 0.3867 - val_loss: 0.2536 - val_acc: 0.3879\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2541 - acc: 0.3877 - val_loss: 0.2532 - val_acc: 0.3867\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2538 - acc: 0.3880 - val_loss: 0.2529 - val_acc: 0.3856\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2536 - acc: 0.3864 - val_loss: 0.2526 - val_acc: 0.3897\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2534 - acc: 0.3870 - val_loss: 0.2523 - val_acc: 0.3852\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2531 - acc: 0.3846 - val_loss: 0.2522 - val_acc: 0.3879\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2531 - acc: 0.3851 - val_loss: 0.2522 - val_acc: 0.3941\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2530 - acc: 0.3852 - val_loss: 0.2519 - val_acc: 0.3902\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2528 - acc: 0.3875 - val_loss: 0.2518 - val_acc: 0.3815\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2528 - acc: 0.3865 - val_loss: 0.2517 - val_acc: 0.3876\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2527 - acc: 0.3837 - val_loss: 0.2516 - val_acc: 0.3863\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2526 - acc: 0.3851 - val_loss: 0.2515 - val_acc: 0.3854\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2526 - acc: 0.3832 - val_loss: 0.2515 - val_acc: 0.3869\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2526 - acc: 0.3851 - val_loss: 0.2514 - val_acc: 0.3807\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2525 - acc: 0.3858 - val_loss: 0.2514 - val_acc: 0.3809\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2525 - acc: 0.3839 - val_loss: 0.2514 - val_acc: 0.3808\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.6214 - acc: 0.1493 - val_loss: 1.5348 - val_acc: 0.0436\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3669 - acc: 0.0423 - val_loss: 1.1897 - val_acc: 0.0503\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1517 - acc: 0.0599 - val_loss: 1.0903 - val_acc: 0.0519\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9857 - acc: 0.0323 - val_loss: 0.8523 - val_acc: 0.0152\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7167 - acc: 0.0070 - val_loss: 0.5814 - val_acc: 0.0031\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4934 - acc: 0.0075 - val_loss: 0.4038 - val_acc: 0.0140\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3541 - acc: 0.0516 - val_loss: 0.3076 - val_acc: 0.0946\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2943 - acc: 0.1018 - val_loss: 0.2894 - val_acc: 0.1411\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2904 - acc: 0.0981 - val_loss: 0.2901 - val_acc: 0.1489\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3037 - acc: 0.1416 - val_loss: 0.3219 - val_acc: 0.0481\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3007 - acc: 0.1085 - val_loss: 0.2790 - val_acc: 0.1030\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2914 - acc: 0.0781 - val_loss: 0.2918 - val_acc: 0.1558\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2872 - acc: 0.1080 - val_loss: 0.2835 - val_acc: 0.0646\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2796 - acc: 0.1051 - val_loss: 0.2737 - val_acc: 0.1002\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2753 - acc: 0.1003 - val_loss: 0.2777 - val_acc: 0.1362\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2897 - acc: 0.1368 - val_loss: 0.2811 - val_acc: 0.0738\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2771 - acc: 0.1084 - val_loss: 0.2721 - val_acc: 0.0962\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2754 - acc: 0.0833 - val_loss: 0.2692 - val_acc: 0.0922\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2996 - acc: 0.1596 - val_loss: 0.2891 - val_acc: 0.1682\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2809 - acc: 0.0929 - val_loss: 0.2701 - val_acc: 0.1238\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2734 - acc: 0.0968 - val_loss: 0.2659 - val_acc: 0.1040\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2707 - acc: 0.1204 - val_loss: 0.2662 - val_acc: 0.0833\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2680 - acc: 0.0943 - val_loss: 0.2635 - val_acc: 0.0974\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2662 - acc: 0.0898 - val_loss: 0.2635 - val_acc: 0.0819\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2647 - acc: 0.0958 - val_loss: 0.2609 - val_acc: 0.1020\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2632 - acc: 0.1022 - val_loss: 0.2596 - val_acc: 0.0977\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2665 - acc: 0.1127 - val_loss: 0.3039 - val_acc: 0.1997\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3017 - acc: 0.1250 - val_loss: 0.2929 - val_acc: 0.0391\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2882 - acc: 0.1490 - val_loss: 0.2637 - val_acc: 0.1336\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2683 - acc: 0.0895 - val_loss: 0.2666 - val_acc: 0.1449\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2639 - acc: 0.1041 - val_loss: 0.2580 - val_acc: 0.0961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2609 - acc: 0.0933 - val_loss: 0.2573 - val_acc: 0.0973\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2601 - acc: 0.0991 - val_loss: 0.2570 - val_acc: 0.0854\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2594 - acc: 0.1001 - val_loss: 0.2562 - val_acc: 0.0879\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2589 - acc: 0.0976 - val_loss: 0.2551 - val_acc: 0.1046\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2580 - acc: 0.0973 - val_loss: 0.2548 - val_acc: 0.1087\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2576 - acc: 0.0973 - val_loss: 0.2542 - val_acc: 0.1036\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2573 - acc: 0.0988 - val_loss: 0.2539 - val_acc: 0.0929\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2569 - acc: 0.0999 - val_loss: 0.2537 - val_acc: 0.0927\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2567 - acc: 0.0965 - val_loss: 0.2534 - val_acc: 0.0948\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2564 - acc: 0.0976 - val_loss: 0.2531 - val_acc: 0.0985\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2563 - acc: 0.0968 - val_loss: 0.2530 - val_acc: 0.0989\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2562 - acc: 0.0957 - val_loss: 0.2529 - val_acc: 0.0978\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2561 - acc: 0.0951 - val_loss: 0.2528 - val_acc: 0.0966\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2560 - acc: 0.0963 - val_loss: 0.2528 - val_acc: 0.0893\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2560 - acc: 0.0962 - val_loss: 0.2528 - val_acc: 0.0870\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2559 - acc: 0.0937 - val_loss: 0.2526 - val_acc: 0.0990\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2559 - acc: 0.0959 - val_loss: 0.2525 - val_acc: 0.1014\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2559 - acc: 0.0947 - val_loss: 0.2525 - val_acc: 0.0957\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2558 - acc: 0.0933 - val_loss: 0.2524 - val_acc: 0.0942\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.6744 - acc: 0.3581 - val_loss: 1.5799 - val_acc: 0.3129\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.4529 - acc: 0.3329 - val_loss: 1.2605 - val_acc: 0.3606\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2146 - acc: 0.3472 - val_loss: 1.1445 - val_acc: 0.3439\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0387 - acc: 0.3708 - val_loss: 0.8755 - val_acc: 0.4122\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7631 - acc: 0.4461 - val_loss: 0.6127 - val_acc: 0.4822\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5157 - acc: 0.5130 - val_loss: 0.4139 - val_acc: 0.5445\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3557 - acc: 0.5463 - val_loss: 0.3098 - val_acc: 0.4997\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2929 - acc: 0.4425 - val_loss: 0.2917 - val_acc: 0.3968\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2869 - acc: 0.3723 - val_loss: 0.2973 - val_acc: 0.3942\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3024 - acc: 0.4063 - val_loss: 0.2965 - val_acc: 0.3469\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2896 - acc: 0.3486 - val_loss: 0.2934 - val_acc: 0.3851\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2954 - acc: 0.3424 - val_loss: 0.3059 - val_acc: 0.3193\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2989 - acc: 0.4332 - val_loss: 0.2897 - val_acc: 0.4390\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2940 - acc: 0.3619 - val_loss: 0.2870 - val_acc: 0.4299\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2901 - acc: 0.4394 - val_loss: 0.3153 - val_acc: 0.3001\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3066 - acc: 0.3398 - val_loss: 0.3126 - val_acc: 0.4889\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2888 - acc: 0.4037 - val_loss: 0.2904 - val_acc: 0.3581\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2789 - acc: 0.4063 - val_loss: 0.2807 - val_acc: 0.4015\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2758 - acc: 0.3921 - val_loss: 0.2794 - val_acc: 0.4031\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2745 - acc: 0.3868 - val_loss: 0.2781 - val_acc: 0.4034\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2998 - acc: 0.4536 - val_loss: 0.2855 - val_acc: 0.4047\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2795 - acc: 0.3557 - val_loss: 0.2846 - val_acc: 0.3481\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2756 - acc: 0.3606 - val_loss: 0.2766 - val_acc: 0.3920\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2756 - acc: 0.4154 - val_loss: 0.2839 - val_acc: 0.3443\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2765 - acc: 0.3710 - val_loss: 0.2748 - val_acc: 0.3967\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2713 - acc: 0.3886 - val_loss: 0.2754 - val_acc: 0.4274\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2690 - acc: 0.4096 - val_loss: 0.2783 - val_acc: 0.3519\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2694 - acc: 0.3805 - val_loss: 0.2717 - val_acc: 0.4142\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2657 - acc: 0.3860 - val_loss: 0.2694 - val_acc: 0.3940\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2636 - acc: 0.3953 - val_loss: 0.2682 - val_acc: 0.3929\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2624 - acc: 0.3897 - val_loss: 0.2671 - val_acc: 0.3980\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2615 - acc: 0.3866 - val_loss: 0.2661 - val_acc: 0.3856\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2603 - acc: 0.3929 - val_loss: 0.2656 - val_acc: 0.3771\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2593 - acc: 0.3912 - val_loss: 0.2643 - val_acc: 0.3953\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2583 - acc: 0.3866 - val_loss: 0.2638 - val_acc: 0.3990\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2577 - acc: 0.3892 - val_loss: 0.2628 - val_acc: 0.3884\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2569 - acc: 0.3906 - val_loss: 0.2623 - val_acc: 0.3861\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2563 - acc: 0.3909 - val_loss: 0.2619 - val_acc: 0.3838\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2560 - acc: 0.3880 - val_loss: 0.2614 - val_acc: 0.3876\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2555 - acc: 0.3884 - val_loss: 0.2612 - val_acc: 0.3919\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2554 - acc: 0.3924 - val_loss: 0.2611 - val_acc: 0.3801\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2553 - acc: 0.3859 - val_loss: 0.2607 - val_acc: 0.3913\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2550 - acc: 0.3868 - val_loss: 0.2607 - val_acc: 0.3991\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2547 - acc: 0.3870 - val_loss: 0.2604 - val_acc: 0.3961\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2545 - acc: 0.3883 - val_loss: 0.2602 - val_acc: 0.3831\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2543 - acc: 0.3901 - val_loss: 0.2601 - val_acc: 0.3812\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2542 - acc: 0.3867 - val_loss: 0.2600 - val_acc: 0.3930\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2541 - acc: 0.3866 - val_loss: 0.2599 - val_acc: 0.3923\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2540 - acc: 0.3874 - val_loss: 0.2598 - val_acc: 0.3905\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2539 - acc: 0.3863 - val_loss: 0.2598 - val_acc: 0.3882\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.5079 - acc: 0.3531 - val_loss: 1.3876 - val_acc: 0.3461\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2037 - acc: 0.3660 - val_loss: 1.0767 - val_acc: 0.3547\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9715 - acc: 0.3795 - val_loss: 0.8146 - val_acc: 0.4274\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6652 - acc: 0.4706 - val_loss: 0.5085 - val_acc: 0.5206\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4172 - acc: 0.5261 - val_loss: 0.3343 - val_acc: 0.5510\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3048 - acc: 0.4968 - val_loss: 0.2886 - val_acc: 0.4094\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2907 - acc: 0.3761 - val_loss: 0.3051 - val_acc: 0.4055\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2959 - acc: 0.3525 - val_loss: 0.2908 - val_acc: 0.3436\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3056 - acc: 0.4123 - val_loss: 0.3065 - val_acc: 0.2985\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3121 - acc: 0.3737 - val_loss: 0.3017 - val_acc: 0.4419\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2962 - acc: 0.3460 - val_loss: 0.2856 - val_acc: 0.4236\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2893 - acc: 0.4219 - val_loss: 0.2861 - val_acc: 0.3518\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2792 - acc: 0.3886 - val_loss: 0.2785 - val_acc: 0.4005\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2764 - acc: 0.3901 - val_loss: 0.2765 - val_acc: 0.3993\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2760 - acc: 0.3982 - val_loss: 0.2782 - val_acc: 0.3662\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2745 - acc: 0.3862 - val_loss: 0.2758 - val_acc: 0.3735\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2718 - acc: 0.3976 - val_loss: 0.2721 - val_acc: 0.4006\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2708 - acc: 0.3982 - val_loss: 0.2718 - val_acc: 0.3731\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2692 - acc: 0.3837 - val_loss: 0.2688 - val_acc: 0.3865\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2668 - acc: 0.4018 - val_loss: 0.2667 - val_acc: 0.3914\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2652 - acc: 0.3915 - val_loss: 0.2736 - val_acc: 0.4336\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2787 - acc: 0.3711 - val_loss: 0.2654 - val_acc: 0.3725\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2639 - acc: 0.3885 - val_loss: 0.2642 - val_acc: 0.4057\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2643 - acc: 0.4112 - val_loss: 0.2654 - val_acc: 0.3623\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2625 - acc: 0.3903 - val_loss: 0.2620 - val_acc: 0.3878\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2611 - acc: 0.3856 - val_loss: 0.2622 - val_acc: 0.4021\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2605 - acc: 0.3888 - val_loss: 0.2611 - val_acc: 0.3926\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2599 - acc: 0.3922 - val_loss: 0.2608 - val_acc: 0.3837\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2596 - acc: 0.3909 - val_loss: 0.2605 - val_acc: 0.3896\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2594 - acc: 0.3903 - val_loss: 0.2603 - val_acc: 0.3909\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2592 - acc: 0.3900 - val_loss: 0.2601 - val_acc: 0.3877\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2590 - acc: 0.3879 - val_loss: 0.2601 - val_acc: 0.3927\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2590 - acc: 0.3899 - val_loss: 0.2599 - val_acc: 0.3821\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2589 - acc: 0.3908 - val_loss: 0.2600 - val_acc: 0.3786\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2589 - acc: 0.3884 - val_loss: 0.2597 - val_acc: 0.3850\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2587 - acc: 0.3885 - val_loss: 0.2598 - val_acc: 0.3910\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2587 - acc: 0.3885 - val_loss: 0.2597 - val_acc: 0.3868\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2587 - acc: 0.3880 - val_loss: 0.2596 - val_acc: 0.3837\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2587 - acc: 0.3908 - val_loss: 0.2596 - val_acc: 0.3886\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2587 - acc: 0.3890 - val_loss: 0.2597 - val_acc: 0.3938\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2586 - acc: 0.3870 - val_loss: 0.2598 - val_acc: 0.3965\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2587 - acc: 0.3872 - val_loss: 0.2600 - val_acc: 0.4002\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2587 - acc: 0.3897 - val_loss: 0.2595 - val_acc: 0.3883\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2586 - acc: 0.3883 - val_loss: 0.2595 - val_acc: 0.3854\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2587 - acc: 0.3882 - val_loss: 0.2595 - val_acc: 0.3892\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2586 - acc: 0.3914 - val_loss: 0.2595 - val_acc: 0.3899\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2585 - acc: 0.3876 - val_loss: 0.2595 - val_acc: 0.3923\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2585 - acc: 0.3894 - val_loss: 0.2594 - val_acc: 0.3879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2585 - acc: 0.3900 - val_loss: 0.2594 - val_acc: 0.3832\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2586 - acc: 0.3876 - val_loss: 0.2594 - val_acc: 0.3844\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.8206 - acc: 0.1791 - val_loss: 1.4742 - val_acc: 0.0420\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.5796 - acc: 0.0382 - val_loss: 1.5767 - val_acc: 0.0348\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.4577 - acc: 0.0345 - val_loss: 1.2998 - val_acc: 0.0350\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2122 - acc: 0.0373 - val_loss: 1.1221 - val_acc: 0.0397\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0612 - acc: 0.0389 - val_loss: 0.9504 - val_acc: 0.0324\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8521 - acc: 0.0212 - val_loss: 0.7359 - val_acc: 0.0080\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6637 - acc: 0.0032 - val_loss: 0.5840 - val_acc: 2.2500e-04\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5323 - acc: 5.5000e-05 - val_loss: 0.4748 - val_acc: 1.9000e-04\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4346 - acc: 0.0049 - val_loss: 0.3919 - val_acc: 0.0183\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3620 - acc: 0.0370 - val_loss: 0.3341 - val_acc: 0.0587\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3146 - acc: 0.0690 - val_loss: 0.3015 - val_acc: 0.0799\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2967 - acc: 0.1100 - val_loss: 0.3279 - val_acc: 0.1832\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3099 - acc: 0.1565 - val_loss: 0.3103 - val_acc: 0.0604\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3044 - acc: 0.0680 - val_loss: 0.2916 - val_acc: 0.1320\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2909 - acc: 0.1403 - val_loss: 0.2876 - val_acc: 0.1038\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2854 - acc: 0.0904 - val_loss: 0.2874 - val_acc: 0.1194\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2905 - acc: 0.1431 - val_loss: 0.2861 - val_acc: 0.1112\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2878 - acc: 0.0803 - val_loss: 0.2912 - val_acc: 0.0769\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2828 - acc: 0.0912 - val_loss: 0.2845 - val_acc: 0.1020\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2806 - acc: 0.1046 - val_loss: 0.2840 - val_acc: 0.1031\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2809 - acc: 0.0896 - val_loss: 0.2834 - val_acc: 0.0979\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2824 - acc: 0.1218 - val_loss: 0.2834 - val_acc: 0.1151\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2812 - acc: 0.0861 - val_loss: 0.2834 - val_acc: 0.0904\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2799 - acc: 0.0952 - val_loss: 0.2880 - val_acc: 0.1377\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2798 - acc: 0.1239 - val_loss: 0.2824 - val_acc: 0.1203\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2777 - acc: 0.1139 - val_loss: 0.2815 - val_acc: 0.1009\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2769 - acc: 0.1045 - val_loss: 0.2806 - val_acc: 0.1111\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2784 - acc: 0.0884 - val_loss: 0.2846 - val_acc: 0.0733\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2769 - acc: 0.0979 - val_loss: 0.2800 - val_acc: 0.1164\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2753 - acc: 0.1101 - val_loss: 0.2785 - val_acc: 0.0935\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2740 - acc: 0.0986 - val_loss: 0.2790 - val_acc: 0.1211\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2743 - acc: 0.1166 - val_loss: 0.2777 - val_acc: 0.0964\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2764 - acc: 0.0804 - val_loss: 0.2789 - val_acc: 0.0806\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2727 - acc: 0.1031 - val_loss: 0.2757 - val_acc: 0.1036\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2716 - acc: 0.0951 - val_loss: 0.2755 - val_acc: 0.0894\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2728 - acc: 0.0787 - val_loss: 0.2745 - val_acc: 0.1052\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2706 - acc: 0.1071 - val_loss: 0.2739 - val_acc: 0.0887\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2694 - acc: 0.0917 - val_loss: 0.2728 - val_acc: 0.1079\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2688 - acc: 0.0957 - val_loss: 0.2735 - val_acc: 0.0830\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2694 - acc: 0.1071 - val_loss: 0.2791 - val_acc: 0.1447\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2718 - acc: 0.0935 - val_loss: 0.2747 - val_acc: 0.0743\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2684 - acc: 0.1084 - val_loss: 0.2731 - val_acc: 0.1271\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2692 - acc: 0.1196 - val_loss: 0.2733 - val_acc: 0.0834\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2689 - acc: 0.1001 - val_loss: 0.2812 - val_acc: 0.1539\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2716 - acc: 0.1165 - val_loss: 0.2775 - val_acc: 0.0665\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2682 - acc: 0.0976 - val_loss: 0.2717 - val_acc: 0.1241\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2661 - acc: 0.0974 - val_loss: 0.2700 - val_acc: 0.0888\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2653 - acc: 0.0958 - val_loss: 0.2691 - val_acc: 0.1039\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2647 - acc: 0.1015 - val_loss: 0.2687 - val_acc: 0.0960\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2644 - acc: 0.0974 - val_loss: 0.2684 - val_acc: 0.1066\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.5129 - acc: 0.1128 - val_loss: 1.3610 - val_acc: 0.0553\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2874 - acc: 0.0782 - val_loss: 1.1844 - val_acc: 0.0721\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0440 - acc: 0.0404 - val_loss: 0.8437 - val_acc: 0.0170\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6741 - acc: 0.0231 - val_loss: 0.4882 - val_acc: 0.0311\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3964 - acc: 0.0657 - val_loss: 0.3365 - val_acc: 0.1472\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3579 - acc: 0.1442 - val_loss: 0.3594 - val_acc: 0.0765\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3313 - acc: 0.1088 - val_loss: 0.3173 - val_acc: 0.1423\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3106 - acc: 0.1200 - val_loss: 0.3198 - val_acc: 0.1593\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3080 - acc: 0.1255 - val_loss: 0.3026 - val_acc: 0.0870\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2977 - acc: 0.0975 - val_loss: 0.2997 - val_acc: 0.0800\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2965 - acc: 0.1106 - val_loss: 0.3002 - val_acc: 0.1387\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3008 - acc: 0.0869 - val_loss: 0.2938 - val_acc: 0.1312\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2950 - acc: 0.0987 - val_loss: 0.2883 - val_acc: 0.0860\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2905 - acc: 0.1242 - val_loss: 0.2866 - val_acc: 0.0867\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2844 - acc: 0.1062 - val_loss: 0.2834 - val_acc: 0.1115\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2959 - acc: 0.0790 - val_loss: 0.3100 - val_acc: 0.1717\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2975 - acc: 0.1170 - val_loss: 0.2832 - val_acc: 0.0785\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2905 - acc: 0.1142 - val_loss: 0.3008 - val_acc: 0.0480\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2855 - acc: 0.1107 - val_loss: 0.2785 - val_acc: 0.0912\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2784 - acc: 0.0987 - val_loss: 0.2812 - val_acc: 0.1306\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2773 - acc: 0.1203 - val_loss: 0.2765 - val_acc: 0.1020\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2779 - acc: 0.0866 - val_loss: 0.2836 - val_acc: 0.0603\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2761 - acc: 0.1041 - val_loss: 0.2762 - val_acc: 0.0771\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2740 - acc: 0.0889 - val_loss: 0.2735 - val_acc: 0.0999\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2712 - acc: 0.0971 - val_loss: 0.2728 - val_acc: 0.1107\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2709 - acc: 0.1039 - val_loss: 0.2858 - val_acc: 0.1568\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2815 - acc: 0.0938 - val_loss: 0.2715 - val_acc: 0.1078\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2764 - acc: 0.0944 - val_loss: 0.2719 - val_acc: 0.0798\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2712 - acc: 0.1045 - val_loss: 0.2728 - val_acc: 0.0700\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2686 - acc: 0.0997 - val_loss: 0.2710 - val_acc: 0.0827\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2679 - acc: 0.1010 - val_loss: 0.2701 - val_acc: 0.0881\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2672 - acc: 0.1002 - val_loss: 0.2695 - val_acc: 0.0905\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2668 - acc: 0.1009 - val_loss: 0.2692 - val_acc: 0.0964\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2666 - acc: 0.1011 - val_loss: 0.2690 - val_acc: 0.0977\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2663 - acc: 0.0983 - val_loss: 0.2691 - val_acc: 0.1045\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2661 - acc: 0.0990 - val_loss: 0.2689 - val_acc: 0.1027\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2660 - acc: 0.0997 - val_loss: 0.2690 - val_acc: 0.1050\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2659 - acc: 0.0979 - val_loss: 0.2688 - val_acc: 0.1002\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2658 - acc: 0.0987 - val_loss: 0.2689 - val_acc: 0.1028\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2658 - acc: 0.0995 - val_loss: 0.2688 - val_acc: 0.0933\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2659 - acc: 0.0978 - val_loss: 0.2688 - val_acc: 0.0967\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2658 - acc: 0.0986 - val_loss: 0.2689 - val_acc: 0.1045\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2658 - acc: 0.0985 - val_loss: 0.2688 - val_acc: 0.1014\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2657 - acc: 0.0994 - val_loss: 0.2688 - val_acc: 0.0977\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2657 - acc: 0.0981 - val_loss: 0.2688 - val_acc: 0.0970\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2657 - acc: 0.0969 - val_loss: 0.2688 - val_acc: 0.0992\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2657 - acc: 0.0983 - val_loss: 0.2691 - val_acc: 0.1063\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2657 - acc: 0.0973 - val_loss: 0.2691 - val_acc: 0.1064\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2657 - acc: 0.0988 - val_loss: 0.2689 - val_acc: 0.1015\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2656 - acc: 0.0986 - val_loss: 0.2688 - val_acc: 0.0966\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 1s 3us/step - loss: 1.7218 - acc: 0.1883 - val_loss: 1.3964 - val_acc: 0.0463\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.4568 - acc: 0.0435 - val_loss: 1.4262 - val_acc: 0.0405\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3044 - acc: 0.0415 - val_loss: 1.1889 - val_acc: 0.0428\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1396 - acc: 0.0472 - val_loss: 1.1006 - val_acc: 0.0506\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0596 - acc: 0.0478 - val_loss: 1.0056 - val_acc: 0.0392\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9421 - acc: 0.0300 - val_loss: 0.8637 - val_acc: 0.0193\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7830 - acc: 0.0124 - val_loss: 0.6791 - val_acc: 0.0053\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6020 - acc: 0.0040 - val_loss: 0.5183 - val_acc: 0.0111\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4628 - acc: 0.0224 - val_loss: 0.4033 - val_acc: 0.0331\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3690 - acc: 0.0457 - val_loss: 0.3344 - val_acc: 0.0693\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3196 - acc: 0.0902 - val_loss: 0.3049 - val_acc: 0.1046\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3063 - acc: 0.0753 - val_loss: 0.2999 - val_acc: 0.0849\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2995 - acc: 0.1158 - val_loss: 0.3015 - val_acc: 0.1341\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2987 - acc: 0.1091 - val_loss: 0.3015 - val_acc: 0.0818\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3085 - acc: 0.1258 - val_loss: 0.3518 - val_acc: 0.1940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3323 - acc: 0.1773 - val_loss: 0.3331 - val_acc: 0.1778\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3185 - acc: 0.1381 - val_loss: 0.3245 - val_acc: 0.0721\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3086 - acc: 0.1020 - val_loss: 0.3028 - val_acc: 0.1428\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3038 - acc: 0.1061 - val_loss: 0.3090 - val_acc: 0.0641\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2989 - acc: 0.1036 - val_loss: 0.3010 - val_acc: 0.1397\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2961 - acc: 0.1152 - val_loss: 0.2962 - val_acc: 0.0796\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2937 - acc: 0.0932 - val_loss: 0.2924 - val_acc: 0.1186\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2922 - acc: 0.1124 - val_loss: 0.2922 - val_acc: 0.0888\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2917 - acc: 0.0978 - val_loss: 0.2929 - val_acc: 0.1279\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2919 - acc: 0.1139 - val_loss: 0.2910 - val_acc: 0.0890\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2901 - acc: 0.1018 - val_loss: 0.2888 - val_acc: 0.1003\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2899 - acc: 0.0906 - val_loss: 0.2894 - val_acc: 0.1223\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2931 - acc: 0.1320 - val_loss: 0.2904 - val_acc: 0.1301\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2895 - acc: 0.1047 - val_loss: 0.2897 - val_acc: 0.0875\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2926 - acc: 0.0771 - val_loss: 0.2860 - val_acc: 0.1091\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2888 - acc: 0.1000 - val_loss: 0.2915 - val_acc: 0.0670\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2883 - acc: 0.0973 - val_loss: 0.2874 - val_acc: 0.1220\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2875 - acc: 0.0855 - val_loss: 0.2846 - val_acc: 0.0870\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2853 - acc: 0.1108 - val_loss: 0.2844 - val_acc: 0.0839\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2860 - acc: 0.0810 - val_loss: 0.2824 - val_acc: 0.1124\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2833 - acc: 0.1158 - val_loss: 0.2818 - val_acc: 0.1147\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2822 - acc: 0.1110 - val_loss: 0.2813 - val_acc: 0.0990\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2827 - acc: 0.0886 - val_loss: 0.2801 - val_acc: 0.1029\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2806 - acc: 0.1004 - val_loss: 0.2805 - val_acc: 0.0852\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2805 - acc: 0.0885 - val_loss: 0.2794 - val_acc: 0.1066\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2798 - acc: 0.1084 - val_loss: 0.2787 - val_acc: 0.0891\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2793 - acc: 0.0901 - val_loss: 0.2779 - val_acc: 0.1108\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2786 - acc: 0.1085 - val_loss: 0.2778 - val_acc: 0.0890\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2778 - acc: 0.0911 - val_loss: 0.2765 - val_acc: 0.0978\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2774 - acc: 0.0976 - val_loss: 0.2847 - val_acc: 0.0534\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2828 - acc: 0.0737 - val_loss: 0.2812 - val_acc: 0.1323\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2803 - acc: 0.1136 - val_loss: 0.2800 - val_acc: 0.0636\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2775 - acc: 0.0946 - val_loss: 0.2750 - val_acc: 0.1136\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2756 - acc: 0.0942 - val_loss: 0.2740 - val_acc: 0.1005\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2749 - acc: 0.1042 - val_loss: 0.2738 - val_acc: 0.0946\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 2.0688 - acc: 0.3760 - val_loss: 1.3339 - val_acc: 0.3549\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3965 - acc: 0.3500 - val_loss: 1.4604 - val_acc: 0.3398\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.4868 - acc: 0.3354 - val_loss: 1.4847 - val_acc: 0.3353\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.4676 - acc: 0.3389 - val_loss: 1.4276 - val_acc: 0.3458\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3995 - acc: 0.3517 - val_loss: 1.3543 - val_acc: 0.3588\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3306 - acc: 0.3620 - val_loss: 1.2964 - val_acc: 0.3661\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2812 - acc: 0.3667 - val_loss: 1.2544 - val_acc: 0.3681\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2434 - acc: 0.3671 - val_loss: 1.2221 - val_acc: 0.3667\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.2110 - acc: 0.3654 - val_loss: 1.1911 - val_acc: 0.3653\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1813 - acc: 0.3649 - val_loss: 1.1597 - val_acc: 0.3663\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.1449 - acc: 0.3669 - val_loss: 1.1161 - val_acc: 0.3689\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0940 - acc: 0.3705 - val_loss: 1.0589 - val_acc: 0.3745\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.0264 - acc: 0.3769 - val_loss: 0.9777 - val_acc: 0.3832\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9342 - acc: 0.3893 - val_loss: 0.8755 - val_acc: 0.4020\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.8301 - acc: 0.4161 - val_loss: 0.7714 - val_acc: 0.4386\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.7260 - acc: 0.4573 - val_loss: 0.6724 - val_acc: 0.4780\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6327 - acc: 0.4885 - val_loss: 0.5861 - val_acc: 0.4967\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.5516 - acc: 0.4989 - val_loss: 0.5118 - val_acc: 0.4998\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4816 - acc: 0.5025 - val_loss: 0.4485 - val_acc: 0.5088\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4231 - acc: 0.5191 - val_loss: 0.3971 - val_acc: 0.5300\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3768 - acc: 0.5404 - val_loss: 0.3580 - val_acc: 0.5501\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3422 - acc: 0.5575 - val_loss: 0.3308 - val_acc: 0.5648\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3193 - acc: 0.5558 - val_loss: 0.3140 - val_acc: 0.5245\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3055 - acc: 0.5006 - val_loss: 0.3046 - val_acc: 0.4782\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2980 - acc: 0.4610 - val_loss: 0.3000 - val_acc: 0.4445\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2941 - acc: 0.4446 - val_loss: 0.2976 - val_acc: 0.4311\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2920 - acc: 0.4270 - val_loss: 0.2970 - val_acc: 0.4104\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2917 - acc: 0.4114 - val_loss: 0.2958 - val_acc: 0.4131\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2903 - acc: 0.4134 - val_loss: 0.2950 - val_acc: 0.4163\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3026 - acc: 0.4490 - val_loss: 0.3415 - val_acc: 0.4883\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3061 - acc: 0.4305 - val_loss: 0.3059 - val_acc: 0.3416\n",
      "Epoch 32/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2963 - acc: 0.3596 - val_loss: 0.2951 - val_acc: 0.4009\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2891 - acc: 0.4074 - val_loss: 0.2944 - val_acc: 0.4074\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2884 - acc: 0.4092 - val_loss: 0.2946 - val_acc: 0.3849\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2968 - acc: 0.3602 - val_loss: 0.2954 - val_acc: 0.3840\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2882 - acc: 0.4195 - val_loss: 0.2921 - val_acc: 0.4211\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2874 - acc: 0.4074 - val_loss: 0.2925 - val_acc: 0.4000\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2865 - acc: 0.4129 - val_loss: 0.2909 - val_acc: 0.4203\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2856 - acc: 0.4215 - val_loss: 0.2903 - val_acc: 0.4164\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2848 - acc: 0.4116 - val_loss: 0.2898 - val_acc: 0.4118\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2850 - acc: 0.3998 - val_loss: 0.2916 - val_acc: 0.3812\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2849 - acc: 0.4066 - val_loss: 0.2914 - val_acc: 0.4314\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2844 - acc: 0.4157 - val_loss: 0.2894 - val_acc: 0.3862\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2832 - acc: 0.3973 - val_loss: 0.2879 - val_acc: 0.4074\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2849 - acc: 0.4247 - val_loss: 0.2907 - val_acc: 0.4263\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2829 - acc: 0.3991 - val_loss: 0.2884 - val_acc: 0.3799\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2819 - acc: 0.3943 - val_loss: 0.2873 - val_acc: 0.4065\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2813 - acc: 0.4073 - val_loss: 0.2865 - val_acc: 0.3988\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2806 - acc: 0.3985 - val_loss: 0.2860 - val_acc: 0.3967\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2802 - acc: 0.4019 - val_loss: 0.2857 - val_acc: 0.4031\n",
      "Train on 200000 samples, validate on 200000 samples\n",
      "Epoch 1/50\n",
      "200000/200000 [==============================] - 0s 2us/step - loss: 1.6637 - acc: 0.1504 - val_loss: 1.5750 - val_acc: 0.0404\n",
      "Epoch 2/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 1.3393 - acc: 0.0378 - val_loss: 1.0564 - val_acc: 0.0403\n",
      "Epoch 3/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.9316 - acc: 0.0459 - val_loss: 0.7876 - val_acc: 0.0164\n",
      "Epoch 4/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.6592 - acc: 0.0037 - val_loss: 0.5381 - val_acc: 5.0000e-05\n",
      "Epoch 5/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.4743 - acc: 6.2500e-04 - val_loss: 0.3967 - val_acc: 0.0134\n",
      "Epoch 6/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3584 - acc: 0.0679 - val_loss: 0.3198 - val_acc: 0.0896\n",
      "Epoch 7/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3046 - acc: 0.0802 - val_loss: 0.2944 - val_acc: 0.0994\n",
      "Epoch 8/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2992 - acc: 0.0883 - val_loss: 0.3064 - val_acc: 0.0638\n",
      "Epoch 9/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3035 - acc: 0.1209 - val_loss: 0.2932 - val_acc: 0.1210\n",
      "Epoch 10/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2965 - acc: 0.0863 - val_loss: 0.2922 - val_acc: 0.1169\n",
      "Epoch 11/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3132 - acc: 0.1592 - val_loss: 0.2932 - val_acc: 0.1229\n",
      "Epoch 12/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2994 - acc: 0.0864 - val_loss: 0.2976 - val_acc: 0.1386\n",
      "Epoch 13/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2964 - acc: 0.1156 - val_loss: 0.2968 - val_acc: 0.0755\n",
      "Epoch 14/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2930 - acc: 0.0976 - val_loss: 0.3010 - val_acc: 0.1468\n",
      "Epoch 15/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2954 - acc: 0.1291 - val_loss: 0.2901 - val_acc: 0.1107\n",
      "Epoch 16/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2921 - acc: 0.1160 - val_loss: 0.2949 - val_acc: 0.0823\n",
      "Epoch 17/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2997 - acc: 0.0783 - val_loss: 0.2975 - val_acc: 0.1429\n",
      "Epoch 18/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2941 - acc: 0.1167 - val_loss: 0.2945 - val_acc: 0.0707\n",
      "Epoch 19/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2916 - acc: 0.1001 - val_loss: 0.3181 - val_acc: 0.1758\n",
      "Epoch 20/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.3022 - acc: 0.1227 - val_loss: 0.3014 - val_acc: 0.0626\n",
      "Epoch 21/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2962 - acc: 0.1182 - val_loss: 0.2889 - val_acc: 0.1190\n",
      "Epoch 22/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2916 - acc: 0.0853 - val_loss: 0.2885 - val_acc: 0.1181\n",
      "Epoch 23/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2891 - acc: 0.1080 - val_loss: 0.2888 - val_acc: 0.0833\n",
      "Epoch 24/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2874 - acc: 0.1036 - val_loss: 0.2867 - val_acc: 0.1009\n",
      "Epoch 25/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2864 - acc: 0.1006 - val_loss: 0.2864 - val_acc: 0.0969\n",
      "Epoch 26/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2859 - acc: 0.0983 - val_loss: 0.2859 - val_acc: 0.1074\n",
      "Epoch 27/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2853 - acc: 0.0997 - val_loss: 0.2854 - val_acc: 0.0985\n",
      "Epoch 28/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2848 - acc: 0.1010 - val_loss: 0.2848 - val_acc: 0.1038\n",
      "Epoch 29/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2870 - acc: 0.1181 - val_loss: 0.2860 - val_acc: 0.0914\n",
      "Epoch 30/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2856 - acc: 0.0978 - val_loss: 0.2858 - val_acc: 0.1192\n",
      "Epoch 31/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2844 - acc: 0.0993 - val_loss: 0.2841 - val_acc: 0.1019\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2839 - acc: 0.1046 - val_loss: 0.2838 - val_acc: 0.1017\n",
      "Epoch 33/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2837 - acc: 0.1050 - val_loss: 0.2836 - val_acc: 0.0978\n",
      "Epoch 34/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2834 - acc: 0.0982 - val_loss: 0.2836 - val_acc: 0.1112\n",
      "Epoch 35/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2830 - acc: 0.1013 - val_loss: 0.2830 - val_acc: 0.1019\n",
      "Epoch 36/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2829 - acc: 0.1025 - val_loss: 0.2830 - val_acc: 0.0942\n",
      "Epoch 37/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2828 - acc: 0.1010 - val_loss: 0.2828 - val_acc: 0.0945\n",
      "Epoch 38/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2825 - acc: 0.1013 - val_loss: 0.2825 - val_acc: 0.1023\n",
      "Epoch 39/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2823 - acc: 0.1008 - val_loss: 0.2824 - val_acc: 0.1068\n",
      "Epoch 40/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2822 - acc: 0.1019 - val_loss: 0.2823 - val_acc: 0.1057\n",
      "Epoch 41/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2821 - acc: 0.0995 - val_loss: 0.2822 - val_acc: 0.1056\n",
      "Epoch 42/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2821 - acc: 0.1000 - val_loss: 0.2823 - val_acc: 0.1089\n",
      "Epoch 43/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2821 - acc: 0.0995 - val_loss: 0.2822 - val_acc: 0.1068\n",
      "Epoch 44/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2819 - acc: 0.1000 - val_loss: 0.2821 - val_acc: 0.0953\n",
      "Epoch 45/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2820 - acc: 0.0938 - val_loss: 0.2822 - val_acc: 0.1081\n",
      "Epoch 46/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2819 - acc: 0.0991 - val_loss: 0.2820 - val_acc: 0.0957\n",
      "Epoch 47/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2817 - acc: 0.1007 - val_loss: 0.2819 - val_acc: 0.0981\n",
      "Epoch 48/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2817 - acc: 0.1003 - val_loss: 0.2819 - val_acc: 0.1003\n",
      "Epoch 49/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2819 - acc: 0.1005 - val_loss: 0.2819 - val_acc: 0.1011\n",
      "Epoch 50/50\n",
      "200000/200000 [==============================] - 0s 1us/step - loss: 0.2819 - acc: 0.0987 - val_loss: 0.2820 - val_acc: 0.1075\n"
     ]
    }
   ],
   "source": [
    "def CustomLoss(y_true, y_pred):\n",
    "    #y_pred[:,0] is the NN output, should approach the LLR.\n",
    "    #y_pred[:,1] is the mean of the prior p(\\theta)\n",
    "    #y_pred[:,2] is the sigma of the prior p(\\theta)\n",
    "\n",
    "    #y_true[:,0] is 0 or 1\n",
    "    #y_true[:,1] is theta\n",
    "    #myweight = (sigma0/y_pred[:,2])*K.exp(-(y_true[:,1]-y_pred[:,1])**2/(2.*y_pred[:,2]**2)+(y_true[:,1]-theta0)**2/(2*sigma0**2))\n",
    "    return (-y_true[:,0]*K.log(y_pred[:,0]**2+0.00000001) + (1.-y_true[:,0])*y_pred[:,0]**2) #*myweight\n",
    "    #return -y_true*K.log(K.exp(y_pred)) + (1.-y_true)*K.exp(y_pred)\n",
    "        \n",
    "N = 200000\n",
    "\n",
    "theta0 = 0.4\n",
    "sigma0 = 0.2\n",
    "\n",
    "X_data = np.random.normal(0.5,0.5,N)\n",
    "\n",
    "sigmaval = []\n",
    "meanval = []\n",
    "lossval1 = []\n",
    "lossval2 = []\n",
    "\n",
    "for theta0 in np.linspace(0.2,1.,10):\n",
    "    holdsig1 = []\n",
    "    holdsig2 = []\n",
    "    for sigma0 in np.linspace(0.01,0.2,10):\n",
    "\n",
    "        thetas = np.random.normal(theta0,sigma0,N)\n",
    "\n",
    "        X_MC = np.random.normal(thetas,0.5,N)\n",
    "\n",
    "        Y_MC = np.zeros(len(X_MC)) #np.c_[np.zeros(len(X_MC)),thetas]\n",
    "        Y_data = np.ones(len(X_data)) #np.c_[np.ones(len(X_data)),thetas]\n",
    "\n",
    "        X_MLE_train, X_MLE_val, Y_MLE_train, Y_MLE_val = train_test_split(np.concatenate([X_data,X_MC]), np.concatenate([Y_data,Y_MC]), test_size=0.5)\n",
    "\n",
    "        K.clear_session()\n",
    "\n",
    "        model_MLE = Sequential()\n",
    "        model_MLE.add(Dense(64, activation='elu',input_shape =(1,))) \n",
    "        model_MLE.add(Dense(128, activation='elu'))\n",
    "        model_MLE.add(Dense(64, activation='elu'))\n",
    "        model_MLE.add(Dense(1, activation='linear')) #was sigmoid\n",
    "        model_MLE.compile(loss=lambda y_true, y_pred: CustomLoss(y_true, y_pred), optimizer='adam', metrics=['accuracy'])\n",
    "        hist_MLE = model_MLE.fit(X_MLE_train, Y_MLE_train, epochs=50, batch_size=int(0.1*len(X_MLE_train)),validation_data=(X_MLE_val, Y_MLE_val))\n",
    "\n",
    "        preds = model_MLE.predict(X_MLE_val)**2\n",
    "        preds = -Y_MLE_val*np.log(preds[:,0]+0.00000001) + (1.-Y_MLE_val)*preds[:,0]\n",
    "\n",
    "        holdsig1+=[np.mean(preds[Y_MLE_val==1])]\n",
    "        holdsig2+=[np.mean(preds[Y_MLE_val==0])]\n",
    "    lossval1+=[holdsig1]\n",
    "    lossval2+=[holdsig2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x7fe6fbdd9710>,\n",
       "  <matplotlib.axis.XTick at 0x7fe6fbde92b0>,\n",
       "  <matplotlib.axis.XTick at 0x7fe6fbec3a90>,\n",
       "  <matplotlib.axis.XTick at 0x7fe88ebf9630>],\n",
       " <a list of 4 Text xticklabel objects>)"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "gs = gridspec.GridSpec(1, 1) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ax0.minorticks_on()\n",
    "\n",
    "im = plt.imshow(lossval1,origin='lower',extent=[0.01,0.2,0.2,1],aspect='auto',vmin=-0.5,vmax=0.1)\n",
    "cbar = fig.colorbar(im, extend='both', spacing='proportional', shrink=0.9)\n",
    "cbar.set_label('$E[-log(f)]$ (data)',fontsize=20)\n",
    "cbar.ax.tick_params(labelsize=20) \n",
    "plt.xlabel(r\"$\\sigma$\",fontsize=20)\n",
    "plt.ylabel(r\"$\\mu$\",fontsize=20)\n",
    "plt.xticks(np.linspace(0.02,0.2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x7fe88564c518>,\n",
       "  <matplotlib.axis.XTick at 0x7fe88fb24048>,\n",
       "  <matplotlib.axis.XTick at 0x7fe885645e48>,\n",
       "  <matplotlib.axis.XTick at 0x7fe8c11389e8>],\n",
       " <a list of 4 Text xticklabel objects>)"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "gs = gridspec.GridSpec(1, 1) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ax0.minorticks_on()\n",
    "\n",
    "im = plt.imshow(lossval2,origin='lower',extent=[0.01,0.2,0.2,1],aspect='auto')\n",
    "cbar = fig.colorbar(im, extend='both', spacing='proportional', shrink=0.9)\n",
    "cbar.set_label('$E[f]$ (MC)',fontsize=20)\n",
    "cbar.ax.tick_params(labelsize=20) \n",
    "plt.xlabel(r\"$\\sigma$\",fontsize=20)\n",
    "plt.ylabel(r\"$\\mu$\",fontsize=20)\n",
    "plt.xticks(np.linspace(0.02,0.2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/850493afcd981cf6b71a6cad2e91534a"
  },
  "gist": {
   "data": {
    "description": "EnsembleLearning.ipynb",
    "public": false
   },
   "id": "850493afcd981cf6b71a6cad2e91534a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
